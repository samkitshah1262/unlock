[
  {
    "id": "prob_thm_correlation_007",
    "subject": "probability",
    "type": "theorem",
    "chapter": "joint_distributions",
    "topic": "correlation",
    "title": "Correlation: Independence vs Uncorrelated",
    "contentHtml": "<p>The Pearson correlation coefficient measures the linear relationship between two random variables. In this theorem, we explore the connection between independence and uncorrelatedness.</p>",
    "formula": "{",
    "latex": "\\(r_{X,Y} = \\frac{\\mathbb{E}[(X-\\mu_X)(Y-\\mu_Y)]}{\\sigma_X \\sigma_Y}\\)",
    "name": "Pearson Correlation\" },",
    "theorem": "{",
    "statement": "\\\\[ X and Y are independent if and only if their Pearson correlation coefficient, r_{X,Y}, is equal to 0. \\\\\\\\ If the variables are uncorrelated, then |r_{X,Y}| \\\\leq 1. \\]\",",
    "proofSketch": "The proof involves showing that independence implies zero correlation, and vice versa. The bound on the absolute value of the correlation coefficient follows from the Cauchy-Schwarz inequality.\" },",
    "intuition": "Intuitively, uncorrelatedness means that knowing one variable doesn't give you any information about the other. Independence takes this a step further by implying that the variables are also statistically independent.",
    "realWorldApplications": [
      "In machine learning, understanding correlation and independence is crucial for feature selection and dimensionality reduction."
    ],
    "tags": [
      "correlation",
      "independence",
      "uncorrelated"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T01:11:36.755Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_thm_correlation_008",
    "subject": "probability",
    "type": "theorem",
    "chapter": "joint_distributions",
    "topic": "correlation",
    "title": "Correlation Theorem",
    "contentHtml": "<p>The Pearson correlation coefficient measures the linear relationship between two random variables X and Y.</p>",
    "formula": "{",
    "latex": "\\\\(r_{XY} = \\\\frac{\\\\sum{(x_i - \\\\bar{x})(y_i - \\\\bar{y})}{\\\\sqrt{\\\\sum{(x_i - \\\\bar{x})^2}\\\\sum{(y_i - \\\\bar{y})^2}}}\\)\",",
    "name": "Pearson Correlation\" },",
    "theorem": "{",
    "statement": "\\[|r_{XY}| \\leq 1,\\] with equality if and only if X and Y are linearly related.",
    "proofSketch": "The proof involves showing that the correlation coefficient is a Cauchy-Schwarz inequality.\" },",
    "intuition": "This theorem provides a fundamental bound on the strength of the relationship between two variables. It shows that the absolute value of the correlation coefficient is always less than or equal to 1, with equality only when there is a linear relationship.",
    "realWorldApplications": [
      "In machine learning, understanding the correlation between features is crucial for feature selection and engineering."
    ],
    "tags": [
      "probability",
      "correlation"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T01:11:55.342Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]