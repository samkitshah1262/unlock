[
  {
    "id": "prob_con_bayes_theorem_001",
    "subject": "probability",
    "type": "concept",
    "chapter": "conditional_probability",
    "topic": "bayes_theorem",
    "title": "Bayes' Theorem",
    "contentHtml": "<p>Bayes' theorem is a cornerstone of probability theory that allows us to update our beliefs about an event based on new information. It's a powerful tool for making predictions and decisions under uncertainty.</p>",
    "formula": {
      "latex": "\\[ P(A|B) = \\frac{P(B|A) P(A)}{P(B)} \\]",
      "name": "Bayes' Theorem"
    },
    "intuition": "Think of Bayes' theorem as a recipe for updating your beliefs. You start with some prior knowledge or probability, then you get new information (the 'conditioning event'), and the theorem tells you how to adjust your beliefs accordingly.",
    "realWorldApplications": [
      "Bayesian inference is used in natural language processing to improve text classification models"
    ],
    "commonMistakes": [
      "Not accounting for the denominator in Bayes' theorem",
      "Confusing posterior with likelihood"
    ],
    "estimatedMinutes": 2,
    "difficulty": 2,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T22:09:44.374Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_con_bayes_theorem_002",
    "subject": "probability",
    "type": "concept",
    "chapter": "conditional_probability",
    "topic": "bayes_theorem",
    "title": "Bayes' Theorem: Conditional Probability and Independence",
    "contentHtml": "<p>Bayes' theorem is a fundamental concept in probability theory that allows us to update our understanding of a conditional probability based on new information.</p><p>Given two events A and B, Bayes' theorem states:</p>",
    "formula": {
      "latex": "\\[ P(A|B) = \\frac{P(B|A) P(A)}{P(B)} \\]",
      "name": "Bayes' Theorem"
    },
    "intuition": "Think of it like updating your understanding of the probability of a coin being heads-up (A) given that you just saw it land on its edge (B).",
    "realWorldApplications": [
      "In machine learning, Bayes' theorem is used in Bayesian inference to update parameters based on new data."
    ],
    "commonMistakes": [
      "Don't confuse Bayes' theorem with the chain rule of probability; they're related but distinct concepts."
    ],
    "estimatedMinutes": 2,
    "difficulty": 2,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T22:10:00.400Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_con_bayes_theorem_003",
    "subject": "probability",
    "type": "concept",
    "chapter": "conditional_probability",
    "topic": "bayes_theorem",
    "title": "Bayes' Theorem",
    "contentHtml": "<p>Bayes' theorem is a fundamental concept in probability theory that allows us to update our beliefs about a random event based on new information.</p><p>Given two events A and B, Bayes' theorem states that the conditional probability of A given B is proportional to the product of the likelihood of B given A and the prior probability of A.</p>",
    "formula": "{",
    "latex": "\\\\[ P(A|B) = \\\\frac{P(B|A) \\* P(A)}{P(B)} \\\\]\",",
    "name": "Bayes' Theorem\" },",
    "intuition": "Think of Bayes' theorem as a recipe for updating your beliefs about the world. You start with some prior knowledge or 'prior probability', and then you get new information that gives you a likelihood ratio. This allows you to adjust your beliefs accordingly.",
    "commonMistakes": [
      "Forgetting to normalize the posterior probability"
    ],
    "difficulty": 2,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T22:10:17.432Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]