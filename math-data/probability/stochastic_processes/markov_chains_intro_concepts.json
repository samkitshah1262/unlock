[
  {
    "id": "prob_con_markov_chains_intro_001",
    "subject": "probability",
    "type": "concept",
    "chapter": "stochastic_processes",
    "topic": "markov_chains_intro",
    "title": "Discrete-Time Markov Chains",
    "contentHtml": "<p>A discrete-time Markov chain (DTMC) is a mathematical system that undergoes transitions from one state to another according to certain probabilistic rules.</p><p>The transition between states is governed by a probability distribution, which is encapsulated in the transition matrix P. This matrix specifies the probability of transitioning from any given state to any other state at each time step.</p>",
    "formula": "{",
    "latex": "\\(P_{ij}\\) represents the probability of transitioning from state \\(i\\) to state \\(j\\)\",",
    "name": "\" },",
    "intuition": "The key insight is that DTMCs are memoryless, meaning that the future state only depends on the current state and not on any past states.",
    "visualDescription": "A diagram showing a sequence of states with arrows representing transitions would help illustrate this concept",
    "commonMistakes": [
      "Confusing DTMCs with continuous-time Markov chains"
    ],
    "realWorldApplications": [
      "Markov chain Monte Carlo (MCMC) algorithms are used in machine learning for tasks like Bayesian inference and sampling from complex distributions"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T02:09:41.602Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_con_markov_chains_intro_002",
    "subject": "probability",
    "type": "concept",
    "chapter": "stochastic_processes",
    "topic": "markov_chains_intro",
    "title": "Discrete-Time Markov Chains",
    "contentHtml": "<p>A Discrete-Time Markov Chain (DTMC) is a mathematical system that undergoes transitions from one state to another according to certain probabilistic rules.</p><p>The transition between states is governed by a probability distribution, which is encapsulated in the <i>transition matrix</i>.</p>",
    "formula": "{",
    "latex": "\\\\[ P = \\\\begin{bmatrix} p_{11} & p_{12} \\\\\\\\ p_{21} & p_{22} \\\\end{bmatrix}\\]\",",
    "name": "Transition Matrix\" },",
    "intuition": "Think of a DTMC as a random walk, where the current state determines the next possible states. The transition matrix captures this probabilistic relationship.",
    "realWorldApplications": [
      "Modeling communication networks",
      "Analyzing social network dynamics"
    ],
    "commonMistakes": [
      "Confusing DTMCs with Continuous-Time Markov Chains",
      "Ignoring the Markov property"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T02:09:57.609Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_con_markov_chains_intro_003",
    "subject": "probability",
    "type": "concept",
    "chapter": "stochastic_processes",
    "topic": "markov_chains_intro",
    "title": "Discrete-Time Markov Chains",
    "contentHtml": "<p>A discrete-time Markov chain (DTMC) is a mathematical system that undergoes transitions from one state to another according to certain rules.</p><p>The key idea is that the future state of the system depends only on its current state, not on any of the past states. This property is known as the Markov property.</p>",
    "formula": {
      "latex": "\\[P(X_{n+1} = j | X_n = i) = p_{ij}\\]",
      "name": "Transition Probability"
    },
    "intuition": "Think of a DTMC like a random walk on a graph. The current state determines the next possible states, and the probability of transitioning to each state is given by the transition matrix.",
    "realWorldApplications": [
      "In reinforcement learning, DTMCs are used to model decision-making processes"
    ],
    "commonMistakes": [
      "Don't confuse DTMCs with continuous-time Markov chains or other types of stochastic processes"
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T02:10:14.241Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]