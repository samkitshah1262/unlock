[
  {
    "id": "prob_con_sampling_methods_001",
    "subject": "probability",
    "type": "concept",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Sampling Methods in Machine Learning",
    "contentHtml": "<p>In machine learning, sampling methods are crucial for efficient and effective training of models. We'll explore three fundamental techniques: Monte Carlo, importance sampling, and rejection sampling.</p><p>These methods allow us to draw representative samples from complex distributions, reducing computational costs and improving model performance.</p>",
    "formula": {
      "latex": "\\[\\mathbf{X} = \\left\\{ x_1, x_2, \\ldots, x_n \\right\\}\\]",
      "name": "Random Variable"
    },
    "intuition": "Sampling methods help us navigate complex probability spaces by providing a manageable subset of representative data points.",
    "realWorldApplications": [
      "Efficiently training neural networks",
      "Approximating complex distributions"
    ],
    "commonMistakes": [
      "Failing to account for bias in sampling",
      "Assuming uniform distribution without justification"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:13:41.032Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_con_sampling_methods_002",
    "subject": "probability",
    "type": "concept",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Sampling Methods in Machine Learning",
    "contentHtml": "<p>In machine learning, sampling methods are crucial for efficient computation and effective data exploration. This concept introduces three fundamental techniques: Monte Carlo, importance sampling, and rejection sampling.</p><p>These methods allow us to approximate complex distributions or integrals by generating random samples from simpler ones. The choice of sampling method depends on the problem's characteristics and desired accuracy.</p>",
    "formula": "{",
    "latex": "\\\\[P(X \\leq x) = \\\\int_{-\\\\infty}^x f(x) dx\\\\]\",",
    "name": "Cumulative Distribution Function\" },",
    "whyMatters": "<p>Sampling methods are essential in machine learning as they enable us to work with large datasets, estimate complex distributions, and optimize model performance.</p>",
    "intuition": "Sampling methods provide a way to approximate complex distributions by generating random samples from simpler ones.",
    "realWorldApplications": [
      "Estimating rare events in insurance claims",
      "Approximating complex integrals in physics simulations"
    ],
    "commonMistakes": [
      "Assuming uniform sampling is always sufficient",
      "Ignoring the importance of sampling method selection"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:13:58.959Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_con_sampling_methods_003",
    "subject": "probability",
    "type": "concept",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Sampling Methods in Machine Learning",
    "contentHtml": "<p>In machine learning, sampling methods are crucial for efficient computation and effective data exploration. This concept card delves into three fundamental techniques: Monte Carlo, importance sampling, and rejection sampling.</p><p>These methods allow us to approximate complex distributions or integrate functions over high-dimensional spaces, making them essential in areas like Bayesian inference, Markov chain Monte Carlo (MCMC), and generative models.</p>",
    "formula": {
      "latex": "\\[P(X) = \\frac{1}{N} \\sum_{i=1}^N f(x_i)\\]"
    },
    "intuition": "Sampling methods provide a way to estimate complex distributions by generating random samples from simpler ones. This allows us to focus on the most informative regions of the data and reduce computational costs.",
    "realWorldApplications": [
      "Bayesian inference for neural networks",
      "MCMC-based generative models"
    ],
    "commonMistakes": [
      "Confusing Monte Carlo with importance sampling",
      "Overlooking rejection sampling's limitations"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:14:15.778Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_for_sampling_methods_004",
    "subject": "probability",
    "type": "formula",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Monte Carlo and Importance Sampling",
    "contentHtml": "<p>Monte Carlo methods are a class of algorithms that rely on repeated random sampling to obtain numerical solutions to mathematical problems. Importance sampling is a specific technique within Monte Carlo methods that involves weighting the samples based on their relative importance.</p>",
    "formula": "{",
    "latex": "\\[ P(x) = \\frac{1}{N} \\sum_{i=1}^N f(x_i) \\]\",",
    "name": "Importance Sampling Formula",
    "variants": "[] },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we want to estimate the area under a curve using Monte Carlo integration.</p>",
    "steps": [
      {
        "stepNumber": 1,
        "description": "Generate random points within the region of interest",
        "mathHtml": "",
        "explanation": "This is the foundation of Monte Carlo methods."
      }
    ],
    "finalAnswer": "\" },",
    "intuition": "Monte Carlo and importance sampling are powerful tools for approximating complex integrals and expectations in machine learning. By carefully designing the sampling process, we can significantly reduce the variance of our estimates.",
    "tags": [
      "montecarlo",
      "importancesampling"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:14:36.384Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_for_sampling_methods_005",
    "subject": "probability",
    "type": "formula",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Monte Carlo and Importance Sampling",
    "contentHtml": "<p>Monte Carlo methods are a class of algorithms that rely on repeated random sampling to obtain numerical solutions to mathematical problems.</p><p>Importance sampling is a technique used in Monte Carlo methods to reduce the variance of the estimates by choosing samples that are more likely to be relevant for the problem at hand.</p>",
    "formula": "{",
    "latex": "\\[P(x) = \\frac{1}{N} \\sum_{i=1}^N f(x_i)\\]\",",
    "name": "Monte Carlo Estimator",
    "variants": "[ {\"latex\": \"\\[P(x) = \\int f(x) dx\\]\", \"description\": \"The true probability distribution\"} ] },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we want to estimate the area under a curve using Monte Carlo integration.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Generate random points within the region of interest\", \"mathHtml\": \"\\(\\mathbf{x} \\sim \\mathcal{U}(0, 1)\\)\", \"explanation\": \"We sample uniformly from the unit square.\"} ],",
    "finalAnswer": "The estimated area\" },",
    "intuition": "Monte Carlo methods provide a way to approximate complex problems by breaking them down into smaller, more manageable pieces.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:14:57.261Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_for_sampling_methods_006",
    "subject": "probability",
    "type": "formula",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Monte Carlo and Importance Sampling",
    "contentHtml": "<p>Monte Carlo methods are a class of algorithms that rely on repeated random sampling to solve complex problems. Importance sampling is a specific technique within Monte Carlo methods that helps reduce computational costs by focusing on the most relevant regions of the input space.</p>",
    "formula": "{",
    "latex": "\\[P(x) = \\frac{1}{N} \\sum_{i=1}^N f(x_i)\\]\",",
    "name": "Monte Carlo Estimator",
    "variants": "[ {\"latex\": \"\\[P(x) = \\int f(x) dx\\]\", \"description\": \"Theoretical probability distribution\"} ] },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we want to estimate the area under a complex curve using Monte Carlo integration.</p>",
    "steps": [
      {
        "stepNumber": 1,
        "description": "Generate random points within the bounding box",
        "mathHtml": "",
        "explanation": "This helps us approximate the integral."
      }
    ],
    "finalAnswer": "\" },",
    "intuition": "Monte Carlo methods are useful when we need to estimate complex quantities or solve problems that involve high-dimensional spaces.",
    "realWorldApplications": [
      "Estimating expectations in Bayesian networks"
    ],
    "tags": [
      "Machine Learning",
      "Probability Theory"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:15:17.881Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_for_sampling_methods_007",
    "subject": "probability",
    "type": "formula",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Monte Carlo and Importance Sampling",
    "contentHtml": "<p>In probability theory, Monte Carlo methods are a class of algorithms that use random sampling to estimate quantities. Importance sampling is a specific technique used in Monte Carlo methods.</p>",
    "formula": "{",
    "latex": "\\[P(x) = \\frac{1}{N} \\sum_{i=1}^N f(x_i)\\]\",",
    "name": "Importance Sampling Formula",
    "variants": "[ {\"latex\": \"\\[f(x) = \\frac{\\pi(x)}{p(x)}\\]\", \"description\": \"Weight function\"} ] },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we want to estimate the area under a curve using Monte Carlo integration.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Generate random points within the bounding box\", \"mathHtml\": \"\\[x_i \\sim U(a, b)\\]\", \"explanation\": \"We generate random x values uniformly distributed between a and b.\"}, {\"stepNumber\": 2, \"description\": \"Evaluate the function at each point\", \"mathHtml\": \"\\[f(x_i) = \\pi(x_i)\\]\", \"explanation\": \"We evaluate the function π(x) at each generated point.\"} ],",
    "finalAnswer": "The estimated area is the average of the function values multiplied by the area of the bounding box.\" },",
    "intuition": "Monte Carlo methods are useful when we need to estimate a quantity that is difficult or impossible to compute directly. Importance sampling helps us focus on regions where the function is high, making the estimation more efficient.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:15:41.942Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_prb_sampling_methods_008",
    "subject": "probability",
    "type": "problem",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "problem": {
      "statementHtml": "Suppose we want to estimate the area under a curve using Monte Carlo integration. We have a function <i>f(x)</i> and a bounding box <i>[a, b]</i>. How can we use rejection sampling to improve our estimation?",
      "hints": [
        "Think about how you would sample points uniformly within the bounding box.",
        "Consider what happens when your function values are very small or large compared to the average value.",
        "Don't forget to account for the area of the bounding box in your final estimate."
      ],
      "solutionHtml": "<p>To apply rejection sampling, we first generate a random point <i>x</i> within the bounding box. Then, we check if <i>f(x) &gt;= 0</i>. If it is, we accept the sample and move on to the next iteration. Otherwise, we reject the sample and try again.</p><p>This process continues until we have a sufficient number of accepted samples. Finally, we estimate the area under the curve by averaging the function values at these accepted points and multiplying by the area of the bounding box.</p>",
      "answerShort": "The estimated area is <i>\\frac{1}{N} \\sum_{i=1}^N f(x_i) (b-a)</i>, where <i>N</i> is the number of accepted samples."
    },
    "commonMistakes": [
      "Forgetting to account for the bounding box area",
      "Not understanding why rejection sampling improves estimation"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:16:03.796Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_prb_sampling_methods_009",
    "subject": "probability",
    "type": "problem",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "problem": {
      "statementHtml": "Suppose we want to estimate the area under a complex curve using Monte Carlo integration. We are given a probability distribution <i>P(x)</i> and a target function <i>f(x)</i>. Describe how you would use rejection sampling to obtain an unbiased estimate of the integral.",
      "hints": [
        "Start by generating random samples from the distribution <i>P(x)</i>",
        "Use these samples to compute the ratio <i>f(x) / P(x)</i> for each point",
        "Reject points where this ratio is below a certain threshold"
      ],
      "solutionHtml": "To use rejection sampling, we first generate <i>n</i> random samples from the distribution <i>P(x)</i>. Then, compute the ratio <i>f(x) / P(x)</i> for each point. If the ratio is above a predetermined value <i>c</i>, accept the sample and store it in our dataset. The accepted points will be distributed according to the target function <i>f(x)</i>. Finally, estimate the integral by averaging the values of the target function at these accepted points.",
      "answerShort": "The estimated integral is given by the average value of <i>f(x)</i> at the accepted points."
    },
    "commonMistakes": [
      "Forgetting to normalize the weights of the accepted samples",
      "Using a threshold that is too low, leading to biased estimates"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:16:25.388Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_prb_sampling_methods_010",
    "subject": "probability",
    "type": "problem",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "problem": "{",
    "statementHtml": "Suppose we want to estimate the probability of a rare event in a dataset. We can use Monte Carlo methods to generate samples from the underlying distribution and then calculate the proportion of samples that satisfy the condition.",
    "hints": [
      "Think about how you would simulate drawing random samples from a distribution.",
      "Recall that importance sampling helps us focus on regions where we're most interested in estimating the probability.",
      "Rejection sampling can be useful when we have a complex proposal distribution."
    ],
    "solutionHtml": "To solve this problem, we can use Monte Carlo integration. Let's say we want to estimate the probability of a rare event $P(A)$. We generate $N$ random samples from the underlying distribution and calculate the proportion of samples that satisfy the condition $A$. The estimated probability is then $\\hat{P}(A) = \\frac{\\text{number of samples satisfying } A}{N}.$\",",
    "answerShort": "The answer is...\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:16:42.565Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_prb_sampling_methods_011",
    "subject": "probability",
    "type": "problem",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "problem": "{",
    "statementHtml": "<p>Given a target distribution <i>P(y)</i>, design a sampling method to approximate the expectation of some function <i>f(y)</i>.</p>",
    "hints": [
      "Start by considering the definition of expectation.",
      "Think about how you can use Monte Carlo methods to estimate the integral.",
      "Don't forget to account for the importance of each sample."
    ],
    "solutionHtml": "<p>One common approach is to use importance sampling. Let <i>q(y)</i> be a proposal distribution that's easy to sample from. We can rewrite the expectation as:</p>\\n\\[ \\int f(y) P(y) dy = \\int f(y) q(y) / Q dy, where Q = \\\\int q(y) dy.\\]\\n<p>We then use Monte Carlo methods to estimate this integral:</p>\\n\\[ \\frac{1}{N} \\sum_{i=1}^N f(y_i) q(y_i) / Q \\approx \\int f(y) P(y) dy,\\]\\n<p>where <i>y_1, ..., y_N</i> are i.i.d. samples from <i>q(y)</i>.</p>\",",
    "answerShort": "Importance sampling with Monte Carlo methods\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:17:02.987Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_prb_sampling_methods_012",
    "subject": "probability",
    "type": "problem",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "problem": "{",
    "statementHtml": "<p>Use Monte Carlo or importance sampling to estimate the area under a curve.</p>",
    "hints": [
      "Start by generating random points in the region of interest.",
      "Consider using stratified sampling for increased efficiency.",
      "Don't forget to account for any boundaries or constraints."
    ],
    "solutionHtml": "<p>To solve this problem, we can use Monte Carlo integration.</p>\\n<p>First, generate <i>N</i> random points in the region of interest:</p>\\n\\[x_1, y_1\\], \\[x_2, y_2\\], ..., \\[x_N, y_N\\]\\n<p>Then, calculate the area under the curve by averaging the function values at these points:</p>\\n\\\\[A] = \\\\frac{1}{N} \\sum_{i=1}^N f(x_i, y_i)\\n<p>The final answer is:</p>\\n\\[A\\]\",",
    "answerShort": "\\\\[A]\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:17:21.156Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_wex_sampling_methods_013",
    "subject": "probability",
    "type": "worked_example",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Monte Carlo and Importance Sampling",
    "contentHtml": "<p>In this worked example, we'll explore how to use Monte Carlo and importance sampling methods in machine learning.</p>",
    "workedExample": "{",
    "problemHtml": "Suppose we want to estimate the value of π using Monte Carlo integration. We have a function <i>f(x)</i> that represents the area under the curve, but it's difficult to integrate exactly.",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Generate random points\", \"mathHtml\": \"\\(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\)\", \"explanation\": \"We generate a set of random points within the area we're interested in.\"}, {\"stepNumber\": 2, \"description\": \"Count points inside the curve\", \"mathHtml\": \"\\(N = \\sum_{i=1}^n I(y_i > f(x_i))\\)\", \"explanation\": \"We count the number of points that fall within the area under the curve.\"}, {\"stepNumber\": 3, \"description\": \"Estimate π using Monte Carlo\", \"mathHtml\": \"\\(\\hat{π} = \\frac{4N}{n}\\)\", \"explanation\": \"We use the ratio of points inside the curve to the total number of points as an estimate for π.\"}, {\"stepNumber\": 4, \"description\": \"Use importance sampling for efficiency\", \"mathHtml\": \"\\(x_i, y_i) \\sim g(x, y)\\)\", \"explanation\": \"To improve efficiency, we use importance sampling by generating points from a distribution <i>g</i> that is proportional to the function <i>f</i>. This helps us focus on the areas of high importance.\"}, {\"stepNumber\": 5, \"description\": \"Combine Monte Carlo and importance sampling\", \"mathHtml\": \"\\(\\hat{π} = \\frac{\\sum_{i=1}^n I(y_i > f(x_i)) g(x_i, y_i)}{\\sum_{i=1}^n g(x_i, y_i)}\\)\", \"explanation\": \"We combine the Monte Carlo estimate with importance sampling to get a more accurate and efficient estimate for π.\"}, ],",
    "finalAnswer": "The estimated value of π\" },",
    "intuition": "Monte Carlo integration is a powerful tool for approximating complex integrals, and importance sampling helps us focus on the areas that matter most.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:17:54.963Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_wex_sampling_methods_014",
    "subject": "probability",
    "type": "worked_example",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Sampling Methods in Machine Learning",
    "contentHtml": "<p>In machine learning, sampling methods are crucial for efficient computation and data exploration.</p>",
    "formula": {
      "latex": "\\[\\frac{1}{N} \\sum_{i=1}^N f(x_i) = E[f(X)]\\]",
      "name": "Monte Carlo Estimator"
    },
    "problem": {
      "statementHtml": "<p>Suppose we want to estimate the expected value of a function <i>f</i>(<i>x</i>) over a continuous distribution <i>X</i>. We have access to a random sample <i>X_1, X_2, ..., X_N</i> from this distribution. How can we use these samples to approximate the true expected value?</p>",
      "hints": [
        "Hint: Think about the law of large numbers."
      ],
      "solutionHtml": "<p>We can use Monte Carlo integration to estimate the expected value.</p><ul><li>Draw <i>N</i> independent and identically distributed (i.i.d.) samples from the distribution <i>X</i>.</li><li>Compute the average of the function values at these sample points: \\(\\frac{1}{N} \\sum_{i=1}^N f(x_i)\\).</li><li>The estimated expected value is the average function value.</li></ul>",
      "answerShort": "Monte Carlo integration"
    },
    "workedExample": {
      "problemHtml": "<p>Suppose we want to estimate the area under a curve using Monte Carlo integration. We have a random sample of <i>N</i> points from the uniform distribution on the unit square [0,1]x[0,1]. How can we use these samples to approximate the true area?</p>",
      "steps": [
        {
          "stepNumber": 1,
          "description": "Draw a random sample",
          "mathHtml": "\\(X_1, X_2, ..., X_N\\)",
          "explanation": "We need i.i.d. samples for the law of large numbers to hold."
        },
        {
          "stepNumber": 2,
          "description": "Compute the average area",
          "mathHtml": "\\(\\frac{1}{N} \\sum_{i=1}^N f(x_i)\\)",
          "explanation": "The estimated area is the average area of the sample points."
        },
        {
          "stepNumber": 3,
          "description": "Scale the result",
          "mathHtml": "\\(E[f(X)] = N \\cdot \\frac{1}{N} \\sum_{i=1}^N f(x_i)\\)",
          "explanation": "We need to scale the estimated area by <i>N</i> to get the true expected value."
        },
        {
          "stepNumber": 4,
          "description": "Repeat and average",
          "mathHtml": "\\(E[f(X)] = \\frac{1}{M} \\sum_{j=1}^M \\left( N \\cdot \\frac{1}{N} \\sum_{i=1}^N f(x_i)\\right)\\)",
          "explanation": "We can repeat the process <i>M</i> times and average the results to reduce variance."
        }
      ],
      "finalAnswer": "The estimated area is approximately 0.5"
    },
    "intuition": "Monte Carlo integration provides a simple way to estimate expected values by averaging function values over random samples.",
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:18:39.740Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_wex_sampling_methods_015",
    "subject": "probability",
    "type": "worked_example",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Monte Carlo and Importance Sampling",
    "contentHtml": "<p>In this example, we'll explore how to use Monte Carlo methods and importance sampling to solve a problem.</p>",
    "workedExample": "{",
    "problemHtml": "Suppose we want to estimate the area under a curve using Monte Carlo integration. We have a function <i>f(x)</i> defined on the interval [0,1].",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Generate random points\", \"mathHtml\": \"\\(\\mathbf{x} = (x_1, x_2, \\ldots, x_n)\\)\", \"explanation\": \"We generate <i>n</i> random points in the interval [0,1].\"}, {\"stepNumber\": 2, \"description\": \"Evaluate function at each point\", \"mathHtml\": \"\\(y_i = f(x_i)\\)\", \"explanation\": \"For each point, we evaluate the function <i>f(x)</i> and get a corresponding value <i>y</i>.\"}, {\"stepNumber\": 3, \"description\": \"Weight points by importance\", \"mathHtml\": \"\\(\\mathbf{w} = (w_1, w_2, \\ldots, w_n)\\)\", \"explanation\": \"We assign weights to each point based on their importance. For example, if the point is close to the curve, we give it a higher weight.\"}, {\"stepNumber\": 4, \"description\": \"Estimate area using weighted average\", \"mathHtml\": \"\\(\\hat{A} = \\frac{\\sum_{i=1}^n w_i y_i}{\\sum_{i=1}^n w_i}\\)\", \"explanation\": \"We estimate the area under the curve by taking a weighted average of the function values at each point.\"}, ],",
    "finalAnswer": "The estimated area is <i>\\hat{A}</i>.\" },",
    "intuition": "Monte Carlo methods and importance sampling are powerful tools for estimating complex integrals. By cleverly generating random points and weighting them by their importance, we can get a good estimate of the area under a curve.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:19:09.535Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_wex_sampling_methods_016",
    "subject": "probability",
    "type": "worked_example",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Monte Carlo and Importance Sampling",
    "contentHtml": "<p>In this example, we'll explore how to use Monte Carlo methods to estimate a probability distribution.</p>",
    "workedExample": "{",
    "problemHtml": "Estimate the area under the curve of <i>f(x) = x^2</i> from 0 to 1 using Monte Carlo integration.",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Generate random points (x, y) within the bounds\", \"mathHtml\": \"\\(x \\sim U[0, 1], y \\sim U[0, f(x)]\\)\", \"explanation\": \"This allows us to approximate the area under the curve by counting the proportion of points that fall below it.\"}, {\"stepNumber\": 2, \"description\": \"Evaluate the function at each point\", \"mathHtml\": \"\\(f(x) = x^2\\)\", \"explanation\": \"We'll use these function values to estimate the area under the curve.\"}, {\"stepNumber\": 3, \"description\": \"Calculate the area of each rectangle\", \"mathHtml\": \"\\(\\Delta A_i = f(x_i) \\cdot \\Delta x\\)\", \"explanation\": \"The width of each rectangle is the difference in x-values between consecutive points.\"}, {\"stepNumber\": 4, \"description\": \"Sum up the areas to get an estimate of the total area\", \"mathHtml\": \"\\(\\hat{A} = \\sum_{i=1}^n \\Delta A_i\\)\", \"explanation\": \"The more points we generate, the better our estimate will be.\"}, ],",
    "finalAnswer": "The estimated area under the curve is approximately 0.3333.\", },",
    "intuition": "Monte Carlo methods are useful when exact calculations are intractable or too computationally expensive. Importance sampling helps us focus on regions of high probability, making our estimates more accurate.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:19:36.879Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_wex_sampling_methods_017",
    "subject": "probability",
    "type": "worked_example",
    "chapter": "ml_probability",
    "topic": "sampling_methods",
    "title": "Monte Carlo Methods",
    "contentHtml": "<p>In this example, we'll explore how to use Monte Carlo methods to estimate a probability distribution.</p>",
    "problem": "{",
    "statementHtml": "<p>Suppose we want to estimate the area under a curve using Monte Carlo integration. We have a function <i>f(x)</i> and a bounding box [a, b].</p>",
    "hints": [
      "Hint: Use random sampling"
    ],
    "solutionHtml": "<p>We'll generate random points within the bounding box and evaluate the function at each point. The ratio of points where <i>f(x) &gt; 0</i> to the total number of points will give us an estimate of the area under the curve.</p>",
    "answerShort": "Monte Carlo integration\" },",
    "workedExample": "{",
    "problemHtml": "<p>Let's say we want to estimate the area under the function <i>f(x) = x^2</i> within the bounding box [0, 1]. We generate 100 random points and evaluate the function at each point.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Generate random points\", \"mathHtml\": \"\\\\[x_i \\\\sim Uniform(0, 1)\\\\]\", \"explanation\": \"We use a uniform distribution to ensure all points are equally likely.\"}, {\"stepNumber\": 2, \"description\": \"Evaluate the function at each point\", \"mathHtml\": \"\\\\[y_i = f(x_i) = x_i^2\\\\]\", \"explanation\": \"We plug in each random point into the function to get a corresponding output value.\"}, {\"stepNumber\": 3, \"description\": \"Count the points where <i>f(x) &gt; 0</i>\", \"mathHtml\": \"\\\\[A = \\\\frac{1}{N} \\\\sum_{i=1}^N I(y_i > 0)\\\\]\", \"explanation\": \"We count the number of points where the function output is positive.\"}, {\"stepNumber\": 4\", \"description\": \"Estimate the area under the curve\", \"mathHtml\": \"\\\\[A \\\\approx \\\\frac{b-a}{N} \\\\sum_{i=1}^N I(y_i > 0)\\\\]\", \"explanation\": \"We use the ratio of positive points to the total number of points as an estimate of the area under the curve.\"}, {\"stepNumber\": 5, \"description\": \"Repeat and average\", \"mathHtml\": \"\\\\[A \\\\approx \\\\frac{1}{M} \\\\sum_{m=1}^M A_m\\\\]\", \"explanation\": \"We repeat this process multiple times to get a more accurate estimate of the area under the curve.\"} ],",
    "finalAnswer": "The estimated area under the curve\" },",
    "intuition": "Monte Carlo methods are useful when we can't find an analytical solution or when the problem is too complex.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T03:20:16.118Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]