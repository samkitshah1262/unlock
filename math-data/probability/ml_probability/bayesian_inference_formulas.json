[
  {
    "id": "prob_for_bayesian_inference_004",
    "subject": "probability",
    "type": "formula",
    "chapter": "ml_probability",
    "topic": "bayesian_inference",
    "title": "Bayesian Inference",
    "contentHtml": "<p>Bayesian inference is a fundamental concept in machine learning that allows us to update our knowledge about a probability distribution based on new data.</p>",
    "formula": "{",
    "latex": "\\[P(\\theta | X) = \\frac{P(X | \\theta) P(\\theta)}{\\int P(X | \\theta) P(\\theta) d\\theta}\\]\",",
    "name": "Bayes' theorem\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a coin with an unknown probability of heads, and we flip it 10 times. If the results are 7 heads and 3 tails, what is our updated estimate of the probability?</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Define the prior distribution\", \"mathHtml\": \"\\[P(\\theta) = \\frac{1}{2}\\]\", \"explanation\": \"We assume a uniform prior.\"}, {\"stepNumber\": 2, \"description\": \"Update the prior with the likelihood\", \"mathHtml\": \"\\[P(X | \\theta) = \\binom{10}{7} \\theta^7 (1-\\theta)^3\\]\", \"explanation\": \"The likelihood is the probability of observing 7 heads and 3 tails given the true probability.\"}, {\"stepNumber\": 3, \"description\": \"Calculate the posterior\", \"mathHtml\": \"\\[P(\\theta | X) = \\frac{P(X | \\theta) P(\\theta)}{\\int P(X | \\theta) P(\\theta) d\\theta}\\]\", \"explanation\": \"We apply Bayes' theorem to update our prior with the new data.\"} ],",
    "finalAnswer": "The updated estimate of the probability is approximately 0.7\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T02:46:25.400Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_for_bayesian_inference_005",
    "subject": "probability",
    "type": "formula",
    "chapter": "ml_probability",
    "topic": "bayesian_inference",
    "title": "Bayesian Inference",
    "contentHtml": "<p>Bayesian inference is a fundamental concept in machine learning that allows us to update our knowledge about a probability distribution based on new data.</p>",
    "formula": "{",
    "latex": "\\[P(\\theta | X) = \\frac{P(X | \\theta) P(\\theta)}{\\int P(X | \\theta) P(\\theta) d\\theta}\\]\",",
    "name": "Bayes' theorem\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a prior distribution over the mean of a normal distribution, and we want to update this distribution based on some new data.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Specify the prior distribution\", \"mathHtml\": \"\\(P(\\mu) = \\mathcal{N}(\\mu | 0, 10^2)\\)\", \"explanation\": \"We choose a normal distribution with mean 0 and variance 100.\"} ],",
    "finalAnswer": "The updated posterior distribution\" },",
    "intuition": "Bayesian inference allows us to incorporate new data into our understanding of a probability distribution while preserving the uncertainty inherent in the data.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T02:46:43.944Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_for_bayesian_inference_006",
    "subject": "probability",
    "type": "formula",
    "chapter": "ml_probability",
    "topic": "bayesian_inference",
    "title": "Bayesian Inference: Prior, Likelihood, Posterior",
    "contentHtml": "<p>Bayesian inference is a fundamental concept in machine learning that allows us to update our beliefs about a model's parameters based on new data.</p><p>The key idea is to combine prior knowledge with likelihood from the observed data to obtain a posterior distribution over the model's parameters.</p>",
    "formula": "{",
    "latex": "\\[P(\\theta | D) = \\frac{P(D | \\theta) P(\\theta)}{\\int P(D | \\theta) P(\\theta) d\\theta}\\]\",",
    "name": "Bayes' theorem\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a coin with an unknown probability of heads, p. We flip the coin 10 times and get 7 heads.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Define the prior distribution over p\", \"mathHtml\": \"\\[P(p) = \\frac{1}{2} I_{(0, 1)}\\]\", \"explanation\": \"We assume a uniform prior.\"}, {\"stepNumber\": 2, \"description\": \"Update the prior with the likelihood from the observed data\", \"mathHtml\": \"\\[P(D | p) = (p^7 (1-p)^3)\\]\", \"explanation\": \"The likelihood is the probability of observing 7 heads and 3 tails given the coin's probability.\"}, {\"stepNumber\": 3, \"description\": \"Compute the posterior distribution\", \"mathHtml\": \"\\[P(p | D) = \\frac{p^7 (1-p)^3}{\\int p^7 (1-p)^3 dp}\\]\", \"explanation\": \"We use Bayes' theorem to update our prior with the likelihood.\"} ],",
    "finalAnswer": "The posterior distribution over p is updated to reflect our new knowledge about the coin's probability.\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T02:47:10.726Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "prob_for_bayesian_inference_007",
    "subject": "probability",
    "type": "formula",
    "chapter": "ml_probability",
    "topic": "bayesian_inference",
    "title": "Bayesian Inference",
    "contentHtml": "<p>Bayesian inference is a fundamental concept in machine learning and statistics that allows us to update our knowledge about a probability distribution based on new data.</p>",
    "formula": "{",
    "latex": "\\[P(\\theta | X, y) = \\frac{P(X, y | \\theta) P(\\theta)}{P(X, y)}\\]\",",
    "name": "Bayes' theorem\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a prior distribution for the mean of a Gaussian distribution and we want to update it based on some new data.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Define the likelihood function\", \"mathHtml\": \"\\(P(X | \\theta) = \\prod_{i=1}^n N(x_i | \\mu, \\sigma)\\)\", \"explanation\": \"This represents our new data\"}, {\"stepNumber\": 2, \"description\": \"Update the prior distribution\", \"mathHtml\": \"\\(P(\\theta | X) \\propto P(X | \\theta) P(\\theta)\\)\", \"explanation\": \"Using Bayes' theorem\"} ],",
    "finalAnswer": "The updated posterior distribution\" },",
    "intuition": "Bayesian inference allows us to incorporate new data into our prior knowledge and update our understanding of the underlying probability distribution.",
    "realWorldApplications": [
      "Estimating parameters in Gaussian mixture models"
    ],
    "tags": [
      "bayes",
      "inference",
      "ml",
      "ai"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T02:47:34.134Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]