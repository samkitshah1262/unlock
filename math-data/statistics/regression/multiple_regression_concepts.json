[
  {
    "id": "stat_con_multiple_regression_001",
    "subject": "statistics",
    "type": "concept",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression: Matrix Formulation and Interpretation",
    "contentHtml": "<p>In multiple linear regression, we model a response variable as a linear combination of multiple predictor variables. The matrix formulation provides a powerful tool for understanding and working with these models.</p><p>Consider a dataset with $n$ samples and $p+1$ features: the response variable $y$ and $p$ predictor variables $\\mathbf{x} = [x_1, \\ldots, x_p]$. The multiple linear regression model can be written as:</p>\\(y = \\mathbf{x}^T\\beta + \\epsilon,\\) where $\\beta$ is a $(p+1)\\times 1$ vector of coefficients and $\\epsilon$ is the error term.<p>The matrix formulation involves writing the design matrix $\\mathbf{X}$, which has $n$ rows and $p+1$ columns:</p>\\[\\mathbf{X} = \\begin{bmatrix} x_{11} & \\cdots & x_{1p} & 1 \\\\ \\vdots & \\ddots & \\vdots & \\vdots \\\\ x_{n1} & \\cdots & x_{np} & 1 \\end{bmatrix},\\]and the response vector $\\mathbf{y}$, which has $n$ elements:</p>\\[\\mathbf{y} = [y_1, \\ldots, y_n]^T.\\]",
    "formula": "{",
    "latex": "\\(y = \\mathbf{x}^T\\beta + \\epsilon\\)\",",
    "name": "Multiple Linear Regression Model\" },",
    "intuition": "The matrix formulation provides a compact and intuitive way to represent the multiple linear regression model. It highlights the relationships between the predictor variables, the response variable, and the coefficients.",
    "realWorldApplications": [
      "In machine learning, multiple linear regression is used in tasks such as feature selection, dimensionality reduction, and modeling complex relationships."
    ],
    "tags": [
      "multiple-linear-regression",
      "matrix-formulation"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:29:56.353Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_con_multiple_regression_002",
    "subject": "statistics",
    "type": "concept",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression: Matrix Formulation and Interpretation",
    "contentHtml": "<p>Multiple linear regression (MLR) is a powerful statistical technique that allows us to model the relationship between multiple predictor variables and a continuous outcome variable.</p><p>In this card, we'll explore the matrix formulation of MLR and how to interpret its partial coefficients.</p>",
    "formula": {
      "latex": "\\[\\mathbf{Y} = \\mathbf{X}\\beta + \\epsilon\\]",
      "name": "Linear Regression Model",
      "variants": []
    },
    "intuition": "The matrix formulation of MLR is useful because it allows us to easily compute the partial coefficients, which represent the change in the outcome variable for a one-unit change in each predictor variable while holding all other predictors constant.",
    "realWorldApplications": [
      "In machine learning, MLR is used as a building block for more complex models, such as neural networks and decision trees."
    ],
    "commonMistakes": [
      "Failing to center or standardize the predictor variables can lead to poor model performance."
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:30:10.705Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_con_multiple_regression_003",
    "subject": "statistics",
    "type": "concept",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression",
    "contentHtml": "<p>Multiple linear regression is a fundamental concept in statistical modeling that extends simple linear regression to multiple predictors.</p><p>In matrix notation, we can represent the model as:</p>\\(\\mathbf{y} = X\\beta + \\epsilon,\\) where \\(\\mathbf{y}\\) is the response vector, \\(X\\) is the design matrix, \\(\\beta\\) is the coefficient vector, and \\(\\epsilon\\) is the error term.</p>\",",
    "formula": "{",
    "latex": "\\(X\\beta + \\epsilon\\)\",",
    "name": "Multiple Linear Regression Model\" },",
    "intuition": "The key insight here is that multiple linear regression allows us to model complex relationships between the response variable and multiple predictor variables.",
    "visualDescription": "A diagram showing the relationship between the response variable, predictors, and error term would be helpful for visualizing the concept.",
    "commonMistakes": [
      "Failing to account for multicollinearity among predictors"
    ],
    "realWorldApplications": [
      "Predicting customer churn in telecommunications using multiple features such as usage patterns and demographics"
    ],
    "tags": [
      "regression",
      "matrix notation"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:30:25.943Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]