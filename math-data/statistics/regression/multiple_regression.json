[
  {
    "id": "stat_con_multiple_regression_001",
    "subject": "statistics",
    "type": "concept",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression: Matrix Formulation and Interpretation",
    "contentHtml": "<p>In multiple linear regression, we model a response variable as a linear combination of multiple predictor variables. The matrix formulation provides a powerful tool for understanding and working with these models.</p><p>Consider a dataset with $n$ samples and $p+1$ features: the response variable $y$ and $p$ predictor variables $\\mathbf{x} = [x_1, \\ldots, x_p]$. The multiple linear regression model can be written as:</p>\\(y = \\mathbf{x}^T\\beta + \\epsilon,\\) where $\\beta$ is a $(p+1)\\times 1$ vector of coefficients and $\\epsilon$ is the error term.<p>The matrix formulation involves writing the design matrix $\\mathbf{X}$, which has $n$ rows and $p+1$ columns:</p>\\[\\mathbf{X} = \\begin{bmatrix} x_{11} & \\cdots & x_{1p} & 1 \\\\ \\vdots & \\ddots & \\vdots & \\vdots \\\\ x_{n1} & \\cdots & x_{np} & 1 \\end{bmatrix},\\]and the response vector $\\mathbf{y}$, which has $n$ elements:</p>\\[\\mathbf{y} = [y_1, \\ldots, y_n]^T.\\]",
    "formula": "{",
    "latex": "\\(y = \\mathbf{x}^T\\beta + \\epsilon\\)\",",
    "name": "Multiple Linear Regression Model\" },",
    "intuition": "The matrix formulation provides a compact and intuitive way to represent the multiple linear regression model. It highlights the relationships between the predictor variables, the response variable, and the coefficients.",
    "realWorldApplications": [
      "In machine learning, multiple linear regression is used in tasks such as feature selection, dimensionality reduction, and modeling complex relationships."
    ],
    "tags": [
      "multiple-linear-regression",
      "matrix-formulation"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:29:56.353Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_con_multiple_regression_002",
    "subject": "statistics",
    "type": "concept",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression: Matrix Formulation and Interpretation",
    "contentHtml": "<p>Multiple linear regression (MLR) is a powerful statistical technique that allows us to model the relationship between multiple predictor variables and a continuous outcome variable.</p><p>In this card, we'll explore the matrix formulation of MLR and how to interpret its partial coefficients.</p>",
    "formula": {
      "latex": "\\[\\mathbf{Y} = \\mathbf{X}\\beta + \\epsilon\\]",
      "name": "Linear Regression Model",
      "variants": []
    },
    "intuition": "The matrix formulation of MLR is useful because it allows us to easily compute the partial coefficients, which represent the change in the outcome variable for a one-unit change in each predictor variable while holding all other predictors constant.",
    "realWorldApplications": [
      "In machine learning, MLR is used as a building block for more complex models, such as neural networks and decision trees."
    ],
    "commonMistakes": [
      "Failing to center or standardize the predictor variables can lead to poor model performance."
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:30:10.705Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_con_multiple_regression_003",
    "subject": "statistics",
    "type": "concept",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression",
    "contentHtml": "<p>Multiple linear regression is a fundamental concept in statistical modeling that extends simple linear regression to multiple predictors.</p><p>In matrix notation, we can represent the model as:</p>\\(\\mathbf{y} = X\\beta + \\epsilon,\\) where \\(\\mathbf{y}\\) is the response vector, \\(X\\) is the design matrix, \\(\\beta\\) is the coefficient vector, and \\(\\epsilon\\) is the error term.</p>\",",
    "formula": "{",
    "latex": "\\(X\\beta + \\epsilon\\)\",",
    "name": "Multiple Linear Regression Model\" },",
    "intuition": "The key insight here is that multiple linear regression allows us to model complex relationships between the response variable and multiple predictor variables.",
    "visualDescription": "A diagram showing the relationship between the response variable, predictors, and error term would be helpful for visualizing the concept.",
    "commonMistakes": [
      "Failing to account for multicollinearity among predictors"
    ],
    "realWorldApplications": [
      "Predicting customer churn in telecommunications using multiple features such as usage patterns and demographics"
    ],
    "tags": [
      "regression",
      "matrix notation"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:30:25.943Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_multiple_regression_004",
    "subject": "statistics",
    "type": "formula",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression Formula",
    "contentHtml": "<p>The multiple linear regression formula is a cornerstone of statistical modeling.</p><p>It allows us to model the relationship between a continuous outcome variable and one or more predictor variables.</p>",
    "formula": "{",
    "latex": "\\[ \\mathbf{y} = X\\beta + \\epsilon \\]\",",
    "name": "Multiple Linear Regression Formula",
    "variants": "[] },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we want to model the relationship between a student's GPA and their hours studied per week.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Collect data on GPA and hours studied\", \"mathHtml\": \"\", \"explanation\": \"This is the foundation of our analysis\"}, {\"stepNumber\": 2, \"description\": \"Fit a multiple linear regression model\", \"mathHtml\": \"\\[ \\hat{\\beta} = (X^T X)^{-1} X^T y \\]\", \"explanation\": \"We use the formula above to estimate the coefficients\"} ],",
    "finalAnswer": "\" },",
    "intuition": "The multiple linear regression formula provides a way to quantify the relationship between a continuous outcome variable and one or more predictor variables.",
    "realWorldApplications": [
      "Predicting student performance based on hours studied"
    ],
    "tags": [
      "multiple",
      "linear",
      "regression"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:30:43.801Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_multiple_regression_005",
    "subject": "statistics",
    "type": "formula",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression Formula",
    "contentHtml": "<p>The multiple linear regression formula is a cornerstone of statistical modeling. It allows us to model the relationship between a dependent variable and one or more independent variables.</p>",
    "formula": "{",
    "latex": "\\[ \\mathbf{Y} = X\\beta + \\epsilon \\]\",",
    "name": "Multiple Linear Regression Formula",
    "variants": "[] },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we want to model the relationship between a student's grade (dependent variable) and their hours studied and age (independent variables). We can use multiple linear regression.</p>",
    "steps": [
      {
        "stepNumber": 1,
        "description": "Collect data on grades, hours studied, and ages",
        "mathHtml": "",
        "explanation": "This involves collecting a dataset of student information."
      }
    ],
    "finalAnswer": "\" },",
    "intuition": "The multiple linear regression formula is useful when we want to understand how multiple variables contribute to the dependent variable.",
    "tags": [
      "regression",
      "statistical modeling"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:30:58.455Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_multiple_regression_006",
    "subject": "statistics",
    "type": "formula",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression Formula",
    "contentHtml": "<p>In matrix formulation, multiple linear regression (MLR) models can be represented as:</p>\\[y = X\\beta + \\epsilon,\\]\\n<p>where <i>y</i> is the response variable, <i>X</i> is the design matrix, <i>&#946;</i> is the coefficient vector, and <i>&#951;</i> represents the error term.</p>\",",
    "formula": "{",
    "latex": "\\[y = X\\beta + \\epsilon,\\]\",",
    "name": "MLR Model",
    "variants": "[] },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we want to model the relationship between exam scores (<i>y</i>) and hours studied (<i>X</i>). We can represent this as:</p>\\[y = X\\beta + \\epsilon,\\]\\n<p>To apply this formula, we would first standardize the features in <i>X</i>, then estimate the coefficients <i>&#946;</i> using ordinary least squares (OLS).</p>\",",
    "steps": "[ {",
    "stepNumber": 2,
    "description": "Estimate the coefficients",
    "mathHtml": "\\[(\\beta, \\sigma^2) = (X_{\\text{std}}^T X_{\\text{std}})^{-1} X_{\\text{std}}^T y\\]\",",
    "explanation": "OLS provides a consistent estimate of the coefficients\" } ],",
    "finalAnswer": "The estimated coefficients and standard errors can be used to interpret the relationships between the features and the response variable.\" },",
    "intuition": "This formula represents the core idea behind multiple linear regression: modeling the relationship between multiple predictor variables and a continuous outcome.",
    "visualDescription": "A diagram showing the MLR model with standardized features would help illustrate the concept",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:31:23.706Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_multiple_regression_007",
    "subject": "statistics",
    "type": "formula",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression: Matrix Formulation",
    "contentHtml": "<p>The matrix formulation of multiple linear regression provides a powerful tool for analyzing relationships between multiple variables.</p><p>In this context, we'll focus on the partial coefficients and their interpretation.</p>",
    "formula": "{",
    "latex": "\\[ \\mathbf{Y} = X\\beta + \\epsilon \\]\",",
    "name": "Multiple Linear Regression Model",
    "variants": "[ {\"latex\": \"\\[ \\hat{\\mathbf{Y}} = X\\hat{\\beta} \\]\", \"description\": \"Predicted outcome\" } ] },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a dataset of students' grades and their corresponding hours studied, and we want to predict the grade based on the study time.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Collect the data\", \"mathHtml\": \"\", \"explanation\": \"Gather relevant information\" }, {\"stepNumber\": 2, \"description\": \"Create a design matrix\", \"mathHtml\": \"\\[ X = \\begin{bmatrix} 1 & 5 \\\\ 1 & 3 \\\\ ... \\end{bmatrix} \\]\", \"explanation\": \"Represent the study time and intercept\" }, {\"stepNumber\": 3, \"description\": \"Estimate the coefficients\", \"mathHtml\": \"\", \"explanation\": \"Use linear regression to find the best-fitting line\" } ],",
    "finalAnswer": "The predicted grades\" },",
    "intuition": "Partial coefficients in multiple linear regression reveal the unique relationship between each predictor variable and the outcome, while controlling for the effects of other variables.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:31:43.817Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_thm_multiple_regression_008",
    "subject": "statistics",
    "type": "theorem",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression Theorem",
    "contentHtml": "<p>The Multiple Linear Regression (MLR) theorem is a fundamental result in statistical modeling.</p>",
    "formula": {
      "latex": "\\[\\mathbf{Y} = X \\beta + \\epsilon\\]",
      "name": "Linear Regression Model"
    },
    "theorem": {
      "statement": "\\[\\beta = (X^T X)^{-1} X^T Y\\]",
      "proofSketch": "The proof involves showing that the least squares estimator is unbiased and consistent, then using the Gauss-Markov theorem to conclude that it's also the maximum likelihood estimator."
    },
    "intuition": "This theorem shows how to estimate the coefficients of a linear regression model when there are multiple predictors. It's a powerful tool for modeling complex relationships between variables.",
    "realWorldApplications": [
      "Predicting customer churn in telecommunications",
      "Analyzing the impact of marketing campaigns on sales"
    ],
    "tags": [
      "multiple linear regression",
      "statistical modeling"
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:31:57.942Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_thm_multiple_regression_009",
    "subject": "statistics",
    "type": "theorem",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression Theorem",
    "contentHtml": "<p>The Multiple Linear Regression theorem provides a powerful framework for modeling relationships between multiple predictor variables and an outcome variable.</p>",
    "formula": "{",
    "latex": "\\[\\mathbf{Y} = \\mathbf{X}\\beta + \\epsilon\\]",
    "name": "Multiple Linear Regression Model",
    "variants": "[] },",
    "theorem": "{",
    "statement": "\\[\\mathbf{E}[(\\mathbf{Y} - \\mathbf{X}\\beta)^T (\\mathbf{Y} - \\mathbf{X}\\beta)] = \\sigma^2 ||\\mathbf{X}||^2\\\\]\",",
    "proofSketch": "The proof involves showing that the expected value of the squared error is minimized when \\\\(\\beta\\\\) is equal to the ordinary least squares (OLS) estimate.\" },",
    "intuition": "This theorem shows that the OLS estimate minimizes the sum of squared errors, providing a fundamental connection between the data and the model.",
    "realWorldApplications": [
      "Predicting customer churn in telecommunications using multiple demographic variables"
    ],
    "tags": [
      "Multiple Linear Regression",
      "Linear Algebra",
      "Statistics"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:32:13.848Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_multiple_regression_010",
    "subject": "statistics",
    "type": "problem",
    "chapter": "regression",
    "topic": "multiple_regression",
    "problem": "{",
    "statementHtml": "In a multiple linear regression setting with <i>n</i> observations and <i>p</i> features, derive an expression for the partial coefficient of the <i>j</i>-th feature.",
    "hints": [
      "Start by writing down the matrix formulation of the regression model.",
      "Focus on the coefficient of interest and rewrite it in terms of the design matrix.",
      "Use properties of matrix products to simplify your answer."
    ],
    "solutionHtml": "<p>To begin, we write the multiple linear regression model as:</p>\\n\\[y = X\\beta + \\epsilon.\\]\\n<p>Next, we extract the coefficient of interest, say <i>\\beta_j</i>, and rewrite it in terms of the design matrix:</p>\\n\\[\\beta_j = (X^T X)^{-1} X^T y.\\]\\n<p>We can simplify this expression by noting that:</p>\\n\\[X^T X \\beta = X^T y,\\]\\n<p>which implies:</p>\\n\\[(X^T X)^{-1} X^T X \\beta = (X^T X)^{-1} X^T y.\\]\\n<p>This simplifies to:</p>\\n\\[\\beta_j = (X^T X)^{-1} X^T e_j,\\]\\n<p>where <i>e_j</i> is the <i>j</i>-th column of the identity matrix.</p>\",",
    "answerShort": "\\[(X^T X)^{-1} X^T e_j\\]\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:32:35.152Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_multiple_regression_011",
    "subject": "statistics",
    "type": "problem",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression: Matrix Formulation and Interpretation",
    "problem": "{",
    "statementHtml": "Consider a multiple linear regression model with <i>n</i> observations and <i>p</i> features. Write the matrix formulation of the model, where <i>X</i> is the design matrix, <i>y</i> is the response vector, and <i>b</i> is the coefficient vector.",
    "hints": [
      "Start by writing the linear regression equation for a single observation.",
      "Notice that the design matrix contains a column of ones for the intercept term.",
      "The coefficient vector <i>b</i> contains the partial coefficients for each feature."
    ],
    "solutionHtml": "<p>To write the matrix formulation, we can start by writing the linear regression equation for a single observation:</p>\\n\\n\\[y_i = \\mathbf{x}_i^T\\mathbf{b} + \\epsilon_i,\\]\\n<p>where <i>y_i</i> is the response value for the <i>i^{th}</i> observation, <i>x_i</i> is the feature vector for that observation, and <i>b</i> is the coefficient vector.</p>\\n\\n<p>We can then stack these equations to get:</p>\\n\\n\\[y = Xb + \\epsilon,\\]\\n<p>The design matrix <i>X</i> contains a column of ones for the intercept term, so we can write:</p>\\n\\n\\[X = [1\\quad x_1\\quad ... \\quad x_p],\\]\\n<p>The coefficient vector <i>b</i> contains the partial coefficients for each feature.</p>\",",
    "answerShort": "The matrix formulation of the multiple linear regression model is <i>y = Xb + ε</i>\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:32:57.244Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_multiple_regression_012",
    "subject": "statistics",
    "type": "problem",
    "chapter": "regression",
    "topic": "multiple_regression",
    "problem": "{",
    "statementHtml": "Given a multiple linear regression model <span class=\\\"math\\\">\\(Y = X\\beta + \\epsilon\\)</span>, derive the partial coefficients and interpret their meaning.\",",
    "hints": "[ \"Start by rewriting the model in matrix form\", \"Use the fact that <span class=\\\"math\\\">\\(X^T X\\)</span> is invertible\", \"Focus on the coefficient for a single predictor variable\" ],",
    "solutionHtml": "<p>To derive the partial coefficients, we can rewrite the model as:</p><span class=\\\"math\\\">\\\\[Y = X \\beta + \\epsilon \\\\]</span><p>Then, using matrix operations, we get:</p><span class=\\\"math\\\">\\\\[\\hat{Y} = X (X^T X)^{-1} X^T Y \\\\]</span><p>The partial coefficient for the <i>i</i>th predictor variable is given by:</p><span class=\\\"math\\\">\\\\[b_i = \\frac{(X^T X)^{-1} x_i^T y}{x_i^T (X^T X)^{-1} x_i} \\\\]</span>\",",
    "answerShort": "The partial coefficient for the <i>i</i>th predictor variable is given by the formula above.\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:33:15.466Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_multiple_regression_013",
    "subject": "statistics",
    "type": "problem",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Multiple Linear Regression: Matrix Formulation and Interpretation",
    "problem": "{",
    "statementHtml": "Consider a multiple linear regression model with <i>n</i> observations and <i>p</i> features:<br>\\[y = X\\beta + \\epsilon\\]<br>where <i>X</i> is the design matrix, <i>y</i> is the response variable, <i>&#946;</i> is the coefficient vector, and <i>&#951;</i> is the error term. Provide a matrix formulation for the partial coefficients.\",",
    "hints": [
      "Start by expressing the model in terms of the design matrix",
      "Think about how to extract the partial coefficients from the model"
    ],
    "solutionHtml": "<p>To start, rewrite the model as:</p>\\[y = X\\beta + \\epsilon\\]\\n<p>Next, multiply both sides by <i>X</i><sup>T</sup>:</p>\\[\\left(X^{T}X\\right)\\beta = X^{T}y\\]\\n<p>Solve for <i>&#946;</i>:</p>\\[\\beta = \\left(X^{T}X\\right)^{-1}X^{T}y\\]\\n<p>The partial coefficients are then given by:</p>\\[b_{j} = \\beta_{j} = \\frac{\\partial y}{\\partial x_{j}} = \\left(X^{T}X\\right)_{jj}^{-1}\\sum_{i=1}^{n}x_{ij}y_{i}\\]\\n<p>where <i>b</i><sub><i>j</i></sub> is the partial coefficient for feature <i>j</i>.</p>\",",
    "answerShort": "The matrix formulation for the partial coefficients is given by the expression above.\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:33:39.111Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_multiple_regression_014",
    "subject": "statistics",
    "type": "problem",
    "chapter": "regression",
    "topic": "multiple_regression",
    "problem": "{",
    "statementHtml": "<p>Given a multiple linear regression model <span class=\\\"math\\\">y = X\\*\\*\\*β + ε</span>, derive the partial coefficients (also known as beta coefficients) using matrix formulation.</p>\",",
    "hints": [
      "Start by rewriting the model in matrix form.",
      "Use the fact that <span class=\"math\">X^T X</span> is invertible to simplify the expression.",
      "Recall the definition of partial coefficients and how they relate to the regression coefficients."
    ],
    "solutionHtml": "<p>To derive the partial coefficients, we can start by rewriting the model in matrix form:</p><ul><li><span class=\\\"math\\\">y = X\\*\\*\\*β + ε</span></li></ul><p>Next, we use the fact that <span class=\\\"math\\\">X^T X</span> is invertible to simplify the expression:</p><ul><li><span class=\\\"math\\\">(X^T X)^{-1} X^T y = (X^T X)^{-1} X^T X\\*\\*\\*β + (X^T X)^{-1} X^T ε</span></li></ul><p>Now, we can define the partial coefficients as:</p><ul><li><span class=\\\"math\\\">β_j = ((X^T X)^{-1} X^T x_j)</span></li></ul><p>The final answer is:</p><ul><li><span class=\\\"math\\\">β_j = (x_{j}^T (X^T X)^{-1} X^T y)</span></li></ul>\",",
    "answerShort": "<span class=\\\"math\\\">β_j</span>\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:34:02.607Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_multiple_regression_015",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Solving Multiple Linear Regression",
    "contentHtml": "<p>In this worked example, we'll walk through a step-by-step solution to a multiple linear regression problem.</p>",
    "workedExample": "{",
    "problemHtml": "Suppose we have the following dataset of exam scores and hours studied:<br><table><tr><td>Exam Score</td><td>Hours Studied</td></tr><tr><td>85</td><td>5</td></tr><tr><td>90</td><td>6</td></tr><tr><td>78</td><td>4</td></tr><tr><td>92</td><td>7</td></tr></table>",
    "steps": "[ {",
    "stepNumber": 4,
    "description": "Calculate the partial R-squared",
    "mathHtml": "\\[R^2 = \\frac{\\sum (y - \\bar{y})^2}{\\sum (y - \\bar{y})^2 + \\sum \\epsilon^2}\\]\",",
    "explanation": "This measures the proportion of variance in exam scores explained by each predictor variable.\" } ],",
    "finalAnswer": "The partial coefficients and R-squared values represent the relationships between hours studied, exam scores, and the error term.\" },",
    "intuition": "Multiple linear regression helps us understand how multiple variables contribute to a outcome variable. By controlling for other variables, we can gain insights into the unique effects of each predictor.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:34:36.117Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_multiple_regression_016",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Solving Multiple Linear Regression Problems",
    "contentHtml": "<p>In this worked example, we'll walk through a step-by-step solution to a multiple linear regression problem.</p>",
    "workedExample": "{",
    "problemHtml": "Suppose we want to model the relationship between exam scores (X) and hours studied (Y). We have the following data:<br><table><tr><th>X</th><th>Y</th></tr><tr><td>5</td><td>80</td></tr><tr><td>6</td><td>85</td></tr><tr><td>7</td><td>90</td></tr><tr><td>8</td><td>95</td></tr></table>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Write the matrix equation\", \"mathHtml\": \"\\[X\\beta + \\epsilon = Y\\]\", \"explanation\": \"We're modeling the relationship between X and Y using a linear combination of coefficients (β) plus some error term (ε)\"}, {\"stepNumber\": 2, \"description\": \"Calculate the mean-centered data\", \"mathHtml\": \"\\[x_i = x_i - \\bar{x}, y_i = y_i - \\bar{y}\\]\", \"explanation\": \"We're subtracting the means to center our data and reduce multicollinearity\"}, {\"stepNumber\": 3, \"description\": \"Calculate the covariance matrix\", \"mathHtml\": \"\\[S = (x'x)^{-1} x'y'\\]\", \"explanation\": \"The covariance matrix is a measure of how variables are related to each other\"}, {\"stepNumber\": 4, \"description\": \"Calculate the partial coefficients\", \"mathHtml\": \"\\[\\beta_j = S_{xyj}/S_{xx}\\]\", \"explanation\": \"We're calculating the partial coefficient for each predictor variable (X) by dividing the covariance between X and Y by the variance of X\"} ],",
    "finalAnswer": "The partial coefficients are [0.5, 1.2, -0.3]\" },",
    "intuition": "Multiple linear regression helps us understand how multiple variables contribute to a outcome variable.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:35:02.844Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_multiple_regression_017",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Solving Multiple Linear Regression Problems",
    "contentHtml": "<p>In this worked example, we'll walk through a step-by-step solution to a multiple linear regression problem.</p>",
    "workedExample": "{",
    "problemHtml": "Suppose we have the following dataset:<br />\\[\\begin{bmatrix}1 & 2 & 3\\\\4 & 5 & 6\\\\7 & 8 & 9\\end{bmatrix}\\]with response variable $y$ and predictor variables $x_1$, $x_2$, and $x_3$. We want to find the coefficients for a multiple linear regression model that predicts $y$ using these three predictors.</p>\",",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Write down the matrix formulation of the problem\", \"mathHtml\": \"\\[X\\beta = y\\]\", \"explanation\": \"We start by writing down the equation for multiple linear regression in matrix form.\" }, {\"stepNumber\": 2, \"description\": \"Find the coefficients using ordinary least squares (OLS)\", \"mathHtml\": \"\\[\\hat{\\beta} = (X^T X)^{-1} X^T y\\]\", \"explanation\": \"We use OLS to find the coefficients by minimizing the squared error.\" }, {\"stepNumber\": 3, \"description\": \"Interpret the partial coefficients\", \"mathHtml\": \"\", \"explanation\": \"The partial coefficients tell us how much each predictor contributes to the response variable, while holding all other predictors constant.\" }, {\"stepNumber\": 4, \"description\": \"Check for multicollinearity by looking at variance inflation factors (VIFs)\", \"mathHtml\": \"\", \"explanation\": \"We check for multicollinearity by calculating VIFs for each predictor.\" } ],",
    "finalAnswer": "The coefficients are \\[\\hat{\\beta} = [0.5, 1.2, -0.8]\\].\" },",
    "intuition": "Partial coefficients help us understand how each predictor contributes to the response variable.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:35:26.976Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_multiple_regression_018",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Solving Multiple Linear Regression with Matrix Formulation",
    "contentHtml": "<p>In this worked example, we'll walk through solving a multiple linear regression problem using matrix formulation.</p>",
    "formula": "{",
    "latex": "\\\\[\\\\mathbf{X} \\\\beta = \\\\mathbf{y}\\]\",",
    "name": "Regression Equation\" },",
    "problem": "{",
    "statementHtml": "<p>Given the data points (x1, x2, y) = ((1, 2, 3), (4, 5, 7), (6, 8, 10)) and the design matrix \\mathbf{X}:</p><ul><li>x1: 1, 4, 6</li><li>x2: 2, 5, 8</li></ul>",
    "hints": [
      "Hint: Use the formula above"
    ],
    "solutionHtml": "<p>To solve this problem, we'll follow these steps:</p>",
    "answerShort": "The coefficients are (b1 = ..., b2 = ...)\" },",
    "workedExample": "{",
    "problemHtml": "<p>Find the partial coefficients for multiple linear regression using matrix formulation.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Write down the design matrix \\\\mathbf{X} and the response vector \\\\mathbf{y}\", \"mathHtml\": \"\\\\[\\\\mathbf{X} = \\\\begin{bmatrix} 1 & 2 \\\\\\\\ 4 & 5 \\\\\\\\ 6 & 8 \\\\end{bmatrix},\\quad \\\\mathbf{y} = \\\\begin{bmatrix} 3 \\\\\\\\ 7 \\\\\\\\ 10 \\\\end{bmatrix}\\]\", \"explanation\": \"This step sets the stage for our matrix formulation.\"}, {\"stepNumber\": 2, \"description\": \"Write down the regression equation using the formula above\", \"mathHtml\": \"\\\\[\\\\mathbf{X} \\\\beta = \\\\mathbf{y}\\]\", \"explanation\": \"We'll use this equation to find the partial coefficients.\" }, {\"stepNumber\": 3, \"description\": \"Find the coefficient matrix \\\\mathbf{X}' \\\\mathbf{X}\", \"mathHtml\": \"\\\\[\\\\mathbf{X}' \\\\mathbf{X} = \\\\begin{bmatrix} ... & ... \\\\\\\\ ... & ... \\\\end{bmatrix}\\]\", \"explanation\": \"This step helps us find the partial coefficients.\" }, {\"stepNumber\": 4, \"description\": \"Find the coefficient vector \\\\beta\", \"mathHtml\": \"\\\\[\\\\beta = (b1, b2) = (..., ...)\\]\", \"explanation\": \"Now we can find the partial coefficients!\" } ],",
    "finalAnswer": "(b1 = ..., b2 = ...)\" },",
    "intuition": "The key insight is that matrix formulation simplifies the calculation of partial coefficients.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:35:59.747Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_multiple_regression_019",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "regression",
    "topic": "multiple_regression",
    "title": "Solving Multiple Linear Regression",
    "contentHtml": "<p>In this worked example, we'll walk through a step-by-step solution to a multiple linear regression problem.</p>",
    "workedExample": "{",
    "problemHtml": "Suppose we want to model the relationship between exam scores (X) and hours studied (Y). We have the following data:<br><table><tr><th>X</th><th>Y</th></tr><tr><td>5</td><td>80</td></tr><tr><td>7</td><td>90</td></tr><tr><td>3</td><td>60</td></tr><tr><td>9</td><td>95</td></tr></table>",
    "steps": "[ {",
    "stepNumber": 4,
    "description": "Estimate the partial coefficients",
    "mathHtml": "\\[\\hat{\\beta}_1 = \\frac{S_{xy}}{S_{xx}}\\]\",",
    "explanation": "The estimated partial coefficient β<sub>1</sub> represents the change in Y for a one-unit change in X, while holding all other variables constant.\" } ],",
    "finalAnswer": "Our estimated partial coefficient is...\" },",
    "intuition": "Multiple linear regression helps us understand how multiple inputs contribute to an output. By standardizing our variables and estimating the partial coefficients, we can gain insights into the relationships between them.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T22:36:31.279Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]