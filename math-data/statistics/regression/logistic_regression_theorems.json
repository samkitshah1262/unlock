[
  {
    "id": "stat_thm_logistic_regression_008",
    "subject": "statistics",
    "type": "theorem",
    "chapter": "regression",
    "topic": "logistic_regression",
    "title": "Logistic Regression Theorem",
    "contentHtml": "<p>The logistic regression theorem is a fundamental result in statistical modeling that helps us understand how to make predictions about binary outcomes.</p>",
    "formula": {
      "latex": "\\[P(Y=1 | x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1x)}}\\]",
      "name": "Logistic Function"
    },
    "theorem": {
      "statement": "\\[P(Y=1 | x) = \\frac{e^\\theta}{1 + e^\\theta}\\] where \\(Y\\) is the binary outcome, \\(x\\) is the feature vector, and \\(\\theta\\) is the log odds.",
      "proofSketch": "The proof involves showing that the logistic function satisfies the properties of a probability distribution."
    },
    "intuition": "This theorem shows us how to model the relationship between a binary outcome and one or more features. It's used extensively in machine learning for tasks like classification and feature engineering.",
    "realWorldApplications": [
      "Predicting customer churn",
      "Classifying medical diagnoses"
    ],
    "tags": [
      "logistic regression",
      "binary classification"
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:05:33.155Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_thm_logistic_regression_009",
    "subject": "statistics",
    "type": "theorem",
    "chapter": "regression",
    "topic": "logistic_regression",
    "title": "Logistic Regression Theorem",
    "contentHtml": "<p>The logistic regression theorem is a fundamental result in binary classification.</p>",
    "formula": {
      "latex": "\\(P(y=1 | x) = \\frac{1}{1 + e^{-(\\beta^T x + b)}}\\)",
      "name": ""
    },
    "theorem": {
      "statement": "\\[H_0: P(y=1 | x) = \\frac{1}{1 + e^{-(\\beta^T x + b)}} \\\\ H_a: P(y=1 | x) \\neq \\frac{1}{1 + e^{-(\\beta^T x + b)}}\\]",
      "proofSketch": "The proof involves showing that the maximum likelihood estimator (MLE) is equivalent to the log-odds ratio."
    },
    "intuition": "This theorem shows that logistic regression models the probability of a binary outcome given some input features.",
    "realWorldApplications": [
      "Predicting customer churn in telecommunications"
    ],
    "tags": [
      "logistic regression",
      "binary classification"
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:05:47.755Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]