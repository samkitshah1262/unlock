[
  {
    "id": "stat_wex_bayesian_estimation_012",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "bayesian_statistics",
    "topic": "bayesian_estimation",
    "title": "Bayesian Point Estimation: Posterior Mean and MAP",
    "contentHtml": "<p>In Bayesian statistics, we often need to estimate parameters of a distribution based on observed data.</p>",
    "formula": "{",
    "latex": "\\( \\mathbb{E}[x | y] = \\int x p(x | y) dx \\)\",",
    "name": "Posterior Mean\" },",
    "problem": "{",
    "statementHtml": "<p>Suppose we have a normal distribution with unknown mean and variance. We observe \\(n\\) data points, and want to estimate the mean using Bayes' theorem.</p>\",",
    "hints": [
      "Hint: Start by defining the prior and likelihood"
    ],
    "solutionHtml": "<p>To solve this problem, we'll follow these steps:</p><ul><li>Step 1: Define the prior distribution for the mean. We'll use a normal distribution with mean \\(0\\) and variance \\(\\sigma^2\\).</li><li>Step 2: Define the likelihood function based on our observed data points.</li><li>Step 3: Compute the posterior distribution using Bayes' theorem.</li><li>Step 4: Calculate the posterior mean, which is the expected value of the posterior distribution.</li></ul>\",",
    "answerShort": "The posterior mean is \\( \\frac{1}{n} \\sum_{i=1}^n x_i + (1-\\frac{1}{n})\\mu_0 \\)\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a normal distribution with unknown mean and variance. We observe \\(5\\) data points: \\(2, 3, 4, 6, 7\\). We want to estimate the mean using Bayes' theorem.</p>\",",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Define the prior distribution for the mean\", \"mathHtml\": \"\\( p(\\mu) = \\mathcal{N}(0, \\sigma^2) \\)\", \"explanation\": \"We choose a normal distribution with mean \\(0\\) and variance \\(\\sigma^2\\), representing our initial uncertainty about the mean.\"}, {\"stepNumber\": 2, \"description\": \"Define the likelihood function\", \"mathHtml\": \"\\( p(x | \\mu) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}} \\)\", \"explanation\": \"The likelihood function represents the probability of observing our data points given the mean.\"}, {\"stepNumber\": 3, \"description\": \"Compute the posterior distribution\", \"mathHtml\": \"\\( p(\\mu | x) = \\frac{p(x | \\mu) p(\\mu)}{\\int p(x | \\mu) p(\\mu) d\\mu} \\)\", \"explanation\": \"We use Bayes' theorem to update our prior distribution with the likelihood function.\"}, {\"stepNumber\": 4, \"description\": \"Calculate the posterior mean\", \"mathHtml\": \"\\( \\mathbb{E}[x | y] = \\frac{\\int x p(x | \\mu) p(\\mu) d\\mu}{\\int p(x | \\mu) p(\\mu) d\\mu} \\)\", \"explanation\": \"The posterior mean is the expected value of our updated distribution.\"} ],",
    "finalAnswer": "The answer is \\( \\frac{1}{5} (2+3+4+6+7) + (1-\\frac{1}{5})0 = 4 \\)\" },",
    "intuition": "Bayesian point estimation provides a way to incorporate prior knowledge and uncertainty into our estimates, making it a powerful tool for many real-world applications.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:30:41.994Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_bayesian_estimation_013",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "bayesian_statistics",
    "topic": "bayesian_estimation",
    "title": "Bayesian Point Estimation: Posterior Mean and MAP",
    "contentHtml": "<p>In Bayesian statistics, we often want to estimate a parameter based on some observed data.</p>",
    "formula": "{",
    "latex": "\\( \\mathbb{E}[x | y] = \\int x p(x | y) dx \\)\",",
    "name": "Posterior mean",
    "variants": "[ {\"latex\": \"\\( \\text{MAP} = \\arg\\max_p p(x | y) \\)\", \"description\": \"Maximum a posteriori estimation\"} ] },",
    "problem": "{",
    "statementHtml": "<p>Suppose we have a normal distribution \\( N(\\mu, \\sigma^2) \\) and we observe some data points. How can we estimate the mean \\( \\mu \\) using Bayesian methods?</p>\",",
    "hints": [
      "Think about Bayes' theorem",
      "Use conjugate priors"
    ],
    "solutionHtml": "<p>We'll use a prior distribution for \\( \\mu \\) and update it based on our observations.</p>\",",
    "answerShort": "The posterior mean is the weighted average of the prior mean and the observed data.\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a normal distribution \\( N(0, 1) \\) and we observe the data points \\( x_1 = 2, x_2 = 3, x_3 = 4 \\). How can we estimate the mean \\( \\mu \\)?</p>\",",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Specify a prior distribution for \\( \\mu \\)\", \"mathHtml\": \"\\( p(\\mu) = N(0, 10) \\)\", \"explanation\": \"We choose a conjugate prior that's also normal.\"}, {\"stepNumber\": 2, \"description\": \"Update the prior using Bayes' theorem\", \"mathHtml\": \"\\( p(\\mu | x) \\propto p(x | \\mu) p(\\mu) \\)\", \"explanation\": \"We use the likelihood function and our prior to get the posterior.\"}, {\"stepNumber\": 3, \"description\": \"Calculate the posterior mean\", \"mathHtml\": \"\\( \\mathbb{E}[\\mu | x] = \\frac{\\int \\mu p(x | \\mu) p(\\mu) d\\mu}{\\int p(x | \\mu) p(\\mu) d\\mu} \\)\", \"explanation\": \"We take the weighted average of our prior mean and the observed data.\"}, {\"stepNumber\": 4, \"description\": \"Calculate the MAP estimate\", \"mathHtml\": \"\\( \\text{MAP} = \\arg\\max_p p(\\mu | x) \\)\", \"explanation\": \"We find the value that maximizes the posterior probability.\"} ],",
    "finalAnswer": "The estimated mean is approximately 2.5.\" },",
    "intuition": "Bayesian point estimation helps us incorporate prior knowledge and update it based on new data.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:31:15.621Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_bayesian_estimation_014",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "bayesian_statistics",
    "topic": "bayesian_estimation",
    "title": "Bayesian Point Estimation: Posterior Mean and MAP",
    "contentHtml": "<p>In Bayesian statistics, we often want to estimate parameters of a model based on observed data.</p><ul><li>We'll explore two common methods for point estimation: the posterior mean and maximum a posteriori (MAP).</li></ul>",
    "problem": "{",
    "statementHtml": "<p>Suppose we have a normal distribution with unknown mean μ and known variance σ^2. We observe n data points x_1, ..., x_n. Find the Bayesian point estimate for μ.</p>",
    "hints": [
      "Consider the prior distribution of μ",
      "Think about how to incorporate the observed data"
    ],
    "solutionHtml": "<p>We'll use a conjugate prior for μ, such as a normal distribution with mean 0 and variance τ^2. The posterior distribution is also normal:</p><p>\\[p(\\mu | x) = \\mathcal{N}(\\mu | \\bar{x}, \\frac{\\tau^2}{n + \\tau^2})\\]</p>\",",
    "answerShort": "The Bayesian point estimate for μ is the mean of the posterior distribution, which is \\(\\bar{x}\\).\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a normal distribution with unknown mean μ and known variance σ^2. We observe two data points x_1 = 3 and x_2 = 5. Find the Bayesian point estimate for μ using a prior distribution with mean 0 and variance 4.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Specify the prior distribution\", \"mathHtml\": \"\\[p(\\mu) = \\mathcal{N}(\\mu | 0, 4)\\]\", \"explanation\": \"We choose a conjugate prior that is also normal.\"}, {\"stepNumber\": 2, \"description\": \"Update the prior with the observed data\", \"mathHtml\": \"\\[p(\\mu | x) = \\mathcal{N}(\\mu | \\frac{\\tau^2\\bar{x}}{n + \\tau^2}, \\frac{\\tau^2}{n + \\tau^2})\\]\", \"explanation\": \"We use Bayes' theorem to update the prior with the likelihood of the observed data.\"}, {\"stepNumber\": 3, \"description\": \"Find the posterior mean\", \"mathHtml\": \"\\[\\bar{x} = \\frac{\\tau^2\\bar{x}}{n + \\tau^2}\\]\", \"explanation\": \"The posterior mean is simply the weighted average of the prior mean and the observed data.\"}, {\"stepNumber\": 4, \"description\": \"Find the MAP estimate\", \"mathHtml\": \"\\[p(\\mu | x) = \\mathcal{N}(\\mu | 3.5, 0.25)\\]\", \"explanation\": \"The MAP estimate is the value of μ that maximizes the posterior distribution.\"}, {\"stepNumber\": 5, \"description\": \"Compare the two estimates\", \"mathHtml\": \"\", \"explanation\": \"We can see that both estimates are close to each other, but the MAP estimate is slightly more precise due to its concentration around a single value.\"} ],",
    "finalAnswer": "The Bayesian point estimate for μ is approximately 3.5.\" },",
    "intuition": "Bayesian point estimation provides a way to incorporate prior knowledge and observed data to make informed decisions.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:31:53.587Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]