[
  {
    "id": "stat_con_computational_bayes_001",
    "subject": "statistics",
    "type": "concept",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Computational Bayes: Grid Approximation and MCMC",
    "contentHtml": "<p>In traditional Bayesian inference, we often rely on conjugate priors or approximate methods to simplify complex computations. Computational Bayes takes a different approach by using grid approximation and Markov Chain Monte Carlo (MCMC) methods to perform Bayesian inference directly.</p><p>Grid approximation involves discretizing the parameter space into a finite grid of points, allowing us to evaluate the posterior distribution at each point. MCMC methods, such as Gibbs sampling or Metropolis-Hastings, then help us navigate this grid and approximate the true posterior distribution.</p>",
    "formula": {
      "latex": "\\[ p(x|y) = \\frac{p(y|x)p(x)}{p(y)} \\]",
      "name": "Bayes' theorem"
    },
    "intuition": "The key insight is that grid approximation and MCMC methods allow us to perform Bayesian inference in high-dimensional spaces, making them particularly useful for complex models and large datasets.",
    "realWorldApplications": [
      "In machine learning, computational Bayes can be used for Bayesian neural networks and Gaussian process regression."
    ],
    "commonMistakes": [
      "Failing to understand the importance of careful grid selection in grid approximation"
    ],
    "estimatedMinutes": 2,
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:51:23.350Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_con_computational_bayes_002",
    "subject": "statistics",
    "type": "concept",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Computational Bayes: Grid Approximation and MCMC",
    "contentHtml": "<p>In traditional Bayesian statistics, we often rely on analytical solutions or numerical methods to compute posterior distributions. However, many problems require more complex computations that involve sampling from high-dimensional spaces.</p><p>Enter computational Bayes, which leverages grid approximation and Markov Chain Monte Carlo (MCMC) techniques to efficiently explore these spaces.</p>",
    "formula": {
      "latex": "\\[ \\text{Grid Approximation: } y \\approx \\sum_{i=1}^n w_i f(x_i) \\]",
      "name": "Grid Approximation"
    },
    "intuition": "The key insight is that by discretizing the space and approximating the posterior using a weighted sum of basis functions, we can efficiently compute complex Bayesian quantities.",
    "realWorldApplications": [
      "Bayesian optimization in ML/AI"
    ],
    "commonMistakes": [
      "Failing to recognize the limitations of analytical solutions",
      "Not considering the computational cost of numerical methods"
    ],
    "tags": [
      "computational Bayes",
      "grid approximation",
      "MCMC"
    ],
    "estimatedMinutes": 2,
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:51:38.644Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_con_computational_bayes_003",
    "subject": "statistics",
    "type": "concept",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Computational Bayes: Grid Approximation and MCMC",
    "contentHtml": "<p>In Bayesian statistics, we often face complex models that require efficient computational methods to estimate posterior distributions.</p><p>Grid approximation and Markov Chain Monte Carlo (MCMC) are two fundamental techniques used in computational Bayes to tackle these challenges.</p>",
    "formula": {
      "latex": "\\[ p(x|y) = \\frac{p(y|x)p(x)}{p(y)} \\]",
      "name": "Bayesian posterior distribution"
    },
    "intuition": "By approximating complex models with grids and using MCMC to sample from the posterior, we can efficiently explore high-dimensional spaces and make accurate predictions.",
    "realWorldApplications": [
      "In machine learning, grid approximation is used in Gaussian mixture models for clustering and density estimation."
    ],
    "commonMistakes": [
      "Failing to account for computational complexity when designing Bayesian models"
    ],
    "estimatedMinutes": 2,
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:51:52.236Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_computational_bayes_004",
    "subject": "statistics",
    "type": "formula",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Grid Approximation in Bayesian Inference",
    "contentHtml": "<p>Bayesian inference relies on approximating complex integrals using grid-based methods or Markov Chain Monte Carlo (MCMC) algorithms. This card focuses on the former, exploring how grids can be used to approximate posterior distributions.</p>",
    "formula": "{",
    "latex": "\\[P(\\theta | x) \\approx \\frac{1}{N} \\sum_{i=1}^N P(x | \\theta_i) P(\\theta_i)\\]\",",
    "name": "Grid Approximation Formula\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a dataset of exam scores, and we want to estimate the mean score using Bayesian inference. We can use grid approximation to approximate the posterior distribution.</p>",
    "steps": [
      {
        "stepNumber": 1,
        "description": "Define a grid of possible mean scores",
        "mathHtml": "",
        "explanation": "This is done by specifying a range of plausible values for the mean score."
      },
      {
        "stepNumber": 2,
        "description": "Calculate the likelihood and prior distributions on each grid point",
        "mathHtml": "",
        "explanation": "The likelihood distribution represents the probability of observing the data given different mean scores. The prior distribution represents our initial beliefs about the mean score."
      }
    ],
    "finalAnswer": "\" },",
    "intuition": "Grid approximation provides a simple and interpretable way to approximate complex posterior distributions, making it a useful tool in Bayesian inference.",
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:52:11.869Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_computational_bayes_005",
    "subject": "statistics",
    "type": "formula",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Grid Approximation in Bayesian Computation",
    "contentHtml": "<p>In Bayesian computation, grid approximation is a technique used to approximate complex integrals and distributions.</p><p>It's particularly useful when working with high-dimensional models or large datasets.</p>",
    "formula": "{",
    "latex": "\\[ \\int f(x) dx \\approx \\sum_{i=1}^N w_i f(x_i) \\]\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a simple Bayesian linear regression model with two features and a target variable.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Discretize the feature space into a grid of points\", \"mathHtml\": \"\\(x_1 \\in [0, 10], x_2 \\in [0, 5]\\)\", \"explanation\": \"This allows us to approximate the integral using a finite sum\"}, {\"stepNumber\": 2, \"description\": \"Evaluate the posterior distribution at each grid point\", \"mathHtml\": \"\\(p(\\theta | D) = \\frac{1}{Z} p(D | \\theta) p(\\theta)\\)\", \"explanation\": \"We can use MCMC or other methods to approximate this distribution\"} ],",
    "finalAnswer": "The approximated posterior distribution\" },",
    "intuition": "Grid approximation provides a way to trade off computational efficiency for accuracy in Bayesian computations.",
    "realWorldApplications": [
      "Bayesian neural networks",
      "Variational inference"
    ],
    "tags": [
      "bayes",
      "computation",
      "grid"
    ],
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:52:31.649Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_computational_bayes_006",
    "subject": "statistics",
    "type": "formula",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Grid Approximation in Bayesian Inference",
    "contentHtml": "<p>In Bayesian inference, we often need to approximate complex distributions using grid-based methods.</p><p>This approach is particularly useful when dealing with high-dimensional spaces or computationally expensive likelihood functions.</p>",
    "formula": "{",
    "latex": "\\[p(x | y) = \\frac{1}{Z} \\prod_{i=1}^n p(x_i | y, x_{<i})\\]\",",
    "name": "Grid Approximation Formula\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we want to approximate the posterior distribution of a Gaussian process given some noisy observations.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Discretize the input space into a grid\", \"mathHtml\": \"\\[x \\in [0, 1] \\rightarrow x \\approx \\{0.1, 0.2, ..., 0.9\\}\\]\", \"explanation\": \"This allows us to approximate the posterior using a product of conditional distributions\"} ],",
    "finalAnswer": "The approximated posterior distribution\" },",
    "intuition": "Grid approximation provides a way to trade off computational efficiency for accuracy in Bayesian inference.",
    "realWorldApplications": [
      "Bayesian optimization in hyperparameter tuning"
    ],
    "tags": [
      "grid approximation",
      "Bayesian inference",
      "MCMC"
    ],
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:52:49.716Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_computational_bayes_007",
    "subject": "statistics",
    "type": "formula",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Grid Approximation in Bayesian Inference",
    "contentHtml": "<p>In computational Bayes, grid approximation is a powerful technique to approximate complex distributions.</p><p>By discretizing the parameter space into a grid of points, we can efficiently evaluate and sample from the posterior distribution using Markov Chain Monte Carlo (MCMC) methods.</p>",
    "formula": "{",
    "latex": "\\[ p(\\theta | x) \\propto p(x | \\theta) \\cdot p(\\theta) \\]\",",
    "name": "Bayes' theorem\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a dataset of coin tosses, and we want to infer the probability of heads.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Define a grid of possible values for the coin's bias\", \"mathHtml\": \"\", \"explanation\": \"This represents our prior knowledge about the coin's behavior\"}, {\"stepNumber\": 2, \"description\": \"Evaluate the likelihood function at each grid point\", \"mathHtml\": \"\\[ p(x | \\theta) = \\prod_{i} \\text{Bernoulli}(x_i | \\theta) \\]\", \"explanation\": \"This represents the probability of observing our dataset given the coin's bias\"} ],",
    "finalAnswer": "The approximate posterior distribution\" },",
    "intuition": "Grid approximation allows us to trade off computational efficiency for accuracy in complex Bayesian inference problems.",
    "realWorldApplications": [
      "Inferring model parameters in machine learning models"
    ],
    "tags": [
      "Bayesian inference",
      "MCMC",
      "grid approximation"
    ],
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:53:10.264Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_computational_bayes_008",
    "subject": "statistics",
    "type": "problem",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "problem": "{",
    "statementHtml": "Given a probability density function <i>f(x)</i> and a set of observations <i>x</i>, use grid approximation to estimate the posterior distribution.",
    "hints": [
      "Start by discretizing the support of <i>f(x)</i>",
      "Use a uniform grid with <i>n</i> intervals",
      "Approximate the integral using the rectangle method"
    ],
    "solutionHtml": "<p>To begin, we divide the support of <i>f(x)</i> into <i>n</i> equal-sized intervals. Let <i>x_i</i> be the midpoint of the <i>i</i>-th interval.</p><p>We then approximate the integral using the rectangle method:</p>\\[\\int f(x) dx \\approx \\sum_{i=1}^n f(x_i) (x_{i+1}-x_i)\\]</p><p>Finally, we can use this approximation to estimate the posterior distribution.</p>\",",
    "answerShort": "The estimated posterior distribution is...\" },",
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:53:25.819Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_computational_bayes_009",
    "subject": "statistics",
    "type": "problem",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "problem": "{",
    "statementHtml": "<p>Use grid approximation to estimate the posterior distribution of a Bayesian model.</p>",
    "hints": [
      "Start by discretizing the prior and likelihood distributions.",
      "Consider using a uniform grid for simplicity.",
      "Think about how you can leverage the grid structure for efficient computation."
    ],
    "solutionHtml": "<p>To solve this problem, we'll use a uniform grid to approximate the posterior distribution. First, let's define our prior and likelihood distributions:</p>\\n\\[p(\\theta) = \\frac{1}{100} \\mathbf{1}_{[-5, 5]}(\\theta)\\]\\n\\n\\[p(y | \\theta) = \\prod_{i=1}^N \\mathcal{N}(y_i | \\theta, 1)\\]\\n<p>Next, we'll create a uniform grid with $M$ points in the range $[-5, 5]$:</p>\\n\\[\\theta_m = -5 + (m-1) \\cdot \\frac{10}{M-1}\\] for \\(m=1,\\ldots,M\\)\\n<p>Now we can approximate the posterior distribution using the grid values:</p>\\n\\[p(\\theta | y) \\approx \\frac{1}{M} \\sum_{m=1}^M p(y | \\theta_m) p(\\theta_m)\\]\\n<p>This is a basic example of grid approximation, which can be used as a starting point for more advanced methods like Markov chain Monte Carlo (MCMC).</p>\",",
    "answerShort": "The posterior distribution is approximated using the grid values.\" },",
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:53:47.475Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_computational_bayes_010",
    "subject": "statistics",
    "type": "problem",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "problem": "{",
    "statementHtml": "<p>Use grid approximation to estimate the posterior distribution of a parameter in a Bayesian model.</p>",
    "hints": [
      "Start by setting up the prior and likelihood distributions.",
      "Think about how you can use the grid to approximate the integral.",
      "Don't forget to normalize the resulting distribution."
    ],
    "solutionHtml": "<p>To solve this problem, we'll first set up our prior and likelihood distributions.</p>\\n\\ \\[p(\\theta) = \\mathcal{N}(\\mu_0, \\sigma_0^2)\\]\\n\\ \\[p(y|\\theta) = \\prod_{i=1}^n \\mathcal{N}(y_i | \\theta, \\sigma^2)\\]\\n\\ <p>Next, we'll use the grid approximation to estimate the posterior distribution.</p>\\n\\ \\[\\hat{p}(\\theta) = \\frac{1}{N}\\sum_{i=1}^N p(\\theta|\\mathbf{y})\\]\\n\\ <p>We can then use Markov chain Monte Carlo (MCMC) methods, such as Stan or PyMC, to sample from this posterior distribution.</p>\",",
    "answerShort": "The estimated posterior distribution is...\" },",
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:54:04.917Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_computational_bayes_011",
    "subject": "statistics",
    "type": "problem",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Grid Approximation in Bayesian Inference",
    "problem": "{",
    "statementHtml": "<p>Given a posterior distribution <i>p</i>(<i>θ</i>|<i>D</i>) and a grid of points {<i>θ</i><sub>i</sub>} with corresponding weights {<i>w</i><sub>i</sub>}, approximate the expected value of some function <i>f</i>(<i>θ</i>) using the grid approximation.</p>",
    "hints": [
      "<p>Start by calculating the weighted sum of the function values at each grid point.</p>",
      "<p>Use the weights to account for the relative importance of each grid point in the approximation.</p>",
      "<p>Compare your result with a Monte Carlo estimate using MCMC methods.</p>"
    ],
    "solutionHtml": "<p>To approximate the expected value, we calculate the weighted sum:</p>\\n\\ \\[ \\mathbb{E}[f(\\theta)] \\approx \\sum_{i} w_i f(\\theta_i) \\]\\n\\ <p>This is a simple and efficient way to approximate expectations in Bayesian inference.</p>\",",
    "answerShort": "The grid approximation\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a posterior distribution <i>p</i>(<i>θ</i>|<i>D</i>) and want to approximate the expected value of some function <i>f</i>(<i>θ</i>) using a grid with 100 points.</p>",
    "steps": "[ {",
    "stepNumber": 1,
    "description": "Calculate the weighted sum",
    "mathHtml": "\\[ \\sum_{i} w_i f(\\theta_i) \\]",
    "explanation": "We use the weights to account for the relative importance of each grid point.\" } ],",
    "finalAnswer": "The approximated expected value\" },",
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:54:28.910Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_computational_bayes_012",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Grid Approximation in Bayesian Inference",
    "contentHtml": "<p>In computational Bayes, we often rely on grid approximation to estimate posterior distributions.</p>",
    "problem": "{",
    "statementHtml": "<p>Suppose we have a Gaussian process prior with mean function <i>m(x)</i> and covariance function <i>k(x, x')</i>. We observe data points <i>y</i> = (<i>y<sub>1</sub></i>, ..., <i>y<sub>n</sub></i>). Find the posterior distribution over the hyperparameters.</p>",
    "hints": [
      "Hint: Use a grid to approximate the integral.",
      "Hint: Consider a Gaussian process prior."
    ],
    "solutionHtml": "<p>To solve this problem, we'll use grid approximation. First, we'll discretize the hyperparameter space using a grid...</p>\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose our prior is <i>N(0, 1)</i>, and we observe data points <i>y</i> = (2, 3). Find the posterior distribution over the mean hyperparameter.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Discretize the hyperparameter space\", \"mathHtml\": \"\\[ \\Delta x = \\frac{1}{10} \\]\", \"explanation\": \"We'll use a grid with 10 points to approximate the integral.\"}, {\"stepNumber\": 2, \"description\": \"Evaluate the prior and likelihood at each grid point\", \"mathHtml\": \"\\[ p(\\theta | y) = \\prod_{i=1}^n p(y_i | \\theta) \\]\", \"explanation\": \"We'll evaluate the prior and likelihood at each grid point to get a set of values.\"}, {\"stepNumber\": 3, \"description\": \"Compute the posterior at each grid point\", \"mathHtml\": \"\\[ p(\\theta | y) = \\frac{p(y | \\theta) p(\\theta)}{\\int p(y | \\theta) p(\\theta) d\\theta} \\]\", \"explanation\": \"We'll use Bayes' theorem to compute the posterior at each grid point.\"}, {\"stepNumber\": 4, \"description\": \"Interpolate the posterior values\", \"mathHtml\": \"\\[ p(\\theta | y) = \\sum_{i=1}^N w_i p(\\theta | y)_i \\]\", \"explanation\": \"We'll interpolate the posterior values to get a smooth distribution.\"} ],",
    "finalAnswer": "The final answer is...\" },",
    "intuition": "Grid approximation helps us avoid expensive computations and provides a good approximation of the true posterior.",
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:54:59.822Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_computational_bayes_013",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Grid Approximation in Bayesian Computation",
    "contentHtml": "<p>In this worked example, we'll explore grid approximation in Bayesian computation using Markov Chain Monte Carlo (MCMC) methods.</p>",
    "workedExample": "{",
    "problemHtml": "Suppose we want to estimate the probability density function (PDF) of a random variable <i>X</i> given some observed data.",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Define the grid\", \"mathHtml\": \"\\[ \\Delta x = \\frac{b-a}{N} \\]\", \"explanation\": \"We divide the support of <i>X</i> into <i>N</i> equal-sized intervals.\"}, {\"stepNumber\": 2, \"description\": \"Evaluate the likelihood function\", \"mathHtml\": \"\\[ p(x_i | \\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}} \\]\", \"explanation\": \"We calculate the likelihood of each data point given our model parameters.\"}, {\"stepNumber\": 3, \"description\": \"Compute the prior distribution\", \"mathHtml\": \"\\[ p(\\theta) = \\mathcal{N}(\\mu_0, \\sigma_0^2) \\]\", \"explanation\": \"We specify a prior distribution for our model parameters.\"}, {\"stepNumber\": 4, \"description\": \"Update the grid values using MCMC\", \"mathHtml\": \"\\[ \\theta^{n+1} = \\theta^n + \\epsilon \\cdot \\frac{\\partial}{\\partial \\theta} \\log p(x | \\theta) \\]\", \"explanation\": \"We use MCMC to update our model parameters based on the likelihood and prior.\"}, {\"stepNumber\": 5, \"description\": \"Estimate the PDF using grid values\", \"mathHtml\": \"\\[ p(x | \\theta) = \\frac{1}{N} \\sum_{n=1}^N \\delta(x - x_n) \\]\", \"explanation\": \"We use our updated model parameters to estimate the PDF at each grid point.\"} ],",
    "finalAnswer": "The estimated PDF is a discrete approximation of the true distribution.\" },",
    "intuition": "Grid approximation provides an efficient way to approximate complex distributions in Bayesian computation, especially when working with high-dimensional data.",
    "visualDescription": "A diagram showing the grid approximation process could include a plot of the observed data and the estimated PDF at each grid point.",
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:55:29.305Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_computational_bayes_014",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Grid Approximation in Bayesian Inference",
    "contentHtml": "<p>In this example, we'll demonstrate how to approximate a complex Bayesian inference problem using grid approximation.</p>",
    "workedExample": "{",
    "problemHtml": "Suppose we want to estimate the probability density function (PDF) of a two-dimensional random variable <i>X</i> = (<i>x</i>, <i>y</i>) given some observed data.",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Discretize the domain\", \"mathHtml\": \"\\[ X \\sim \\mathcal{U}([0,10] \\times [0,5]) \\]\", \"explanation\": \"We divide the domain into a grid of small rectangles to simplify the calculation.\"}, {\"stepNumber\": 2, \"description\": \"Define the prior\", \"mathHtml\": \"\\[ p(X) = \\prod_{i=1}^2 \\mathcal{N}(x_i | 0, 1) \\]\", \"explanation\": \"We choose a normal distribution as our prior for each dimension.\"}, {\"stepNumber\": 3, \"description\": \"Update the prior using Bayes' rule\", \"mathHtml\": \"\\[ p(X|y) = \\frac{p(y|X) p(X)}{\\int p(y|X) p(X) dX} \\]\", \"explanation\": \"We apply Bayes' rule to update our prior with the likelihood.\"}, {\"stepNumber\": 4, \"description\": \"Evaluate the posterior using grid approximation\", \"mathHtml\": \"\\[ p(X|y) \\approx \\frac{1}{N} \\sum_{i=1}^N I(X_i) \\]\", \"explanation\": \"We approximate the integral by summing over the grid points.\"}, {\"stepNumber\": 5, \"description\": \"Visualize and interpret the results\", \"mathHtml\": \"\", \"explanation\": \"We can visualize the posterior distribution using a heatmap or contour plot.\"} ],",
    "finalAnswer": "The resulting posterior PDF approximates the true distribution.\" },",
    "intuition": "Grid approximation is a simple yet effective way to approximate complex Bayesian inference problems.",
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:55:54.816Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_computational_bayes_015",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "bayesian_statistics",
    "topic": "computational_bayes",
    "title": "Grid Approximation in Bayesian Inference",
    "contentHtml": "<p>In this worked example, we'll demonstrate how to apply grid approximation to a Bayesian inference problem.</p>",
    "problem": "{",
    "statementHtml": "<p>Suppose we have a Gaussian distribution <span class='math'>\\(N(x | \\mu, \\sigma^2)\\)</span> with unknown mean <span class='math'>\\(\\mu\\)</span> and variance <span class='math'>\\(\\sigma^2\\)</span>. We observe <span class='math'>\\(x_1, x_2, ..., x_n\\)</span> and want to infer the posterior distribution of <span class='math'>\\(\\mu\\)</span>.</p>\",",
    "hints": [
      "Hint: Use grid approximation to approximate the integral"
    ],
    "solutionHtml": "<ul><li>We first specify a grid size <span class='math'>\\(M\\)</span> and define a set of discrete values for <span class='math'>\\(\\mu\\)</span>, denoted as <span class='math'>\\(\\{\\mu_1, ..., \\mu_M\\}\\)</span>.</li><li>We then compute the likelihood function <span class='math'>\\(p(x | \\mu_i)\\)</span> for each grid point <span class='math'>\\(\\mu_i\\)</span>, using the observed data <span class='math'>\\(x_1, ..., x_n\\)</span>.</li><li>We compute the prior distribution <span class='math'>\\(p(\\mu)\\)</span> and normalize it to get the posterior distribution <span class='math'>\\(p(\\mu | x)\\)</span> for each grid point.</li><li>We can now approximate the integral by summing over the discrete values of <span class='math'>\\(\\mu\\)</span>, weighted by their corresponding posterior probabilities.</li></ul>\",",
    "answerShort": "The answer is...\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a dataset <span class='math'>\\(x_1, x_2, ..., x_n\\)</span> with mean <span class='math'>\\(\\mu = 5\\)</span> and variance <span class='math'>\\(\\sigma^2 = 4\\)</span>. We want to infer the posterior distribution of <span class='math'>\\(\\mu\\)</span>.</p>\",",
    "steps": [
      {
        "stepNumber": 1,
        "description": "Define a grid size",
        "mathHtml": "",
        "explanation": "We choose a suitable grid size for our problem."
      },
      {
        "stepNumber": 2,
        "description": "Compute likelihood function",
        "mathHtml": "",
        "explanation": "We use the observed data to compute the likelihood function for each grid point."
      }
    ],
    "difficulty": 5,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T23:56:26.682Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]