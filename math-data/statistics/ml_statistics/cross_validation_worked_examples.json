[
  {
    "id": "stat_wex_cross_validation_013",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "ml_statistics",
    "topic": "cross_validation",
    "title": "Cross-Validation: K-Fold and Beyond",
    "contentHtml": "<p>In this worked example, we'll walk through a step-by-step solution to a cross-validation problem.</p>",
    "workedExample": "{",
    "problemHtml": "Suppose we have a dataset of 100 samples from two classes (A and B) with equal proportions. We want to evaluate the performance of a classifier using k-fold cross-validation.",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Split the data into training and testing sets\", \"mathHtml\": \"\", \"explanation\": \"This step is crucial in ensuring that our evaluation is unbiased.\"}, {\"stepNumber\": 2, \"description\": \"Choose a suitable value for k (e.g., k=5)\", \"mathHtml\": \"\", \"explanation\": \"A common choice is k=5 or k=10, depending on the size of the dataset and computational resources.\"}, {\"stepNumber\": 3, \"description\": \"Perform k-fold cross-validation\", \"mathHtml\": \"\\[ \\text{Accuracy} = \\frac{\\sum_{i=1}^k \\mathbf{1}_{\\hat{y}_i=y_i}}{n} \\]\", \"explanation\": \"We calculate the accuracy for each fold and then average them to get an overall estimate.\"}, {\"stepNumber\": 4, \"description\": \"Repeat steps 2-3 multiple times (e.g., 10 iterations) and report the mean accuracy\", \"mathHtml\": \"\", \"explanation\": \"This helps us account for any variability in our evaluation due to random fluctuations.\"} ],",
    "finalAnswer": "The final answer is the mean accuracy across all iterations.\" },",
    "intuition": "Cross-validation provides a way to evaluate model performance while avoiding overfitting by using unseen data during training.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:05:59.966Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_cross_validation_014",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "ml_statistics",
    "topic": "cross_validation",
    "title": "Solving Cross-Validation Problems",
    "contentHtml": "<p>In this worked example, we'll walk through a step-by-step solution to a cross-validation problem.</p>",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a dataset with 100 samples and want to evaluate the performance of a classifier using k-fold cross-validation. We set <i>k</i> = 5. How many training sets and test sets will we create?</p>",
    "steps": "[ {",
    "stepNumber": "3\",",
    "description": "Verify the calculation",
    "mathHtml": "\\[20 \\times 5 = 100\\]",
    "explanation": "We can verify our calculation by ensuring that the total number of samples (100) is equal to the sum of training and test sets.\" } ],",
    "finalAnswer": "We'll create 20 training sets and 20 test sets\" },",
    "intuition": "Cross-validation helps us evaluate a model's performance on unseen data by creating multiple training-test splits.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:06:20.942Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_cross_validation_015",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "ml_statistics",
    "topic": "cross_validation",
    "title": "Cross-Validation in Machine Learning",
    "contentHtml": "<p>Cross-validation is a crucial technique in machine learning to evaluate and improve model performance.</p>",
    "formula": "{",
    "latex": "\\\\[k\\\\text{-fold CV}: \\\\frac{1}{k} \\sum_{i=1}^k L(y, y_i)\\\\]\",",
    "name": "Cross-Validation Loss\" },",
    "problem": "{",
    "statementHtml": "<p>Suppose we have a dataset of 1000 samples, and we want to evaluate the performance of our logistic regression model. How can we use cross-validation to do this?</p>",
    "hints": [
      "Hint: Think about splitting the data into training and testing sets"
    ],
    "solutionHtml": "",
    "answerShort": "\" },",
    "workedExample": "{",
    "problemHtml": "<p>Let's say we have a dataset of 1000 samples, with features X1, X2, and target variable Y. We want to evaluate the performance of our logistic regression model.</p>",
    "steps": [
      {
        "stepNumber": 1,
        "description": "Split the data into training (80%) and testing sets",
        "mathHtml": "\\[\\frac{800}{1000}\\]",
        "explanation": "We need a representative sample for evaluation"
      },
      {
        "stepNumber": 2,
        "description": "Train the model on the training set",
        "mathHtml": "",
        "explanation": "This is where our model learns from the data"
      },
      {
        "stepNumber": 3,
        "description": "Evaluate the model's performance on the testing set",
        "mathHtml": "\\[L(y, y_i)\\]",
        "explanation": "We want to see how well our model generalizes to new data"
      },
      {
        "stepNumber": 4,
        "description": "Repeat steps 1-3 for multiple iterations (e.g., k-fold CV)",
        "mathHtml": "",
        "explanation": "This helps us account for overfitting and get a more accurate estimate of the model's performance"
      }
    ],
    "finalAnswer": "\" },",
    "intuition": "Cross-validation is like taking a snapshot of your model's performance at different points in time. By averaging these snapshots, you get a better sense of how well your model will perform on new data.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:06:47.920Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_cross_validation_016",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "ml_statistics",
    "topic": "cross_validation",
    "title": "Cross-Validation in Machine Learning",
    "contentHtml": "<p>Cross-validation is a crucial technique in machine learning to evaluate and improve model performance.</p>",
    "workedExample": "{",
    "problemHtml": "Suppose we have a dataset of 1000 images, each labeled as either 'dog' or 'cat'. We want to train a convolutional neural network (CNN) to classify these images. How can we ensure our model generalizes well to new, unseen data?",
    "steps": "[ {",
    "stepNumber": "4\",",
    "description": "Average the performance metrics across folds",
    "mathHtml": "\\[\\text{Mean Accuracy} = \\frac{1}{5} \\sum_{i=1}^5 \\text{Accuracy}_i\\]",
    "explanation": "By averaging our results, we're getting a more representative estimate of our model's performance.\" } ],",
    "finalAnswer": "The mean accuracy across the 5 folds is 0.85\" },",
    "intuition": "Cross-validation helps us avoid overfitting by testing our model on unseen data and averaging its performance.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:07:16.081Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_cross_validation_017",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "ml_statistics",
    "topic": "cross_validation",
    "title": "Cross-Validation: A Step-by-Step Guide",
    "contentHtml": "<p>Cross-validation is a crucial technique in machine learning that helps evaluate and improve model performance.</p>",
    "workedExample": "{",
    "problemHtml": "Suppose we have a dataset of 1000 images, each labeled as either 'dog' or 'cat'. We want to train a classifier to predict the animal type. However, we're concerned about overfitting due to the limited training data.",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Split the dataset into training and testing sets\", \"mathHtml\": \"\", \"explanation\": \"This is the first step in cross-validation.\"}, {\"stepNumber\": 2, \"description\": \"Choose a suitable k-fold strategy (e.g., k=5)\", \"mathHtml\": \"\\[k = 5\\]\", \"explanation\": \"A common choice for k is 5, as it provides a good balance between overfitting and underfitting.\"}, {\"stepNumber\": 3, \"description\": \"Train the classifier on each fold's training set\", \"mathHtml\": \"\", \"explanation\": \"This step helps us evaluate the model's performance on unseen data.\"}, {\"stepNumber\": 4, \"description\": \"Calculate the average accuracy across all folds\", \"mathHtml\": \"\", \"explanation\": \"The final answer is the average of these accuracies.\"} ],",
    "finalAnswer": "Average accuracy across all folds\" },",
    "intuition": "Cross-validation helps us avoid overfitting by evaluating our model on unseen data, which is crucial for machine learning applications.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:07:36.263Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]