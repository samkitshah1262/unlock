[
  {
    "id": "stat_con_ab_testing_001",
    "subject": "statistics",
    "type": "concept",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing: Design and Analysis",
    "contentHtml": "<p>A/B testing is a fundamental concept in statistical inference that helps us determine whether the difference between two groups (e.g., treatment vs. control) is statistically significant.</p><p>In machine learning, A/B testing is crucial for evaluating the performance of different models or hyperparameters.</p>",
    "formula": {
      "latex": "\\[\\text{H}_0: \\mu_1 = \\mu_2 \\\\ \\text{H}_a: \\mu_1 \\neq \\mu_2\\]",
      "name": "Null and Alternative Hypotheses"
    },
    "intuition": "A/B testing is about comparing two groups to determine if the difference is due to chance or a real effect. In machine learning, this helps us identify which model or hyperparameters perform better.",
    "realWorldApplications": [
      "Evaluating the effectiveness of different marketing campaigns"
    ],
    "commonMistakes": [
      "Failing to account for sequential testing",
      "Not considering the type I error rate"
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:20:11.727Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_con_ab_testing_002",
    "subject": "statistics",
    "type": "concept",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing: Design and Analysis",
    "contentHtml": "<p>A/B testing is a fundamental concept in statistical inference, crucial for making informed decisions in various fields, including machine learning.</p><p>Imagine you're a product manager at an e-commerce platform. You want to determine whether changing the color of your website's 'Add to Cart' button will increase conversions. A/B testing helps you answer this question by comparing the performance of two versions: the original (A) and the new (B).</p>",
    "formula": {
      "latex": "\\[\\text{Hypothesis Test}: H_0: \\mu_A = \\mu_B \\quad vs. \\quad H_1: \\mu_A \\neq \\mu_B\\]",
      "name": "Two-Sample Hypothesis Test"
    },
    "intuition": "A/B testing is about comparing two groups (e.g., users who see version A and those who see version B) to determine if there's a statistically significant difference between them.",
    "commonMistakes": [
      "Failing to account for confounding variables",
      "Not ensuring sufficient sample sizes"
    ],
    "realWorldApplications": [
      "Personalizing product recommendations based on user behavior",
      "Optimizing marketing campaigns"
    ],
    "tags": [
      "A/B testing",
      "statistical inference",
      "machine learning"
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:20:29.097Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_con_ab_testing_003",
    "subject": "statistics",
    "type": "concept",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing: Design and Analysis",
    "contentHtml": "<p>A/B testing is a fundamental concept in statistical inference that helps us determine whether two treatments have different effects on a population.</p><p>We'll explore how to design an A/B test, analyze the results, and avoid common pitfalls.</p>",
    "formula": {
      "latex": "\\(\\mathbf{X} = \\begin{bmatrix} x_1 & x_2 & \\cdots & x_n \\end{bmatrix}\\)",
      "name": "Treatment Matrix"
    },
    "intuition": "A/B testing is crucial in machine learning as it helps us evaluate the effectiveness of different models, features, or hyperparameters.",
    "realWorldApplications": [
      "Comparing the performance of two neural network architectures"
    ],
    "commonMistakes": [
      "Failing to account for confounding variables",
      "Not checking for normality assumptions"
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:20:42.420Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_ab_testing_004",
    "subject": "statistics",
    "type": "formula",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing Formula",
    "contentHtml": "<p>A/B testing is a crucial component in machine learning experimentation. The formula below helps you design and analyze your tests.</p>",
    "formula": "{",
    "latex": "\\[p(A|B) = \\frac{\\sum_{i=1}^{n_B} I(y_i=1)}{n_B}\\]\",",
    "name": "A/B Test Success Rate\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose you want to test the effectiveness of a new marketing campaign. You have two groups: one with the old campaign and another with the new campaign.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Count the number of positive responses in each group\", \"mathHtml\": \"\\[n_B\\]\", \"explanation\": \"This represents the number of people who responded positively to the new campaign\"}, {\"stepNumber\": 2, \"description\": \"Divide by the total number of people in the new campaign group\", \"mathHtml\": \"\\[\\frac{n_B}{n_B}\\]\", \"explanation\": \"This gives us the proportion of positive responses\"} ],",
    "finalAnswer": "The formula calculates the success rate of the new marketing campaign\" },",
    "intuition": "A/B testing helps you measure the effectiveness of different approaches by comparing their outcomes. This formula provides a straightforward way to calculate the success rate of your test.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:21:01.245Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_ab_testing_005",
    "subject": "statistics",
    "type": "formula",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing Formula",
    "contentHtml": "<p>A/B testing is a crucial component of machine learning experimentation. The formula below helps you design and analyze your tests.</p>",
    "formula": "{",
    "latex": "\\[p(A|B) = \\frac{p(B|A)p(A)}{p(B)}\\]\",",
    "name": "Bayes' theorem for A/B testing\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose you want to test the effectiveness of a new ad campaign. You have two groups: one with the new ad and one without.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Define the events\", \"mathHtml\": \"\\(A\\) is the event that the user clicks on the ad, \\(B\\) is the event that the user sees the new ad.\", \"explanation\": \"This helps us understand what we're measuring.\"}, {\"stepNumber\": 2, \"description\": \"Calculate the probabilities\", \"mathHtml\": \"\\(p(A|B) = \\frac{0.3}{0.5}\\)\", \"explanation\": \"We need to calculate the probability of a user clicking given they saw the new ad.\"} ],",
    "finalAnswer": "The answer is \\(p(A|B) = 0.6\\)\" },",
    "intuition": "A/B testing helps you measure the causal effect of an intervention (like a new ad). Bayes' theorem provides a way to update your beliefs about this effect given new data.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:21:20.660Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_ab_testing_006",
    "subject": "statistics",
    "type": "formula",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing Formula",
    "contentHtml": "<p>A/B testing is a crucial technique in machine learning to compare the performance of different models or variants.</p><p>The key formula is:</p>\\(\\hat{p}_1 - \\hat{p}_0 = \\frac{\\sum_{i=1}^n I(y_i=1|A_1)}{\\sqrt{n\\cdot \\hat{p}_0 \\cdot (1-\\hat{p}_0)}}\\)<p>where:</p><ul><li>\\(\\hat{p}_1\\) is the estimated proportion of positive outcomes for treatment A</li><li>\\(\\hat{p}_0\\) is the estimated proportion of positive outcomes for control B</li><li>n is the number of samples</li><li>I(y_i=1|A_1) is an indicator function that equals 1 if the ith sample has a positive outcome and was assigned to treatment A, and 0 otherwise</li></ul>\",",
    "formula": "{",
    "latex": "\\(\\hat{p}_1 - \\hat{p}_0 = \\frac{\\sum_{i=1}^n I(y_i=1|A_1)}{\\sqrt{n\\cdot \\hat{p}_0 \\cdot (1-\\hat{p}_0)}}\\)\",",
    "name": "A/B Testing Formula\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a dataset of user clicks on two different ads, A and B. We want to compare the conversion rates for each ad.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Calculate the estimated proportion of positive outcomes for each ad\", \"mathHtml\": \"\\(\\hat{p}_1 = \\frac{\\sum_{i=1}^n I(y_i=1|A_1)}{n}\\)\", \"explanation\": \"We use the sample mean to estimate the conversion rate\"}, {\"stepNumber\": 2, \"description\": \"Calculate the estimated proportion of positive outcomes for the control\", \"mathHtml\": \"\\(\\hat{p}_0 = \\frac{\\sum_{i=1}^n I(y_i=1|B_0)}{n}\\)\", \"explanation\": \"We use the sample mean to estimate the conversion rate\"} ],",
    "finalAnswer": "The estimated difference in conversion rates between ads A and B\" },",
    "intuition": "A/B testing helps us determine if the difference in conversion rates is statistically significant, allowing us to make informed decisions about which ad to prioritize.",
    "realWorldApplications": [
      "Comparing the effectiveness of different marketing campaigns"
    ],
    "tags": [
      "A/B Testing",
      "Machine Learning",
      "Statistics"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:21:51.206Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_for_ab_testing_007",
    "subject": "statistics",
    "type": "formula",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing Formula",
    "contentHtml": "<p>A/B testing is a crucial technique in machine learning to compare the performance of different models or treatments. The formula we'll explore today helps us calculate the statistical significance of our results.</p>",
    "formula": "{",
    "latex": "\\[ p = \\frac{1}{2} + \\frac{\\phi^{-1}(1 - \\alpha)}{2\\sqrt{n}} \\]\",",
    "name": "One-Sided Test Formula\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we want to compare the conversion rates of two marketing campaigns. We have a sample size of 1000 users and an alpha level of 0.05.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Calculate the standard normal distribution value\", \"mathHtml\": \"\\[ \\phi^{-1}(1 - \\alpha) \\]\", \"explanation\": \"This represents the number of standard deviations from the mean required to achieve our desired level of significance.\"} ],",
    "finalAnswer": "The answer\" },",
    "intuition": "This formula helps us determine when the difference between our two groups is statistically significant, allowing us to make informed decisions about which campaign performs better.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:22:07.934Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_ab_testing_008",
    "subject": "statistics",
    "type": "problem",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "problem": "{",
    "statementHtml": "In an A/B testing scenario, a company wants to determine if a new marketing campaign is more effective than their current one. They have two groups: Group A receives the new campaign, and Group B receives the current campaign. Assuming equal sample sizes, what is the minimum number of observations required for each group to detect a statistically significant difference in conversion rates with a 95% confidence level?",
    "hints": [
      "Start by determining the required effect size.",
      "Use the formula for calculating the sample size for two-sample proportions tests.",
      "Consider using sequential testing to reduce the overall sample size."
    ],
    "solutionHtml": "\\[Let's assume we want to detect a difference of 5% in conversion rates. Using the formula for calculating the sample size for two-sample proportions tests, we get...\\] (steps omitted for brevity)\",",
    "answerShort": "At least 384 observations per group\" },",
    "commonMistakes": [
      "Not considering the effect size",
      "Using a non-parametric test when the data is continuous"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:22:22.941Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_ab_testing_009",
    "subject": "statistics",
    "type": "problem",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing: Design and Analysis",
    "problem": {
      "statementHtml": "<p>Design an A/B testing experiment to determine if a new marketing campaign is effective.</p>",
      "hints": [
        "Start by defining the null and alternative hypotheses.",
        "Choose a suitable statistical test for this problem.",
        "Consider how you will handle confounding variables."
      ],
      "solutionHtml": "<p>To design an A/B testing experiment, we need to define the null and alternative hypotheses. Let's say our null hypothesis is that the new marketing campaign has no significant impact on sales (H<sub>0</sub>: μ<sub>A</sub> = μ<sub>B</sub>). Our alternative hypothesis is that the new marketing campaign has a significant positive impact on sales (H<sub>1</sub>: μ<sub>A</sub> > μ<sub>B</sub>). We will use a two-sample t-test to analyze the results.</p><p>We will randomly assign half of our customers to the treatment group and the other half to the control group. This way, we can compare the average sales for each group.</p>",
      "answerShort": "Two-sample t-test"
    },
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:22:38.388Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_ab_testing_010",
    "subject": "statistics",
    "type": "problem",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "problem": "{",
    "statementHtml": "<p>Design an A/B testing experiment to measure the effect of a new feature on user engagement.</p>",
    "hints": [
      "Start by defining the null and alternative hypotheses.",
      "Consider how you will collect data (e.g., randomize users into treatment and control groups).",
      "Think about how you will analyze the results (e.g., calculate the difference in means between groups)"
    ],
    "solutionHtml": "<p>To solve this problem, we need to specify the null and alternative hypotheses.</p>\\n<p>\\(H_0: \\mu_A = \\mu_B\\)</p>\\n<p>\\(H_a: \\mu_A > \\mu_B\\)</p>\\n<p>Next, we will design a randomized experiment with two groups: A (treatment) and B (control).</p>\\n<p>We will collect data by randomly assigning users to either group.</p>\\n<p>To analyze the results, we can calculate the difference in means between the two groups:</p>\\n<p>\\(\\bar{x}_A - \\bar{x}_B\\)</p>\",",
    "answerShort": "The null hypothesis is rejected if the p-value is below a certain significance level.\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:22:55.694Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_ab_testing_011",
    "subject": "statistics",
    "type": "problem",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "problem": {
      "statementHtml": "<p>Design an A/B testing experiment to compare the conversion rates of two different product offers.</p>",
      "hints": [
        "Start by defining the null and alternative hypotheses.",
        "Consider using a sequential testing approach to optimize the experiment's duration.",
        "Think about how you'll measure the conversion rate and calculate the sample size."
      ],
      "solutionHtml": "<p>To design an A/B testing experiment, we first need to define the null and alternative hypotheses. Let <i>p</i><sub>A</sub> be the true conversion rate of offer A, and <i>p</i><sub>B</sub> be the true conversion rate of offer B. The null hypothesis is that the two offers have equal conversion rates (<i>H<sub>0</sub></i>: <i>p</i><sub>A</sub> = <i>p</i><sub>B</sub>). The alternative hypothesis is that one offer has a higher conversion rate than the other (<i>H<sub>1</sub></i>: <i>p</i><sub>A</sub> ≠ <i>p</i><sub>B</sub>). We'll use a sequential testing approach to optimize the experiment's duration.</p>",
      "answerShort": "The null and alternative hypotheses are defined, and a sequential testing approach is chosen."
    },
    "commonMistakes": [
      "Failing to define clear null and alternative hypotheses.",
      "Not considering a sequential testing approach to optimize the experiment's duration."
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:23:14.199Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_ab_testing_012",
    "subject": "statistics",
    "type": "problem",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "problem": "{",
    "statementHtml": "An e-commerce company wants to test whether a new product page design increases conversions. Design an A/B testing plan with a sample size of 1000 users.",
    "hints": [
      "Start by defining the null and alternative hypotheses",
      "Choose a suitable statistical test for this problem",
      "Consider how you'll handle unequal group sizes"
    ],
    "solutionHtml": "<p>Let's assume we want to detect a 5% increase in conversions with a power of 80%. We can set up the hypotheses as:</p>\\(\\mathbf{H}_0: p_1 = p_2 \\quad \\text{vs.} \\quad \\mathbf{H}_a: p_1 > p_2\\)<p>where \\(p_1\\) and \\(p_2\\) are the conversion rates for the old and new designs, respectively.</p><p>We can use a two-sample proportion test to compare the conversion rates. Since we want to detect a 5% increase, we'll need a sufficient sample size to achieve this power.</p>\",",
    "answerShort": "Sample size: approximately 1200 users\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:23:30.891Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_ab_testing_013",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing: Design and Analysis",
    "problem": "{",
    "statementHtml": "Suppose we want to test whether a new button design increases conversions on our website. We have two versions of the button: A (old) and B (new). We randomly assign users to one of these groups, with 50% going to each group. After collecting data, we find that 200 out of 500 users in group A converted, while 250 out of 500 users in group B converted. Can we conclude that the new button design is better?",
    "hints": [
      "Think about what 'better' means",
      "Consider the sample size"
    ],
    "solutionHtml": "",
    "answerShort": "\" },",
    "workedExample": "{",
    "problemHtml": "Let's analyze this data step-by-step.",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Calculate the conversion rates for each group\", \"mathHtml\": \"\\(\\frac{200}{500} = 0.4\\) and \\(\\frac{250}{500} = 0.5\\)\", \"explanation\": \"We're calculating the proportion of users who converted in each group.\" }, {\"stepNumber\": 2, \"description\": \"Calculate the difference in conversion rates\", \"mathHtml\": \"\\(0.5 - 0.4 = 0.1\\)\", \"explanation\": \"This is the 'effect size' we're interested in.\" }, {\"stepNumber\": 3, \"description\": \"Check if the difference is statistically significant\", \"mathHtml\": \"\", \"explanation\": \"We can use a two-sample proportion test or a confidence interval to determine if this difference is due to chance or not.\" }, {\"stepNumber\": 4, \"description\": \"Interpret the results\", \"mathHtml\": \"\", \"explanation\": \"If the p-value is below our significance level (e.g., 0.05), we can conclude that the new button design has a statistically significant impact on conversions.\" } ],",
    "finalAnswer": "\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:23:55.362Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_ab_testing_014",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing: Design and Analysis",
    "problem": "{",
    "statementHtml": "Suppose we want to compare the conversion rates of two versions of a website's landing page.",
    "hints": [
      "Determine the null hypothesis",
      "Choose an appropriate test statistic"
    ],
    "solutionHtml": "<p>To design an A/B testing experiment, we need to specify the null and alternative hypotheses.</p>",
    "answerShort": "H0: p1 = p2 vs. H1: p1 ≠ p2\" },",
    "workedExample": "{",
    "problemHtml": "<p>We want to compare the conversion rates of two versions of a website's landing page.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Specify the null and alternative hypotheses\", \"mathHtml\": \"\\(H_0: p_1 = p_2\\) vs. \\(H_1: p_1 \\neq p_2\\)\", \"explanation\": \"We want to test whether there's a significant difference in conversion rates between the two versions.\"}, {\"stepNumber\": 2, \"description\": \"Choose an appropriate test statistic\", \"mathHtml\": \"\\[t = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p}\\]\", \"explanation\": \"We'll use the Welch's t-test to compare the means of the two groups.\"}, {\"stepNumber\": 3, \"description\": \"Calculate the sample sizes\", \"mathHtml\": \"\\(n_1 = 100\\), \\(n_2 = 100\\)\", \"explanation\": \"Assuming equal sample sizes for simplicity.\"}, {\"stepNumber\": 4, \"description\": \"Perform the t-test\", \"mathHtml\": \"\\[t = -2.5, p-value = 0.012\\]\", \"explanation\": \"We'll use a significance level of 0.05 and reject the null hypothesis if the p-value is below this threshold.\"}, {\"stepNumber\": 5, \"description\": \"Interpret the results\", \"mathHtml\": \"\", \"explanation\": \"Since the p-value is below our threshold, we can conclude that there's a statistically significant difference in conversion rates between the two versions.\"} ],",
    "finalAnswer": "Reject H0: p1 = p2\" },",
    "intuition": "A/B testing helps us identify which version of a product or service performs better.",
    "commonMistakes": [
      "Not accounting for sequential effects",
      "Incorrectly interpreting the results"
    ],
    "realWorldApplications": [
      "Improving conversion rates in e-commerce",
      "Optimizing marketing campaigns"
    ],
    "tags": [
      "A/B Testing",
      "Hypothesis Testing"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:24:25.452Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_ab_testing_015",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing: Design and Analysis",
    "contentHtml": "<p>A/B testing is a fundamental concept in machine learning, allowing us to evaluate the effectiveness of different treatments or features.</p>",
    "problem": {
      "statementHtml": "Suppose we want to compare the conversion rates of two website designs. We have 1000 users and can randomly assign them to either design A or design B.",
      "hints": [
        "Make sure to account for any biases in the assignment process",
        "Use a significance level of 0.05"
      ],
      "solutionHtml": "<p>We'll use a two-sample proportion test to compare the conversion rates.</p>",
      "answerShort": "Reject the null hypothesis if p-value < 0.05"
    },
    "workedExample": {
      "problemHtml": "Assume we have the following data: design A has 80 conversions out of 500 users, while design B has 90 conversions out of 500 users.",
      "steps": [
        {
          "stepNumber": 1,
          "description": "Calculate the sample proportions",
          "mathHtml": "\\[p_A = \\frac{80}{500}, p_B = \\frac{90}{500}\\]",
          "explanation": "We need to calculate the proportion of conversions for each design"
        },
        {
          "stepNumber": 2,
          "description": "Calculate the standard error",
          "mathHtml": "\\[SE = \\sqrt{\\frac{(p_A + p_B) (1 - (p_A + p_B))}{500}}\\]",
          "explanation": "We need to calculate the standard error for each design"
        },
        {
          "stepNumber": 3,
          "description": "Calculate the test statistic",
          "mathHtml": "\\[z = \\frac{p_B - p_A}{SE}\\]",
          "explanation": "The test statistic is the difference between the two proportions divided by the standard error"
        },
        {
          "stepNumber": 4,
          "description": "Determine the p-value",
          "mathHtml": "\\[p-value = P(Z &lt; z)\\]",
          "explanation": "We need to determine the probability of observing a test statistic at least as extreme as the one we calculated"
        }
      ],
      "finalAnswer": "Reject the null hypothesis if p-value < 0.05"
    },
    "intuition": "A/B testing is all about comparing two groups and determining if there's a statistically significant difference between them.",
    "visualDescription": "A simple bar chart showing the conversion rates for each design",
    "commonMistakes": [
      "Forgetting to account for biases in the assignment process",
      "Not using a significance level"
    ],
    "realWorldApplications": [
      "Comparing the effectiveness of different marketing campaigns",
      "Evaluating the impact of new product features"
    ],
    "tags": [
      "A/B testing",
      "machine learning",
      "statistics"
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:24:56.946Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_ab_testing_016",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing: Design and Analysis",
    "contentHtml": "<p>A/B testing is a fundamental concept in statistics and machine learning, allowing us to compare the performance of different versions of a product or service.</p>",
    "problem": "{",
    "statementHtml": "Suppose we want to test whether a new website design increases conversions compared to the current design. We have 1000 users per day and want to detect a 5% increase in conversions.",
    "hints": [
      "Consider the power of the test",
      "Think about the null hypothesis"
    ],
    "solutionHtml": "<p>We need to decide on a sample size, alpha level, and power for our A/B test. Let's assume we want a 90% chance to detect a 5% increase in conversions.</p>",
    "answerShort": "What would be an appropriate sample size?\" },",
    "workedExample": "{",
    "problemHtml": "<p>Design an A/B testing experiment with the following specifications:</p><ul><li>Null hypothesis: The new design does not increase conversions</li><li>Alternative hypothesis: The new design increases conversions by at least 5%</li><li>Alpha level: 0.05</li><li>Power: 90%</li></ul>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Calculate the required sample size\", \"mathHtml\": \"\\\\[n = \\\\frac{(Z_{\\\\alpha/2} + Z_\\\\beta)^2 \\* (1 - p) \\* p}{(p_0 - p_1)^2}\\]\", \"explanation\": \"We use the formula for calculating the sample size in an A/B test\"}, {\"stepNumber\": 2, \"description\": \"Determine the number of users per group\", \"mathHtml\": \"\\\\[n_1 = n_2 = \\\\frac{n}{2}\\]\", \"explanation\": \"Since we want to compare two groups, we divide the total sample size by 2\"}, {\"stepNumber\": 3, \"description\": \"Calculate the expected conversion rates for each group\", \"mathHtml\": \"\\\\[p_0 = 0.05, p_1 = 0.10\\]\", \"explanation\": \"We assume a baseline conversion rate of 5% and an increased conversion rate of 10%\"}, {\"stepNumber\": 4, \"description\": \"Calculate the test statistic\", \"mathHtml\": \"\\\\[t = \\\\frac{(p_1 - p_0)}{\\\\sqrt{\\\\frac{(p_0 + p_1)}{2} \\* (1 - p_0 - p_1)}}\\]\", \"explanation\": \"We calculate the test statistic to compare the conversion rates between groups\"} ],",
    "finalAnswer": "What would be an appropriate sample size?\" },",
    "intuition": "A/B testing is a powerful tool for evaluating the effectiveness of different designs or treatments. By carefully designing and analyzing the experiment, we can make data-driven decisions with confidence.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:25:30.485Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_wex_ab_testing_017",
    "subject": "statistics",
    "type": "worked_example",
    "chapter": "ml_statistics",
    "topic": "ab_testing",
    "title": "A/B Testing: Design and Analysis",
    "problem": "{",
    "statementHtml": "<p>Suppose you're a product manager at an e-commerce company, and you want to test whether a new button design increases conversion rates.</p>",
    "hints": [
      "Define the null hypothesis",
      "Choose a suitable statistical test"
    ],
    "solutionHtml": "",
    "answerShort": "\" },",
    "workedExample": "{",
    "problemHtml": "<p>Design an A/B testing experiment to compare the conversion rate of two different button designs for a new product launch.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Specify the null and alternative hypotheses\", \"mathHtml\": \"\\\\(H_0: p_1 = p_2\\\\) vs. \\\\(H_a: p_1 > p_2\\\\)\", \"explanation\": \"We want to test whether the new button design increases conversion rates.\"}, {\"stepNumber\": 2, \"description\": \"Choose a suitable statistical test\", \"mathHtml\": \"\\\\[t = \\frac{p_1 - p_2}{\\sqrt{\\frac{p_1(1-p_1) + p_2(1-p_2)}{n}}\\\\]\", \"explanation\": \"The Welch's t-test is suitable for this problem.\"}, {\"stepNumber\": 3, \"description\": \"Calculate the sample sizes\", \"mathHtml\": \"\\\\[n = 1000, m = 500\\\\]\", \"explanation\": \"We need to determine the required sample size for each group.\"}, {\"stepNumber\": 4, \"description\": \"Interpret the results\", \"mathHtml\": \"\", \"explanation\": \"If the p-value is below a certain significance level (e.g., 0.05), we reject the null hypothesis and conclude that the new button design increases conversion rates.\"} ],",
    "finalAnswer": "\" },",
    "intuition": "A/B testing helps you make data-driven decisions by comparing the performance of different designs or treatments.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-28T00:25:54.393Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]