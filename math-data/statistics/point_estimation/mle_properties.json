[
  {
    "id": "stat_con_mle_properties_001",
    "subject": "statistics",
    "type": "concept",
    "chapter": "point_estimation",
    "topic": "mle_properties",
    "title": "Properties of Maximum Likelihood Estimators (MLEs)",
    "contentHtml": "<p>Maximum likelihood estimators (MLEs) are widely used in statistical inference and machine learning. However, not all MLEs share certain desirable properties. In this card, we'll explore the key characteristics of MLEs: invariance, consistency, asymptotic normality, and efficiency.</p>",
    "formula": "{",
    "latex": "\\( \\text{MLE} = \\arg\\max_{\\theta} p(X | \\theta) \\)\",",
    "name": "MLE Definition\" },",
    "intuition": "Understanding the properties of MLEs is crucial in statistical inference and machine learning, as they provide a way to make informed decisions about the underlying distribution.",
    "visualDescription": "A diagram showing the relationship between the likelihood function and the MLE could help illustrate these concepts.",
    "commonMistakes": [
      "Assuming all MLEs are efficient",
      "Failing to consider asymptotic normality"
    ],
    "realWorldApplications": [
      "Estimating model parameters in neural networks",
      "Inferring population means from sample data"
    ],
    "tags": [
      "statistical inference",
      "machine learning",
      "MLE"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:41:39.392Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_con_mle_properties_002",
    "subject": "statistics",
    "type": "concept",
    "chapter": "point_estimation",
    "topic": "mle_properties",
    "title": "Properties of Maximum Likelihood Estimators (MLEs)",
    "contentHtml": "<p>Maximum likelihood estimators (MLEs) are widely used in statistical inference due to their desirable properties. In this concept card, we'll explore the key characteristics of MLEs: invariance, consistency, asymptotic normality, and efficiency.</p>",
    "formula": "{",
    "latex": "\\( \\mathbf{x} \\sim f(\\mathbf{x}; \\theta) \\)\",",
    "name": "ML Estimator\" },",
    "intuition": "MLEs are attractive because they're often easy to compute and provide a natural way to make inferences about unknown parameters. However, their properties ensure that we can trust the results.",
    "visualDescription": "A diagram showing the relationship between the likelihood function and the MLE would help illustrate the concept.",
    "commonMistakes": [
      "Failing to recognize that MLEs are not always unique"
    ],
    "realWorldApplications": [
      "Machine learning models, such as neural networks, often rely on MLEs for parameter estimation."
    ],
    "tags": [
      "statistical inference",
      "maximum likelihood estimation"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:41:54.530Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_con_mle_properties_003",
    "subject": "statistics",
    "type": "concept",
    "chapter": "point_estimation",
    "topic": "mle_properties",
    "title": "Properties of Maximum Likelihood Estimators (MLEs)",
    "contentHtml": "<p>In statistics, we often encounter estimation problems where we need to find the best possible estimate of a parameter based on observed data. One popular method is the maximum likelihood estimator (MLE), which chooses the value that maximizes the probability of observing the given data.</p><p>However, not all MLEs are created equal. In this concept card, we'll explore four essential properties of MLEs: invariance, consistency, asymptotic normality, and efficiency.</p>",
    "formula": {
      "latex": "\\[\\text{MLE} = \\arg\\max_\\theta p(X | \\theta) \\]",
      "name": "Maximum Likelihood Estimator"
    },
    "intuition": "These properties ensure that MLEs are reliable, accurate, and efficient in estimating parameters. Invariance means the estimator is unaffected by transformations of the data or model. Consistency guarantees that the estimator converges to the true value as the sample size increases. Asymptotic normality implies that the estimator's distribution approaches a normal distribution for large samples. Efficiency measures how well an estimator performs relative to others.",
    "realWorldApplications": [
      "In machine learning, MLEs are used in algorithms like expectation-maximization (EM) and variational inference."
    ],
    "commonMistakes": [
      "Failing to account for transformations or model changes can lead to inconsistent or inefficient estimators."
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:42:12.792Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_thm_mle_properties_004",
    "subject": "statistics",
    "type": "theorem",
    "chapter": "point_estimation",
    "topic": "mle_properties",
    "title": "Properties of Maximum Likelihood Estimators (MLEs)",
    "contentHtml": "<p>In statistics, MLEs are widely used to estimate parameters in probability distributions.</p><p>This theorem provides fundamental properties that ensure the reliability and accuracy of these estimates.</p>",
    "formula": "{",
    "latex": "\\\\[ \\det(A) = \\\\sum_{\\\\sigma} \\\\text{sgn}(\\\\sigma) \\\\prod_{i} a_{i,\\\\sigma(i)} \\\\]\",",
    "name": "MLE Properties\" },",
    "theorem": "{",
    "statement": "\\[ \\textbf{Theorem: } The MLE is invariant under reparameterization. It is consistent if the true parameter belongs to the interior of the parameter space. Asymptotically, it is normally distributed with mean equal to the true parameter and variance inversely proportional to the Fisher information. Finally, it is efficient among all regular estimators. \\]",
    "proofSketch": "The proof involves showing that the MLE is a consistent estimator using the law of large numbers, then demonstrating its asymptotic normality by applying the central limit theorem.\" },",
    "intuition": "These properties ensure that MLEs are robust and accurate in estimating parameters. Invariance means the estimate doesn't change under different parameterizations. Consistency guarantees it converges to the true value as the sample size increases. Asymptotic normality provides a distribution for the estimate, while efficiency ensures it's the best possible among all regular estimators.",
    "realWorldApplications": [
      "In machine learning, MLEs are used in various algorithms, such as logistic regression and neural networks."
    ],
    "tags": [
      "MLE",
      "statistical inference"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:42:33.604Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_thm_mle_properties_005",
    "subject": "statistics",
    "type": "theorem",
    "chapter": "point_estimation",
    "topic": "mle_properties",
    "title": "Properties of Maximum Likelihood Estimators (MLEs)",
    "contentHtml": "<p>A fundamental concept in statistical inference is the maximum likelihood estimator (MLE), which chooses the value that maximizes the probability of observing the data.</p><p>In this card, we explore three essential properties of MLEs: invariance, consistency, asymptotic normality, and efficiency.</p>",
    "formula": {
      "latex": "\\[ P(X | \\theta) = \\frac{1}{Z} e^{\\theta^T X} \\]",
      "name": "Likelihood function"
    },
    "theorem": {
      "statement": "\\[ \\text{Invariance: } \\hat{\\theta}(X) = g(\\hat{\\theta}(g^{-1}(X))) \\\\ \\text{Consistency: } P(Lim_{n \\to \\infty} \\hat{\\theta}_n = \\theta | X_1, \\ldots, X_n) = 1 \\\\ \\text{Asymptotic Normality: } \\sqrt{n} (\\hat{\\theta}_n - \\theta) \\xrightarrow{d} N(0, I^{-1}) \\\\ \\text{Efficiency: } \\frac{1}{n} \\sum_{i=1}^n X_i \\geq \\frac{1}{2n} \\sum_{i=1}^n X_i^2 \\]",
      "proofSketch": "The invariance property follows from the fact that MLEs are invariant to reparameterizations. Consistency is proven by showing that the likelihood function converges to a delta function at the true parameter value. Asymptotic normality is established using the central limit theorem and Taylor series expansions. Efficiency is demonstrated by comparing the variance of the MLE with that of an alternative estimator."
    },
    "intuition": "These properties ensure that MLEs are robust, reliable, and efficient in estimating parameters from data.",
    "realWorldApplications": [
      "In machine learning, MLEs are used to estimate model parameters, such as weights and biases in neural networks."
    ],
    "tags": [
      "MLE",
      "statistical inference"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:42:58.772Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_mle_properties_006",
    "subject": "statistics",
    "type": "problem",
    "chapter": "point_estimation",
    "topic": "mle_properties",
    "problem": "{",
    "statementHtml": "<p>Let X<sub>1</sub>, ..., X<sub>n</sub> be a random sample from a population with probability density function (PDF) f(x; θ). Prove that the Maximum Likelihood Estimator (MLE) of θ is invariant under one-to-one transformations.</p>",
    "hints": [
      "<p>The MLE is defined as the value of θ that maximizes the likelihood function L(θ|x<sub>1</sub>, ..., x<sub>n</sub>). Show that this definition remains unchanged when applying a one-to-one transformation to X.</p>",
      "<p>Use the fact that the likelihood function is a product of terms, each depending only on the corresponding data point. Then, apply the chain rule for differentiation.</p>",
      "<p>Show that the logarithmic derivative of L(θ|x) with respect to θ is invariant under the transformation.</p>"
    ],
    "solutionHtml": "<p>To prove invariance, we need to show that the MLE remains unchanged when applying a one-to-one transformation T(x). Let y = T(x), and denote the PDF of Y by f(y; θ).</p><p>The likelihood function L(θ|y) is given by:</p>\\[\\prod_{i=1}^{n} f(T^{-1}(y_i); \\theta)\\] <p>Take the logarithmic derivative with respect to θ:</p>\\[\\frac{\\partial}{\\partial \\theta} \\log L(\\theta|y) = \\sum_{i=1}^{n} \\frac{\\partial}{\\partial \\theta} \\log f(T^{-1}(y_i); \\theta)\\] <p>Since the transformation is one-to-one, we can rewrite:</p>\\[\\frac{\\partial}{\\partial \\theta} \\log L(\\theta|y) = \\sum_{i=1}^{n} \\frac{\\partial}{\\partial x_i} \\log f(x_i; \\theta)\\] <p>This shows that the logarithmic derivative is invariant under the transformation. Therefore, the MLE of θ remains unchanged.</p>\",",
    "answerShort": "<p>The MLE is invariant under one-to-one transformations.</p>\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:43:26.795Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_mle_properties_007",
    "subject": "statistics",
    "type": "problem",
    "chapter": "point_estimation",
    "topic": "mle_properties",
    "problem": "{",
    "statementHtml": "Let $X_1, X_2, \\ldots, X_n$ be a random sample from a population with probability density function (PDF) $f(x|\\theta)$, where $\\theta$ is an unknown parameter. Show that the Maximum Likelihood Estimator (MLE) of $\\theta$ is invariant under one-to-one transformations.\",",
    "hints": [
      "Start by considering the likelihood function and its relationship to the MLE.",
      "Think about how the transformation affects the likelihood function.",
      "Use the fact that the MLE maximizes the likelihood function."
    ],
    "solutionHtml": "<p>To show invariance, we need to demonstrate that if $\\hat{\\theta}$ is the MLE of $\\theta$, then $g(\\hat{\\theta})$ is also the MLE of $g(\\theta)$ for any one-to-one transformation $g(x)</p><p>Let $L(\\theta|x_1, \\ldots, x_n)$ be the likelihood function. Since the MLE maximizes the likelihood function, we have $\\hat{\\theta} = \\arg\\max_{\\theta} L(\\theta|x_1, \\ldots, x_n).$</p><p>Now, consider the transformed likelihood function $L(g(\\theta)|x_1, \\ldots, x_n)$. Since $g(x)$ is one-to-one, we can invert it to obtain $\\theta = g^{-1}(g(\\theta))$. Substituting this into the likelihood function, we get</p><p>$L(g(\\theta)|x_1, \\ldots, x_n) = L(g(g^{-1}(g(\\theta)))|x_1, \\ldots, x_n) = L(\\hat{\\theta}|x_1, \\ldots, x_n).$</p><p>This shows that $L(g(\\theta)|x_1, \\ldots, x_n)$ is also maximized at $\\hat{\\theta}$, so $g(\\hat{\\theta})$ is the MLE of $g(\\theta).</p>\",",
    "answerShort": "The MLE is invariant under one-to-one transformations.\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:43:53.457Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_mle_properties_008",
    "subject": "statistics",
    "type": "problem",
    "chapter": "point_estimation",
    "topic": "mle_properties",
    "title": "Properties of MLEs: Invariance, Consistency, Asymptotic Normality, Efficiency",
    "problem": "{",
    "statementHtml": "Let $X_1, X_2, \\ldots, X_n$ be i.i.d. random variables from a distribution with density $f(x | \\theta)$. Show that the Maximum Likelihood Estimator (MLE) $\\hat{\\theta}$ is invariant under one-to-one transformations of the parameter.\",",
    "hints": [
      "Start by considering the likelihood function",
      "Use the chain rule to differentiate the log-likelihood"
    ],
    "solutionHtml": "<p>To prove invariance, we show that the MLE remains unchanged when applying a one-to-one transformation $\\phi(\\theta)$.</p><p>Let $g(x | \\theta) = f(x | \\phi^{-1}(\\theta))$. The likelihood function for the transformed parameter is</p>\\[L(\\theta | x_1, \\ldots, x_n) = \\prod_{i=1}^n g(x_i | \\phi^{-1}(\\theta)).\\]Taking the logarithm and differentiating with respect to $\\theta$ gives</p>\\[\\frac{\\partial}{\\partial \\theta} \\log L(\\theta | x_1, \\ldots, x_n) = 0.\\]Since the MLE is defined as the value of $\\theta$ that maximizes the likelihood, we have</p>\\[\\hat{\\theta} = \\arg\\max_{\\theta} L(\\theta | x_1, \\ldots, x_n).\\]Substituting $g(x | \\phi^{-1}(\\theta))$ for $f(x | \\theta)$ in the above equation shows that the MLE remains unchanged under one-to-one transformations.</p>\",",
    "answerShort": "The MLE is invariant under one-to-one transformations of the parameter.\" },",
    "workedExample": "{",
    "problemHtml": "<p>Suppose we have a random sample $X_1, X_2, \\ldots, X_n$ from a normal distribution with mean $\\theta$. Find the MLE for $\\theta$.</p>\",",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Write down the likelihood function\", \"mathHtml\": \"\\[L(\\theta | x_1, \\ldots, x_n) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}} e^{-(x_i - \\theta)^2/2}\\]\", \"explanation\": \"The likelihood function is the product of normal densities with mean $\\theta$.\"} ],",
    "finalAnswer": "The MLE for $\\theta$ is the sample mean.\" },",
    "intuition": "Invariance of the MLE means that the method of maximum likelihood is robust to changes in the parameter's scale or location.",
    "commonMistakes": [
      "Forgetting to consider one-to-one transformations",
      "Not recognizing the importance of the chain rule"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:44:26.808Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_mle_properties_009",
    "subject": "statistics",
    "type": "problem",
    "chapter": "point_estimation",
    "topic": "mle_properties",
    "problem": "{",
    "statementHtml": "<p>Let $X_1, X_2, \\ldots, X_n$ be a random sample from a population with probability density function (PDF) $f(x | \\theta)$.</p><p>Show that the Maximum Likelihood Estimator (MLE) $\\hat{\\theta}$ is invariant under one-to-one transformations of the parameter space.</p>\",",
    "hints": "[ \"<p>Start by considering a simple transformation, such as $\\phi(\\theta) = 2\\theta + 1$.</p>\", \"<p>Show that the likelihood function remains unchanged when the parameter is transformed in this way.</p>\", \"<p>Generalize your result to any one-to-one transformation of the parameter space.</p>\" ],",
    "solutionHtml": "<p>To show that the MLE $\\hat{\\theta}$ is invariant, we need to demonstrate that the likelihood function remains unchanged under a one-to-one transformation of the parameter space.</p><p>Let $\\phi(\\theta)$ be such a transformation. Then, the transformed PDF is $f(x | \\phi(\\theta)) = f(x | \\theta) / |\\phi'(\\theta)|$.</p><p>The likelihood function for the transformed parameters is</p>\\[\\mathcal{L}(\\phi(\\theta) | x_1, x_2, \\ldots, x_n) = \\prod_{i=1}^n f(x_i | \\phi(\\theta)) = \\prod_{i=1}^n f(x_i | \\theta) / |\\phi'(\\theta)|.\\]\\<p>Since the MLE $\\hat{\\theta}$ maximizes the likelihood function, we have</p>\\[\\mathcal{L}(\\phi(\\hat{\\theta}) | x_1, x_2, \\ldots, x_n) = \\max_{\\theta} \\mathcal{L}(\\theta | x_1, x_2, \\ldots, x_n).\\]\\<p>This shows that the MLE $\\hat{\\theta}$ is invariant under one-to-one transformations of the parameter space.</p>\",",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:44:51.982Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_prb_mle_properties_010",
    "subject": "statistics",
    "type": "problem",
    "chapter": "point_estimation",
    "topic": "mle_properties",
    "problem": "{",
    "statementHtml": "<p>Let $X_1, X_2, \\ldots, X_n$ be a random sample from a population with density $f(x|\\theta)$, where $\\theta$ is an unknown parameter.</p><p>Show that the Maximum Likelihood Estimator (MLE) of $\\theta$ is invariant to one-to-one transformations.</p>\",",
    "hints": "[ \"<p>Start by considering a simple transformation $g(\\cdot)$ and show that it preserves the likelihood function.</p>\", \"<p>Use the fact that MLE maximizes the likelihood function to conclude that the transformed estimator is also an MLE.</p>\", \"<p>Generalize your result to any one-to-one transformation.</p>\" ],",
    "solutionHtml": "<p>To show invariance, consider a one-to-one transformation $g(\\cdot)$. The likelihood function becomes</p><p>\\(L(g(X_1), g(X_2), \\ldots, g(X_n)|\\theta) = f(g(X_i)|\\theta)\\).</p><p>This is equivalent to the original likelihood function \\(L(X_1, X_2, \\ldots, X_n|\\theta) = f(X_i|\\theta)\\) since $g(\\cdot)$ is one-to-one.</p><p>Thus, the MLE of $\\theta$ remains unchanged under the transformation.</p>\",",
    "answerShort": "The MLE is invariant to one-to-one transformations.\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:45:11.670Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]