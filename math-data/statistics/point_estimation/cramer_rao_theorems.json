[
  {
    "id": "stat_thm_cramer_rao_007",
    "subject": "statistics",
    "type": "theorem",
    "chapter": "point_estimation",
    "topic": "cramer_rao",
    "title": "Cramér-Rao Lower Bound",
    "contentHtml": "<p>The Cramér-Rao lower bound (CR bound) is a fundamental concept in point estimation that provides a variance bound for any unbiased estimator of a parameter.</p>",
    "formula": {
      "latex": "\\[ \\text{Var}[^\\theta] \\geq \\frac{1}{nI(\\theta; X_1, \\ldots, X_n)} \\]",
      "name": "Cramér-Rao Lower Bound"
    },
    "theorem": {
      "statement": "\\[ \\text{Let } \\hat{\\theta} \\text{ be an unbiased estimator of } \\theta. Then, }",
      "proofSketch": "The proof involves showing that the CR bound is a lower bound for the variance of any unbiased estimator."
    },
    "intuition": "The CR bound provides a fundamental limit on the precision of any unbiased estimator, making it a crucial concept in point estimation.",
    "realWorldApplications": [
      "In machine learning, the CR bound has implications for the design of efficient algorithms and the analysis of statistical models."
    ],
    "tags": [
      "Point Estimation",
      "Cramér-Rao Lower Bound",
      "Variance"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "important",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:52:08.195Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "stat_thm_cramer_rao_008",
    "subject": "statistics",
    "type": "theorem",
    "chapter": "point_estimation",
    "topic": "cramer_rao",
    "title": "Cramér-Rao Lower Bound",
    "contentHtml": "<p>The Cramér-Rao lower bound is a fundamental concept in mathematical statistics that provides a variance bound for any unbiased estimator.</p>",
    "formula": {
      "latex": "\\[ \\text{CRB} = \\frac{1}{\\mathbf{E}[f'(x)^2]} \\]",
      "name": "Cramér-Rao Lower Bound"
    },
    "theorem": {
      "statement": "\\[ \\text{If } \\hat{x} \\text{ is an unbiased estimator of } x, then } \\text{Var}(\\hat{x}) \\geq \\frac{1}{-E[f'(x)^2]} \\]",
      "proofSketch": "The proof involves showing that the variance of any unbiased estimator must be greater than or equal to the reciprocal of the expected value of the squared derivative of the score function."
    },
    "intuition": "In essence, the Cramér-Rao lower bound states that there is a fundamental limit on how well we can estimate a parameter. Any unbiased estimator must have a variance at least as large as this bound.",
    "realWorldApplications": [
      "This concept has important implications in machine learning and artificial intelligence, where it is used to analyze the performance of various estimation algorithms."
    ],
    "tags": [
      "Cramér-Rao Lower Bound",
      "Point Estimation"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "important",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-27T09:52:25.778Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]