[
  {
    "id": "la_con_orthogonal_matrices_001",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "matrices_fundamentals",
    "topic": "orthogonal_matrices",
    "title": "Orthogonal Matrices",
    "contentHtml": "<p>A matrix is said to be orthogonal if its transpose is equal to its inverse.</p><p>This means that an orthogonal matrix preserves the length of any vector and also preserves the angle between two vectors.</p>",
    "formula": {
      "latex": "\\[\\mathbf{A}^T \\mathbf{A} = \\mathbf{I}\\]",
      "name": "Orthogonality Condition"
    },
    "intuition": "Think of an orthogonal matrix as a rotation that preserves the shape and size of objects. It's like a camera lens that doesn't distort the image.",
    "realWorldApplications": [
      "In machine learning, orthogonal matrices are used in dimensionality reduction techniques such as PCA (Principal Component Analysis)"
    ],
    "commonMistakes": [
      "Don't confuse orthogonality with unitary matrices, which have a different property."
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T10:29:31.211Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_orthogonal_matrices_002",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "matrices_fundamentals",
    "topic": "orthogonal_matrices",
    "title": "Orthogonal Matrices",
    "contentHtml": "<p>An orthogonal matrix is a square matrix whose columns and rows are orthogonal unit vectors.</p><p>This means that the dot product of any two distinct column vectors (or row vectors) is zero, while each vector has length one.</p>",
    "formula": {
      "latex": "\\[\\mathbf{Q}^T \\mathbf{Q} = I\\]",
      "name": "Orthogonality Condition"
    },
    "intuition": "Think of orthogonal matrices as rotations in space. When you rotate a vector by an angle, the resulting vector is still a unit vector, but it's pointing in a different direction. The orthogonality condition ensures that these rotated vectors are perpendicular to each other.",
    "realWorldApplications": [
      "In machine learning, orthogonal matrices can be used as initialization for neural networks or as a way to regularize the weights"
    ],
    "commonMistakes": [
      "Not realizing that orthogonal matrices preserve lengths and angles",
      "Thinking that orthogonal matrices are always invertible"
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T10:29:46.646Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_orthogonal_matrices_003",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "matrices_fundamentals",
    "topic": "orthogonal_matrices",
    "title": "Orthogonal Matrices",
    "contentHtml": "<p>A matrix is said to be orthogonal if its transpose is equal to its inverse.</p><p>This means that an orthogonal matrix preserves lengths and angles in a way that's similar to rotation matrices.</p>",
    "formula": {
      "latex": "\\[ A^\\top = A^{-1} \\]",
      "name": "Orthogonality Condition"
    },
    "intuition": "Think of an orthogonal matrix as a special kind of rotation. It doesn't change the magnitude of any vector, only its direction.",
    "realWorldApplications": [
      "In machine learning, orthogonal matrices are used in dimensionality reduction techniques like PCA and LLE."
    ],
    "commonMistakes": [
      "Don't confuse orthogonality with unitarity; not all orthogonal matrices have a magnitude of 1."
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T10:30:00.283Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]