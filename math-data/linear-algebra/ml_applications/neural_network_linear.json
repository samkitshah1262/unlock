[
  {
    "id": "la_con_neural_network_linear_001",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Linear Algebra in Neural Networks: Weight Matrices and Forward Pass",
    "contentHtml": "<p>In neural networks, weight matrices play a crucial role in processing inputs through layers of artificial neurons.</p><p>During the forward pass, each layer's output is calculated by multiplying its input with the corresponding weights and adding a bias term. This process can be viewed as matrix operations.</p>",
    "formula": {
      "latex": "\\mathbf{z} = \\sigma(\\mathbf{Wx} + \\mathbf{b})",
      "name": "Forward Pass"
    },
    "intuition": "Think of the weight matrix as a set of filters that adjust the strength of connections between neurons. The forward pass is like propagating signals through these filters, allowing the network to learn and represent complex patterns.",
    "realWorldApplications": [
      "Neural networks for image classification",
      "Natural Language Processing"
    ],
    "commonMistakes": [
      "Forgetting to include bias terms in calculations",
      "Not accounting for matrix operations' order of operations"
    ],
    "tags": [
      "Linear Algebra",
      "Machine Learning",
      "Artificial Intelligence"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:35:45.622Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_neural_network_linear_002",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Linear Algebra in Neural Networks: Weight Matrices and Forward Pass",
    "contentHtml": "<p>In neural networks, weight matrices are used to represent the connections between neurons. The forward pass is a process where an input is propagated through the network, layer by layer, using these weight matrices.</p><p>Mathematically, this can be represented as matrix operations. For example, given an input vector <i>x</i>, the output of the first layer can be calculated as <i>W1x</i>, where <i>W1</i> is the weight matrix for that layer.</p>",
    "formula": "{",
    "latex": "\\( W_1 x \\)\",",
    "name": "Forward Pass\" },",
    "intuition": "The key insight here is that neural networks can be viewed as a series of linear transformations, which are then combined using non-linear activation functions.",
    "realWorldApplications": [
      "Neural network architectures like convolutional and recurrent networks"
    ],
    "commonMistakes": [
      "Not understanding the importance of weight matrices in neural networks",
      "Thinking that the forward pass is simply a matter of applying activation functions"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:36:02.619Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_neural_network_linear_003",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Linear Algebra in Neural Network Forward Pass",
    "contentHtml": "<p>In neural networks, the forward pass is a critical step where input data flows through layers of weights and biases to produce an output. This process can be viewed as a series of matrix operations.</p><p>Consider a neural network with <i>n</i> inputs, <i>m</i> hidden units, and <i>p</i> outputs. The weight matrix <span class=\\\"math\\\">\\(W_{hidden}\\)</span> maps the input to the hidden layer, while the bias vector <span class=\\\"math\\\">\\(b_{hidden}\\)</span> adds an offset.</p>\",",
    "formula": "{",
    "latex": "\\[ W_{hidden} \\cdot x + b_{hidden} \\]\",",
    "name": "Forward Pass Formula\" },",
    "intuition": "The forward pass is a series of matrix operations that transform the input data into a higher-level representation. This process allows the network to learn complex patterns and relationships in the data.",
    "realWorldApplications": [
      "Neural networks are widely used in computer vision, natural language processing, and speech recognition."
    ],
    "commonMistakes": [
      "Failing to recognize the matrix operations involved in the forward pass"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:36:20.303Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_neural_network_linear_004",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Weight Matrices and Forward Pass in Neural Networks",
    "contentHtml": "<p>In neural networks, weight matrices play a crucial role in the forward pass. This process can be viewed as matrix operations.</p>",
    "formula": "{",
    "latex": "\\[W \\cdot x\\]\",",
    "name": "Weighted Sum\" },",
    "workedExample": "{",
    "problemHtml": "<p>Given a weight matrix W and an input vector x, compute the output y = Wx.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Multiply W with x\", \"mathHtml\": \"\\(W \\cdot x\\)\", \"explanation\": \"This represents the weighted sum of inputs.\"} ],",
    "finalAnswer": "The output vector y\" },",
    "intuition": "Understanding weight matrices and forward pass is essential for building neural networks, which are a fundamental component in many machine learning models.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:36:34.980Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_neural_network_linear_005",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Weight Matrices and Forward Pass",
    "contentHtml": "<p>In neural networks, weight matrices are used to compute the output of each layer during the forward pass.</p><ul><li>The weight matrix is multiplied by the input vector to produce the output.</li></ul>",
    "formula": "{",
    "latex": "\\\\[\\\\mathbf{y} = \\\\sigma(\\\\mathbf{W} \\* \\\\mathbf{x})\\\\]\",",
    "name": "Forward Pass Formula\" },",
    "workedExample": "{",
    "problemHtml": "<p>Given a weight matrix W and an input vector x, compute the output y.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Multiply the weight matrix by the input vector\", \"mathHtml\": \"\\\\[\\\\mathbf{W} \\* \\\\mathbf{x}\\\\]\", \"explanation\": \"This is done to compute the weighted sum of the inputs.\"}, {\"stepNumber\": 2, \"description\": \"Apply the activation function\", \"mathHtml\": \"\\\\[\\\\sigma(\\\\mathbf{W} \\* \\\\mathbf{x})\\\\]\", \"explanation\": \"The activation function determines the output of each neuron.\"} ],",
    "finalAnswer": "The output y\" },",
    "intuition": "Understanding how weight matrices and forward passes work is crucial for building neural networks that can learn complex patterns.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:36:54.265Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_neural_network_linear_006",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Forward Pass in Neural Networks",
    "contentHtml": "<p>In neural networks, the forward pass is a crucial step where input data flows through layers of weights and biases to produce an output.</p><p>Mathematically, this can be represented as matrix operations.</p>",
    "formula": "{",
    "latex": "\\[W \\cdot x + b\\]\",",
    "name": "Forward Pass Formula",
    "variants": "[] },",
    "workedExample": "{",
    "problemHtml": "<p>Given a weight matrix W and input vector x, calculate the output of the forward pass.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Multiply the input vector by the weight matrix\", \"mathHtml\": \"\\(W \\cdot x\\)\", \"explanation\": \"This represents the dot product of each row in W with the corresponding element in x.\"} ],",
    "finalAnswer": "The output of the forward pass\" },",
    "intuition": "The forward pass is a fundamental concept in neural networks, allowing data to flow through layers and produce an output.",
    "tags": [
      "neural networks",
      "forward pass"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:37:10.776Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_neural_network_linear_007",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Weight Matrices in Neural Networks",
    "contentHtml": "<p>In neural networks, weight matrices are used to represent the connections between layers. This formula shows how to perform a forward pass using matrix operations.</p>",
    "formula": "{",
    "latex": "\\[W \\cdot x\\]\",",
    "name": "Weight Matrix Multiplication\" },",
    "workedExample": "{",
    "problemHtml": "<p>Given a weight matrix W and an input vector x, calculate the output y = Wx.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Multiply each row of W with x\", \"mathHtml\": \"\\(W \\cdot x\\)\", \"explanation\": \"This represents the dot product of each weight vector and the input vector.\"} ],",
    "finalAnswer": "The output y = Wx\" },",
    "intuition": "Weight matrices enable neural networks to learn complex patterns by combining inputs in a weighted sum.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:37:25.722Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_neural_network_linear_008",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "problem": "{",
    "statementHtml": "Consider a neural network with <i>N</i> layers and <i>M</i> neurons in each layer. During the forward pass, the output of each neuron is calculated as the dot product of its weights and inputs, followed by an activation function. Write the matrix equation for this process.",
    "hints": [
      "Think about how you would represent the weights and inputs as matrices.",
      "Recall that matrix multiplication can be viewed as a series of dot products.",
      "Consider how batch processing affects the calculation."
    ],
    "solutionHtml": "<p>To write the matrix equation, we'll denote the weight matrix for each layer as <i>W</i><sub>i</sub>, the input vector as <i>x</i>, and the output vector as <i>y</i>. We can represent the forward pass as:</p>\\n\\[y = \\sigma(W_1x) = \\sigma(W_2\\sigma(W_1x)) = ... = \\sigma(W_Nx)\\]\\n<p>where <i>σ</i> is the activation function.</p>\",",
    "answerShort": "The matrix equation for the forward pass is given by the recursive formula above.\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:37:44.411Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_neural_network_linear_009",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "problem": "{",
    "statementHtml": "<p>Given a neural network with weight matrices W1 and W2, compute the output of the forward pass using matrix operations.</p>",
    "hints": "[ \"Consider the dot product \\(\\mathbf{z} = \\mathbf{W}_1 \\cdot \\mathbf{x}\\) as the first step.\", \"Think about how you can apply the weight matrices to the input vector \\(\\mathbf{x}\\) using matrix multiplication.\", \"Batch processing involves applying these operations to each sample in the batch.\" ],",
    "solutionHtml": "<p>To compute the output of the forward pass, we perform the following steps:</p><ol><li>Compute the dot product \\(\\mathbf{z} = \\mathbf{W}_1 \\cdot \\mathbf{x}\\) using matrix multiplication.</li><li>Apply the weight matrix \\(\\mathbf{W}_2\\) to the output \\(\\mathbf{z}\\) to get the final output \\(\\mathbf{y}\\).</li></ol>\",",
    "answerShort": "The output of the forward pass is given by \\(\\mathbf{y} = \\mathbf{W}_2 \\cdot \\mathbf{z}\\)\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:38:02.954Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_neural_network_linear_010",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "problem": "{",
    "statementHtml": "<p>Consider a neural network with weight matrix W and input X. Perform a forward pass using matrix operations to compute the output.</p>",
    "hints": [
      "Think about how you would multiply W by X.",
      "Recall that matrix multiplication is not commutative.",
      "Batch processing involves applying the same operation to multiple inputs."
    ],
    "solutionHtml": "<p>To perform a forward pass, we need to compute WX. This can be done using matrix multiplication:</p>\\n<p>\\(WX = W \\cdot X\\)</p>\\n<p>This is equivalent to computing the dot product of each row in W with the corresponding column in X.</p>\",",
    "answerShort": "WX\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:38:16.209Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_neural_network_linear_011",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "problem": "{",
    "statementHtml": "<p>Consider a neural network with weight matrices W1 and W2 during the forward pass. Express the output as matrix operations.</p>",
    "hints": [
      "Think about how you would compute the output of each layer.",
      "Recall that matrix multiplication is associative.",
      "Batch processing can be represented as matrix operations."
    ],
    "solutionHtml": "<p>To perform the forward pass, we multiply the input by W1 and then by W2:</p>\\n\\ \\[ \\mathbf{y} = \\sigma(\\mathbf{W}_2 \\cdot (\\mathbf{W}_1 \\cdot \\mathbf{x})) \\]\\n\\ <p>where σ is the activation function.</p>\",",
    "answerShort": "The output is the result of matrix multiplication.\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:38:30.463Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_neural_network_linear_012",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Linear Algebra in Neural Networks: Forward Pass",
    "contentHtml": "<p>In neural networks, forward pass is a crucial step where input data flows through layers of neurons to produce an output.</p>",
    "formula": {
      "latex": "\\[Wx + b = y\\]",
      "name": "Forward Pass Formula"
    },
    "problem": {
      "statementHtml": "<p>Given a neural network with weight matrix W, input x, bias term b, and output y, perform the forward pass to compute y.</p>",
      "hints": [
        "Hint: Think of it as a series of matrix multiplications."
      ],
      "solutionHtml": "<p>To perform the forward pass, we can write:</p><ul><li>Step 1: Compute z = Wx + b</li><li>Step 2: Apply activation function to get y = sigmoid(z)</li></ul>",
      "answerShort": "y = sigmoid(Wx + b)"
    },
    "workedExample": {
      "problemHtml": "<p>Suppose we have a neural network with weight matrix W = \\[\\begin{bmatrix} 0.5 & 0.2 \\\\ -0.3 & 0.9 \\end{bmatrix}\\], input x = \\[\\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}\\], bias term b = 0, and output y.</p>",
      "steps": [
        {
          "stepNumber": 1,
          "description": "Compute z",
          "mathHtml": "\\[z = Wx + b = \\begin{bmatrix} 0.5 & 0.2 \\\\ -0.3 & 0.9 \\end{bmatrix}\\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} + 0\\] = \\[\\begin{bmatrix} 1.8 \\\\ 1.7 \\end{bmatrix}\\]",
          "explanation": "We're applying the weight matrix to the input, then adding the bias term."
        },
        {
          "stepNumber": 2,
          "description": "Apply activation function",
          "mathHtml": "\\[y = sigmoid(z) = \\frac{1}{1 + e^{-z}}\\] = ?"
        },
        {
          "stepNumber": 3,
          "description": "Calculate y",
          "mathHtml": "? = ?"
        },
        {
          "stepNumber": 4,
          "description": "Final answer",
          "mathHtml": "\\[y = \\frac{1}{1 + e^{-(1.8)}}\\]"
        }
      ],
      "finalAnswer": "\\[y = \\frac{1}{1 + e^{-(1.8)}}\\]"
    },
    "intuition": "The forward pass is a series of matrix multiplications that allow the input data to flow through the network, producing an output.",
    "visualDescription": "A diagram showing the neural network with input x, weight matrix W, bias term b, and output y would help illustrate this concept.",
    "commonMistakes": [
      "Forgetting to apply the activation function",
      "Not accounting for bias terms"
    ],
    "realWorldApplications": [
      "Image classification using convolutional neural networks"
    ],
    "tags": [
      "neural networks",
      "forward pass"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:39:09.032Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_neural_network_linear_013",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Linear Algebra in Neural Networks: Forward Pass",
    "contentHtml": "<p>In neural networks, forward pass is a crucial step where input data flows through layers of neurons to produce an output.</p>",
    "workedExample": "{",
    "problemHtml": "Consider a simple feedforward neural network with two inputs <i>x</i> and <i>y</i>, one hidden layer with two neurons, and one output neuron. The weights for the first hidden neuron are <i>w<sub>11</sub></i> = 0.5, <i>w<sub>12</sub></i> = 1.2, and <i>w<sub>21</sub></i> = -0.8.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Calculate the input to the first hidden neuron\", \"mathHtml\": \"\\[z_1 = w_{11}x + w_{12}y\\]\", \"explanation\": \"We're applying the weights to the inputs and summing them up.\"}, {\"stepNumber\": 2, \"description\": \"Apply the activation function to get the output of the first hidden neuron\", \"mathHtml\": \"\\[h_1 = \\sigma(z_1) = \\sigma(0.5x + 1.2y - 0.8)\\]\", \"explanation\": \"We're using some activation function like sigmoid or ReLU.\"}, {\"stepNumber\": 3, \"description\": \"Repeat the process for the second hidden neuron\", \"mathHtml\": \"\\[z_2 = w_{21}x + w_{22}y\\]\", \"explanation\": \"Same idea as before, but with different weights.\"}, {\"stepNumber\": 4, \"description\": \"Calculate the output of the network by applying the final weights and activation function\", \"mathHtml\": \"\\[o = \\sigma(w_{31}h_1 + w_{32}h_2)\\]\", \"explanation\": \"We're combining the outputs of the hidden neurons with some final weights and applying another activation function.\"}, ],",
    "finalAnswer": "The output <i>o</i>\" },",
    "intuition": "Forward pass in neural networks is essentially matrix multiplication, where input data flows through layers of neurons. This example illustrates how we can break down the process into smaller steps.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:39:38.419Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_neural_network_linear_014",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Linear Algebra in Neural Networks: Forward Pass",
    "contentHtml": "<p>In neural networks, forward pass is a crucial step where input data flows through layers of weights and biases to produce output.</p>",
    "workedExample": "{",
    "problemHtml": "Consider a simple neural network with two inputs <i>x</i> and <i>y</i>, one hidden layer with one neuron, and one output layer. The weight matrix for the hidden layer is <i>W = [[w11, w12], [w21, w22]]</i>. Suppose we have input data <i>x = [x1, x2]</i> and <i>y = [y1, y2]</i>. What is the output of the forward pass?",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Calculate the pre-activation values for the hidden layer\", \"mathHtml\": \"\\[z = Wx + b\\]\", \"explanation\": \"We're using the weight matrix to dot product with the input data and adding the bias term.\"}, {\"stepNumber\": 2, \"description\": \"Apply the activation function to get the output of the hidden layer\", \"mathHtml\": \"\\[h = \\sigma(z)\\]\", \"explanation\": \"The activation function introduces non-linearity in the model.\"}, {\"stepNumber\": 3, \"description\": \"Calculate the pre-activation values for the output layer\", \"mathHtml\": \"\\[o = Wo + c\\]\", \"explanation\": \"We're using the weight matrix to dot product with the hidden layer output and adding the bias term.\"}, {\"stepNumber\": 4, \"description\": \"Apply the activation function to get the final output\", \"mathHtml\": \"\\[y = \\sigma(o)\\]\", \"explanation\": \"The final output is the result of applying the activation function to the pre-activation values.\"} ],",
    "finalAnswer": "The final output <i>y</i> is calculated by applying the activation function to the pre-activation values obtained from the weight matrix and bias term.\" },",
    "intuition": "Forward pass in neural networks can be thought of as a series of dot products and element-wise operations that transform input data into meaningful representations.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:40:06.047Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_neural_network_linear_015",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Linear Algebra in Neural Networks: Forward Pass",
    "contentHtml": "<p>In neural networks, forward pass is a crucial step where input data flows through layers of neurons to produce output.</p>",
    "formula": {
      "latex": "\\[W \\cdot x + b\\]",
      "name": "Weight Matrix Multiplication"
    },
    "problem": {
      "statementHtml": "<p>Suppose we have a neural network with two hidden layers, each having 3 neurons. The weight matrix for the first layer is given as:</p><p>\\[W_1 = \\begin{bmatrix} 0.5 & -0.2 & 0.8 \\\\ 0.3 & 0.9 & -0.4 \\\\ -0.7 & 0.6 & 0.1 \\end{bmatrix}\\]</p>",
      "hints": [
        "Consider the matrix operations"
      ],
      "solutionHtml": "<p>To perform the forward pass, we need to compute the output of each layer.</p><ul><li>First, we multiply the input data with the weight matrix:</li><li>\\[W_1 \\cdot x = \\begin{bmatrix} 0.5x_1 - 0.2x_2 + 0.8x_3 \\\\ 0.3x_1 + 0.9x_2 - 0.4x_3 \\\\ -0.7x_1 + 0.6x_2 + 0.1x_3 \\end{bmatrix}\\]</li><li>Next, we add the bias term:</li><li>\\[W_1 \\cdot x + b = \\begin{bmatrix} 0.5x_1 - 0.2x_2 + 0.8x_3 + 0.2 \\\\ 0.3x_1 + 0.9x_2 - 0.4x_3 + 0.5 \\\\ -0.7x_1 + 0.6x_2 + 0.1x_3 + 0.8 \\end{bmatrix}\\]</li></ul>",
      "answerShort": "The output of the first layer is a 3-dimensional vector."
    },
    "workedExample": {
      "problemHtml": "<p>For this example, assume input data x = [1, 2, 3].</p>",
      "steps": [
        {
          "stepNumber": 1,
          "description": "Compute the output of the first layer",
          "mathHtml": "\\[W_1 \\cdot x + b\\]",
          "explanation": "We multiply the input data with the weight matrix and add the bias term."
        },
        {
          "stepNumber": 2,
          "description": "Repeat for each hidden layer",
          "mathHtml": "",
          "explanation": "The process is repeated for each subsequent layer."
        }
      ],
      "finalAnswer": "The output of the forward pass is a vector representing the output of the neural network."
    },
    "intuition": "Forward pass in neural networks can be thought of as matrix operations, where input data flows through layers to produce output.",
    "visualDescription": "A diagram showing the flow of input data through multiple hidden layers and an output layer would help illustrate this concept.",
    "commonMistakes": [
      "Forgetting to add bias terms",
      "Not considering batch processing"
    ],
    "realWorldApplications": [
      "Image classification using convolutional neural networks"
    ],
    "tags": [
      "neural networks",
      "forward pass",
      "linear algebra"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:40:49.480Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]