[
  {
    "id": "la_prb_neural_network_linear_008",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "problem": "{",
    "statementHtml": "Consider a neural network with <i>N</i> layers and <i>M</i> neurons in each layer. During the forward pass, the output of each neuron is calculated as the dot product of its weights and inputs, followed by an activation function. Write the matrix equation for this process.",
    "hints": [
      "Think about how you would represent the weights and inputs as matrices.",
      "Recall that matrix multiplication can be viewed as a series of dot products.",
      "Consider how batch processing affects the calculation."
    ],
    "solutionHtml": "<p>To write the matrix equation, we'll denote the weight matrix for each layer as <i>W</i><sub>i</sub>, the input vector as <i>x</i>, and the output vector as <i>y</i>. We can represent the forward pass as:</p>\\n\\[y = \\sigma(W_1x) = \\sigma(W_2\\sigma(W_1x)) = ... = \\sigma(W_Nx)\\]\\n<p>where <i>σ</i> is the activation function.</p>\",",
    "answerShort": "The matrix equation for the forward pass is given by the recursive formula above.\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:37:44.411Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_neural_network_linear_009",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "problem": "{",
    "statementHtml": "<p>Given a neural network with weight matrices W1 and W2, compute the output of the forward pass using matrix operations.</p>",
    "hints": "[ \"Consider the dot product \\(\\mathbf{z} = \\mathbf{W}_1 \\cdot \\mathbf{x}\\) as the first step.\", \"Think about how you can apply the weight matrices to the input vector \\(\\mathbf{x}\\) using matrix multiplication.\", \"Batch processing involves applying these operations to each sample in the batch.\" ],",
    "solutionHtml": "<p>To compute the output of the forward pass, we perform the following steps:</p><ol><li>Compute the dot product \\(\\mathbf{z} = \\mathbf{W}_1 \\cdot \\mathbf{x}\\) using matrix multiplication.</li><li>Apply the weight matrix \\(\\mathbf{W}_2\\) to the output \\(\\mathbf{z}\\) to get the final output \\(\\mathbf{y}\\).</li></ol>\",",
    "answerShort": "The output of the forward pass is given by \\(\\mathbf{y} = \\mathbf{W}_2 \\cdot \\mathbf{z}\\)\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:38:02.954Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_neural_network_linear_010",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "problem": "{",
    "statementHtml": "<p>Consider a neural network with weight matrix W and input X. Perform a forward pass using matrix operations to compute the output.</p>",
    "hints": [
      "Think about how you would multiply W by X.",
      "Recall that matrix multiplication is not commutative.",
      "Batch processing involves applying the same operation to multiple inputs."
    ],
    "solutionHtml": "<p>To perform a forward pass, we need to compute WX. This can be done using matrix multiplication:</p>\\n<p>\\(WX = W \\cdot X\\)</p>\\n<p>This is equivalent to computing the dot product of each row in W with the corresponding column in X.</p>\",",
    "answerShort": "WX\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:38:16.209Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_neural_network_linear_011",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "problem": "{",
    "statementHtml": "<p>Consider a neural network with weight matrices W1 and W2 during the forward pass. Express the output as matrix operations.</p>",
    "hints": [
      "Think about how you would compute the output of each layer.",
      "Recall that matrix multiplication is associative.",
      "Batch processing can be represented as matrix operations."
    ],
    "solutionHtml": "<p>To perform the forward pass, we multiply the input by W1 and then by W2:</p>\\n\\ \\[ \\mathbf{y} = \\sigma(\\mathbf{W}_2 \\cdot (\\mathbf{W}_1 \\cdot \\mathbf{x})) \\]\\n\\ <p>where σ is the activation function.</p>\",",
    "answerShort": "The output is the result of matrix multiplication.\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:38:30.463Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]