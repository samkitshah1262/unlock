[
  {
    "id": "la_con_neural_network_linear_001",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Linear Algebra in Neural Networks: Weight Matrices and Forward Pass",
    "contentHtml": "<p>In neural networks, weight matrices play a crucial role in processing inputs through layers of artificial neurons.</p><p>During the forward pass, each layer's output is calculated by multiplying its input with the corresponding weights and adding a bias term. This process can be viewed as matrix operations.</p>",
    "formula": {
      "latex": "\\mathbf{z} = \\sigma(\\mathbf{Wx} + \\mathbf{b})",
      "name": "Forward Pass"
    },
    "intuition": "Think of the weight matrix as a set of filters that adjust the strength of connections between neurons. The forward pass is like propagating signals through these filters, allowing the network to learn and represent complex patterns.",
    "realWorldApplications": [
      "Neural networks for image classification",
      "Natural Language Processing"
    ],
    "commonMistakes": [
      "Forgetting to include bias terms in calculations",
      "Not accounting for matrix operations' order of operations"
    ],
    "tags": [
      "Linear Algebra",
      "Machine Learning",
      "Artificial Intelligence"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:35:45.622Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_neural_network_linear_002",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Linear Algebra in Neural Networks: Weight Matrices and Forward Pass",
    "contentHtml": "<p>In neural networks, weight matrices are used to represent the connections between neurons. The forward pass is a process where an input is propagated through the network, layer by layer, using these weight matrices.</p><p>Mathematically, this can be represented as matrix operations. For example, given an input vector <i>x</i>, the output of the first layer can be calculated as <i>W1x</i>, where <i>W1</i> is the weight matrix for that layer.</p>",
    "formula": "{",
    "latex": "\\( W_1 x \\)\",",
    "name": "Forward Pass\" },",
    "intuition": "The key insight here is that neural networks can be viewed as a series of linear transformations, which are then combined using non-linear activation functions.",
    "realWorldApplications": [
      "Neural network architectures like convolutional and recurrent networks"
    ],
    "commonMistakes": [
      "Not understanding the importance of weight matrices in neural networks",
      "Thinking that the forward pass is simply a matter of applying activation functions"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:36:02.619Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_neural_network_linear_003",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "neural_network_linear",
    "title": "Linear Algebra in Neural Network Forward Pass",
    "contentHtml": "<p>In neural networks, the forward pass is a critical step where input data flows through layers of weights and biases to produce an output. This process can be viewed as a series of matrix operations.</p><p>Consider a neural network with <i>n</i> inputs, <i>m</i> hidden units, and <i>p</i> outputs. The weight matrix <span class=\\\"math\\\">\\(W_{hidden}\\)</span> maps the input to the hidden layer, while the bias vector <span class=\\\"math\\\">\\(b_{hidden}\\)</span> adds an offset.</p>\",",
    "formula": "{",
    "latex": "\\[ W_{hidden} \\cdot x + b_{hidden} \\]\",",
    "name": "Forward Pass Formula\" },",
    "intuition": "The forward pass is a series of matrix operations that transform the input data into a higher-level representation. This process allows the network to learn complex patterns and relationships in the data.",
    "realWorldApplications": [
      "Neural networks are widely used in computer vision, natural language processing, and speech recognition."
    ],
    "commonMistakes": [
      "Failing to recognize the matrix operations involved in the forward pass"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:36:20.303Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]