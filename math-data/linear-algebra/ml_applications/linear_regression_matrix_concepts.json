[
  {
    "id": "la_con_linear_regression_matrix_001",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "linear_regression_matrix",
    "title": "Linear Regression via Linear Algebra",
    "subtitle": "A fundamental concept in machine learning",
    "contentHtml": "<p>Linear regression is a cornerstone of machine learning, and its mathematical foundation lies in linear algebra.</p><p>In this card, we'll explore the normal equations, ridge regression, and matrix formulation of linear regression.</p>",
    "formula": {
      "latex": "\\[ \\mathbf{w} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y} \\]",
      "name": "Normal Equations",
      "variants": []
    },
    "intuition": "Linear regression finds the best-fitting hyperplane to separate classes by minimizing the mean squared error between predicted and actual values.",
    "realWorldApplications": [
      "Image classification",
      "Recommendation systems"
    ],
    "commonMistakes": [
      "Forgetting that ridge regression is a regularization technique"
    ],
    "tags": [
      "linear-algebra",
      "machine-learning"
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:19:32.330Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_linear_regression_matrix_002",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "linear_regression_matrix",
    "title": "Linear Regression via Linear Algebra",
    "contentHtml": "<p>Linear regression is a fundamental concept in machine learning that involves modeling the relationship between a dependent variable and one or more independent variables using a linear equation.</p><p>In this card, we'll explore how linear algebra provides a powerful framework for solving linear regression problems.</p>",
    "formula": "{",
    "latex": "\\\\[\\\\mathbf{w} = (\\\\mathbf{X}^T \\\\mathbf{X})^{-1} \\\\mathbf{X}^T \\\\mathbf{y}\\]\",",
    "name": "Normal Equation\" },",
    "intuition": "The normal equation provides a closed-form solution for the weights in linear regression, which is essential for efficient computation and scalability.",
    "realWorldApplications": [
      "Image classification",
      "Recommendation systems"
    ],
    "commonMistakes": [
      "Forgetting to add an intercept term",
      "Not accounting for regularization terms"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:19:46.215Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_linear_regression_matrix_003",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "linear_regression_matrix",
    "title": "Linear Regression via Linear Algebra",
    "contentHtml": "<p>Linear regression is a fundamental concept in machine learning that involves modeling the relationship between a dependent variable and one or more independent variables. In this card, we'll explore how linear algebra provides a powerful framework for understanding and implementing linear regression.</p>",
    "formula": "{",
    "latex": "\\\\[\\\\mathbf{w} = (\\\\mathbf{X}^T \\\\mathbf{X})^{-1} \\\\mathbf{X}^T \\\\mathbf{y}\\]\",",
    "name": "Normal Equation\" },",
    "intuition": "The normal equation is a way to find the optimal weights in linear regression by minimizing the mean squared error between predicted and actual values. It's a powerful tool for understanding how the independent variables contribute to the dependent variable.",
    "realWorldApplications": [
      "Predicting house prices based on features like number of bedrooms, square footage, etc."
    ],
    "commonMistakes": [
      "Not accounting for multicollinearity in the independent variables",
      "Failing to regularize the model with techniques like ridge regression"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:20:02.232Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]