[
  {
    "id": "la_con_kernel_matrices_001",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "kernel_matrices",
    "title": "Kernel Methods in Linear Algebra",
    "contentHtml": "<p>In machine learning, kernel methods are a powerful tool for transforming data into a higher-dimensional space where it's easier to classify or cluster. But how do they work? The key lies in the Gram matrix.</p>",
    "formula": {
      "latex": "\\[ K = [k(x_i, x_j)]_{i,j=1}^n \\]",
      "name": "Kernel Matrix"
    },
    "intuition": "Think of the kernel as a similarity metric between data points. By choosing the right kernel, you can effectively capture complex relationships in your data.",
    "realWorldApplications": [
      "Support Vector Machines",
      "Principal Component Analysis"
    ],
    "commonMistakes": [
      "Confusing the kernel with the feature space"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:31:59.960Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_kernel_matrices_002",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "kernel_matrices",
    "title": "Kernel Methods: Gram Matrices and Positive Semi-Definite Kernels",
    "contentHtml": "<p>In machine learning, kernel methods are a powerful tool for transforming non-linearly separable data into a higher-dimensional space where it becomes linearly separable.</p><p>The key to kernel methods lies in the concept of gram matrices. A gram matrix is a square matrix whose entries are the dot products of pairs of vectors from some input space.</p>",
    "formula": {
      "latex": "\\[ K = [k(x_i, x_j)]_{i,j=1}^n \\]",
      "name": "Kernel Gram Matrix"
    },
    "intuition": "The gram matrix allows us to capture complex relationships between data points without explicitly mapping them to a higher-dimensional space.",
    "realWorldApplications": [
      "Support Vector Machines (SVMs)"
    ],
    "commonMistakes": [
      "Confusing the kernel with the feature map"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:32:13.786Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_kernel_matrices_003",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "ml_applications",
    "topic": "kernel_matrices",
    "title": "Kernel Methods: Gram Matrices and Positive Semi-Definite Kernels",
    "contentHtml": "<p>In machine learning, kernel methods are a powerful tool for transforming non-linearly separable data into a higher-dimensional space where it becomes linearly separable. The key to this transformation lies in the concept of gram matrices.</p><p>A gram matrix is a square matrix that represents the dot products between all pairs of vectors. In other words, if we have a set of vectors $\\mathbf{x}_1, \\ldots, \\mathbf{x}_n$ and a kernel function $k(\\cdot, \\cdot)$, then the gram matrix $G$ is defined as:</p><p>\\[ G = [k(\\mathbf{x}_i, \\mathbf{x}_j)]_{ij}.\\]</p>\",",
    "formula": "{",
    "latex": "\\( k(\\mathbf{x}, \\mathbf{y}) = \\langle \\phi(\\mathbf{x}), \\phi(\\mathbf{y}) \\rangle \\)\",",
    "name": "Kernel Function\" },",
    "intuition": "The kernel trick allows us to implicitly transform our data into a higher-dimensional space without explicitly computing the transformation. This is particularly useful when dealing with large datasets or complex transformations.",
    "realWorldApplications": [
      "Support Vector Machines",
      "Principal Component Analysis"
    ],
    "commonMistakes": [
      "Confusing the gram matrix with the covariance matrix"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T14:32:32.557Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]