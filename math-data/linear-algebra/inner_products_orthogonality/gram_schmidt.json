[
  {
    "id": "la_con_gram_schmidt_001",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "title": "Gram-Schmidt Process",
    "contentHtml": "<p>The Gram-Schmidt process is an algorithm used to orthonormalize a set of vectors in a Hilbert space.</p><p>Given a sequence of vectors <code>\\(\\mathbf{v}_1, \\mathbf{v}_2, \\ldots\\)</code>, the goal is to produce an orthonormal basis <code>\\(\\mathbf{u}_1, \\mathbf{u}_2, \\ldots\\)</code> such that each <code>\\(\\mathbf{u}_i\\)</code> is a linear combination of the original vectors.</p>\",",
    "formula": "{",
    "latex": "\\[\\mathbf{u}_i = \\frac{\\mathbf{v}_i - \\sum_{j=1}^{i-1} (\\mathbf{v}_i \\cdot \\mathbf{u}_j) \\mathbf{u}_j}{\\|\\mathbf{v}_i - \\sum_{j=1}^{i-1} (\\mathbf{v}_i \\cdot \\mathbf{u}_j) \\mathbf{u}_j\\|}\\]\",",
    "name": "\" },",
    "intuition": "The Gram-Schmidt process is a way to 'normalize' vectors while preserving their relationships.",
    "realWorldApplications": [
      "In machine learning, the Gram-Schmidt process is used in dimensionality reduction techniques like PCA."
    ],
    "commonMistakes": [
      "Don't forget to normalize each vector individually"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:05:21.541Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_gram_schmidt_002",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "title": "Gram-Schmidt Process",
    "contentHtml": "<p>The Gram-Schmidt process is an algorithm used to orthonormalize a set of vectors in a Hilbert space.</p><p>This process is essential for many applications, including machine learning and computer graphics.</p>",
    "formula": {
      "latex": "\\[v_1 = \\frac{\\mathbf{a}_1}{||\\mathbf{a}_1||}, v_2 = \\frac{\\mathbf{a}_2 - (\\mathbf{a}_2 \\cdot v_1) v_1}{||\\mathbf{a}_2 - (\\mathbf{a}_2 \\cdot v_1) v_1||} \\]",
      "name": "Orthonormalization"
    },
    "intuition": "The Gram-Schmidt process is a way to take a set of vectors and make them orthonormal, which means they are perpendicular to each other. This is useful because it allows us to work with these vectors in a more efficient and meaningful way.",
    "realWorldApplications": [
      "Principal Component Analysis (PCA)"
    ],
    "tags": [
      "linear-algebra",
      "orthogonality",
      "machine-learning"
    ],
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:05:39.591Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_gram_schmidt_003",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "title": "Gram-Schmidt Process",
    "contentHtml": "<p>The Gram-Schmidt process is a fundamental algorithm in linear algebra that orthonormalizes a set of vectors.</p><p>Given a sequence of vectors <code>\\{\\mathbf{v}_1, \\mathbf{v}_2, ..., \\mathbf{v}_n\\}</code>, the goal is to produce an orthonormal basis <code>\\{\\mathbf{u}_1, \\mathbf{u}_2, ..., \\mathbf{u}_n\\}</code> such that each <code>\\mathbf{u}_i</code> is a linear combination of the original vectors.</p>\",",
    "formula": "{",
    "latex": "\\[\\mathbf{u}_k = \\frac{\\mathbf{v}_k - \\sum_{j=1}^{k-1} c_j \\mathbf{u}_j}{\\left\\lVert\\mathbf{v}_k - \\sum_{j=1}^{k-1} c_j \\mathbf{u}_j\\right\\rVert}\\]\",",
    "name": "Gram-Schmidt Formula\" },",
    "intuition": "The Gram-Schmidt process is a clever way to 'normalize' vectors while preserving their relationships.",
    "realWorldApplications": [
      "Principal Component Analysis (PCA) in machine learning"
    ],
    "commonMistakes": [
      "Failing to normalize the vectors correctly",
      "Not recognizing that the process is iterative"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:05:59.277Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_gram_schmidt_004",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "title": "Gram-Schmidt Process",
    "contentHtml": "<p>The Gram-Schmidt process is a widely used algorithm in linear algebra to orthonormalize a set of vectors.</p><p>This process is essential in many machine learning and artificial intelligence applications, such as principal component analysis (PCA), independent component analysis (ICA), and singular value decomposition (SVD).</p>",
    "formula": "{",
    "latex": "\\[v_i = \\frac{v_i - \\sum_{j=1}^{i-1} v_j \\cdot v_i}{\\| v_i - \\sum_{j=1}^{i-1} v_j \\cdot v_i \\|}\\]\",",
    "name": "Gram-Schmidt Process Formula",
    "variants": "[] },",
    "workedExample": "{",
    "problemHtml": "<p>Given a set of vectors {v_1, ..., v_n}, orthonormalize them using the Gram-Schmidt process.</p>",
    "steps": "[ {",
    "stepNumber": 2,
    "description": "For each subsequent vector v_i, subtract the projection of v_i onto the previously orthonormalized vectors.",
    "mathHtml": "\\[v_i = \\frac{v_i - \\sum_{j=1}^{i-1} v_j \\cdot v_i}{\\| v_i - \\sum_{j=1}^{i-1} v_j \\cdot v_i \\|}\\]\",",
    "explanation": "We subtract the projection of each vector onto the previously orthonormalized vectors to ensure orthogonality.\" } ],",
    "finalAnswer": "The resulting set of orthonormal vectors {v_1, ..., v_n}\" },",
    "intuition": "The Gram-Schmidt process is a recursive algorithm that ensures a set of vectors remains orthonormal by subtracting the projection of each vector onto the previously orthonormalized vectors.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:06:27.378Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_gram_schmidt_005",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "title": "Gram-Schmidt Process",
    "contentHtml": "<p>The Gram-Schmidt process is a widely used algorithm in linear algebra to orthonormalize a set of vectors.</p><ul><li>Given a set of vectors <code>\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_n\\}</code>, the goal is to find an orthonormal basis <code>\\{\\mathbf{u}_1, \\ldots, \\mathbf{u}_n\\}</code> such that each <code>\\mathbf{u}_i</code> is a linear combination of the original vectors.</li></ul>\",",
    "formula": "{",
    "latex": "\\[\\mathbf{u}_k = \\frac{\\mathbf{v}_k - \\sum_{i=1}^{k-1} \\text{proj}_{\\mathbf{u}_i}(\\mathbf{v}_k)}{\\|\\mathbf{v}_k - \\sum_{i=1}^{k-1} \\text{proj}_{\\mathbf{u}_i}(\\mathbf{v}_k)\\|}\\]\",",
    "name": "Gram-Schmidt Process\" },",
    "workedExample": "{",
    "problemHtml": "<p>Given the vectors <code>\\{\\mathbf{v}_1 = [1, 0], \\mathbf{v}_2 = [0, 1]\\}</code>, apply the Gram-Schmidt process to find an orthonormal basis.</p>\",",
    "steps": "[ {",
    "stepNumber": 2,
    "description": "Compute <code>\\mathbf{u}_2</code> as a linear combination of <code>\\mathbf{v}_2</code>, orthogonal to <code>\\mathbf{u}_1</code>\",",
    "mathHtml": "\\[\\mathbf{u}_2 = \\frac{\\mathbf{v}_2 - \\text{proj}_{\\mathbf{u}_1}(\\mathbf{v}_2)}{\\|\\mathbf{v}_2 - \\text{proj}_{\\mathbf{u}_1}(\\mathbf{v}_2)\\|} = [0, 1]\\]\",",
    "explanation": "We subtract the projection of <code>\\mathbf{v}_2</code> onto <code>\\mathbf{u}_1</code> to ensure orthogonality.\" } ],",
    "finalAnswer": "[[1, 0], [0, 1]]\" },",
    "intuition": "The Gram-Schmidt process is a recursive algorithm that ensures each new vector is orthogonal to the previously computed orthonormal vectors.",
    "tags": [
      "linear-algebra",
      "orthogonality"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:07:05.881Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_gram_schmidt_006",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "title": "Gram-Schmidt Process",
    "contentHtml": "<p>The Gram-Schmidt process is a fundamental algorithm in linear algebra that orthonormalizes a set of vectors.</p><p>Given a sequence of vectors <code>\\{v_1, v_2, ..., v_n\\}</code>, the goal is to produce an orthonormal basis <code>\\{\\hat{v}_1, \\hat{v}_2, ..., \\hat{v}_n\\}</code>.</p>\",",
    "formula": "{",
    "latex": "\\[\\hat{v}_i = \\frac{v_i - \\sum_{j=1}^{i-1} \\left(\\frac{v_i}{||v_j||}\\right) \\cdot v_j}{||v_i - \\sum_{j=1}^{i-1} \\left(\\frac{v_i}{||v_j||}\\right) \\cdot v_j||}\\]\" },",
    "workedExample": "{",
    "problemHtml": "<p>Given the vectors <code>\\[v_1 = [1, 0], v_2 = [0, 1]\\]</code>, apply the Gram-Schmidt process to produce an orthonormal basis.</p>\",",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Compute the projection of <code>v_2</code> onto <code>v_1</code>\", \"mathHtml\": \"\\[v_2 - \\frac{v_2 \\cdot v_1}{||v_1||^2} v_1\\]\", \"explanation\": \"This step removes the component of <code>v_2</code> parallel to <code>v_1</code>\"} ],",
    "finalAnswer": "[0, 1]\" },",
    "intuition": "The Gram-Schmidt process ensures that each vector in the orthonormal basis is orthogonal to all previous vectors and has a length of 1.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:07:30.469Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_gram_schmidt_007",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "title": "Gram-Schmidt Process",
    "contentHtml": "<p>The Gram-Schmidt process is a widely used algorithm in linear algebra to orthonormalize a set of vectors.</p><p>Given a set of vectors <code>\\{v_1, v_2, ..., v_n\\}</code>, the goal is to find an orthonormal basis <code>\\{u_1, u_2, ..., u_n\\}</code> such that each <code>u_i</code> is orthogonal to all previous vectors.</p>\",",
    "formula": "{",
    "latex": "\\[v_{i+1} = v_{i+1} - \\sum_{j=1}^{i} \\frac{v_{i+1}^T u_j}{u_j^T u_j} u_j\\]\",",
    "name": "Gram-Schmidt Iteration\" },",
    "workedExample": "{",
    "problemHtml": "<p>Given the vectors <code>\\[1, 2], [3, 4]</code>, apply the Gram-Schmidt process to orthonormalize them.</p>\",",
    "steps": "[ {",
    "stepNumber": 2,
    "description": "Update the second vector by subtracting its projection onto the first",
    "mathHtml": "\\[v_2 = [3, 4] - P\\]\",",
    "explanation": "This step removes any component of the second vector that is parallel to the first\" } ],",
    "finalAnswer": "The orthonormalized vectors are <code>\\[\\frac{1}{\\sqrt{5}}, \\frac{2}{\\sqrt{5}], [-\\frac{4}{\\sqrt{29}}, -\\frac{3}{\\sqrt{29}}]\\]</code>\" },",
    "intuition": "The Gram-Schmidt process is a clever way to 'normalize' each vector while keeping track of the previous ones, ensuring orthogonality.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:08:00.813Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_gram_schmidt_008",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "problem": "{",
    "statementHtml": "<p>Given a set of vectors \\(\\mathbf{v}_1, \\ldots, \\mathbf{v}_n\\) in a Hilbert space, use the Gram-Schmidt process to orthonormalize them.</p>\",",
    "hints": [
      "Start by normalizing the first vector.",
      "Use the previously computed orthonormal vectors to find the next one.",
      "The key is to ensure that each new vector is orthogonal to all previous ones."
    ],
    "solutionHtml": "<p>To orthonormalize \\(\\mathbf{v}_1\\), we compute its norm and divide it by itself:</p>\\n\\[ \\mathbf{u}_1 = \\frac{\\mathbf{v}_1}{||\\mathbf{v}_1||}.\\]\\n<p>Now, for each subsequent vector \\(\\mathbf{v}_i\\), we subtract the projection of \\(\\mathbf{v}_i\\) onto the previously computed orthonormal vectors:</p>\\n\\[ \\mathbf{u}_i = \\mathbf{v}_i - \\sum_{j=1}^{i-1} (\\mathbf{v}_i \\cdot \\mathbf{u}_j) \\mathbf{u}_j.\\]\\n<p>Finally, we normalize the resulting vector:</p>\\n\\[ \\mathbf{u}_i = \\frac{\\mathbf{u}_i}{||\\mathbf{u}_i||}.\\]\",",
    "answerShort": "The orthonormalized vectors are given by \\(\\mathbf{u}_1, \\ldots, \\mathbf{u}_n\\).\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:08:24.364Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_gram_schmidt_009",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "problem": "{",
    "statementHtml": "<p>Given a set of vectors <code>\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_n\\}</code>, use the Gram-Schmidt process to orthonormalize them.</p>\",",
    "hints": "[ \"<p>Start by normalizing the first vector.</p>\", \"<p>Use the fact that <code>\\mathbf{u} \\cdot \\mathbf{w} = 0</code> for orthogonal vectors.</p>\", \"<p>Recursively apply the process to the remaining vectors, considering the projection of each onto the previously orthonormalized ones.</p>\" ],",
    "solutionHtml": "<p>To orthonormalize <code>\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_n\\}</code>, we can proceed as follows:</p><ol><li><p>Let <code>\\mathbf{u}_1 = \\frac{\\mathbf{v}_1}{\\|\\mathbf{v}_1\\|}</code>.</p></li><li><p>For each subsequent vector <code>\\mathbf{v}_i</code>, compute its projection onto the previously orthonormalized vectors:</p><p><code>\\mathbf{w}_i = \\sum_{j=1}^{i-1} (\\mathbf{u}_j \\cdot \\mathbf{v}_i) \\mathbf{u}_j</code>.</p></li><li><p>Compute the residual vector:</p><p><code>\\mathbf{r}_i = \\mathbf{v}_i - \\mathbf{w}_i</code>.</p></li><li><p>Normalize the residual:</p><p><code>\\mathbf{u}_i = \\frac{\\mathbf{r}_i}{\\|\\mathbf{r}_i\\|}</code>.</p></li></ol>\",",
    "answerShort": "<code>\\{\\mathbf{u}_1, \\ldots, \\mathbf{u}_n\\}</code>\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:08:51.735Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_gram_schmidt_010",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "problem": "{",
    "statementHtml": "<p>Given a set of vectors <i>V</i>, use the Gram-Schmidt process to orthogonalize them.</p>",
    "hints": [
      "Start by normalizing the first vector.",
      "Use the previous result to find an orthogonal complement for each subsequent vector.",
      "Be mindful of numerical stability when performing the calculations."
    ],
    "solutionHtml": "<p>To begin, normalize the first vector <i>v</i><sub>1</sub>: \\\\( \\mathbf{v}_1 = \\frac{\\mathbf{v}_1}{\\|\\mathbf{v}_1\\|} \\\\)</p><p>Next, for each subsequent vector <i>v</i><sub>i+1</sub>, find its orthogonal complement with respect to the previously orthogonalized vectors:</p><p>\\\\( \\mathbf{w}_{i+1} = \\mathbf{v}_{i+1} - \\sum_{j=1}^i \\left(\\frac{\\mathbf{v}_{i+1}}{\\|\\mathbf{v}_j\\|}\\cdot\\mathbf{v}_j\\right)\\mathbf{v}_j \\\\)</p><p>Finally, normalize the resulting vector:</p><p>\\\\( \\mathbf{v}_{i+1} = \\frac{\\mathbf{w}_{i+1}}{\\|\\mathbf{w}_{i+1}\\|} \\\\)</p>\",",
    "answerShort": "The orthogonalized vectors\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:09:12.494Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_gram_schmidt_011",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "problem": "{",
    "statementHtml": "Given a set of vectors <i>u</i><sub>1</sub>, …, <i>u</i><sub>k</sub> in ℝ<sup>n</sup>, use the Gram-Schmidt process to orthonormalize them.",
    "hints": [
      "Start by normalizing each vector.",
      "Use the previous vectors to find the projection of the current one onto the subspace spanned by the previous ones.",
      "The final step is to subtract the projection from the original vector."
    ],
    "solutionHtml": "<p>Let's orthonormalize the vectors <i>u</i><sub>1</sub>, …, <i>u</i><sub>k</sub>. First, we normalize each vector:</p>\\[ u_i = \\frac{u_i}{\\|u_i\\|} \\]\\n<p>Next, we use the previous vectors to find the projection of the current one onto the subspace spanned by the previous ones:</p>\\[ v_i = u_i - \\sum_{j=1}^{i-1} (u_i \\cdot v_j) v_j \\]\\n<p>The final step is to subtract the projection from the original vector:</p>\\[ w_i = v_i \\]\\n<p>Repeat this process until all vectors are orthonormal.</p>\",",
    "answerShort": "The orthonormalized vectors <i>w</i><sub>1</sub>, …, <i>w</i><sub>k</sub>\" },",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:09:33.780Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_gram_schmidt_012",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "title": "Gram-Schmidt Process: Orthonormalization",
    "contentHtml": "<p>The Gram-Schmidt process is a popular method for orthonormalizing vectors in linear algebra.</p>",
    "formula": "{",
    "latex": "\\[v_1, \\ldots, v_k\\]",
    "name": "Orthonormal basis\" },",
    "problem": "{",
    "statementHtml": "<p>Given three vectors <code>a</code>, <code>b</code>, and <code>c</code> in a Hilbert space, find an orthonormal basis using the Gram-Schmidt process.</p>",
    "hints": [
      "Hint: Start with the first vector"
    ],
    "solutionHtml": "<p><ul><li>We start by normalizing the first vector:</li>\\( v_1 = \\frac{a}{\\| a \\|} \\)</li><li>Next, we subtract the projection of <code>b</code> onto <code>v_1</code> from <code>b</code>:</li>\\( b' = b - \\frac{b \\cdot v_1}{v_1 \\cdot v_1} v_1 \\)</li><li>We then normalize <code>b'</code>:</li>\\( v_2 = \\frac{b'}{\\| b' \\|} \\)</li><li>Repeat the process for <code>c</code>:</li>\\( c' = c - \\frac{c \\cdot v_1}{v_1 \\cdot v_1} v_1 - \\frac{c \\cdot v_2}{v_2 \\cdot v_2} v_2 \\)</li><li>Finally, normalize <code>c'</code>:</li>\\( v_3 = \\frac{c'}{\\| c' \\|} \\)</li></ul></p>\",",
    "answerShort": "The orthonormal basis is {v_1, v_2, v_3}\" },",
    "workedExample": "{",
    "problemHtml": "<p>Find an orthonormal basis for the vectors <code>a = [1, 0, 1]</code>, <code>b = [0, 1, 1]</code>, and <code>c = [1, 1, 0]</code>.</p>",
    "steps": "[ {",
    "stepNumber": 5,
    "description": "Normalize the third vector",
    "mathHtml": "\\( v_3 = \\frac{[0, -\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}]}{\\| [0, -\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}] \\|} = [0, -\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}] \\)\",",
    "explanation": "We normalize the third vector to ensure it has a length of 1.\" } ],",
    "finalAnswer": "The orthonormal basis is {v_1, v_2, v_3}\" },",
    "intuition": "The Gram-Schmidt process ensures that each new vector is orthogonal to all previous vectors.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:10:53.148Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_gram_schmidt_013",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "title": "Gram-Schmidt Process: Orthonormalization",
    "contentHtml": "<p>The Gram-Schmidt process is a widely used algorithm in linear algebra to orthonormalize a set of vectors.</p>",
    "formula": {
      "latex": "\\[v_1, \\ldots, v_k = Q\\begin{bmatrix} e_1 \\\\vdots\\\\ e_k \\end{bmatrix}\\]",
      "name": "Orthonormalization"
    },
    "problem": {
      "statementHtml": "<p>Given a set of vectors {v_1, \\ldots, v_n}, find an orthonormal basis {u_1, \\ldots, u_k} such that span({u_1, \\ldots, u_k}) = span({v_1, \\ldots, v_n}).</p>",
      "hints": [
        "Start with the first vector",
        "Use the dot product to orthogonalize"
      ],
      "solutionHtml": "<p>Step 1: Choose the first vector u_1 = v_1.</p><p>Step 2: For each subsequent vector v_i, subtract its projection onto the previously chosen vectors:</p><ul><li>v_i - \\sum_{j=1}^{i-1} (v_i \\cdot u_j)u_j</li></ul><p>Step 3: Normalize the resulting vector to get the orthonormal basis.</p>",
      "answerShort": "The orthonormal basis {u_1, \\ldots, u_k}"
    },
    "workedExample": {
      "problemHtml": "<p>Given vectors v_1 = [1, 0], v_2 = [0, 1], and v_3 = [1, 1], find an orthonormal basis.</p>",
      "steps": [
        {
          "stepNumber": 1,
          "description": "Choose the first vector",
          "mathHtml": "\\[u_1 = v_1 = [1, 0]\\]",
          "explanation": "We start with the first vector."
        },
        {
          "stepNumber": 2,
          "description": "Orthogonalize the second vector",
          "mathHtml": "\\[v_2 - (v_2 \\cdot u_1)u_1 = [0, 1] - \\frac{1}{\\sqrt{2}}[1, 0] = \\left[-\\frac{1}{\\sqrt{2}}, 1\\right]\\]",
          "explanation": "We subtract the projection of v_2 onto u_1."
        },
        {
          "stepNumber": 3,
          "description": "Normalize the resulting vector",
          "mathHtml": "\\[u_2 = \\frac{1}{\\sqrt{2}}[-1, 1]\\]",
          "explanation": "We normalize the resulting vector to get an orthonormal basis."
        }
      ],
      "finalAnswer": "The orthonormal basis {u_1, u_2} = {[1, 0], [\\frac{-1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}]}"
    },
    "intuition": "The Gram-Schmidt process helps us find an orthonormal basis by iteratively orthogonalizing and normalizing vectors.",
    "estimatedMinutes": 2,
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:11:33.070Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_gram_schmidt_014",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "title": "Gram-Schmidt Process: A Step-by-Step Guide",
    "contentHtml": "<p>The Gram-Schmidt process is a powerful tool for orthonormalizing vectors in linear algebra.</p>",
    "workedExample": "{",
    "problemHtml": "Find the orthonormal basis of the span of <math>\\{\\mathbf{v}_1, \\mathbf{v}_2\\}</math> where\", \"<ul><li><math>\\mathbf{v}_1 = [1, -1, 0]</math></li><li><math>\\mathbf{v}_2 = [1, 1, 1]</math></li></ul>\",",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Normalize the first vector\", \"mathHtml\": \"<math>\\mathbf{u}_1 = \\frac{\\mathbf{v}_1}{\\|\\mathbf{v}_1\\|}</math>\", \"explanation\": \"We do this to ensure that our vectors have unit length.\"}, {\"stepNumber\": 2, \"description\": \"Project the second vector onto the first\", \"mathHtml\": \"<math>\\mathbf{p} = \\frac{\\mathbf{v}_2^T \\mathbf{u}_1}{\\|\\mathbf{u}_1\\|^2}</math>\", \"explanation\": \"This step removes any component of <math>\\mathbf{v}_2</math> that is already accounted for by <math>\\mathbf{u}_1</math>.\"}, {\"stepNumber\": 3, \"description\": \"Subtract the projection from the second vector\", \"mathHtml\": \"<math>\\mathbf{w} = \\mathbf{v}_2 - \\mathbf{p}</math>\", \"explanation\": \"This ensures that <math>\\mathbf{w}</math> is orthogonal to <math>\\mathbf{u}_1</math>.\"}, {\"stepNumber\": 4, \"description\": \"Normalize the resulting vector\", \"mathHtml\": \"<math>\\mathbf{u}_2 = \\frac{\\mathbf{w}}{\\|\\mathbf{w}\\|}</math>\", \"explanation\": \"This step ensures that our vectors have unit length again.\"} ],",
    "finalAnswer": "<math>\\{\\mathbf{u}_1, \\mathbf{u}_2\\}</math>\" },",
    "intuition": "The Gram-Schmidt process is a way to iteratively orthonormalize a set of vectors. It's like a game of 'vector subtraction' where you keep removing any components that are already accounted for by the previous vectors.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:12:04.725Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_gram_schmidt_015",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "inner_products_orthogonality",
    "topic": "gram_schmidt",
    "title": "Gram-Schmidt Process: A Step-by-Step Guide",
    "contentHtml": "<p>The Gram-Schmidt process is a fundamental algorithm in linear algebra that orthonormalizes vectors.</p>",
    "workedExample": "{",
    "problemHtml": "Given two vectors <math>\\mathbf{a} = \\left[\\begin{array}{c}1\\\\2\\end{array}\\right]</math> and <math>\\mathbf{b} = \\left[\\begin{array}{c}3\\\\4\\end{array}\\right]</math>, apply the Gram-Schmidt process to find an orthonormal basis.\",",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Find the projection of <math>\\mathbf{b}</math> onto <math>\\mathbf{a}</math>\", \"mathHtml\": \"<math>P_\\mathbf{a}(\\mathbf{b}) = \\frac{\\mathbf{a}\\cdot\\mathbf{b}}{\\|\\mathbf{a}\\|^2}\\mathbf{a}</math>\", \"explanation\": \"We're finding the component of <math>\\mathbf{b}</math> that lies in the direction of <math>\\mathbf{a}</math>.\"}, {\"stepNumber\": 2, \"description\": \"Subtract the projection from <math>\\mathbf{b}</math>\", \"mathHtml\": \"<math>\\mathbf{v}_1 = \\mathbf{b} - P_\\mathbf{a}(\\mathbf{b})</math>\", \"explanation\": \"This step ensures that <math>\\mathbf{v}_1</math> is orthogonal to <math>\\mathbf{a}</math>.\"}, {\"stepNumber\": 3, \"description\": \"Normalize <math>\\mathbf{v}_1</math>\", \"mathHtml\": \"<math>\\mathbf{u}_1 = \\frac{\\mathbf{v}_1}{\\|\\mathbf{v}_1\\|}</math>\", \"explanation\": \"We're making sure that the resulting vector has length 1.\"}, {\"stepNumber\": 4, \"description\": \"Repeat steps 1-3 for <math>\\mathbf{u}_1</math> and <math>\\mathbf{b}</math>\", \"mathHtml\": \"\", \"explanation\": \"We're applying the Gram-Schmidt process recursively to find an orthonormal basis.\"}, {\"stepNumber\": 5, \"description\": \"The final orthonormal basis is given by <math>\\{\\mathbf{u}_1, \\mathbf{u}_2\\}</math>\", \"mathHtml\": \"\", \"explanation\": \"This is the resulting orthonormal basis.\"} ],",
    "finalAnswer": "<math>\\{\\mathbf{u}_1 = [0.2679, 0.5345], \\mathbf{u}_2 = [-0.8018, -0.6018]\\}</math>\" },",
    "intuition": "The Gram-Schmidt process is a powerful tool for orthonormalizing vectors, and it has many applications in machine learning and artificial intelligence.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:12:43.445Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]