[
  {
    "id": "la_for_orthogonal_projection_004",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "inner_products_orthogonality",
    "topic": "orthogonal_projection",
    "title": "Orthogonal Projection",
    "contentHtml": "<p>The orthogonal projection of a vector onto a subspace is crucial in many applications, including machine learning and signal processing.</p>",
    "formula": "{",
    "latex": "\\[P_A = A (A^T A)^{-1} A^T\\]\",",
    "name": "Orthogonal Projection Matrix",
    "variants": "[ {\"latex\": \"\\[P_A x = P_A x\\]\", \"description\": \" Idempotence\"} ] },",
    "workedExample": "{",
    "problemHtml": "<p>Find the orthogonal projection of a vector <code>x</code> onto a subspace spanned by the matrix <code>A</code>.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Compute the projection matrix <code>P_A</code>\", \"mathHtml\": \"\\[P_A = A (A^T A)^{-1} A^T\\]\", \"explanation\": \"We use the formula for orthogonal projection matrices.\"} ],",
    "finalAnswer": "The answer is...\" },",
    "intuition": "Orthogonal projection helps us find the best approximation of a vector within a subspace, which is essential in many machine learning algorithms.",
    "realWorldApplications": [
      "Dimensionality reduction",
      "Anomaly detection"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:13:47.637Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_orthogonal_projection_005",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "inner_products_orthogonality",
    "topic": "orthogonal_projection",
    "title": "Orthogonal Projection",
    "contentHtml": "<p>The orthogonal projection of a vector onto a subspace is crucial in many applications, including machine learning and data analysis.</p>",
    "formula": "{",
    "latex": "\\[ P_A = A (A^T A)^{-1} A^T \\]\",",
    "name": "Projection Matrix",
    "variants": "[ {\"latex\": \"\\[ P_A x = (x^T A) (A^T A)^{-1} A^T \\]\", \"description\": \"Vector projection\"} ] },",
    "intuition": "The orthogonal projection matrix, P_A, maps a vector to its closest point in the subspace. This is useful when we want to find the best approximation of a vector within that subspace.",
    "visualDescription": "A diagram showing the original vector, the subspace, and the projected vector would help illustrate this concept.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:14:02.322Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_orthogonal_projection_006",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "inner_products_orthogonality",
    "topic": "orthogonal_projection",
    "title": "Orthogonal Projection",
    "contentHtml": "<p>The orthogonal projection of a vector onto a subspace is a fundamental concept in linear algebra and has numerous applications in machine learning.</p>",
    "formula": "{",
    "latex": "\\[ P = A (A^T A)^{-1} A^T \\]\",",
    "name": "Projection Matrix\" },",
    "workedExample": "{",
    "problemHtml": "<p>Find the orthogonal projection of <math>\\mathbf{x}</math> onto the subspace spanned by <math>\\mathbf{v}</math>.</p>\",",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Compute the matrix A\", \"mathHtml\": \"\\[ A = \\begin{bmatrix} v_1 & v_2 & \\cdots \\end{bmatrix} \\]\", \"explanation\": \"A is the matrix of column vectors that span the subspace.\"} ],",
    "finalAnswer": "The answer\" },",
    "intuition": "The orthogonal projection matrix P minimizes the squared distance between a vector and its projection, making it a crucial component in many machine learning algorithms.",
    "realWorldApplications": [
      "Dimensionality reduction",
      "Anomaly detection"
    ],
    "tags": [
      "orthogonal projection",
      "linear algebra",
      "machine learning"
    ],
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:14:20.753Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_orthogonal_projection_007",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "inner_products_orthogonality",
    "topic": "orthogonal_projection",
    "title": "Orthogonal Projection",
    "contentHtml": "<p>Given a subspace and a vector, orthogonal projection finds the closest point in that subspace to the original vector.</p>",
    "formula": "{",
    "latex": "\\[P = A (A^T A)^{-1} A^T\\]\",",
    "name": "Orthogonal Projection Formula",
    "variants": "[ {\"latex\": \"\\[P = I - Q\\]\", \"description\": \"Alternative formula using the orthogonal complement\"} ] },",
    "workedExample": "{",
    "problemHtml": "<p>Find the closest point in the subspace spanned by <math>\\mathbf{v}_1</math> and <math>\\mathbf{v}_2</math> to the vector <math>\\mathbf{x}</math>.</p>\",",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Find the projection matrix\", \"mathHtml\": \"\\[A = [\\mathbf{v}_1 \\quad \\mathbf{v}_2]\\]\", \"explanation\": \"We use the formula above to construct the projection matrix.\"}, {\"stepNumber\": 2, \"description\": \"Compute the projection\", \"mathHtml\": \"\\[P\\mathbf{x}\\]\", \"explanation\": \"We multiply the projection matrix by the original vector.\"} ],",
    "finalAnswer": "<p>The closest point is <math>P \\mathbf{x}</math>.</p>\" },",
    "intuition": "Orthogonal projection helps us find the best approximation of a vector within a subspace, which is crucial in many machine learning and computer vision applications.",
    "difficulty": 3,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:14:42.526Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]