[
  {
    "id": "la_con_svd_definition_001",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>Singular Value Decomposition (SVD) is a fundamental concept in linear algebra that allows us to decompose a matrix into three matrices: U, Σ, and Vᵀ. This decomposition has far-reaching implications for many areas of mathematics and computer science.</p><p>In essence, SVD helps us identify the most important features or directions in a dataset by capturing its energy in a compact way.</p>",
    "formula": {
      "latex": "\\[ A = U \\Sigma V^\\mathsf{T} \\]",
      "name": "SVD Decomposition"
    },
    "intuition": "Think of SVD as a tool to compress the information in a matrix while preserving its essential structure. This is crucial in machine learning, where we often need to reduce the dimensionality of large datasets or identify the most important features.",
    "realWorldApplications": [
      "Dimensionality reduction",
      "Feature selection"
    ],
    "commonMistakes": [
      "Not understanding the difference between SVD and PCA",
      "Thinking SVD only applies to square matrices"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:35:29.559Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_svd_definition_002",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>Singular Value Decomposition (SVD) is a fundamental matrix decomposition technique that factorizes a real-valued matrix into three matrices: U, Σ, and Vᵀ.</p><p>Given a matrix A, SVD represents it as A = UΣVᵀ, where U and V are orthogonal matrices, and Σ is a diagonal matrix containing the singular values of A.</p>",
    "formula": {
      "latex": "\\[A = U\\Sigma V^\\T\\]",
      "name": "SVD Formula"
    },
    "intuition": "Think of SVD as a way to compress a high-dimensional space into a lower-dimensional one, retaining most of the information. This is crucial in many ML/AI applications, such as dimensionality reduction and feature extraction.",
    "realWorldApplications": [
      "Dimensionality Reduction",
      "Feature Extraction"
    ],
    "commonMistakes": [
      "Confusing SVD with PCA; not understanding the difference between singular values and eigenvalues"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:35:44.725Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_svd_definition_003",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>The Singular Value Decomposition (SVD) is a fundamental matrix decomposition that factorizes a real-valued matrix A into three matrices: U, Σ, and Vᵀ. It's a way to represent a matrix in terms of its eigenvectors and eigenvalues.</p><p>In essence, SVD helps us identify the most important directions in which the matrix is varying. This is particularly useful in machine learning applications where we often work with high-dimensional data.</p>",
    "formula": {
      "latex": "\\[ A = U \\Sigma V^\\mathsf{T} \\]",
      "name": "SVD Factorization",
      "variants": [
        {
          "latex": "\\[ \\sigma_i \\geq 0, \\sum_{i=1}^r \\sigma_i^2 = \\|A\\|^2_2 \\]",
          "description": "Properties of singular values"
        }
      ]
    },
    "intuition": "Think of SVD as a way to compress the information in a matrix by retaining only its most important features. The matrices U and Vᵀ contain the eigenvectors, while Σ contains the eigenvalues (or singular values).",
    "realWorldApplications": [
      "Dimensionality reduction in image compression"
    ],
    "commonMistakes": [
      "Failing to recognize that SVD is not unique; there are many possible decompositions."
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:36:03.453Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_svd_definition_004",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>Singular Value Decomposition (SVD) is a powerful matrix decomposition technique that factorizes a real-valued matrix into three matrices: U, Σ, and Vᵀ.</p><p>This decomposition provides a compact representation of the original matrix, retaining most of its information.</p>",
    "formula": "{",
    "latex": "\\[A = U\\Sigma V^\\mathsf{T}\\]\",",
    "name": "SVD Decomposition",
    "variants": "[ {\"latex\": \"\\[\\Sigma = \\text{diag}(\\sigma_1, ..., \\sigma_r)\\]\", \"description\": \"where σ_i are the singular values\"} ] },",
    "workedExample": "{",
    "problemHtml": "<p>Given a matrix A, find its SVD decomposition.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Compute the covariance matrix Σ\", \"mathHtml\": \"\\[\\Sigma = \\frac{1}{n} AA^\\mathsf{T}\\]\", \"explanation\": \"This step helps us identify the singular values.\"} ],",
    "finalAnswer": "The SVD decomposition of A\" },",
    "intuition": "SVD is useful for dimensionality reduction, feature extraction, and data compression in machine learning applications.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:36:22.519Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_svd_definition_005",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>The Singular Value Decomposition (SVD) is a fundamental matrix decomposition technique in linear algebra.</p><p>Given an m × n matrix A, the SVD decomposes it into three matrices: U ∈ ℝ<sup>m</sup>xk, Σ ∈ ℝ<sup>k</sup>xk, and Vᵀ ∈ ℝ<sup>n</sup>xk, where k is the rank of A.</p>",
    "formula": "{",
    "latex": "\\[A = U\\Sigma V^T\\]\",",
    "name": "SVD Decomposition",
    "variants": "[] },",
    "workedExample": "{",
    "problemHtml": "<p>Consider a matrix A representing an image, where each column is a pixel.</p>",
    "steps": "[ {\"stepNumber\": 1, \"description\": \"Find the SVD decomposition of A\", \"mathHtml\": \"\\[A = U\\Sigma V^T\\]\", \"explanation\": \"This allows us to represent the image in a more compact form\"} ],",
    "finalAnswer": "The SVD decomposition\" },",
    "intuition": "SVD helps us identify the most important features or directions in a dataset, which is crucial for many machine learning and AI applications.",
    "realWorldApplications": [
      "Dimensionality reduction",
      "Image compression"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:36:41.228Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_svd_definition_006",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>The Singular Value Decomposition (SVD) is a fundamental matrix decomposition technique in linear algebra.</p><p>Given an m × n matrix A, the SVD factorizes it as A = UΣVᵀ, where U and V are orthogonal matrices, and Σ is a diagonal matrix containing the singular values of A.</p>",
    "formula": "{",
    "latex": "\\[A = U\\Sigma V^\\mathsf{T}\\]\",",
    "name": "SVD",
    "variants": "[ {\"latex\": \"\\[\\Sigma = \\text{diag}(\\sigma_1, ..., \\sigma_r)\\]\",",
    "description": "where σ_i are the r non-zero singular values\"} ] },",
    "intuition": "The SVD provides a compact representation of A by retaining only the most important information in the form of the top-k singular values and their corresponding left and right singular vectors.",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:36:55.471Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_for_svd_definition_007",
    "subject": "linear_algebra",
    "type": "formula",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>Singular Value Decomposition (SVD) is a fundamental matrix decomposition technique in linear algebra.</p><p>Given a rectangular matrix A, SVD factorizes it into three matrices: U, Σ, and Vᵀ, such that A = UΣVᵀ.</p>",
    "formula": "{",
    "latex": "\\[A = U\\Sigma V^\\mathsf{T}\\]\",",
    "name": "SVD Factorization\" },",
    "intuition": "SVD is a powerful tool for analyzing and compressing data, as it allows us to identify the most important features or directions in a dataset.",
    "realWorldApplications": [
      "Dimensionality reduction in computer vision",
      "Compressing neural networks"
    ],
    "tags": [
      "Linear Algebra",
      "Matrix Decomposition",
      "Machine Learning"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:37:08.666Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_thm_svd_definition_008",
    "subject": "linear_algebra",
    "type": "theorem",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>The Singular Value Decomposition (SVD) is a fundamental matrix decomposition that factorizes a real-valued matrix A into three matrices: U, Σ, and Vᵀ.</p><p>This theorem provides the existence and uniqueness of SVD for any given matrix A.</p>",
    "formula": {
      "latex": "\\[A = U\\Sigma V^\\T\\]",
      "name": "SVD Factorization"
    },
    "theorem": {
      "statement": "\\[A = U\\Sigma V^\\T\\] exists and is unique for any given matrix A.",
      "proofSketch": "The proof involves showing that the SVD is equivalent to a diagonalization of the covariance matrix, leveraging properties of symmetric matrices."
    },
    "intuition": "SVD provides a compact representation of a matrix by capturing its essential features in terms of singular values and vectors. This decomposition has far-reaching implications for dimensionality reduction, data compression, and feature extraction in machine learning applications.",
    "realWorldApplications": [
      "Dimensionality reduction in recommender systems",
      "Data compression in computer vision"
    ],
    "tags": [
      "SVD",
      "Matrix Decomposition",
      "Linear Algebra"
    ],
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:37:26.735Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_thm_svd_definition_009",
    "subject": "linear_algebra",
    "type": "theorem",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>The Singular Value Decomposition (SVD) is a fundamental matrix decomposition that represents any matrix A as the product of three matrices: U, Σ, and Vᵀ.</p>",
    "formula": "{",
    "latex": "\\[A = U\\Sigma V^T\\]\",",
    "name": "SVD\" },",
    "theorem": "{",
    "statement": "\\[A = U\\Sigma V^T,\\quad \\text{where }U, V \\in \\mathbb{R}^{m\\times k}, \\Sigma \\in \\mathbb{R}^{k\\times k}\\]\",",
    "proofSketch": "The proof involves showing that the SVD is a decomposition of the matrix A into its left and right singular vectors and values.\" },",
    "intuition": "The SVD provides a way to compress or reduce the dimensionality of a matrix, which has important implications in machine learning and data analysis.",
    "realWorldApplications": [
      "Principal component analysis (PCA)"
    ],
    "tags": [
      "Singular Value Decomposition",
      "Matrix Decomposition"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:37:42.669Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_svd_definition_010",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "problem": "{",
    "statementHtml": "Given a matrix A ∈ ℝ<sup>m×n</sup>, prove that its Singular Value Decomposition (SVD) exists and is unique.",
    "hints": [
      "Start by recalling the definition of SVD: A = UΣVᵀ. What does this decomposition tell us about the matrix?",
      "Think about what makes a matrix singular or non-singular. How does this relate to the existence and uniqueness of SVD?",
      "Consider the properties of the matrices U, Σ, and Vᵀ. Which ones are crucial for the existence and uniqueness of SVD?"
    ],
    "solutionHtml": " To prove the existence of SVD, we can show that any matrix A ∈ ℝ<sup>m×n</sup> can be written as A = UΣVᵀ, where U and V are orthogonal matrices, and Σ is a diagonal matrix with non-negative entries.  First, note that if A has full column rank (i.e., its columns are linearly independent), then the SVD exists. This is because we can always find an orthonormal basis for the column space of A, which corresponds to the columns of U. Similarly, we can find an orthonormal basis for the row space of A, which corresponds to the rows of V.  Now, suppose A does not have full column rank. Then, its nullspace (the set of vectors that satisfy Ax = 0) is non-trivial. Let u be a unit vector in this nullspace. Then, Au = 0, so Uu = ΣVᵀu = 0.  Since U and V are orthogonal matrices, their columns form orthonormal bases for the column and row spaces of A, respectively. Therefore, we can write any matrix A as A = UΣVᵀ, where U and V are orthogonal matrices, and Σ is a diagonal matrix with non-negative entries.  To prove uniqueness, suppose that A = U₁Σ₁V₁ᵀ = U₂Σ₂V₂ᵀ for some matrices U₁, U₂, V₁, and V₂. Then,  \\[\\begin{align*} U₁^T U₂ & = I, \\\\ V₁^T V₂ & = I, \\\\ Σ₁ Σ₂ & = Σ \\end{align*}\\]  These equations imply that U₁ = U₂, Σ₁ = Σ₂, and V₁ = V₂. Therefore, the SVD is unique.  The answerShort: The SVD exists and is unique for any matrix A ∈ ℝ<sup>m×n</sup>.\",",
    "answerShort": "The SVD exists and is unique.\" },",
    "commonMistakes": [
      "Forgetting to consider the case where A has full column rank",
      "Not recognizing that U and V are orthogonal matrices"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:38:16.106Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_svd_definition_011",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "problem": "{",
    "statementHtml": "<p>Given a matrix A ∈ ℝ<sup>m×n</sup>, prove that it can be decomposed as A = UΣVᵀ, where U and V are orthogonal matrices, Σ is a diagonal matrix containing the singular values of A.</p>",
    "hints": [
      "Start by considering the eigenvalues and eigenvectors of AA<sup>T</sup>.",
      "Use the fact that Σ is a diagonal matrix to simplify the decomposition.",
      "Recall that U and V are orthogonal matrices, which implies certain properties."
    ],
    "solutionHtml": "<p>To prove the existence of such a decomposition, we can start by considering the eigenvalues and eigenvectors of AA<sup>T</sup>. Let λ be an eigenvalue with corresponding eigenvector v. Then:</p>\\n\\[AA^T v = λv\\]\\n<p>Since AA<sup>T</sup> is symmetric, its eigenvalues are real. We can then define the matrices U and Σ as follows:</p>\\n\\[U = [u_1, ..., u_k], Σ = diag(σ_1, ..., σ_k), V = [v_1, ..., v_k]\\]\\n<p>where u_i and v_i are the eigenvectors corresponding to λ_i. The matrix Σ contains the singular values of A.</p>\\n<p>To prove uniqueness, suppose we have another decomposition A = U'Σ'V'. Then:</p>\\n\\[U'S'V' = AA^T\\]\\n<p>Since U and V are orthogonal, so are U' and V'. This implies that Σ = Σ', U = U', and V = V', proving uniqueness.</p>\",",
    "answerShort": "The decomposition A = UΣVᵀ exists and is unique.\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:38:40.938Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_svd_definition_012",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "problem": "{",
    "statementHtml": "<p>Given a matrix A ∈ ℝ<sup>m×n</sup>, prove that it can be decomposed as A = UΣVᵀ, where U and V are orthogonal matrices, Σ is a diagonal matrix containing the singular values of A.</p>",
    "hints": [
      "Start by considering the eigenvalue decomposition of AA<sup>T</sup>.",
      "Show that the columns of U are the left-singular vectors of A.",
      "Use the fact that Σ is a diagonal matrix to simplify the expression for Vᵀ."
    ],
    "solutionHtml": "<p>To prove the existence and uniqueness of the SVD, start by considering the eigenvalue decomposition of AA<sup>T</sup>.</p><ul><li>\\[AA^T = UΔU^T\\]</li></ul><p>Now, show that the columns of U are the left-singular vectors of A.</p><ul><li>\\[\\mathbf{u}_i = \\frac{\\mathbf{a}_i}{\\|\\mathbf{a}_i\\|}\\]</li></ul><p>Next, use the fact that Σ is a diagonal matrix to simplify the expression for Vᵀ.</p><ul><li>\\[V^T = UΣ^{-1}\\]</li></ul><p>This shows that A can be decomposed as A = UΣV^T.</p>\",",
    "answerShort": "A = UΣVᵀ\" },",
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:39:02.651Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_prb_svd_definition_013",
    "subject": "linear_algebra",
    "type": "problem",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "problem": {
      "statementHtml": "<p>Given a matrix A ∈ ℝ<sup>m×n</sup>, prove that it can be decomposed as A = UΣVᵀ, where U and V are orthogonal matrices, Σ is a diagonal matrix containing the singular values of A.</p>",
      "hints": [
        "Start by considering the eigenvalues and eigenvectors of AA<sup>T</sup>.",
        "Recall that the SVD is closely related to the PCA decomposition.",
        "Think about how you can use the properties of orthogonal matrices to simplify the expression."
      ],
      "solutionHtml": "<p>To prove the existence of the SVD, we need to show that AA<sup>T</sup> has only real eigenvalues. This follows from the fact that AA<sup>T</sup> is symmetric.</p><p>Next, we can use the spectral theorem to diagonalize AA<sup>T</sup></p>",
      "answerShort": "The SVD exists and is unique."
    },
    "commonMistakes": [
      "Forgetting that AA<sup>T</sup> has only real eigenvalues.",
      "Trying to diagonalize AA instead of AA<sup>T</sup>"
    ],
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:39:19.158Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_svd_definition_014",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>Solve a matrix decomposition problem step-by-step using SVD.</p>",
    "formula": {
      "latex": "\\[ A = U\\Sigma V^\\mathsf{T} \\]",
      "name": "SVD Formula"
    },
    "problem": {
      "statementHtml": "<p>Given a matrix A, find its singular value decomposition (SVD) A = UΣVᵀ.</p>",
      "hints": [
        "Hint: SVD is a factorization of A into three matrices."
      ],
      "solutionHtml": "<p>Solution steps:</p><ul><li>Step 1: Compute the covariance matrix Σ.</li><li>Step 2: Find the eigenvectors and eigenvalues of Σ.</li><li>Step 3: Construct the orthogonal matrices U and Vᵀ from the eigenvectors.</li></ul>",
      "answerShort": "The SVD decomposition A = UΣVᵀ."
    },
    "workedExample": {
      "problemHtml": "<p>Consider a matrix A with singular value decomposition A = UΣVᵀ. Compute Σ and Vᵀ given U.</p>",
      "steps": [
        {
          "stepNumber": 1,
          "description": "Compute the covariance matrix Σ.",
          "mathHtml": "\\[ \\Sigma = (U^\\mathsf{T} AU)/n \\]",
          "explanation": "We compute Σ as the average of the outer product of U and A."
        },
        {
          "stepNumber": 2,
          "description": "Find the eigenvectors and eigenvalues of Σ.",
          "mathHtml": "\\[ \\Sigma = U\\Lambda U^\\mathsf{T} \\]",
          "explanation": "We diagonalize Σ to obtain its eigenvectors and eigenvalues."
        },
        {
          "stepNumber": 3,
          "description": "Construct the orthogonal matrices U and Vᵀ from the eigenvectors.",
          "mathHtml": "\\[ V = U\\Lambda^\\frac{1}{2} \\]",
          "explanation": "We construct Vᵀ as the matrix of eigenvectors scaled by their eigenvalues."
        }
      ],
      "finalAnswer": "The SVD decomposition A = UΣVᵀ."
    },
    "intuition": "SVD is a powerful tool for dimensionality reduction and feature extraction in machine learning.",
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:39:48.627Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_svd_definition_015",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>Solve the SVD problem step-by-step.</p>",
    "formula": {
      "latex": "\\[A = U\\Sigma V^\\T\\]",
      "name": "SVD"
    },
    "problem": {
      "statementHtml": "<p>Given a matrix A, find its SVD decomposition.</p>",
      "hints": [
        "Hint: Use the definition of SVD"
      ],
      "solutionHtml": ""
    },
    "workedExample": {
      "problemHtml": "<p>Find the SVD decomposition of \\[\\begin{bmatrix}1 & 2 \\\\ 3 & 4\\end{bmatrix}\\].</p>",
      "steps": [
        {
          "stepNumber": 1,
          "description": "Write down the definition of SVD",
          "mathHtml": "\\[A = U\\Sigma V^\\T\\]",
          "explanation": "We're using the definition to guide our solution."
        },
        {
          "stepNumber": 2,
          "description": "Find the singular values and vectors",
          "mathHtml": "",
          "explanation": "We'll use the definition again to find the singular values and vectors."
        },
        {
          "stepNumber": 3,
          "description": "Compute the diagonal matrix Σ",
          "mathHtml": "\\[\\Sigma = \\begin{bmatrix}2 & 0 \\\\ 0 & 1.5\\end{bmatrix}\\]",
          "explanation": "The diagonal entries of Σ are the singular values."
        },
        {
          "stepNumber": 4,
          "description": "Find the matrices U and V",
          "mathHtml": "\\[U = \\begin{bmatrix}0.2673 & -0.9487 \\\\ 0.9487 & 0.2673\\end{bmatrix},\nV^\\T = \\begin{bmatrix}-0.7071 & 0.7071 \\\\ 0.7071 & -0.7071\\end{bmatrix}\\]",
          "explanation": "We'll use the definition again to find U and V."
        },
        {
          "stepNumber": 5,
          "description": "Verify the SVD decomposition",
          "mathHtml": "",
          "explanation": "We can verify that A = UΣV^T by plugging in our values."
        }
      ],
      "finalAnswer": "\\[\\begin{bmatrix}1 & 2 \\\\ 3 & 4\\end{bmatrix} = \\begin{bmatrix}0.2673 & -0.9487 \\\\ 0.9487 & 0.2673\\end{bmatrix}\\begin{bmatrix}2 & 0 \\\\ 0 & 1.5\\end{bmatrix}\\begin{bmatrix}-0.7071 & 0.7071 \\\\ 0.7071 & -0.7071\\end{bmatrix}^\\T\\]"
    },
    "intuition": "SVD is a powerful tool for dimensionality reduction and feature extraction in machine learning.",
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:40:24.206Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_svd_definition_016",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>Solve a matrix decomposition problem step-by-step.</p>",
    "formula": {
      "latex": "\\[A = U\\Sigma V^\\T\\]",
      "name": "SVD",
      "variants": [
        {
          "latex": "\\[U\\in \\mathbb{R}^{m \\times k}, \\Sigma\\in \\mathbb{R}^{k \\times k}, V\\in \\mathbb{R}^{n \\times k}\\]",
          "description": "Matrix dimensions"
        }
      ]
    },
    "workedExample": {
      "problemHtml": "<p>Find the SVD of a matrix A.</p>",
      "steps": [
        {
          "stepNumber": 1,
          "description": "Standardize the input matrix",
          "mathHtml": "\\[A = \\frac{1}{\\sqrt{n}} \\begin{bmatrix} 2 & 0 \\\\ 0 & 3 \\end{bmatrix}\\]",
          "explanation": "To ensure numerical stability"
        },
        {
          "stepNumber": 2,
          "description": "Compute the covariance matrix",
          "mathHtml": "\\[Σ = (A^T A)\\]",
          "explanation": "This is the core of SVD"
        },
        {
          "stepNumber": 3,
          "description": "Find the eigenvectors and eigenvalues",
          "mathHtml": "\\[V Σ V^T = U Σ^2 U^T\\]",
          "explanation": "These are the singular vectors and values"
        },
        {
          "stepNumber": 4,
          "description": "Reconstruct the original matrix",
          "mathHtml": "\\[A \\approx U Σ V^T\\]",
          "explanation": "This is the final result"
        }
      ],
      "finalAnswer": "The SVD of A is given by UΣVᵀ"
    },
    "intuition": "SVD decomposes a matrix into three components: left singular vectors (U), diagonal matrix of singular values (Σ), and right singular vectors (V). This allows us to capture the essence of the original matrix in a more interpretable way.",
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:40:50.158Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_wex_svd_definition_017",
    "subject": "linear_algebra",
    "type": "worked_example",
    "chapter": "matrix_decompositions",
    "topic": "svd_definition",
    "title": "Singular Value Decomposition (SVD)",
    "contentHtml": "<p>Solve a matrix decomposition problem step-by-step using SVD.</p>",
    "formula": {
      "latex": "\\[A = U\\Sigma V^T\\]",
      "name": "SVD"
    },
    "problem": {
      "statementHtml": "<p>Decompose the following matrix into its singular values, left and right singular vectors:</p><p>\\[A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\\]</p>",
      "hints": [
        "Hint: Use SVD to diagonalize A"
      ],
      "solutionHtml": "<p>To solve this problem, we'll follow these steps:</p><ul><li>Step 1: Compute the covariance matrix Σ.</li><li>Step 2: Find the eigenvectors and eigenvalues of Σ.</li><li>Step 3: Use the eigenvectors to form U and V.</li></ul>",
      "answerShort": "The SVD decomposition is..."
    },
    "workedExample": {
      "problemHtml": "<p>Given matrix A:</p><p>\\[A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\\]</p>",
      "steps": [
        {
          "stepNumber": 1,
          "description": "Compute the covariance matrix Σ.",
          "mathHtml": "\\[Σ = A^T A\\]",
          "explanation": "This helps us diagonalize A."
        },
        {
          "stepNumber": 2,
          "description": "Find the eigenvectors and eigenvalues of Σ.",
          "mathHtml": "\\[Σ = U \\Lambda V^T\\]",
          "explanation": "Eigenvectors help us find the directions of maximum variance."
        },
        {
          "stepNumber": 3,
          "description": "Use the eigenvectors to form U and V.",
          "mathHtml": "\\[A = U \\Sigma V^T\\]",
          "explanation": "Now we have our SVD decomposition!"
        }
      ],
      "finalAnswer": "The SVD decomposition is..."
    },
    "intuition": "SVD helps us understand the underlying structure of a matrix by decomposing it into its most important features.",
    "estimatedMinutes": 2,
    "difficulty": 4,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T13:41:18.173Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]