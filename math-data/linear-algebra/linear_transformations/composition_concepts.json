[
  {
    "id": "la_con_composition_001",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "linear_transformations",
    "topic": "composition",
    "title": "Composition of Linear Transformations",
    "contentHtml": "<p>When we combine two linear transformations, we get a new transformation that can be tricky to work with. Luckily, there's a simple rule: composition is associative, but not commutative.</p><p>This means that when we multiply matrices representing these transformations, the order matters!</p>",
    "formula": "{",
    "latex": "\\(T \\circ S = (ST) = S T\\)\",",
    "name": "Composition Formula\" },",
    "intuition": "Think of it like a pipeline: data flows through each transformation in sequence. The order matters because each step can change the output in different ways.",
    "visualDescription": "A simple diagram showing two linear transformations, A and B, with their matrices, and how they combine to form a new matrix.",
    "realWorldApplications": [
      "In neural networks, this concept is crucial for understanding how layers are connected and how data flows through them."
    ],
    "commonMistakes": [
      "Not considering the order of transformations when composing them"
    ],
    "difficulty": 2,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T10:54:06.259Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_composition_002",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "linear_transformations",
    "topic": "composition",
    "title": "Composition of Linear Transformations",
    "contentHtml": "<p>In linear algebra, we often encounter transformations that can be composed together to create a new transformation. This concept is crucial in understanding how multiple operations interact with each other.</p><p>Think of it like a sequence of instructions: you first perform operation A, then B, and finally C. The order matters because the outcome depends on the specific sequence.</p>",
    "formula": {
      "latex": "\\((A \\circ B) \\cdot (C \\circ D) = (AC) \\circ (BD)\\)",
      "name": "Composition of Linear Transformations"
    },
    "intuition": "The key insight is that the order in which you compose transformations matters, as it changes the resulting transformation.",
    "realWorldApplications": [
      "In machine learning, composition of transformations is used to create complex neural networks by stacking multiple layers."
    ],
    "commonMistakes": [
      "Failing to consider the order of operations when composing transformations"
    ],
    "estimatedMinutes": 2,
    "difficulty": 2,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T10:54:21.294Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  },
  {
    "id": "la_con_composition_003",
    "subject": "linear_algebra",
    "type": "concept",
    "chapter": "linear_transformations",
    "topic": "composition",
    "title": "Composition of Linear Transformations",
    "contentHtml": "<p>When working with linear transformations, it's essential to understand how they compose. In essence, composition is like chaining multiple operations together.</p><p>Imagine you have a camera that applies a series of filters: first, it brightens the image, then it applies a warm tone, and finally, it adds a vignette effect. The order in which these filters are applied matters – if you apply them in reverse order, the result will be different.</p>",
    "formula": "{",
    "latex": "\\\\[(T \\circ S) \\\\mathbf{x} = T(S\\\\mathbf{x})\\\\]\",",
    "name": "Composition of Linear Transformations\" },",
    "intuition": "Think of composition as a sequence of operations. The order in which you apply these operations affects the final result.",
    "visualDescription": "A diagram showing two linear transformations, S and T, with an arrow representing the composition (T ∘ S).",
    "commonMistakes": [
      "Assuming the order doesn't matter"
    ],
    "realWorldApplications": [
      "In neural networks, the composition of transformations is crucial for backpropagation and training."
    ],
    "tags": [
      "linear-algebra",
      "transformations"
    ],
    "difficulty": 2,
    "mlRelevance": "core",
    "prerequisites": [],
    "relatedCards": [],
    "nextCards": [],
    "generatedAt": "2025-12-26T10:54:38.778Z",
    "generatedBy": "llama3:latest",
    "reviewed": false,
    "version": 1
  }
]