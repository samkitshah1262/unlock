{
  "id": "la_con_eigen_basics_test",
  "subject": "linear_algebra",
  "type": "concept",
  "chapter": "eigenvalues_eigenvectors",
  "topic": "eigen_basics",
  "title": "Eigenvalue Fundamentals",
  "subtitle": "Understanding the essence of linear transformations",
  "contentHtml": "<p>In linear algebra, eigenvalues and eigenvectors are a fundamental concept that helps us understand how matrices transform vectors.</p><p>Given a square matrix A, an eigenvector v is a non-zero vector that, when transformed by A, results in a scaled version of itself: Av = λv. The scalar λ is the corresponding eigenvalue.</p>",
  "intuition": "Eigenvalues represent the amount of stretching or shrinking a transformation applies to a direction, while eigenvectors show us the directions themselves.",
  "visualDescription": "Imagine a rubber sheet with a vector drawn on it. As you stretch the sheet (representing the matrix transformation), the vector gets scaled and possibly rotated. The eigenvalue tells you how much the vector is stretched or shrunk, while the eigenvector shows its new direction.",
  "commonMistakes": [
    "Thinking eigenvalues are unique to diagonal matrices",
    "Confusing eigenvectors with principal axes"
  ],
  "realWorldApplications": [
    "Principal component analysis (PCA) in machine learning",
    "Image compression and feature extraction"
  ],
  "tags": [
    "linear algebra",
    "matrix transformations",
    "eigenvalues"
  ],
  "estimatedMinutes": 2,
  "difficulty": 3,
  "mlRelevance": "core",
  "generatedAt": "2025-12-26T09:04:10.111Z",
  "generatedBy": "llama3:latest",
  "reviewed": false,
  "version": 1
}