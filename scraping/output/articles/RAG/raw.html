<!DOCTYPE html><html lang="en"><head><style type="text/css" id="nanobarcss">.nanobar{width:100%;height:4px;z-index:9999;top:0}.bar{width:0;height:100%;transition:height .3s;background:#000}</style><style>#back-to-top{background:#fff;-webkit-border-radius:50%;-moz-border-radius:50%;border-radius:50%;bottom:20px;-webkit-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);-moz-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);box-shadow:0 2px 5px 0 rgba(0,0,0,.26);color:#333;cursor:pointer;display:block;height:56px;opacity:1;outline:0;position:fixed;right:20px;-webkit-tap-highlight-color:transparent;-webkit-touch-callout:none;-webkit-transition:bottom .2s,opacity .2s;-o-transition:bottom .2s,opacity .2s;-moz-transition:bottom .2s,opacity .2s;transition:bottom .2s,opacity .2s;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:56px;z-index:1}#back-to-top svg{display:block;fill:currentColor;height:24px;margin:16px auto 0;width:24px}#back-to-top.hidden{bottom:-56px;opacity:0}</style>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Aman's AI Journal • Primers • Retrieval Augmented Generation</title>
  <meta name="viewport" content="width=device-width">
  <meta name="description" content="Aman's AI Journal | Course notes and learning material for Artificial Intelligence and Deep Learning Stanford classes.">
  <link rel="canonical" href="https://aman.ai/primers/ai/RAG/">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/css/main.css">

  <!-- Google fonts -->
  <!-- <link href='https://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'>-->

  <!-- RSS feed -->
  <link rel="alternate" type="application/atom+xml" title="Aman’s AI Journal" href="/feed.xml">  
  
  <link href="https://aman.ai/favicon.jpg" rel="shortcut icon">

  <!-- Google ads -->
  <script src="https://pagead2.googlesyndication.com/pagead/managed/js/adsense/m202512100101/show_ads_impl.js"></script><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5905744527956213" crossorigin="anonymous" data-checked-head="true"></script>
<meta http-equiv="origin-trial" content="AlK2UR5SkAlj8jjdEc9p3F3xuFYlF6LYjAML3EOqw1g26eCwWPjdmecULvBH5MVPoqKYrOfPhYVL71xAXI1IBQoAAAB8eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="Amm8/NmvvQfhwCib6I7ZsmUxiSCfOxWxHayJwyU1r3gRIItzr7bNQid6O8ZYaE1GSQTa69WwhPC9flq/oYkRBwsAAACCeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="A9nrunKdU5m96PSN1XsSGr3qOP0lvPFUB2AiAylCDlN5DTl17uDFkpQuHj1AFtgWLxpLaiBZuhrtb2WOu7ofHwEAAACKeyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiQUlQcm9tcHRBUElNdWx0aW1vZGFsSW5wdXQiLCJleHBpcnkiOjE3NzQzMTA0MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A93bovR+QVXNx2/38qDbmeYYf1wdte9EO37K9eMq3r+541qo0byhYU899BhPB7Cv9QqD7wIbR1B6OAc9kEfYCA4AAACQeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiQUlQcm9tcHRBUElNdWx0aW1vZGFsSW5wdXQiLCJleHBpcnkiOjE3NzQzMTA0MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A1S5fojrAunSDrFbD8OfGmFHdRFZymSM/1ss3G+NEttCLfHkXvlcF6LGLH8Mo5PakLO1sCASXU1/gQf6XGuTBgwAAACQeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXRhZ3NlcnZpY2VzLmNvbTo0NDMiLCJmZWF0dXJlIjoiQUlQcm9tcHRBUElNdWx0aW1vZGFsSW5wdXQiLCJleHBpcnkiOjE3NzQzMTA0MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax_LineBox {display: table!important}
.MathJax_LineBox span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Blank; src: url('about:blank')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><script async="" src="https://fundingchoicesmessages.google.com/i/ca-pub-5905744527956213?href=https%3A%2F%2Faman.ai%2Fprimers%2Fai%2FRAG&amp;ers=2"></script><script async="" src="https://fundingchoicesmessages.google.com/f/AGSKWxU4HMu1Mh6c2q0hLML_YK2BkfFFNaUq96o90Zv9aY91i2_369j3SUfQC0h8-txxFHVTqLgugVgw3Akb-NACdzFM68QXF4h3jtu4Tl0ongeysKskZ1WPIE1TldXxEZD5THwBj_G-JQ==?fccs=W1siQUtzUm9sLTVJVGIxNTYxRU05ZlBPelZxN2ttZURETUZaYk4xSC15cWwzSXh4SWdyaEY1ZlBDY1poX3lKVndQbTBiNHhwWGFLTlUxWjFmZ3JWWWhLbW9ycnFnMU4wZ19rWHNtbm1hWEZNSXduNHB4SXpLNFNkOTJ0NGRtZ0NGclkxdk1TcHhFZXpaZXE0QVdYRl83ZGZQOHdzbHlVdHNlVUxnPT0iXSxudWxsLG51bGwsbnVsbCxudWxsLG51bGwsWzE3NjY5MjI4NjMsNDQxMDAwMDAwXSxudWxsLG51bGwsbnVsbCxbbnVsbCxbN11dLCJodHRwczovL2FtYW4uYWkvcHJpbWVycy9haS9SQUcvIixudWxsLFtbOCwic0NoTkg1T3NhazAiXSxbOSwiZW4tVVMiXSxbMTksIjIiXSxbMTcsIlswXSJdLFsyNCwiIl0sWzI5LCJmYWxzZSJdXV0"></script><script async="" src="https://fundingchoicesmessages.google.com/f/AGSKWxWNkXoKh-5UNZ9qbHfKjLT_WdayrneWk0LdJDTM_OKK_wRqedCYGfEE9bbkHgjkng6Um1-EXKDywS2P_zwrsQjf8PLUr-ECq6__trwxIOC5mLOAlQH3a1J5i6atMXRUQpZNExUepQ==?fccs=W1siQUtzUm9sLTVJVGIxNTYxRU05ZlBPelZxN2ttZURETUZaYk4xSC15cWwzSXh4SWdyaEY1ZlBDY1poX3lKVndQbTBiNHhwWGFLTlUxWjFmZ3JWWWhLbW9ycnFnMU4wZ19rWHNtbm1hWEZNSXduNHB4SXpLNFNkOTJ0NGRtZ0NGclkxdk1TcHhFZXpaZXE0QVdYRl83ZGZQOHdzbHlVdHNlVUxnPT0iXSxudWxsLG51bGwsbnVsbCxudWxsLG51bGwsWzE3NjY5MjI4NjMsNTY2MDAwMDAwXSxudWxsLG51bGwsbnVsbCxbbnVsbCxbNyw5XSxudWxsLDIsbnVsbCwiZW4iXSwiaHR0cHM6Ly9hbWFuLmFpL3ByaW1lcnMvYWkvUkFHLyIsbnVsbCxbWzgsInNDaE5INU9zYWswIl0sWzksImVuLVVTIl0sWzE5LCIyIl0sWzE3LCJbMF0iXSxbMjQsIiJdLFsyOSwiZmFsc2UiXV1d"></script><meta http-equiv="origin-trial" content="AxjhRadLCARYRJawRjMjq4U8V8okQvSnrBIJWdMajuEkN3/DfVAcLcFhMVrUWnOXagwlI8dQD84FwJDGj9ohqAYAAABveyJvcmlnaW4iOiJodHRwczovL2dvb2dsZWFkc2VydmljZXMuY29tOjQ0MyIsImZlYXR1cmUiOiJGZXRjaExhdGVyQVBJIiwiZXhwaXJ5IjoxNzI1NDA3OTk5LCJpc1RoaXJkUGFydHkiOnRydWV9"><script async="" src="https://fundingchoicesmessages.google.com/f/AGSKWxVnFS8JJtg_v6UQAX6TsKVdGbweSqmu3RC-GdO9aAzUmRo4Zqo-9aoeaY9M7qJM_ekHWq81biMnoUSavSCA3q107aBtkIEhNTeaN9laREaTvPPgYIuuN3jraXMvXr5_SF0N6hj_sQ==?fccs=W1siQUtzUm9sLTVJVGIxNTYxRU05ZlBPelZxN2ttZURETUZaYk4xSC15cWwzSXh4SWdyaEY1ZlBDY1poX3lKVndQbTBiNHhwWGFLTlUxWjFmZ3JWWWhLbW9ycnFnMU4wZ19rWHNtbm1hWEZNSXduNHB4SXpLNFNkOTJ0NGRtZ0NGclkxdk1TcHhFZXpaZXE0QVdYRl83ZGZQOHdzbHlVdHNlVUxnPT0iXSxudWxsLG51bGwsbnVsbCxudWxsLG51bGwsWzE3NjY5MjI4NjQsNTAxMDAwMDAwXSxudWxsLG51bGwsbnVsbCxbbnVsbCxbNyw5LDZdLG51bGwsMixudWxsLCJlbiIsbnVsbCxudWxsLG51bGwsbnVsbCxudWxsLDFdLCJodHRwczovL2FtYW4uYWkvcHJpbWVycy9haS9SQUcvIixudWxsLFtbOCwic0NoTkg1T3NhazAiXSxbOSwiZW4tVVMiXSxbMTksIjIiXSxbMTcsIlswXSJdLFsyNCwiIl0sWzI5LCJmYWxzZSJdXV0"></script></head>


    <body><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>

      <script src="https://unpkg.com/vanilla-back-to-top@7.2.1/dist/vanilla-back-to-top.min.js"></script>
      <script>addBackToTop({
        backgroundColor: '#fff',
        innerHTML: 'Back to Top',
        textColor: '#333'
      })</script><div id="back-to-top" class="hidden">Back to Top</div>
      <style>
        #back-to-top {
          border: 1px solid #ccc;
          border-radius: 0;
          font-family: sans-serif;
          font-size: 14px;
          width: 100px;
          text-align: center;
          line-height: 30px;
          height: 30px;
        }
      </style>   

    <header class="site-header">

  <a class="site-title" href="../">Distilled AI</a>

  <a class="site-link" href="https://aman.ai">Back to aman.ai</a>

  <!-- Html Elements for Search -->
  <div id="search-container">
  <input class="site-search-box" type="text" autocomplete="off" id="search-input" placeholder="search...">
  <div id="results-container"></div>
  </div>

  <!-- Script pointing to aman-script.js -->
  <script src="https://aman.ai/js/aman-search.min.js" type="text/javascript"></script>

  <!-- Configuration -->
  <script>
  document.getElementById('search-input').value='';
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('results-container'),
    exclude: ["cs231a"],
    searchResultTemplate: '<div class="site-search-results"><a href="{url}">{title}</a></div>',
    noResultsText: '<div class="site-search-results"><p>No results found</p></div>',
    json: 'https://aman.ai/search.json',
    limit: 5,
    fuzzy: false,
  })
  </script>    

</header>     

    <div class="page-content">
      <div class="wrap">
      <div class="post">

  <header class="post-header">
    <h1>Primers • Retrieval Augmented Generation</h1>
  </header>

  <article class="post-content">
  <ul id="markdown-toc">
  <li><a href="#overview" id="markdown-toc-overview">Overview</a></li>
  <li><a href="#motivation" id="markdown-toc-motivation">Motivation</a></li>
  <li><a href="#the-retrieval-augmented-generation-rag-pipeline" id="markdown-toc-the-retrieval-augmented-generation-rag-pipeline">The Retrieval Augmented Generation (RAG) Pipeline</a></li>
  <li><a href="#benefits-of-rag" id="markdown-toc-benefits-of-rag">Benefits of RAG</a>    <ul>
      <li><a href="#rag-vs-fine-tuning" id="markdown-toc-rag-vs-fine-tuning">RAG vs. Fine-tuning</a></li>
    </ul>
  </li>
  <li><a href="#ensemble-of-rag" id="markdown-toc-ensemble-of-rag">Ensemble of RAG</a></li>
  <li><a href="#choosing-a-vector-db-using-a-feature-matrix" id="markdown-toc-choosing-a-vector-db-using-a-feature-matrix">Choosing a Vector DB Using a Feature Matrix</a></li>
  <li><a href="#building-a-rag-pipeline" id="markdown-toc-building-a-rag-pipeline">Building a RAG Pipeline</a>    <ul>
      <li><a href="#ingestion" id="markdown-toc-ingestion">Ingestion</a>        <ul>
          <li><a href="#chunking" id="markdown-toc-chunking">Chunking</a>            <ul>
              <li><a href="#figuring-out-the-ideal-chunk-size" id="markdown-toc-figuring-out-the-ideal-chunk-size">Figuring Out the Ideal Chunk Size</a>                <ul>
                  <li><a href="#retriever-ensembling-and-re-ranking" id="markdown-toc-retriever-ensembling-and-re-ranking">Retriever Ensembling and Re-ranking</a></li>
                </ul>
              </li>
            </ul>
          </li>
          <li><a href="#embeddings" id="markdown-toc-embeddings">Embeddings</a></li>
          <li><a href="#naive-chunking-vs-late-chunking-vs-late-interaction-colbert-and-colpali" id="markdown-toc-naive-chunking-vs-late-chunking-vs-late-interaction-colbert-and-colpali">Naive Chunking vs. Late Chunking vs. Late Interaction (ColBERT and ColPali)</a>            <ul>
              <li><a href="#overview-1" id="markdown-toc-overview-1">Overview</a></li>
              <li><a href="#naivevanilla-chunking" id="markdown-toc-naivevanilla-chunking">Naive/Vanilla Chunking</a>                <ul>
                  <li><a href="#what-is-naivevanilla-chunking" id="markdown-toc-what-is-naivevanilla-chunking">What is Naive/Vanilla Chunking?</a></li>
                  <li><a href="#example" id="markdown-toc-example">Example</a></li>
                  <li><a href="#advantages-and-limitations" id="markdown-toc-advantages-and-limitations">Advantages and Limitations</a></li>
                </ul>
              </li>
              <li><a href="#late-chunking" id="markdown-toc-late-chunking">Late Chunking</a>                <ul>
                  <li><a href="#what-is-late-chunking" id="markdown-toc-what-is-late-chunking">What is Late Chunking?</a></li>
                  <li><a href="#how-late-chunking-works" id="markdown-toc-how-late-chunking-works">How Late Chunking Works</a></li>
                  <li><a href="#example-1" id="markdown-toc-example-1">Example</a></li>
                  <li><a href="#advantages-and-trade-offs" id="markdown-toc-advantages-and-trade-offs">Advantages and Trade-offs</a></li>
                </ul>
              </li>
              <li><a href="#late-interaction" id="markdown-toc-late-interaction">Late Interaction</a>                <ul>
                  <li><a href="#what-is-late-interaction" id="markdown-toc-what-is-late-interaction">What is Late Interaction?</a></li>
                  <li><a href="#colbert-late-interaction-in-practice" id="markdown-toc-colbert-late-interaction-in-practice">ColBERT: Late Interaction in Practice</a></li>
                  <li><a href="#maxsim-a-key-component-of-colbert" id="markdown-toc-maxsim-a-key-component-of-colbert">MaxSim: a Key Component of ColBERT</a></li>
                  <li><a href="#example-2" id="markdown-toc-example-2">Example</a></li>
                  <li><a href="#advantages-and-trade-offs-1" id="markdown-toc-advantages-and-trade-offs-1">Advantages and Trade-offs</a></li>
                </ul>
              </li>
              <li><a href="#colpali-expanding-to-multimodal-late-interaction-retrieval" id="markdown-toc-colpali-expanding-to-multimodal-late-interaction-retrieval">ColPali: Expanding to Multimodal Late-Interaction Retrieval</a>                <ul>
                  <li><a href="#example-3" id="markdown-toc-example-3">Example</a></li>
                </ul>
              </li>
              <li><a href="#comparative-analysis" id="markdown-toc-comparative-analysis">Comparative Analysis</a></li>
            </ul>
          </li>
          <li><a href="#sentence-embeddings-the-what-and-why" id="markdown-toc-sentence-embeddings-the-what-and-why">Sentence Embeddings: the What and Why</a>            <ul>
              <li><a href="#background-differences-compared-to-token-level-models-like-bert" id="markdown-toc-background-differences-compared-to-token-level-models-like-bert">Background: Differences Compared to Token-Level Models Like BERT</a></li>
              <li><a href="#training-process-for-sentence-transformers-vs-token-level-embedding-models" id="markdown-toc-training-process-for-sentence-transformers-vs-token-level-embedding-models">Training Process for Sentence Transformers vs. Token-Level Embedding Models</a></li>
              <li><a href="#applying-sentence-transformers-for-rag" id="markdown-toc-applying-sentence-transformers-for-rag">Applying Sentence Transformers for RAG</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#retrieval" id="markdown-toc-retrieval">Retrieval</a>        <ul>
          <li><a href="#lexical-retrieval" id="markdown-toc-lexical-retrieval">Lexical Retrieval</a>            <ul>
              <li><a href="#core-assumptions" id="markdown-toc-core-assumptions">Core Assumptions</a></li>
              <li><a href="#tf-idf-term-frequencyinverse-document-frequency" id="markdown-toc-tf-idf-term-frequencyinverse-document-frequency">TF-IDF (Term Frequency–Inverse Document Frequency)</a></li>
              <li><a href="#strengths-of-tf-idf" id="markdown-toc-strengths-of-tf-idf">Strengths of TF-IDF</a></li>
              <li><a href="#limitations-of-tf-idf" id="markdown-toc-limitations-of-tf-idf">Limitations of TF-IDF</a></li>
              <li><a href="#bm25-best-matching-25" id="markdown-toc-bm25-best-matching-25">BM25 (Best Matching 25)</a></li>
              <li><a href="#why-bm25-outperforms-tf-idf" id="markdown-toc-why-bm25-outperforms-tf-idf">Why BM25 Outperforms TF-IDF</a></li>
              <li><a href="#operational-characteristics-of-lexical-retrieval" id="markdown-toc-operational-characteristics-of-lexical-retrieval">Operational Characteristics of Lexical Retrieval</a></li>
              <li><a href="#advantages-of-lexical-retrieval" id="markdown-toc-advantages-of-lexical-retrieval">Advantages of Lexical Retrieval</a></li>
              <li><a href="#limitations-of-lexical-retrieval" id="markdown-toc-limitations-of-lexical-retrieval">Limitations of Lexical Retrieval</a></li>
            </ul>
          </li>
          <li><a href="#semantic-retrieval" id="markdown-toc-semantic-retrieval">Semantic Retrieval</a>            <ul>
              <li><a href="#core-idea" id="markdown-toc-core-idea">Core Idea</a></li>
              <li><a href="#vector-encoding" id="markdown-toc-vector-encoding">Vector Encoding</a></li>
              <li><a href="#semantic-matching-and-retrieval" id="markdown-toc-semantic-matching-and-retrieval">Semantic Matching and Retrieval</a></li>
              <li><a href="#approaches" id="markdown-toc-approaches">Approaches</a>                <ul>
                  <li><a href="#standardnaive-approach" id="markdown-toc-standardnaive-approach">Standard/Naive Approach</a></li>
                  <li><a href="#sentence-window-retrieval--small-to-large-retrieval" id="markdown-toc-sentence-window-retrieval--small-to-large-retrieval">Sentence-Window Retrieval / Small-to-Large Retrieval</a></li>
                  <li><a href="#auto-merging-retriever--hierarchical-retriever" id="markdown-toc-auto-merging-retriever--hierarchical-retriever">Auto-merging Retriever / Hierarchical Retriever</a></li>
                  <li><a href="#contextual-retrieval" id="markdown-toc-contextual-retrieval">Contextual Retrieval</a></li>
                </ul>
              </li>
              <li><a href="#using-approximate-nearest-neighbors-ann-for-retrieval" id="markdown-toc-using-approximate-nearest-neighbors-ann-for-retrieval">Using Approximate Nearest Neighbors (ANN) for Retrieval</a></li>
              <li><a href="#advantages-of-semantic-retrieval" id="markdown-toc-advantages-of-semantic-retrieval">Advantages of Semantic Retrieval</a></li>
              <li><a href="#challenges" id="markdown-toc-challenges">Challenges</a></li>
              <li><a href="#use-cases-where-semantic-retrieval-excels" id="markdown-toc-use-cases-where-semantic-retrieval-excels">Use-cases Where Semantic Retrieval Excels</a></li>
              <li><a href="#use-cases-where-semantic-retrieval-struggles" id="markdown-toc-use-cases-where-semantic-retrieval-struggles">Use-cases Where Semantic Retrieval Struggles</a></li>
            </ul>
          </li>
          <li><a href="#hybrid-retrieval-lexical--semantic" id="markdown-toc-hybrid-retrieval-lexical--semantic">Hybrid Retrieval (Lexical + Semantic)</a>            <ul>
              <li><a href="#why-hybrid-retrieval-is-necessary" id="markdown-toc-why-hybrid-retrieval-is-necessary">Why Hybrid Retrieval is Necessary</a></li>
              <li><a href="#common-hybrid-retrieval-architectures" id="markdown-toc-common-hybrid-retrieval-architectures">Common Hybrid Retrieval Architectures</a>                <ul>
                  <li><a href="#the-dominant-production-architecture-lexical-retrieval--semantic-re-ranking" id="markdown-toc-the-dominant-production-architecture-lexical-retrieval--semantic-re-ranking">The Dominant Production Architecture: Lexical Retrieval + Semantic Re-ranking</a></li>
                </ul>
              </li>
              <li><a href="#parallel-hybrid-retrieval-and-score-fusion" id="markdown-toc-parallel-hybrid-retrieval-and-score-fusion">Parallel Hybrid Retrieval and Score Fusion</a>                <ul>
                  <li><a href="#linear-score-fusion" id="markdown-toc-linear-score-fusion">Linear Score Fusion</a></li>
                  <li><a href="#reciprocal-rank-fusion-rrf" id="markdown-toc-reciprocal-rank-fusion-rrf">Reciprocal Rank Fusion (RRF)</a></li>
                </ul>
              </li>
              <li><a href="#advanced-variations" id="markdown-toc-advanced-variations">Advanced Variations</a></li>
              <li><a href="#common-pitfalls" id="markdown-toc-common-pitfalls">Common Pitfalls</a></li>
              <li><a href="#mental-model" id="markdown-toc-mental-model">Mental Model</a></li>
              <li><a href="#system-tuning" id="markdown-toc-system-tuning">System Tuning</a>                <ul>
                  <li><a href="#choosing-the-candidate-set-size-k" id="markdown-toc-choosing-the-candidate-set-size-k">Choosing the Candidate Set Size (<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-1">K</script>)</a></li>
                  <li><a href="#latency-and-cost-considerations" id="markdown-toc-latency-and-cost-considerations">Latency and Cost Considerations</a></li>
                  <li><a href="#query-aware-tuning" id="markdown-toc-query-aware-tuning">Query-aware Tuning</a></li>
                  <li><a href="#evaluation-and-tuning-methodology" id="markdown-toc-evaluation-and-tuning-methodology">Evaluation and Tuning Methodology</a></li>
                </ul>
              </li>
              <li><a href="#hybrid-retrieval-in-rag-architectures" id="markdown-toc-hybrid-retrieval-in-rag-architectures">Hybrid Retrieval in RAG Architectures</a>                <ul>
                  <li><a href="#why-hybrid-retrieval-is-critical-for-rag" id="markdown-toc-why-hybrid-retrieval-is-critical-for-rag">Why Hybrid Retrieval is Critical for RAG</a></li>
                  <li><a href="#canonical-rag-retrieval-pipeline" id="markdown-toc-canonical-rag-retrieval-pipeline">Canonical RAG Retrieval Pipeline</a></li>
                  <li><a href="#failure-modes-avoided-by-hybrid-rag" id="markdown-toc-failure-modes-avoided-by-hybrid-rag">Failure Modes Avoided by Hybrid RAG</a></li>
                  <li><a href="#final-synthesis" id="markdown-toc-final-synthesis">Final Synthesis</a></li>
                </ul>
              </li>
            </ul>
          </li>
          <li><a href="#metadata-filtering" id="markdown-toc-metadata-filtering">Metadata Filtering</a>            <ul>
              <li><a href="#standard-pattern" id="markdown-toc-standard-pattern">Standard Pattern</a></li>
              <li><a href="#hard-filters-metadata-filtering-vs-soft-boosts-metadata-re-ranking" id="markdown-toc-hard-filters-metadata-filtering-vs-soft-boosts-metadata-re-ranking">Hard Filters (Metadata Filtering) vs. Soft Boosts (Metadata Re-ranking)</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#re-ranking" id="markdown-toc-re-ranking">Re-ranking</a>        <ul>
          <li><a href="#re-ranking-in-multistage-retrieval-pipelines" id="markdown-toc-re-ranking-in-multistage-retrieval-pipelines">Re-ranking in Multistage Retrieval Pipelines</a></li>
          <li><a href="#classes-of-semantic-re-ranking-models" id="markdown-toc-classes-of-semantic-re-ranking-models">Classes of Semantic Re-ranking Models</a></li>
          <li><a href="#learning-to-rank-paradigms" id="markdown-toc-learning-to-rank-paradigms">Learning-to-Rank Paradigms</a></li>
          <li><a href="#neural-re-rankers" id="markdown-toc-neural-re-rankers">Neural Re-rankers</a>            <ul>
              <li><a href="#bi-encoder-re-rankers-early-stage-or-lightweight-re-ranking" id="markdown-toc-bi-encoder-re-rankers-early-stage-or-lightweight-re-ranking">Bi-encoder Re-rankers (early-stage or Lightweight Re-ranking)</a></li>
              <li><a href="#cross-encoder-re-rankers-late-stage-high-precision-re-ranking" id="markdown-toc-cross-encoder-re-rankers-late-stage-high-precision-re-ranking">Cross-encoder Re-rankers (late-stage, High-precision Re-ranking)</a></li>
              <li><a href="#example-models" id="markdown-toc-example-models">Example Models</a>                <ul>
                  <li><a href="#examples-cross-encoder-re-rankers" id="markdown-toc-examples-cross-encoder-re-rankers">Examples: Cross-encoder Re-rankers</a></li>
                  <li><a href="#examples-encoder-decoder--decoder-based-listwise-re-rankers-fusion-in-decoder-architectures" id="markdown-toc-examples-encoder-decoder--decoder-based-listwise-re-rankers-fusion-in-decoder-architectures">Examples: Encoder-Decoder / Decoder-based Listwise Re-rankers (Fusion-in-Decoder Architectures)</a></li>
                </ul>
              </li>
              <li><a href="#domain-specific-adaptations" id="markdown-toc-domain-specific-adaptations">Domain-Specific Adaptations</a></li>
            </ul>
          </li>
          <li><a href="#instruction-following-re-ranking" id="markdown-toc-instruction-following-re-ranking">Instruction-Following Re-ranking</a></li>
          <li><a href="#metadata-based-re-rankers" id="markdown-toc-metadata-based-re-rankers">Metadata-Based Re-rankers</a></li>
        </ul>
      </li>
      <li><a href="#response-generation--synthesis" id="markdown-toc-response-generation--synthesis">Response Generation / Synthesis</a>        <ul>
          <li><a href="#lost-in-the-middle-how-language-models-use-long-contexts" id="markdown-toc-lost-in-the-middle-how-language-models-use-long-contexts">Lost in the Middle: How Language Models Use Long Contexts</a></li>
          <li><a href="#the-needle-in-a-haystack-test" id="markdown-toc-the-needle-in-a-haystack-test">The “Needle in a Haystack” Test</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#rag-in-multi-turn-chatbots-embedding-queries-for-retrieval" id="markdown-toc-rag-in-multi-turn-chatbots-embedding-queries-for-retrieval">RAG in Multi-Turn Chatbots: Embedding Queries for Retrieval</a>    <ul>
      <li><a href="#embedding-the-latest-user-turn-only" id="markdown-toc-embedding-the-latest-user-turn-only">Embedding the Latest User Turn Only</a></li>
      <li><a href="#embedding-concatenated-recent-turns-truncated-dialogue-history" id="markdown-toc-embedding-concatenated-recent-turns-truncated-dialogue-history">Embedding Concatenated Recent Turns (Truncated Dialogue History)</a></li>
      <li><a href="#embedding-a-condensed-or-summarized-history" id="markdown-toc-embedding-a-condensed-or-summarized-history">Embedding a Condensed or Summarized History</a></li>
      <li><a href="#embedding-structured-dialogue-state" id="markdown-toc-embedding-structured-dialogue-state">Embedding Structured Dialogue State</a></li>
      <li><a href="#task-optimized-embedding-via-query-reformulation" id="markdown-toc-task-optimized-embedding-via-query-reformulation">Task-Optimized Embedding Via Query Reformulation</a></li>
      <li><a href="#best-practices-and-considerations" id="markdown-toc-best-practices-and-considerations">Best Practices and Considerations</a></li>
    </ul>
  </li>
  <li><a href="#component-wise-evaluation" id="markdown-toc-component-wise-evaluation">Component-Wise Evaluation</a>    <ul>
      <li><a href="#retrieval-metrics" id="markdown-toc-retrieval-metrics">Retrieval Metrics</a>        <ul>
          <li><a href="#context-precision" id="markdown-toc-context-precision">Context Precision</a></li>
          <li><a href="#context-recall" id="markdown-toc-context-recall">Context Recall</a></li>
          <li><a href="#context-relevance" id="markdown-toc-context-relevance">Context Relevance</a></li>
        </ul>
      </li>
      <li><a href="#generation-metrics" id="markdown-toc-generation-metrics">Generation Metrics</a>        <ul>
          <li><a href="#groundedness-aka-faithfulness" id="markdown-toc-groundedness-aka-faithfulness">Groundedness (a.k.a. Faithfulness)</a></li>
          <li><a href="#answer-relevance" id="markdown-toc-answer-relevance">Answer Relevance</a></li>
          <li><a href="#answer-semantic-similarity" id="markdown-toc-answer-semantic-similarity">Answer Semantic Similarity</a></li>
          <li><a href="#bleu-score" id="markdown-toc-bleu-score">BLEU Score</a></li>
          <li><a href="#rouge-score" id="markdown-toc-rouge-score">ROUGE Score</a></li>
          <li><a href="#string-presence" id="markdown-toc-string-presence">String Presence</a></li>
          <li><a href="#exact-match" id="markdown-toc-exact-match">Exact Match</a></li>
          <li><a href="#context-entities-recall" id="markdown-toc-context-entities-recall">Context Entities Recall</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#multimodal-input-handling" id="markdown-toc-multimodal-input-handling">Multimodal Input Handling</a>    <ul>
      <li><a href="#flow-of-multimodal-input" id="markdown-toc-flow-of-multimodal-input">Flow of Multimodal Input</a></li>
      <li><a href="#benefits-of-multimodal-embeddings-in-rag" id="markdown-toc-benefits-of-multimodal-embeddings-in-rag">Benefits of Multimodal Embeddings in RAG</a></li>
    </ul>
  </li>
  <li><a href="#multimodal-rag" id="markdown-toc-multimodal-rag">Multimodal RAG</a></li>
  <li><a href="#agentic-retrieval-augmented-generation" id="markdown-toc-agentic-retrieval-augmented-generation">Agentic Retrieval-Augmented Generation</a>    <ul>
      <li><a href="#how-agentic-rag-works" id="markdown-toc-how-agentic-rag-works">How Agentic RAG Works</a></li>
      <li><a href="#agentic-decision-making-in-retrieval" id="markdown-toc-agentic-decision-making-in-retrieval">Agentic Decision-Making in Retrieval</a></li>
      <li><a href="#agentic-rag-architectures-single-agent-vs-multi-agent-systems" id="markdown-toc-agentic-rag-architectures-single-agent-vs-multi-agent-systems">Agentic RAG Architectures: Single-Agent vs. Multi-Agent Systems</a>        <ul>
          <li><a href="#single-agent-rag-router" id="markdown-toc-single-agent-rag-router">Single-Agent RAG (Router)</a></li>
          <li><a href="#multi-agent-rag-systems" id="markdown-toc-multi-agent-rag-systems">Multi-Agent RAG Systems</a></li>
        </ul>
      </li>
      <li><a href="#beyond-retrieval-expanding-agentic-rags-capabilities" id="markdown-toc-beyond-retrieval-expanding-agentic-rags-capabilities">Beyond Retrieval: Expanding Agentic RAG’s Capabilities</a></li>
      <li><a href="#agentic-rag-vs-vanilla-rag-key-differences" id="markdown-toc-agentic-rag-vs-vanilla-rag-key-differences">Agentic RAG vs. Vanilla RAG: Key Differences</a></li>
      <li><a href="#implementing-agentic-rag-key-approaches" id="markdown-toc-implementing-agentic-rag-key-approaches">Implementing Agentic RAG: Key Approaches</a>        <ul>
          <li><a href="#language-models-with-function-calling" id="markdown-toc-language-models-with-function-calling">Language Models with Function Calling</a></li>
          <li><a href="#agent-frameworks" id="markdown-toc-agent-frameworks">Agent Frameworks</a></li>
        </ul>
      </li>
      <li><a href="#enterprise-driven-adoption" id="markdown-toc-enterprise-driven-adoption">Enterprise-driven Adoption</a></li>
      <li><a href="#benefits" id="markdown-toc-benefits">Benefits</a></li>
      <li><a href="#limitations" id="markdown-toc-limitations">Limitations</a></li>
      <li><a href="#code" id="markdown-toc-code">Code</a>        <ul>
          <li><a href="#implementing-agentic-rag-with-function-calling" id="markdown-toc-implementing-agentic-rag-with-function-calling">Implementing Agentic RAG with Function Calling</a>            <ul>
              <li><a href="#define-the-function-for-retrieval" id="markdown-toc-define-the-function-for-retrieval">Define the Function for Retrieval</a></li>
              <li><a href="#define-the-tools-schema" id="markdown-toc-define-the-tools-schema">Define the Tools Schema</a></li>
              <li><a href="#setting-up-the-interaction-loop" id="markdown-toc-setting-up-the-interaction-loop">Setting up the Interaction Loop</a></li>
              <li><a href="#executing-the-agentic-rag-query" id="markdown-toc-executing-the-agentic-rag-query">Executing the Agentic RAG Query</a></li>
            </ul>
          </li>
          <li><a href="#implementing-agentic-rag-with-agent-frameworks" id="markdown-toc-implementing-agentic-rag-with-agent-frameworks">Implementing Agentic RAG with Agent Frameworks</a>            <ul>
              <li><a href="#step-1-define-agents-and-tools" id="markdown-toc-step-1-define-agents-and-tools">Step 1: Define Agents and Tools</a></li>
              <li><a href="#step-2-configure-agent-routing" id="markdown-toc-step-2-configure-agent-routing">Step 2: Configure Agent Routing</a></li>
              <li><a href="#step-3-chain-agents-for-multi-agent-rag" id="markdown-toc-step-3-chain-agents-for-multi-agent-rag">Step 3: Chain Agents for Multi-Agent RAG</a></li>
              <li><a href="#running-the-multi-agent-query" id="markdown-toc-running-the-multi-agent-query">Running the Multi-Agent Query</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#disadvantages-of-agentic-rag" id="markdown-toc-disadvantages-of-agentic-rag">Disadvantages of Agentic RAG</a></li>
      <li><a href="#summary" id="markdown-toc-summary">Summary</a></li>
    </ul>
  </li>
  <li><a href="#rag-vs-long-context-windows" id="markdown-toc-rag-vs-long-context-windows">RAG vs. Long Context Windows</a>    <ul>
      <li><a href="#computational-cost" id="markdown-toc-computational-cost">Computational Cost</a></li>
      <li><a href="#inference-latency-and-throughput" id="markdown-toc-inference-latency-and-throughput">Inference Latency and Throughput</a></li>
      <li><a href="#contextual-comprehension-and-model-training-limitations" id="markdown-toc-contextual-comprehension-and-model-training-limitations">Contextual Comprehension and Model Training Limitations</a></li>
      <li><a href="#rag-as-a-targeted-cost-efficient-solution" id="markdown-toc-rag-as-a-targeted-cost-efficient-solution">RAG As a Targeted, Cost-Efficient Solution</a></li>
    </ul>
  </li>
  <li><a href="#improving-rag-systems" id="markdown-toc-improving-rag-systems">Improving RAG Systems</a></li>
  <li><a href="#rag-20" id="markdown-toc-rag-20">RAG 2.0</a></li>
  <li><a href="#rag-benchmarks" id="markdown-toc-rag-benchmarks">RAG Benchmarks</a>    <ul>
      <li><a href="#retrieval-only-evaluation" id="markdown-toc-retrieval-only-evaluation">Retrieval-Only Evaluation</a></li>
      <li><a href="#end-to-end-evaluation-retrieval--generation" id="markdown-toc-end-to-end-evaluation-retrieval--generation">End-to-End Evaluation (Retrieval + Generation)</a></li>
    </ul>
  </li>
  <li><a href="#selected-papers" id="markdown-toc-selected-papers">Selected Papers</a>    <ul>
      <li><a href="#retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks" id="markdown-toc-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li>
      <li><a href="#active-retrieval-augmented-generation" id="markdown-toc-active-retrieval-augmented-generation">Active Retrieval Augmented Generation</a></li>
      <li><a href="#murag-multimodal-retrieval-augmented-generator" id="markdown-toc-murag-multimodal-retrieval-augmented-generator">MuRAG: Multimodal Retrieval-Augmented Generator</a></li>
      <li><a href="#hypothetical-document-embeddings-hyde" id="markdown-toc-hypothetical-document-embeddings-hyde">Hypothetical Document Embeddings (HyDE)</a></li>
      <li><a href="#ragas-automated-evaluation-of-retrieval-augmented-generation" id="markdown-toc-ragas-automated-evaluation-of-retrieval-augmented-generation">RAGAS: Automated Evaluation of Retrieval Augmented Generation</a></li>
      <li><a href="#fine-tuning-or-retrieval-comparing-knowledge-injection-in-llms" id="markdown-toc-fine-tuning-or-retrieval-comparing-knowledge-injection-in-llms">Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs</a></li>
      <li><a href="#dense-x-retrieval-what-retrieval-granularity-should-we-use" id="markdown-toc-dense-x-retrieval-what-retrieval-granularity-should-we-use">Dense X Retrieval: What Retrieval Granularity Should We Use?</a></li>
      <li><a href="#ares-an-automated-evaluation-framework-for-retrieval-augmented-generation-systems" id="markdown-toc-ares-an-automated-evaluation-framework-for-retrieval-augmented-generation-systems">ARES: an Automated Evaluation Framework for Retrieval-Augmented Generation Systems</a></li>
      <li><a href="#seven-failure-points-when-engineering-a-retrieval-augmented-generation-system" id="markdown-toc-seven-failure-points-when-engineering-a-retrieval-augmented-generation-system">Seven Failure Points When Engineering a Retrieval Augmented Generation System</a></li>
      <li><a href="#raptor-recursive-abstractive-processing-for-tree-organized-retrieval" id="markdown-toc-raptor-recursive-abstractive-processing-for-tree-organized-retrieval">RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval</a></li>
      <li><a href="#the-power-of-noise-redefining-retrieval-for-rag-systems" id="markdown-toc-the-power-of-noise-redefining-retrieval-for-rag-systems">The Power of Noise: Redefining Retrieval for RAG Systems</a></li>
      <li><a href="#multihop-rag-benchmarking-retrieval-augmented-generation-for-multi-hop-queries" id="markdown-toc-multihop-rag-benchmarking-retrieval-augmented-generation-for-multi-hop-queries">MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries</a></li>
      <li><a href="#rag-vs-fine-tuning-pipelines-tradeoffs-and-a-case-study-on-agriculture" id="markdown-toc-rag-vs-fine-tuning-pipelines-tradeoffs-and-a-case-study-on-agriculture">RAG vs. Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture</a></li>
      <li><a href="#raft-adapting-language-model-to-domain-specific-rag" id="markdown-toc-raft-adapting-language-model-to-domain-specific-rag">RAFT: Adapting Language Model to Domain Specific RAG</a></li>
      <li><a href="#corrective-retrieval-augmented-generation" id="markdown-toc-corrective-retrieval-augmented-generation">Corrective Retrieval Augmented Generation</a></li>
      <li><a href="#fine-tuning-vs-retrieval-augmented-generation-for-less-popular-knowledge" id="markdown-toc-fine-tuning-vs-retrieval-augmented-generation-for-less-popular-knowledge">Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge</a></li>
      <li><a href="#hgot-hierarchical-graph-of-thoughts-for-retrieval-augmented-in-context-learning-in-factuality-evaluation" id="markdown-toc-hgot-hierarchical-graph-of-thoughts-for-retrieval-augmented-in-context-learning-in-factuality-evaluation">HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation</a></li>
      <li><a href="#how-faithful-are-rag-models-quantifying-the-tug-of-war-between-rag-and-llms-internal-prior" id="markdown-toc-how-faithful-are-rag-models-quantifying-the-tug-of-war-between-rag-and-llms-internal-prior">How Faithful are RAG Models? Quantifying the Tug-of-war Between RAG and LLMs’ Internal Prior</a></li>
      <li><a href="#adaptive-rag-learning-to-adapt-retrieval-augmented-large-language-models-through-question-complexity" id="markdown-toc-adaptive-rag-learning-to-adapt-retrieval-augmented-large-language-models-through-question-complexity">Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models Through Question Complexity</a></li>
      <li><a href="#richrag-crafting-rich-responses-for-multi-faceted-queries-in-retrieval-augmented-generation" id="markdown-toc-richrag-crafting-rich-responses-for-multi-faceted-queries-in-retrieval-augmented-generation">RichRAG: Crafting Rich Responses for Multi-faceted Queries in Retrieval-Augmented Generation</a></li>
      <li><a href="#hiqa-a-hierarchical-contextual-augmentation-rag-for-massive-documents-qa" id="markdown-toc-hiqa-a-hierarchical-contextual-augmentation-rag-for-massive-documents-qa">HiQA: a Hierarchical Contextual Augmentation RAG for Massive Documents QA</a></li>
      <li><a href="#refrag-rethinking-rag-based-decoding" id="markdown-toc-refrag-rethinking-rag-based-decoding">REFRAG: Rethinking RAG Based Decoding</a></li>
      <li><a href="#fact-fetch-and-reason-a-unified-evaluation-of-retrieval-augmented-generation" id="markdown-toc-fact-fetch-and-reason-a-unified-evaluation-of-retrieval-augmented-generation">Fact, Fetch, and Reason: a Unified Evaluation of Retrieval-Augmented Generation</a></li>
      <li><a href="#long-form-factuality-in-large-language-models" id="markdown-toc-long-form-factuality-in-large-language-models">Long-form Factuality in Large Language Models</a></li>
    </ul>
  </li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
  <li><a href="#citation" id="markdown-toc-citation">Citation</a></li>
</ul>

<h2 id="overview">Overview</h2>

<ul>
  <li>Retrieval-Augmented Generation (RAG) is an advanced technique designed to enhance the output of Language Models (LMs) by incorporating external knowledge sources.</li>
  <li>RAG is achieved by retrieving relevant information from a large corpus of documents and utilizing that information to guide and inform the generative process of the model. The subsequent sections provide a detailed examination of this methodology.</li>
</ul>

<h2 id="motivation">Motivation</h2>

<ul>
  <li>In many real-world scenarios, organizations maintain extensive collections of proprietary documents, such as technical manuals, from which precise information must be extracted. This challenge is often analogous to locating a needle in a haystack, given the sheer volume and complexity of the content.</li>
  <li>While recent advancements, such as OpenAI’s introduction of GPT-4 Turbo, offer improved capabilities for processing lengthy documents, they are not without limitations. Notably, these models exhibit a tendency known as the “Lost in the Middle” phenomenon, wherein information positioned near the center of the context window is more likely to be overlooked or forgotten. This issue is akin to reading a comprehensive text such as the Bible, yet struggling to recall specific content from its middle chapters.</li>
  <li>To address this shortcoming, the RAG approach has been introduced. This method involves segmenting documents into discrete units—typically paragraphs—and creating an index for each. Upon receiving a query, the system efficiently identifies and retrieves the most relevant segments, which are then supplied to the language model. By narrowing the input to only the most pertinent information, this strategy mitigates cognitive overload within the model and substantially improves the relevance and accuracy of its responses.</li>
</ul>

<h2 id="the-retrieval-augmented-generation-rag-pipeline">The Retrieval Augmented Generation (RAG) Pipeline</h2>

<ul>
  <li>With RAG, the LLM is able to leverage knowledge and information that is not necessarily in its weights by providing it access to external knowledge sources such as databases.</li>
  <li>It leverages a retriever to find relevant contexts to condition the LLM, in this way, RAG is able to augment the knowledge-base of an LLM with relevant documents.</li>
  <li>The retriever here could be any of the following depending on the need for semantic retrieval or not:
    <ul>
      <li><strong>Vector database:</strong> Typically, queries are embedded using models like BERT for generating dense vector embeddings. Alternatively, traditional methods like TF-IDF can be used for sparse embeddings. The search is then conducted based on term frequency or semantic similarity.</li>
      <li><strong>Graph database:</strong> Constructs a knowledge base from extracted entity relationships within the text. This approach is precise but may require exact query matching, which could be restrictive in some applications.</li>
      <li><strong>Regular SQL database:</strong> Offers structured data storage and retrieval but might lack the semantic flexibility of vector databases.</li>
    </ul>
  </li>
  <li>The image below from <a href="https://www.linkedin.com/posts/damienbenveniste_machinelearning-datascience-artificialintelligence-activity-7119708674868051969-5HA1?utm_source=share&amp;utm_medium=member_desktop">Damien Benveniste, PhD</a> talks a bit about the difference between using Graph vs. Vector database for RAG.</li>
</ul>

<p><img src="/primers/ai/assets/LLMtune/1.jpeg" alt=""></p>

<ul>
  <li>In his post linked above, Damien states that Graph Databases are favored for Retrieval Augmented Generation (RAG) when compared to Vector Databases. While Vector Databases partition and index data using LLM-encoded vectors, allowing for semantically similar vector retrieval, they may fetch irrelevant data.</li>
  <li>Graph Databases, on the other hand, build a knowledge base from extracted entity relationships in the text, making retrievals concise. However, it requires exact query matching which can be limiting.</li>
  <li>
    <p>A potential solution could be to combine the strengths of both databases: indexing parsed entity relationships with vector representations in a graph database for more flexible information retrieval. It remains to be seen if such a hybrid model exists.</p>
  </li>
  <li>After retrieving, you may want to look into filtering the candidates further by adding ranking and/or fine ranking layers that allow you to filter down candidates that do not match your business rules, are not personalized for the user, current context, or response limit.</li>
  <li>Let’s succinctly summarize the process of RAG and then delve into its pros and cons:
    <ol>
      <li><strong>Vector Database Creation</strong>: RAG starts by converting an internal dataset into vectors and storing them in a vector database (or a database of your choosing).</li>
      <li><strong>User Input</strong>: A user provides a query in natural language, seeking an answer or completion.</li>
      <li><strong>Information Retrieval</strong>: The retrieval mechanism scans the vector database to identify segments that are semantically similar to the user’s query (which is also embedded). These segments are then given to the LLM to enrich its context for generating responses.</li>
      <li><strong>Combining Data</strong>: The chosen data segments from the database are combined with the user’s initial query, creating an expanded prompt.</li>
      <li><strong>Generating Text</strong>: The enlarged prompt, filled with added context, is then given to the LLM, which crafts the final, context-aware response.</li>
    </ol>
  </li>
  <li>The image below <a href="https://vectara.com/retrieval-augmented-generation-everything-you-need-to-know/">(source)</a> displays the high-level working of RAG.
<img src="/primers/ai/assets/RAG/3.png" alt=""></li>
</ul>

<h2 id="benefits-of-rag">Benefits of RAG</h2>

<ul>
  <li>
    <p>RAG enhances language model outputs by grounding generation in external knowledge sources that are not contained within the model’s parameters. By retrieving relevant documents or passages at inference time, RAG enables models to produce more accurate, current, and domain-specific responses without modifying their internal weights. The following list highlights some of the distinct advantages of RAG:</p>

    <ul>
      <li>
        <p><strong>External knowledge access</strong>: RAG allows language models to leverage information from external knowledge bases, enabling access to up-to-date, proprietary, or domain-specific data that would otherwise be unavailable or stale if stored solely in model parameters.</p>
      </li>
      <li>
        <p><strong>Support for dynamic and changing corpora</strong>: RAG naturally supports dynamic or frequently changing corpora, since new, updated, or removed documents can be reflected immediately through the retriever without requiring model retraining, making it well suited for evolving knowledge bases.</p>
      </li>
      <li>
        <p><strong>No retraining required</strong>: RAG avoids the need for expensive and time-consuming model retraining or fine-tuning, reducing computational cost and accelerating iteration while still allowing the system to incorporate new information.</p>
      </li>
      <li>
        <p><strong>Effective with limited labeled data</strong>: Because RAG relies on retrieval rather than supervised learning for knowledge injection, it performs well in environments where labeled training data is scarce but large volumes of unlabeled or weakly structured data are available.</p>
      </li>
      <li>
        <p><strong>Well-suited for real-time and knowledge-intensive applications</strong>: RAG is particularly effective for use cases such as virtual assistants, enterprise search, and question answering over technical documentation or product manuals, where accurate, real-time access to specific information is required.</p>
      </li>
      <li>
        <p><strong>Improved factual grounding and traceability</strong>: By explicitly retrieving and conditioning on source documents, RAG improves factual grounding and enables greater transparency and traceability in generated responses.</p>
      </li>
      <li>
        <p><strong>Dependence on retrieval quality</strong>: A key limitation of RAG is that its performance is bounded by the quality, coverage, and freshness of the retrieval system and underlying knowledge base; missing or incorrect retrievals can directly degrade generation quality.</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="rag-vs-fine-tuning">RAG vs. Fine-tuning</h3>

<ul>
  <li>The table below <a href="https://arxiv.org/pdf/2312.10997v1.pdf">(source)</a> compares RAG vs. fine-tuning.</li>
</ul>

<p><img src="../../../images/papers/RAGvsFT.jpg" alt=""></p>

<ul>
  <li>To summarize the above table:
    <ol>
      <li>RAG offers Large Language Models (LLMs) access to factual, access-controlled, timely information. This integration enables LLMs to fetch precise and verified facts directly from relevant databases and knowledge repositories in real-time. While fine-tuning can address some of these aspects by adapting the model to specific data, RAG excels at providing up-to-date and specific information without the substantial costs associated with fine-tuning. Moreover, RAG enhances the model’s ability to remain current and relevant by dynamically accessing and retrieving the latest data, thus ensuring the responses are accurate and contextually appropriate. Additionally, RAG’s approach to leveraging external sources can be more flexible and scalable, allowing for easy updates and adjustments without the need for extensive retraining.</li>
      <li>Fine-tuning adapts the style, tone, and vocabulary of LLMs so that your linguistic “paint brush” matches the desired domain and style. RAG does not provide this level of customization in terms of linguistic style and vocabulary.</li>
      <li>Focus on RAG first. A successful LLM application typically involves connecting specialized data to the LLM workflow. Once you have a functional application, you can add fine-tuning to enhance the style and vocabulary of the system.</li>
    </ol>
  </li>
</ul>

<h2 id="ensemble-of-rag">Ensemble of RAG</h2>

<ul>
  <li>Leveraging an ensemble of RAG systems offers a substantial upgrade to the model’s ability to produce rich and contextually accurate text. Here’s an enhanced breakdown of how this procedure could work:
    <ul>
      <li><strong>Knowledge sources:</strong> RAG models retrieve information from external knowledge stores to augment their knowledge in a particular domain. These can include passages, tables, images, etc. from domains like Wikipedia, books, news, databases.</li>
      <li><strong>Combining sources:</strong> At inference time, multiple retrievers can pull relevant content from different corpora. For example, one retriever searches Wikipedia, another searches news sources. Their results are concatenated into a pooled set of candidates.</li>
      <li><strong>Ranking:</strong> The model ranks the pooled candidates by their relevance to the context.</li>
      <li><strong>Selection:</strong> Highly ranked candidates are selected to condition the language model for generation.</li>
      <li><strong>Ensembling:</strong> Separate RAG models specialized on different corpora can be ensembled. Their outputs are merged, ranked, and voted on.</li>
    </ul>
  </li>
  <li>Multiple knowledge sources can augment RAG models through pooling and ensembles. Careful ranking and selection helps integrate these diverse sources for improved generation.</li>
  <li>One thing to keep in mind when using multiple retrievers is to rank the different outputs from each retriever before merging them to form a response. This can be done in a variety of ways, using LTR algorithms, multi-armed bandit framework, multi-objective optimization, or according to specific business use cases.</li>
</ul>

<h2 id="choosing-a-vector-db-using-a-feature-matrix">Choosing a Vector DB Using a Feature Matrix</h2>

<ul>
  <li>To compare the plethora of Vector DB offerings, a feature matrix that highlights the differences between Vector DBs and which to use in which scenario is essential.</li>
  <li><a href="https://vdbs.superlinked.com/">Vector DB Comparison by VectorHub</a> offers a great comparison spanning 37 vendors and 29 features (as of this writing).</li>
</ul>

<p><a href="https://vdbs.superlinked.com/"><img src="/primers/ai/assets/LLM/superlinked.jpg" alt=""></a></p>

<ul>
  <li>As a secondary resource, the following table (<a href="https://docs.google.com/spreadsheets/d/170HErOyOkLDjQfy3TJ6a3XXXM1rHvw_779Sit-KT7uc/edit#gid=0">source</a>) shows a comparison of some of the prevalent Vector DB offers along various feature dimensions:</li>
</ul>

<p><img src="/primers/ai/assets/LLM/VDBFeatureMatrix.jpg" alt=""></p>

<ul>
  <li>Access the full spreadsheet <a href="https://docs.google.com/spreadsheets/d/170HErOyOkLDjQfy3TJ6a3XXXM1rHvw_779Sit-KT7uc/edit#gid=0">here</a>.</li>
</ul>

<h2 id="building-a-rag-pipeline">Building a RAG Pipeline</h2>

<ul>
  <li>The image below <a href="https://learn.deeplearning.ai/building-evaluating-advanced-rag/lesson/2/advanced-rag-pipeline">(source)</a>, gives a visual overview of the three different steps of RAG: Ingestion, Retrieval, and Synthesis/Response Generation.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/4.png" alt=""></p>

<ul>
  <li>In the sections below, we will go over these key areas.</li>
</ul>

<h3 id="ingestion">Ingestion</h3>

<h4 id="chunking">Chunking</h4>

<ul>
  <li>Chunking is the process of dividing the prompts and/or the documents to be retrieved, into smaller, manageable segments or chunks. These chunks can be defined either by a fixed size, such as a specific number of characters, sentences, or paragraphs. The choice of chunking strategy plays a critical role in determining both the performance and efficiency of your RAG system.</li>
  <li>Each chunk is encoded into an embedding vector for retrieval. Smaller, more precise chunks lead to a finer match between the user’s query and the content, enhancing the accuracy and relevance of the information retrieved.</li>
  <li>Larger chunks might include irrelevant information, introducing noise and potentially reducing the retrieval accuracy. By controlling the chunk size, RAG can maintain a balance between comprehensiveness and precision.</li>
  <li>So the next natural question that comes up is, how do you choose the right chunk size for your use case? The choice of chunk size in RAG is crucial. It needs to be small enough to ensure relevance and reduce noise but large enough to maintain the context’s integrity. Let’s look at a few methods below referred from <a href="https://www.pinecone.io/learn/chunking-strategies/">Pinecone</a>:
    <ul>
      <li><strong>Fixed-size Chunking:</strong> Simply decide the number of tokens in our chunk along with whether there should be overlap between them or not. Overlap between chunks guarantees there to be minimal semantic context loss between chunks. This option is computationally cheap and simple to implement.
        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code0"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code0"><span class="n">text</span> <span class="o">=</span> <span class="s">"..."</span> <span class="c1"># your text
</span><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="p">(</span>
    <span class="n">separator</span> <span class="o">=</span> <span class="s">"</span><span class="se">\n\n</span><span class="s">"</span><span class="p">,</span>
    <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
    <span class="n">chunk_overlap</span>  <span class="o">=</span> <span class="mi">20</span>
<span class="p">)</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="n">create_documents</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
</code></pre></div>        </div>
      </li>
      <li><strong>Context-aware Chunking:</strong> Content-aware chunking leverages the intrinsic structure of the text to create chunks that are more meaningful and contextually relevant. Here are several approaches to achieving this:
        <ol>
          <li><strong>Sentence Splitting</strong>: This method aligns with models optimized for embedding sentence-level content. Different tools and techniques can be used for sentence splitting:
            <ul>
              <li><strong>Naive Splitting:</strong> A basic method where sentences are split using periods and new lines. Example:
                <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code1"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code1">   <span class="n">text</span> <span class="o">=</span> <span class="s">"..."</span>  <span class="c1"># Your text
</span>   <span class="n">docs</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">"."</span><span class="p">)</span>
</code></pre></div>                </div>
                <ul>
                  <li>This method is quick but may overlook complex sentence structures.</li>
                </ul>
              </li>
              <li><strong>NLTK (Natural Language Toolkit):</strong> A comprehensive Python library for language processing. NLTK includes a sentence tokenizer that effectively splits text into sentences. Example:
                <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code2"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code2"><span class="n">text</span> <span class="o">=</span> <span class="s">"..."</span>  <span class="c1"># Your text
</span><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">NLTKTextSplitter</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">NLTKTextSplitter</span><span class="p">()</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="n">split_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div>                </div>
              </li>
              <li><strong>spaCy:</strong> An advanced Python library for NLP tasks, spaCy offers efficient sentence segmentation. Example:
                <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code3"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code3"><span class="n">text</span> <span class="o">=</span> <span class="s">"..."</span>  <span class="c1"># Your text
</span><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">SpacyTextSplitter</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">SpacyTextSplitter</span><span class="p">()</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="n">split_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div>                </div>
              </li>
            </ul>
          </li>
          <li><strong>Recursive Chunking:</strong> Recursive chunking is an iterative method that splits text hierarchically using various separators. It adapts to create chunks of similar size or structure by recursively applying different criteria. Example using LangChain:
            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code4"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code4">   <span class="n">text</span> <span class="o">=</span> <span class="s">"..."</span>  <span class="c1"># Your text
</span>   <span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
   <span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span>
       <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
       <span class="n">chunk_overlap</span> <span class="o">=</span> <span class="mi">20</span>
   <span class="p">)</span>
   <span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="n">create_documents</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
</code></pre></div>            </div>
          </li>
          <li><strong>Structure-based Chunking:</strong> For formatted content like Markdown, HTML, or LaTeX, specialized chunking can be applied to maintain the original structure:
            <ul>
              <li><strong>Markdown Chunking:</strong> Recognizes markdown syntax and divides content based on structure. Example:
                <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code5"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code5"><span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">MarkdownTextSplitter</span>
<span class="n">markdown_text</span> <span class="o">=</span> <span class="s">"..."</span>
<span class="n">markdown_splitter</span> <span class="o">=</span> <span class="n">MarkdownTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">markdown_splitter</span><span class="p">.</span><span class="n">create_documents</span><span class="p">([</span><span class="n">markdown_text</span><span class="p">])</span>
</code></pre></div>                </div>
              </li>
              <li><strong>HTML Chunking:</strong> Leverages HTML tags (such as headings, sections, and semantic elements) to segment content while preserving document hierarchy and structural meaning.</li>
              <li><strong>LaTeX Chunking:</strong> Parses LaTeX commands and environments to chunk content while preserving its logical organization.</li>
            </ul>
          </li>
          <li><strong>Semantic Chunking:</strong> Segment text based on semantic similarity. This means that sentences with the strongest semantic connections are grouped together, while sentences that move to another topic or theme are separated into distinct chunks. For an implementation of semantic chunking, please refer to <a href="https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb">this</a> notebook.
            <ul>
              <li>Semantic chunking can be summarized in four steps:
                <ol>
                  <li>Split the text into sentences, paragraphs, or other rule-based units.</li>
                  <li>Vectorize a window of sentences or other units.</li>
                  <li>Calculate the cosine distance between the embedded windows.</li>
                  <li>Merge sentences or units until the cosine similarity value reaches a specific threshold.</li>
                </ol>
              </li>
              <li>The following figure (<a href="https://www.linkedin.com/in/edwardschmuhl">source</a>) visually summarizes the overall process:
 <img src="/primers/ai/assets/RAG/semc.jpg" alt=""></li>
            </ul>
          </li>
        </ol>
      </li>
    </ul>
  </li>
  <li>As a rule of thumb, if the chunk of text makes sense without the surrounding context to a human, it will make sense to the language model as well. Therefore, finding the optimal chunk size for the documents in the corpus is crucial to ensuring that the search results are accurate and relevant.</li>
</ul>

<h5 id="figuring-out-the-ideal-chunk-size">Figuring Out the Ideal Chunk Size</h5>

<ul>
  <li>Choosing the right chunk size is foundational to building an effective RAG system. It directly influences retrieval quality, model efficiency, and how well the system captures relevant context for downstream tasks. Poor chunking can lead to fragmented information or excessive context loss, undermining overall performance.</li>
  <li>
    <p>Building a RAG system involves determining the ideal chunk sizes for the documents that the retriever component will process. The ideal chunk size depends on several factors:</p>

    <ol>
      <li>
        <p><strong>Data Characteristics</strong>: The nature of your data is crucial. For text documents, consider the average length of paragraphs or sections. If the documents are well-structured with distinct sections, these natural divisions might serve as a good basis for chunking.</p>
      </li>
      <li>
        <p><strong>Retriever Constraints</strong>: The retriever model you choose (like BM25, TF-IDF, or a neural retriever like DPR) might have limitations on the input length. It’s essential to ensure that the chunks are compatible with these constraints.</p>
      </li>
      <li>
        <p><strong>Memory and Computational Resources</strong>: Larger chunk sizes can lead to higher memory usage and computational overhead. Balance the chunk size with the available resources to ensure efficient processing.</p>
      </li>
      <li>
        <p><strong>Task Requirements</strong>: The nature of the task (e.g., question answering, document summarization) can influence the ideal chunk size. For detailed tasks, smaller chunks might be more effective to capture specific details, while broader tasks might benefit from larger chunks to capture more context.</p>
      </li>
      <li>
        <p><strong>Experimentation</strong>: Often, the best way to determine the ideal chunk size is through empirical testing. Run experiments with different chunk sizes and evaluate the performance on a validation set to find the optimal balance between granularity and context.</p>
      </li>
      <li>
        <p><strong>Overlap Consideration</strong>: Sometimes, it’s beneficial to have overlap between chunks to ensure that no important information is missed at the boundaries. Decide on an appropriate overlap size based on the task and data characteristics.</p>
      </li>
    </ol>
  </li>
  <li>To summarize, determining the ideal chunk size for a RAG system is a balancing act that involves considering the characteristics of your data, the limitations of your retriever model, the resources at your disposal, the specific requirements of your task, and empirical experimentation. It’s a process that may require iteration and fine-tuning to achieve the best results.</li>
</ul>

<h6 id="retriever-ensembling-and-re-ranking">Retriever Ensembling and Re-ranking</h6>

<ul>
  <li>In some scenarios, it may be beneficial to simultaneously utilize multiple chunk sizes and apply a re-ranking mechanism to refine the retrieved results. A detailed discourse on re-ranking is available in the <a href="#re-ranking">Re-ranking</a> section.</li>
  <li>This approach serves two primary purposes:
    <ul>
      <li>It potentially improves the quality of retrieved content—albeit at increased computational cost—by aggregating outputs from multiple chunking strategies, provided the re-ranker performs with a reasonable degree of accuracy.</li>
      <li>It enables systematic comparison of different retrieval methods relative to the re-ranker’s effectiveness.</li>
    </ul>
  </li>
  <li>
    <p>The methodology proceeds as follows:</p>

    <ul>
      <li>Segment the same source document using various chunk sizes, for example: 128, 256, 512, and 1024 tokens.</li>
      <li>During the retrieval phase, extract relevant segments from each retrieval method, thereby forming an ensemble of retrievers.</li>
      <li>Apply a re-ranking model to prioritize and filter the aggregated results.</li>
    </ul>
  </li>
  <li>The following diagram <a href="https://www.linkedin.com/posts/llamaindex_a-big-pain-point-when-trying-to-build-rag-activity-7113307664616484864-RT6n/">(source)</a> illustrates the process.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/RetrieverEnsembling.jpg" alt=""></p>

<ul>
  <li>According to <a href="https://docs.llamaindex.ai/en/latest/examples/retrievers/ensemble_retrieval.html">evaluation data provided by LlamaIndex</a>, the ensemble retrieval strategy leads to a modest improvement in faithfulness metrics, suggesting slightly enhanced relevance of retrieved content. However, pairwise comparisons show equal preference between the ensembled and baseline approaches, thereby leaving the superiority of ensembling open to debate.</li>
  <li>It is important to note that this ensembling methodology is not limited to variations in chunk size. It can also be extended to other dimensions of a RAG pipeline, including vector-based, keyword-based, and hybrid search strategies.</li>
</ul>

<h4 id="embeddings">Embeddings</h4>

<ul>
  <li>Once you have your prompt chunked appropriately, the next step is to embed it. Embedding prompts and documents in RAG involves transforming both the user’s query (prompt) and the documents in the knowledge base into a format that can be effectively compared for relevance. This process is critical for RAG’s ability to retrieve the most relevant information from its knowledge base in response to a user query. Here’s how it typically works:</li>
  <li>One option to help pick which embedding model would be best suited for your task is to look at <a href="https://huggingface.co/spaces/mteb/leaderboard">HuggingFace’s Massive Text Embedding Benchmark (MTEB) leaderboard</a>. There is a question of whether a dense or sparse embedding can be used so let’s look into benefits of each below:</li>
  <li><strong>Sparse embedding:</strong> Sparse embeddings such as TF-IDF are great for lexical matching the prompt with the documents. Best for applications where keyword relevance is crucial. It’s computationally less intensive but may not capture the deeper semantic meanings in the text.</li>
  <li><strong>Semantic embedding:</strong> Semantic embeddings, such as BERT or SentenceBERT lend themselves naturally to the RAG use-case.
    <ul>
      <li><strong>BERT:</strong> Suitable for capturing contextual nuances in both the documents and queries. Requires more computational resources compared to sparse embeddings but offers more semantically rich embeddings.</li>
      <li><strong>SentenceBERT:</strong> Ideal for scenarios where the context and meaning at the sentence level are important. It strikes a balance between the deep contextual understanding of BERT and the need for concise, meaningful sentence representations. This is usually the preferred route for RAG.</li>
    </ul>
  </li>
</ul>

<h4 id="naive-chunking-vs-late-chunking-vs-late-interaction-colbert-and-colpali">Naive Chunking vs. Late Chunking vs. Late Interaction (<a href="https://arxiv.org/abs/2004.12832">ColBERT</a> and <a href="https://arxiv.org/abs/2407.01449">ColPali</a>)</h4>

<ul>
  <li>
    <p>The choice between naive chunking, late chunking, and late interaction (<a href="https://arxiv.org/abs/2004.12832">ColBERT</a> and <a href="https://arxiv.org/abs/2407.01449">ColPali</a>) depends on the specific requirements of the retrieval task:</p>

    <ul>
      <li><strong>Naive Chunking</strong> is suitable for scenarios with strict resource constraints but where retrieval precision is less critical.</li>
      <li><strong>Late Chunking</strong>, introduced by <a href="https://jina.ai">JinaAI</a>, offers an attractive middle ground, maintaining context and providing improved retrieval accuracy without incurring significant additional costs. Put simply, late chunking balances the trade-offs between cost and precision, making it an excellent option for building scalable and effective RAG systems, particularly in long-context retrieval scenarios.</li>
      <li><strong>Late Interaction (<a href="https://arxiv.org/abs/2004.12832">ColBERT</a> and <a href="https://arxiv.org/abs/2407.01449">ColPali</a>)</strong> is best suited for applications where retrieval precision is paramount and resource costs are less of a concern.</li>
    </ul>
  </li>
  <li>
    <p>Let’s explore the differences between three primary strategies: Naive Chunking, Late Chunking, and Late Interaction (<a href="https://arxiv.org/abs/2004.12832">ColBERT</a> and <a href="https://arxiv.org/abs/2407.01449">ColPali</a>), focusing on their methodologies, advantages, and trade-offs.</p>
  </li>
</ul>

<h5 id="overview-1">Overview</h5>

<ul>
  <li>Long-context retrieval presents a challenge when balancing precision, context retention, and cost efficiency. Solutions range from simple and low-cost, like Naive Chunking, to more sophisticated and resource-intensive approaches, such as Late Interaction (<a href="https://arxiv.org/abs/2004.12832">ColBERT</a> and <a href="https://arxiv.org/abs/2407.01449">ColPali</a>). <a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/">Late Chunking</a>, a novel approach by <a href="https://jina.ai">JinaAI</a>, offers a middle ground, preserving context with efficiency comparable to Naive Chunking.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/chunking-strategies.png" alt=""></p>

<h5 id="naivevanilla-chunking">Naive/Vanilla Chunking</h5>

<h6 id="what-is-naivevanilla-chunking">What is Naive/Vanilla Chunking?</h6>

<ul>
  <li>As discussed in the <a href="#chunking">Chunking</a> section, naive/vanilla chunking divides a document into fixed-size chunks based on metrics like sentence boundaries or token count (e.g., 512 tokens per chunk).</li>
  <li>Each chunk is independently embedded into a vector without considering the context of neighboring chunks.</li>
</ul>

<h6 id="example">Example</h6>

<ul>
  <li>
    <p>Consider the following paragraph: <em>Alice went for a walk in the woods one day and on her walk, she spotted something. She saw a rabbit hole at the base of a large tree. She fell into the hole and found herself in a strange new world.</em></p>
  </li>
  <li>
    <p>If chunked by sentences:</p>
    <ul>
      <li><strong>Chunk 1</strong>: “Alice went for a walk in the woods one day and on her walk, she spotted something.”</li>
      <li><strong>Chunk 2</strong>: “She saw a rabbit hole at the base of a large tree.”</li>
      <li><strong>Chunk 3</strong>: “She fell into the hole and found herself in a strange new world.”</li>
    </ul>
  </li>
</ul>

<h6 id="advantages-and-limitations">Advantages and Limitations</h6>

<ul>
  <li><strong>Advantages</strong>:
    <ul>
      <li>Efficient in terms of storage and computation.</li>
      <li>Simple to implement and integrate with most retrieval pipelines.</li>
    </ul>
  </li>
  <li><strong>Limitations</strong>:
    <ul>
      <li><strong>Context Loss</strong>: Each chunk is processed independently, leading to a loss of contextual relationships. For example, the connection between “she” and “Alice” would be lost, reducing retrieval accuracy for context-heavy queries like “Where did Alice fall?”.</li>
      <li><strong>Fragmented Meaning</strong>: Splitting paragraphs or semantically related sections can dilute the meaning of each chunk, reducing retrieval precision.</li>
    </ul>
  </li>
</ul>

<h5 id="late-chunking">Late Chunking</h5>

<h6 id="what-is-late-chunking">What is Late Chunking?</h6>

<ul>
  <li>Late Chunking flips the order of vectorizing (i.e., embedding generation) and chunking compared to naive/vanilla chunking. In other words, it delays the chunking process until after the entire document has been embedded into token-level representations. This allows chunks to retain context from the full document, leading to richer, more contextually aware embeddings.</li>
</ul>

<h6 id="how-late-chunking-works">How Late Chunking Works</h6>

<ol>
  <li><strong>Embedding First</strong>: The entire document is embedded into token-level representations using a long context model.</li>
  <li><strong>Chunking After</strong>: After embedding, the token-level representations are pooled into chunks based on a predefined chunking strategy (e.g., 512-token chunks).</li>
  <li><strong>Context Retention</strong>: Each chunk retains contextual information from the full document, allowing for improved retrieval precision without increasing storage costs.</li>
</ol>

<h6 id="example-1">Example</h6>

<ul>
  <li>Using the same paragraph:
    <ul>
      <li>The entire paragraph is first embedded as a whole, preserving the relationships between all sentences.</li>
      <li>The document is then split into chunks after embedding, ensuring that chunks like “She fell into the hole…” are contextually aware of the mention of “Alice” from earlier sentences.</li>
    </ul>
  </li>
</ul>

<h6 id="advantages-and-trade-offs">Advantages and Trade-offs</h6>

<ul>
  <li><strong>Advantages</strong>:
    <ul>
      <li><strong>Context Preservation</strong>: Late chunking ensures that the relationship between tokens across different chunks is maintained.</li>
      <li><strong>Efficiency</strong>: Late chunking requires the same amount of storage as naive chunking while significantly improving retrieval accuracy.</li>
    </ul>
  </li>
  <li><strong>Trade-offs</strong>:
    <ul>
      <li><strong>Requires Long Context Models</strong>: To embed the entire document at once, a model with long-context capabilities (e.g., supporting up to 8192 tokens) is necessary.</li>
      <li><strong>Slightly Higher Compute Costs</strong>: Late chunking introduces an extra pooling step after embedding, although it’s more efficient than late interaction approaches like <a href="https://arxiv.org/abs/2004.12832">ColBERT</a>.</li>
    </ul>
  </li>
</ul>

<h5 id="late-interaction">Late Interaction</h5>

<h6 id="what-is-late-interaction">What is Late Interaction?</h6>

<ul>
  <li>Late Interaction refers to a retrieval approach where token embeddings for both the document and the query are computed separately and compared at the token level, without any pooling operation. The key advantage is fine-grained, token-level matching, which improves retrieval accuracy.</li>
</ul>

<h6 id="colbert-late-interaction-in-practice"><a href="https://arxiv.org/abs/2004.12832">ColBERT</a>: Late Interaction in Practice</h6>

<ul>
  <li><a href="https://arxiv.org/abs/2004.12832">ColBERT</a> (Contextualized Late Interaction over BERT) by Khattab et al. (2020) uses late interaction to compare individual token embeddings from the query and document using a MaxSim operator. This allows for granular, token-to-token comparisons, which results in highly precise matches but at a significantly higher storage cost.</li>
</ul>

<h6 id="maxsim-a-key-component-of-colbert">MaxSim: a Key Component of <a href="https://arxiv.org/abs/2004.12832">ColBERT</a></h6>

<ul>
  <li><a href="https://stackoverflow.com/questions/74972472/how-to-perform-the-maxsim-operator-leveraging-torch-procedures">MaxSim</a> (Maximum Similarity) is a core component of the <a href="https://arxiv.org/abs/2004.12832">ColBERT</a> retrieval framework. It refers to a specific way of calculating the similarity between token embeddings of a query and document during retrieval.</li>
  <li>Here’s a step-by-step breakdown of how MaxSim works:
    <ol>
      <li><strong>Token-level Embedding Comparisons</strong>:
        <ul>
          <li>When a query is processed, it is tokenized and each token is embedded separately (e.g., “apple” and “sweet”).</li>
          <li>The document is already indexed at the token level, meaning that each token in the document also has its own embedding.</li>
        </ul>
      </li>
      <li><strong>Similarity Computation</strong>:
        <ul>
          <li>At query time, the system compares each query token embedding to every token embedding in the document. The similarity between two token embeddings is often measured using a dot product or cosine similarity.</li>
          <li>For example, given a query token <code class="language-plaintext highlighter-rouge">"apple"</code> and a document containing tokens like <code class="language-plaintext highlighter-rouge">"apple"</code>, <code class="language-plaintext highlighter-rouge">"banana"</code>, and <code class="language-plaintext highlighter-rouge">"fruit"</code>, the system computes the similarity of <code class="language-plaintext highlighter-rouge">"apple"</code> to each of these tokens.</li>
        </ul>
      </li>
      <li><strong>Selecting Maximum Similarity (MaxSim)</strong>:
        <ul>
          <li>The system selects the highest similarity score between the query token and the document tokens. This is known as the MaxSim operation.</li>
          <li>In the above example, the system compares the similarity of <code class="language-plaintext highlighter-rouge">"apple"</code> (query token) with all document tokens and selects the highest similarity score, say between <code class="language-plaintext highlighter-rouge">"apple"</code> and the corresponding token <code class="language-plaintext highlighter-rouge">"apple"</code> in the document.</li>
        </ul>
      </li>
      <li><strong>MaxSim Aggregation</strong>:
        <blockquote>
          <p>The MaxSim scores for each token in the query are aggregated (i.e., summed up) to calculate a final relevance score for the document with respect to the query.</p>
        </blockquote>
        <ul>
          <li>This approach allows for token-level precision, capturing subtle nuances in the document-query matching that would be lost with traditional pooling methods.</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<h6 id="example-2">Example</h6>

<ul>
  <li>
    <p>Consider the query <code class="language-plaintext highlighter-rouge">"sweet apple"</code> and two documents:</p>

    <ul>
      <li><strong>Document 1</strong>: “The apple is sweet and crisp.”</li>
      <li><strong>Document 2</strong>: “The banana is ripe and yellow.”</li>
    </ul>
  </li>
  <li>
    <p>Each query token, <code class="language-plaintext highlighter-rouge">"sweet"</code> and <code class="language-plaintext highlighter-rouge">"apple"</code>, is compared with every token in both documents:</p>

    <ul>
      <li>For <strong>Document 1</strong>, <code class="language-plaintext highlighter-rouge">"sweet"</code> has a high similarity with <code class="language-plaintext highlighter-rouge">"sweet"</code> in the document, and <code class="language-plaintext highlighter-rouge">"apple"</code> has a high similarity with <code class="language-plaintext highlighter-rouge">"apple"</code>.</li>
      <li>For <strong>Document 2</strong>, <code class="language-plaintext highlighter-rouge">"sweet"</code> does not have a strong match with any token, and <code class="language-plaintext highlighter-rouge">"apple"</code> does not appear.</li>
    </ul>
  </li>
  <li>
    <p>Using MaxSim, Document 1 would have a higher relevance score for the query than Document 2 because the most similar tokens in Document 1 (i.e., <code class="language-plaintext highlighter-rouge">"sweet"</code> and <code class="language-plaintext highlighter-rouge">"apple"</code>) align more closely with the query tokens.</p>
  </li>
</ul>

<h6 id="advantages-and-trade-offs-1">Advantages and Trade-offs</h6>

<ul>
  <li><strong>Advantages</strong>:
    <ul>
      <li><strong>High Precision</strong>: <a href="https://arxiv.org/abs/2004.12832">ColBERT</a>’s token-level comparisons, facilitated by MaxSim, lead to highly accurate retrieval, particularly for specific or complex queries.</li>
      <li><strong>Flexible Query Matching</strong>: By calculating similarity at the token level, <a href="https://arxiv.org/abs/2004.12832">ColBERT</a> can capture fine-grained relationships that simpler models might overlook.</li>
    </ul>
  </li>
  <li><strong>Trade-offs</strong>:
    <ul>
      <li><strong>Storage Intensive</strong>: Storing all token embeddings for each document can be extremely costly. For example, storing token embeddings for a corpus of 100,000 documents could require upwards of 2.46 TB.</li>
      <li><strong>Computational Complexity</strong>: While precise, MaxSim increases computational demands at query time, as each token in the query must be compared to all tokens in the document.</li>
    </ul>
  </li>
</ul>

<h5 id="colpali-expanding-to-multimodal-late-interaction-retrieval"><a href="https://arxiv.org/abs/2407.01449">ColPali</a>: Expanding to Multimodal Late-Interaction Retrieval</h5>

<ul>
  <li><a href="https://arxiv.org/abs/2407.01449">ColPali</a> by Faysse et al. (2024) integrates the late interaction mechanism from <a href="https://arxiv.org/abs/2004.12832">ColBERT</a> with a Vision Language Model (VLM) called PaliGemma to handle multimodal documents, such as PDFs with text, images, and tables. Instead of relying on OCR and layout parsing, <a href="https://arxiv.org/abs/2407.01449">ColPali</a> uses screenshots of PDF pages to directly embed both visual and textual content. This enables powerful multimodal retrieval in complex documents.</li>
</ul>

<h6 id="example-3">Example</h6>

<ul>
  <li>Consider a complex PDF with both text and images. <a href="https://arxiv.org/abs/2407.01449">ColPali</a> treats each page as an image and embeds it using a VLM. When a user queries the system, the query is matched with embedded screenshots via late interaction, improving the ability to retrieve relevant pages based on both visual and textual content.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/ColPali.jpg" alt=""></p>

<h5 id="comparative-analysis">Comparative Analysis</h5>

<div align="center">
<table class="tg">
 <thead>
<tr>
<th class="tg-hcenter-valign-first"><strong>Metric</strong></th>
<th class="tg-hcenter-valign-first"><strong>Naive Chunking</strong></th>
<th class="tg-hcenter-valign-first"><strong>Late Chunking</strong></th>
<th class="tg-hcenter-valign-second"><strong>Late Interaction</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="tg-tleft-valign-first">Storage Requirements</td>
<td class="tg-tleft-valign-first">Minimal storage, ~4.9 GB for 100,000 documents</td>
<td class="tg-tleft-valign-first">Same as naive chunking, ~4.9 GB for 100,000 documents</td>
<td class="tg-tleft-valign-second">Extremely high storage, ~2.46 TB for 100,000 documents</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Retrieval Precision</td>
<td class="tg-tleft-valign-first">Lower precision due to context fragmentation</td>
<td class="tg-tleft-valign-first">Improved precision by retaining context across chunks</td>
<td class="tg-tleft-valign-second">Highest precision with token-level matching</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Complexity and Cost</td>
<td class="tg-tleft-valign-first">Simple implementation, minimal resources</td>
<td class="tg-tleft-valign-first">Moderately more complex, efficient in compute and storage</td>
<td class="tg-tleft-valign-second">Highly complex, resource-intensive in both storage and computation</td>
</tr>
</tbody>
</table>
</div>

<h4 id="sentence-embeddings-the-what-and-why">Sentence Embeddings: the What and Why</h4>

<ul>
  <li><strong>Motivation:</strong>
    <ul>
      <li>Before the introduction of Sentence-BERT (SBERT), applying BERT to semantic similarity or retrieval tasks was computationally infeasible at scale. BERT operated as a <em>cross-encoder</em>, where each sentence pair required a joint forward pass with full cross-attention, resulting in <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-4" style="width: 2.815em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.201em, 1002.29em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-5"><span class="mi" id="MathJax-Span-6" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-7" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-8"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-9" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.523em;"><span class="mn" id="MathJax-Span-10" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-11" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-2">O(n^2)</script> complexity. Using raw BERT embeddings—such as averaging token vectors or taking the <code class="language-plaintext highlighter-rouge">[CLS]</code> output—performed worse than earlier static embedding models like GloVe, meaning embeddings couldn’t be precomputed or efficiently compared. Consequently, BERT was limited to re-ranking a small number of candidate sentences rather than performing large-scale semantic retrieval.</li>
      <li>SBERT addressed this limitation by fine-tuning BERT in a Siamese or triplet configuration, enabling independent computation of sentence embeddings. This allowed <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-12" style="width: 2.294em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1001.83em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-13"><span class="mi" id="MathJax-Span-14" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-15" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-16" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-17" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-3">O(n)</script> embedding computations followed by lightweight cosine similarity comparisons, reducing semantic search computation from roughly 65 hours to 5 seconds while preserving accuracy. This breakthrough laid the foundation for modern <strong>dense retrieval</strong>, <strong>dual-encoder architectures</strong>, and <strong>retrieval-augmented generation (RAG)</strong> systems, all of which depend on scalable, precomputable embeddings.</li>
    </ul>
  </li>
</ul>

<h5 id="background-differences-compared-to-token-level-models-like-bert">Background: Differences Compared to Token-Level Models Like BERT</h5>

<ul>
  <li>
    <p>As an overview, let’s look into how sentence transformers differ compared to token-level embedding models such as BERT.</p>
  </li>
  <li>
    <p>Sentence Transformers are a modification of the traditional BERT model, tailored specifically for generating embeddings of entire sentences (i.e., sentence embeddings). The key differences in their training approaches are:</p>

    <ol>
      <li><strong>Objective</strong>: BERT is trained to predict masked words and next sentence prediction. Sentence Transformers, as introduced in <a href="https://arxiv.org/abs/1908.10084">Sentence-BERT</a> by Reimers and Gurevych (2019), are fine-tuned specifically to understand relationships between sentences. They produce embeddings where semantically similar sentences are close in vector space, typically using cosine similarity as the comparison metric.</li>
      <li><strong>Level of Embedding</strong>: BERT provides contextualized token embeddings, while Sentence Transformers produce a single, semantically meaningful embedding for the entire sentence by applying a pooling operation to the transformer’s output.</li>
      <li><strong>Training Data and Tasks</strong>: SBERT is fine-tuned using datasets like SNLI and MultiNLI, which contain labeled sentence pairs (entailment, contradiction, neutral). This contrastive supervision enables it to learn sentence-level semantics that generalize well to similarity tasks.</li>
      <li><strong>Siamese and Triplet Network Structures</strong>: SBERT introduces a siamese or triplet architecture where two or three BERT models (sharing weights) encode input sentences into embeddings. During training, these embeddings are optimized so that semantically close sentences have higher cosine similarity and dissimilar ones have lower similarity.</li>
      <li><strong>Pooling Strategies</strong>: To obtain a fixed-size vector, SBERT applies pooling over the last hidden layer of BERT. The paper experiments with three strategies—mean pooling, max pooling, and using the <code class="language-plaintext highlighter-rouge">[CLS]</code> token output—with mean pooling performing best.</li>
      <li><strong>Fine-Tuning Objectives</strong>: Depending on available supervision, SBERT can use classification (softmax over concatenated embeddings and element-wise differences), regression (cosine similarity with mean-squared error), or triplet loss objectives to align embeddings of related sentences.
        <ul>
          <li>For the classification objective, the embeddings <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-18" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-19"><span class="mi" id="MathJax-Span-20" style="font-family: STIXGeneral-Italic;">u</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>u</mi></math></span></span><script type="math/tex" id="MathJax-Element-4">u</script> and <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-21" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-22"><span class="mi" id="MathJax-Span-23" style="font-family: STIXGeneral-Italic;">v</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi></math></span></span><script type="math/tex" id="MathJax-Element-5">v</script> are concatenated with their element-wise absolute difference <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-6-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-24" style="width: 3.128em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.607em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1002.5em, 2.607em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-25"><span class="mo" id="MathJax-Span-26" style="font-family: STIXGeneral-Regular;">∣</span><span class="mi" id="MathJax-Span-27" style="font-family: STIXGeneral-Italic;">u</span><span class="mo" id="MathJax-Span-28" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">−</span><span class="mi" id="MathJax-Span-29" style="font-family: STIXGeneral-Italic; padding-left: 0.263em;">v</span><span class="mo" id="MathJax-Span-30" style="font-family: STIXGeneral-Regular;">∣</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">∣</mo><mi>u</mi><mo>−</mo><mi>v</mi><mo stretchy="false">∣</mo></math></span></span><script type="math/tex" id="MathJax-Element-6">\mid u - v \mid</script>, forming a vector of size <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-31" style="width: 1.201em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.99em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-32"><span class="mn" id="MathJax-Span-33" style="font-family: STIXGeneral-Regular;">3</span><span class="mi" id="MathJax-Span-34" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3</mn><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-7">3n</script>. This is passed through a fully connected linear layer with weight matrix <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;msup&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;R&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-35" style="width: 5.523em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.586em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.201em, 1004.59em, 2.555em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-36"><span class="msubsup" id="MathJax-Span-37"><span style="display: inline-block; position: relative; width: 1.096em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-38" style="font-family: STIXGeneral-Italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.836em;"><span class="mi" id="MathJax-Span-39" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-40" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∈</span><span class="msubsup" id="MathJax-Span-41" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.294em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="texatom" id="MathJax-Span-42"><span class="mrow" id="MathJax-Span-43"><span class="mi" id="MathJax-Span-44" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.732em;"><span class="texatom" id="MathJax-Span-45"><span class="mrow" id="MathJax-Span-46"><span class="mn" id="MathJax-Span-47" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span class="mi" id="MathJax-Span-48" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-49" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">×</span><span class="mi" id="MathJax-Span-50" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>W</mi><mi>t</mi></msub><mo>∈</mo><msup><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="double-struck">R</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mn>3</mn><mi>n</mi><mo>×</mo><mi>k</mi></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-8">W_t \in \mathbb{R}^{3n \times k}</script> before applying softmax <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-9-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mtext&gt;softmax&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-51" style="width: 15.107em; display: inline-block;"><span style="display: inline-block; position: relative; width: 12.555em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1012.5em, 2.607em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-52"><span class="mi" id="MathJax-Span-53" style="font-family: STIXGeneral-Italic;">o</span><span class="mo" id="MathJax-Span-54" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mtext" id="MathJax-Span-55" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">softmax</span><span class="mo" id="MathJax-Span-56" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-57"><span style="display: inline-block; position: relative; width: 1.096em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-58" style="font-family: STIXGeneral-Italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.836em;"><span class="mi" id="MathJax-Span-59" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-60" style="font-family: STIXGeneral-Regular;">[</span><span class="mi" id="MathJax-Span-61" style="font-family: STIXGeneral-Italic;">u</span><span class="mo" id="MathJax-Span-62" style="font-family: STIXGeneral-Regular;">;</span><span class="mi" id="MathJax-Span-63" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">v</span><span class="mo" id="MathJax-Span-64" style="font-family: STIXGeneral-Regular;">;</span><span class="mo" id="MathJax-Span-65" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">∣</span><span class="mi" id="MathJax-Span-66" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">u</span><span class="mo" id="MathJax-Span-67" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">−</span><span class="mi" id="MathJax-Span-68" style="font-family: STIXGeneral-Italic; padding-left: 0.263em;">v</span><span class="mo" id="MathJax-Span-69" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣</span><span class="mo" id="MathJax-Span-70" style="font-family: STIXGeneral-Regular;">]</span><span class="mo" id="MathJax-Span-71" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>o</mi><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><msub><mi>W</mi><mi>t</mi></msub><mo stretchy="false">[</mo><mi>u</mi><mo>;</mo><mi>v</mi><mo>;</mo><mo>∣</mo><mi>u</mi><mo>−</mo><mi>v</mi><mo>∣</mo><mo stretchy="false">]</mo><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-9">o = \text{softmax}(W_t [u; v; \mid u - v \mid])</script>, where <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-72" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-73"><span class="mi" id="MathJax-Span-74" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-10">k</script> is the number of output classes (since the <a href="https://arxiv.org/abs/1908.10084">SBERT paper</a> focused on NLI, they were entailment, contradiction, and neutral). This projection layer provides the learned transformation before softmax classification. By removing the softmax head at inference time, SBERT reduces similarity computation from <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-75" style="width: 2.815em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.201em, 1002.29em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-76"><span class="mi" id="MathJax-Span-77" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-78" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-79"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-80" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.523em;"><span class="mn" id="MathJax-Span-81" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-82" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-11">O(n^2)</script> pairwise comparisons to <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-83" style="width: 2.294em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1001.83em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-84"><span class="mi" id="MathJax-Span-85" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-86" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-87" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-88" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-12">O(n)</script> independent embedding computations followed by lightweight cosine similarity scoring—enabling massive speedups in retrieval. During training, the softmax classifier makes the model <strong>close-ended</strong>, restricted to a fixed set of <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-89" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-90"><span class="mi" id="MathJax-Span-91" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-13">k</script> output classes (e.g., entailment, contradiction, neutral). In contrast, inference is <strong>open-ended</strong>: without the softmax constraint, SBERT functions as a general-purpose feature extractor whose embeddings can be compared across unseen categories using cosine similarity, optionally followed by thresholding on the score <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mtext&gt;sim&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mo&gt;&amp;#x22C5;&lt;/mo&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mo&gt;&amp;#x2223;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-92" style="width: 7.815em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.513em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1006.51em, 2.867em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-93"><span class="mtext" id="MathJax-Span-94" style="font-family: STIXGeneral-Regular;">sim</span><span class="mo" id="MathJax-Span-95" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-96" style="font-family: STIXGeneral-Italic;">u</span><span class="mo" id="MathJax-Span-97" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-98" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">v</span><span class="mo" id="MathJax-Span-99" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-100" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-101" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.513em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.544em, 1000.84em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -0.414em;"><span class="mrow" id="MathJax-Span-102"><span class="mi" id="MathJax-Span-103" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">u</span><span class="mo" id="MathJax-Span-104" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">⋅</span><span class="mi" id="MathJax-Span-105" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">v</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1001.3em, 4.326em, -999.997em); top: -3.591em; left: 50%; margin-left: -0.674em;"><span class="mrow" id="MathJax-Span-106"><span class="mo" id="MathJax-Span-107" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∣</span><span class="mi" id="MathJax-Span-108" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">u</span><span class="mo" id="MathJax-Span-109" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∣<span style="font-family: STIXGeneral-Regular; font-style: normal; font-weight: normal;">∣</span></span><span class="mi" id="MathJax-Span-110" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">v</span><span class="mo" id="MathJax-Span-111" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∣</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.51em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.513em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.684em; border-left: 0px solid; width: 0px; height: 1.628em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>sim</mtext><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>u</mi><mo>⋅</mo><mi>v</mi></mrow><mrow><mo stretchy="false">∣</mo><mi>u</mi><mo>∣∣</mo><mi>v</mi><mo stretchy="false">∣</mo></mrow></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-14">\text{sim}(u, v) = \frac{u \cdot v}{\mid u \mid \mid v \mid}</script> for binary decisions (e.g., “similar” vs. “not similar”).</li>
          <li>Although the original SBERT paper did not employ it, this triplet framework can be <strong>extended to Multiple Negatives Ranking Loss (MNRL)</strong>, where each batch provides multiple implicit negatives for every anchor–positive pair. MNRL improves efficiency by leveraging all non-matching pairs within a batch as negatives, making training more stable and scalable for large datasets.</li>
        </ul>
      </li>
      <li><strong>Efficiency in Generating Sentence Embeddings or Similarity Tasks</strong>: In the standard BERT model, sentence embeddings are generated using the <code class="language-plaintext highlighter-rouge">[CLS]</code> vector from the last layer, which performs poorly for semantic similarity (correlations as low as 0.29 on STS tasks). In contrast, SBERT dramatically improves both accuracy and computational efficiency: semantic similarity searches that would take ~65 hours with BERT can be done in about 5 seconds with SBERT.</li>
      <li><strong>Applicability</strong>: While BERT excels at tasks requiring token-level understanding (e.g., named entity recognition, question answering), Sentence Transformers are optimized for semantic similarity, clustering, and retrieval tasks.</li>
    </ol>
  </li>
  <li>The left half of the following figure (<a href="https://arxiv.org/abs/1908.10084">source</a>) shows the SBERT architecture with the classification objective function, e.g., for fine-tuning on SNLI dataset. The two BERT networks have tied weights (siamese network structure).
    <ul>
      <li>This figure illustrates the <strong>training phase</strong>, where two tied-weight BERT encoders process sentences A and B to produce embeddings <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-112" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-113"><span class="mi" id="MathJax-Span-114" style="font-family: STIXGeneral-Italic;">u</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>u</mi></math></span></span><script type="math/tex" id="MathJax-Element-15">u</script> and <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-115" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-116"><span class="mi" id="MathJax-Span-117" style="font-family: STIXGeneral-Italic;">v</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi></math></span></span><script type="math/tex" id="MathJax-Element-16">v</script>. These embeddings are concatenated with their <strong>element-wise absolute difference <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-118" style="width: 3.153em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.585em; height: 0px; font-size: 121%;"><span style="position: absolute; clip: rect(1.397em, 1002.48em, 2.585em, -999.997em); top: -2.218em; left: 0em;"><span class="mrow" id="MathJax-Span-119"><span class="mo" id="MathJax-Span-120" style="font-family: STIXGeneral-Regular;">∣</span><span class="mi" id="MathJax-Span-121" style="font-family: STIXGeneral-Italic;">u</span><span class="mo" id="MathJax-Span-122" style="font-family: STIXGeneral-Regular; padding-left: 0.261em;">−</span><span class="mi" id="MathJax-Span-123" style="font-family: STIXGeneral-Italic; padding-left: 0.261em;">v</span><span class="mo" id="MathJax-Span-124" style="font-family: STIXGeneral-Regular;">∣</span></span><span style="display: inline-block; width: 0px; height: 2.224em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">∣</mo><mi>u</mi><mo>−</mo><mi>v</mi><mo stretchy="false">∣</mo></math></span></span><script type="math/tex" id="MathJax-Element-17">\mid u - v \mid</script></strong> and passed through a <strong>linear projection layer <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-18-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-125" style="width: 1.397em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.139em; height: 0px; font-size: 121%;"><span style="position: absolute; clip: rect(1.294em, 1001.14em, 2.43em, -999.997em); top: -2.115em; left: 0em;"><span class="mrow" id="MathJax-Span-126"><span class="msubsup" id="MathJax-Span-127"><span style="display: inline-block; position: relative; width: 1.139em; height: 0px;"><span style="position: absolute; clip: rect(3.153em, 1000.93em, 4.135em, -999.997em); top: -3.975em; left: 0em;"><span class="mi" id="MathJax-Span-128" style="font-family: STIXGeneral-Italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span style="display: inline-block; width: 0px; height: 3.98em;"></span></span><span style="position: absolute; top: -3.82em; left: 0.829em;"><span class="mi" id="MathJax-Span-129" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 3.98em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.12em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>W</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-18">W_t</script></strong> before a softmax classifier predicts relational labels such as entailment or contradiction. The softmax layer is critical during training because it provides a supervised learning signal (with discrete classification labels) that guides the model to map semantically related sentences close together in embedding space.</li>
    </ul>
  </li>
  <li>The right half of the following figure (<a href="https://arxiv.org/abs/1908.10084">source</a>) shows the SBERT architecture during inference, for example, to compute similarity scores. This architecture is also used with the regression objective function.
    <ul>
      <li>This figure depicts the <strong>inference phase</strong>, where the trained encoders are used without the softmax classification head. Instead, embeddings are generated independently for each sentence and compared using <strong>cosine similarity</strong>, optionally followed by thresholding to make binary similarity decisions.</li>
      <li>The removal of the softmax layer is essential because, if retained, it would require concatenating pairs of embeddings and performing a new forward pass for each pair—reintroducing the <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-19-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-130" style="width: 2.815em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.201em, 1002.29em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-131"><span class="mi" id="MathJax-Span-132" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-133" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-134"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-135" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.523em;"><span class="mn" id="MathJax-Span-136" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-137" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-19">O(n^2)</script> cost of cross-encoding. Without the softmax layer, embeddings can be computed once per sentence (offline or on-demand), allowing fast vector-based retrieval and comparison. In other words, omitting the softmax during inference enables the key property that makes SBERT efficient: sentence embeddings become <strong>independent representations</strong> that can be precomputed and compared directly using cosine similarity, without needing joint inference over pairs.</li>
    </ul>
  </li>
</ul>

<p><img src="../../../images/papers/sbert.jpg" alt=""></p>

<ul>
  <li>In summary, while BERT is a general-purpose contextual language model, Sentence Transformers like SBERT are optimized for semantic comparison at the sentence level, producing dense, meaningful embeddings well-suited for similarity-based tasks.</li>
</ul>

<h5 id="training-process-for-sentence-transformers-vs-token-level-embedding-models">Training Process for Sentence Transformers vs. Token-Level Embedding Models</h5>

<ul>
  <li>
    <p>Sentence Transformers are trained differently from token-level models such as BERT. Their process focuses on aligning sentence meanings rather than predicting masked words.</p>

    <ol>
      <li><strong>Model Architecture</strong>: SBERT builds on pretrained BERT or RoBERTa models by adding a pooling layer that converts token-level outputs into a single sentence embedding.</li>
      <li><strong>Training Data</strong>: SBERT is fine-tuned on Natural Language Inference (NLI) datasets like SNLI and MultiNLI, containing hundreds of thousands of labeled sentence pairs that capture semantic relations.</li>
      <li><strong>Training Objectives</strong>:
        <ul>
          <li><strong>Classification Objective</strong>: Concatenates embeddings of two sentences <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-20-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-138" style="width: 2.607em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1002.09em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-139"><span class="mo" id="MathJax-Span-140" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-141" style="font-family: STIXGeneral-Italic;">u</span><span class="mo" id="MathJax-Span-142" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-143" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">v</span><span class="mo" id="MathJax-Span-144" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-20">(u, v)</script> with their element-wise absolute difference <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-21-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-145" style="width: 3.128em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.607em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1002.5em, 2.607em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-146"><span class="mo" id="MathJax-Span-147" style="font-family: STIXGeneral-Regular;">∣</span><span class="mi" id="MathJax-Span-148" style="font-family: STIXGeneral-Italic;">u</span><span class="mo" id="MathJax-Span-149" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">−</span><span class="mi" id="MathJax-Span-150" style="font-family: STIXGeneral-Italic; padding-left: 0.263em;">v</span><span class="mo" id="MathJax-Span-151" style="font-family: STIXGeneral-Regular;">∣</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">∣</mo><mi>u</mi><mo>−</mo><mi>v</mi><mo stretchy="false">∣</mo></math></span></span><script type="math/tex" id="MathJax-Element-21">\mid u - v \mid</script>, projects the resulting <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-22-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-152" style="width: 1.201em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.99em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-153"><span class="mn" id="MathJax-Span-154" style="font-family: STIXGeneral-Regular;">3</span><span class="mi" id="MathJax-Span-155" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>3</mn><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-22">3n</script>-dimensional vector through a linear layer <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-23-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;msup&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;double-struck&quot;&gt;R&lt;/mi&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-156" style="width: 5.523em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.586em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.201em, 1004.59em, 2.555em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-157"><span class="msubsup" id="MathJax-Span-158"><span style="display: inline-block; position: relative; width: 1.096em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-159" style="font-family: STIXGeneral-Italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.836em;"><span class="mi" id="MathJax-Span-160" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-161" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∈</span><span class="msubsup" id="MathJax-Span-162" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.294em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="texatom" id="MathJax-Span-163"><span class="mrow" id="MathJax-Span-164"><span class="mi" id="MathJax-Span-165" style="font-family: STIXGeneral-Regular;">ℝ</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.732em;"><span class="texatom" id="MathJax-Span-166"><span class="mrow" id="MathJax-Span-167"><span class="mn" id="MathJax-Span-168" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span class="mi" id="MathJax-Span-169" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-170" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">×</span><span class="mi" id="MathJax-Span-171" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>W</mi><mi>t</mi></msub><mo>∈</mo><msup><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="double-struck">R</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mn>3</mn><mi>n</mi><mo>×</mo><mi>k</mi></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-23">W_t \in \mathbb{R}^{3n \times k}</script>, and applies softmax to obtain class probabilities. This setup makes training <strong>close-ended</strong>, restricted to the predefined NLI labels, whereas inference is <strong>open-ended</strong>, since embeddings can later be compared beyond those classes using cosine similarity and thresholding.</li>
          <li><strong>Regression Objective</strong>: Minimizes mean-squared error between cosine similarity of embeddings and human-annotated similarity scores.</li>
          <li><strong>Triplet Objective</strong>: Minimizes the margin between anchor–positive and anchor–negative pairs, ensuring semantically close sentences are closer in embedding space. Although the original paper did not use it, this triplet loss can naturally extend to <strong>Multiple Negatives Ranking Loss (MNRL)</strong>, which treats every non-matching sentence in the same batch as a negative sample—improving data efficiency and convergence for large-scale contrastive learning.</li>
        </ul>
      </li>
      <li><strong>Pooling and Representation</strong>: The final sentence embedding is typically the mean of all token embeddings from the last hidden layer, which captures overall sentence meaning better than using only the <code class="language-plaintext highlighter-rouge">[CLS]</code> token.</li>
      <li><strong>Efficiency Gains</strong>: SBERT reduces the number of required pairwise comparisons from <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-24-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-172" style="width: 2.815em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.201em, 1002.29em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-173"><span class="mi" id="MathJax-Span-174" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-175" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-176"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-177" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.523em;"><span class="mn" id="MathJax-Span-178" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-179" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-24">O(n^2)</script> to <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-25-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;O&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-180" style="width: 2.294em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1001.83em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-181"><span class="mi" id="MathJax-Span-182" style="font-family: STIXGeneral-Italic;">O</span><span class="mo" id="MathJax-Span-183" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-184" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-185" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-25">O(n)</script>, since sentence embeddings can be precomputed and compared using cosine similarity. This makes it suitable for large-scale applications like semantic search or clustering.</li>
      <li><strong>Evaluation and Performance</strong>: SBERT achieves state-of-the-art performance on multiple STS benchmarks, outperforming models like InferSent and Universal Sentence Encoder by significant margins (average correlation improvements of 5–12 points).</li>
    </ol>
  </li>
  <li>
    <p><strong>Practical Impact on Retrieval Systems</strong>: SBERT’s dual-encoder setup—where sentences are encoded independently and compared via cosine similarity—became the cornerstone of dense retrieval. Removing the softmax layer in inference is precisely what enables offline precomputation and real-time similarity search across massive corpora. This innovation allowed embedding-based retrieval systems, approximate nearest neighbor (ANN) search, and RAG pipelines to become scalable and efficient at industrial scale.</p>
  </li>
  <li>
    <p>In summary, Sentence-BERT extends BERT with architecture and training modifications that produce semantically rich, scalable, and efficient sentence representations suitable for similarity and clustering tasks.</p>
  </li>
</ul>

<h5 id="applying-sentence-transformers-for-rag">Applying Sentence Transformers for RAG</h5>

<ul>
  <li>Now, let’s look into why sentence transformers are the numero uno choice of models to generate embeddings for RAG.</li>
  <li>RAG leverages Sentence Transformers for their ability to understand and compare the semantic content of sentences. This integration is particularly useful in scenarios where the model needs to retrieve relevant information before generating a response. Here’s how Sentence Transformers are useful in a RAG setting:
    <ol>
      <li><strong>Improved Document Retrieval</strong>: Sentence Transformers are trained to generate embeddings that capture the semantic meaning of sentences. In a RAG setting, these embeddings can be used to match a query (like a user’s question) with the most relevant documents or passages in a database. This is critical because the quality of the generated response often depends on the relevance of the retrieved information.</li>
      <li><strong>Efficient Semantic Search</strong>: Traditional keyword-based search methods might struggle with understanding the context or the semantic nuances of a query. Sentence Transformers, by providing semantically meaningful embeddings, enable more nuanced searches that go beyond keyword matching. This means that the retrieval component of RAG can find documents that are semantically related to the query, even if they don’t contain the exact keywords.</li>
      <li><strong>Contextual Understanding for Better Responses</strong>: By using Sentence Transformers, the RAG model can better understand the context and nuances of both the input query and the content of potential source documents. This leads to more accurate and contextually appropriate responses, as the generation component of the model has more relevant and well-understood information to work with.</li>
      <li><strong>Scalability in Information Retrieval</strong>: Sentence Transformers can efficiently handle large databases of documents by pre-computing embeddings for all documents. This makes the retrieval process faster and more scalable, as the model only needs to compute the embedding for the query at runtime and then quickly find the closest document embeddings.</li>
      <li><strong>Enhancing the Generation Process</strong>: In a RAG setup, the generation component benefits from the retrieval component’s ability to provide relevant, semantically-rich information. This allows the language model to generate responses that are not only contextually accurate but also informed by a broader range of information than what the model itself was trained on.</li>
    </ol>
  </li>
  <li>In summary, Sentence Transformers enhance the retrieval capabilities of RAG models with LLMs by enabling more effective semantic search and retrieval of information. This leads to improved performance in tasks that require understanding and generating responses based on large volumes of text data, such as question answering, chatbots, and information extraction.</li>
</ul>

<h3 id="retrieval">Retrieval</h3>

<ul>
  <li>Retrieval is the core mechanism that enables RAG systems to ground language model outputs in external knowledge by selecting a small, relevant subset of documents or passages from a large corpus to condition generation.</li>
  <li>Lexical, semantic, and hybrid retrieval methods define how queries are mapped to candidate context, directly influencing what information the language model can and cannot use when generating an answer.</li>
  <li>A solid understanding of retrieval techniques is critical for RAG because retrieval failures (missing key facts, retrieving irrelevant context, or violating constraints) propagate downstream and manifest as hallucinations, inaccuracies, or unsafe outputs during generation.</li>
  <li>A detailed discourse of retrieval (also known as the information retrieval problem) is available in our <a href="../../../recsys/search">Search</a> primer.</li>
</ul>

<h4 id="lexical-retrieval">Lexical Retrieval</h4>

<ul>
  <li>Lexical retrieval, also referred to as sparse retrieval, term-based retrieval, or keyword-based retrieval, is the classical foundation of information retrieval systems. It operates purely on observable text signals, relying on exact token matches between a query and documents. Relevance is estimated using statistical properties of terms within documents and across the corpus, without attempting to model meaning or intent.</li>
  <li>At its core, lexical retrieval assumes that relevance correlates with how frequently and distinctively query terms appear in a document.</li>
</ul>

<h5 id="core-assumptions">Core Assumptions</h5>

<ul>
  <li>
    <p>Lexical retrieval is deterministic, interpretable, and highly efficient at scale because of the following assumptions:</p>

    <ul>
      <li>Words are treated as discrete symbols (tokens).</li>
      <li>Matching is based on an exact match overlap.</li>
      <li>Importance is inferred from distributional statistics, not semantics.</li>
      <li>Query intent is approximated by the literal terms provided.</li>
    </ul>
  </li>
</ul>

<h5 id="tf-idf-term-frequencyinverse-document-frequency">TF-IDF (Term Frequency–Inverse Document Frequency)</h5>

<ul>
  <li>
    <p>TF-IDF is one of the earliest and most influential scoring schemes in information retrieval. It decomposes relevance into two components:</p>

    <ol>
      <li>
        <p><strong>Term Frequency (TF)</strong>: Measures how often a term appears in a document. The intuition is that repeated mentions indicate topical relevance.</p>
      </li>
      <li>
        <p><strong>Inverse Document Frequency (IDF)</strong>: Downweights terms that appear frequently across the corpus, under the assumption that common words carry less discriminative power.</p>
      </li>
    </ol>
  </li>
  <li>
    <p>A standard formulation is:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-26-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;TF-IDF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mtext&gt;TF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x22C5;&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mfrac&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;mrow&gt;&lt;mtext&gt;DF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-186" style="width: 18.648em; display: inline-block;"><span style="display: inline-block; position: relative; width: 15.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(2.294em, 1015.37em, 4.846em, -999.997em); top: -3.799em; left: 0em;"><span class="mrow" id="MathJax-Span-187"><span class="mtext" id="MathJax-Span-188" style="font-family: STIXGeneral-Regular;">TF-IDF</span><span class="mo" id="MathJax-Span-189" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-190" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-191" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-192" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-193" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-194" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mtext" id="MathJax-Span-195" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">TF</span><span class="mo" id="MathJax-Span-196" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-197" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-198" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-199" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-200" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-201" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">⋅</span><span class="mi" id="MathJax-Span-202" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">log</span><span class="mo" id="MathJax-Span-203"></span><span class="mrow" id="MathJax-Span-204"><span class="mo" id="MathJax-Span-205" style="vertical-align: -0.466em;"><span><span style="font-size: 111%; font-family: STIXSizeTwoSym;">(</span></span></span><span class="mfrac" id="MathJax-Span-206"><span style="display: inline-block; position: relative; width: 2.346em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.362em;"><span class="mi" id="MathJax-Span-207" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1002.19em, 4.326em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.143em;"><span class="mrow" id="MathJax-Span-208"><span class="mtext" id="MathJax-Span-209" style="font-family: STIXGeneral-Regular;">DF</span><span class="mo" id="MathJax-Span-210" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-211" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-212" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.35em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.346em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-213" style="vertical-align: -0.466em;"><span><span style="font-size: 111%; font-family: STIXSizeTwoSym;">)</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.805em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.122em; border-left: 0px solid; width: 0px; height: 2.753em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>TF-IDF</mtext><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>TF</mtext><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mi>d</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>log</mi><mo>⁡</mo><mrow><mo>(</mo><mfrac><mi>N</mi><mrow><mtext>DF</mtext><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>)</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-26">\text{TF-IDF}(t, d) = \text{TF}(t, d) \cdot \log\left(\frac{N}{\text{DF}(t)}\right)</script>

    <ul>
      <li>
        <p>where:</p>

        <ul>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-27-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-214" style="width: 0.315em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-215"><span class="mi" id="MathJax-Span-216" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math></span></span><script type="math/tex" id="MathJax-Element-27">t</script> is a term,</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-28-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-217" style="width: 0.732em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-218"><span class="mi" id="MathJax-Span-219" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></span></span><script type="math/tex" id="MathJax-Element-28">d</script> is a document,</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-29-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-220" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-221"><span class="mi" id="MathJax-Span-222" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi></math></span></span><script type="math/tex" id="MathJax-Element-29">N</script> is the total number of documents,</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-30-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mtext&gt;DF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-223" style="width: 2.711em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.242em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1002.19em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-224"><span class="mtext" id="MathJax-Span-225" style="font-family: STIXGeneral-Regular;">DF</span><span class="mo" id="MathJax-Span-226" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-227" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-228" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>DF</mtext><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-30">\text{DF}(t)</script> is the number of documents containing <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-31-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-229" style="width: 0.315em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-230"><span class="mi" id="MathJax-Span-231" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math></span></span><script type="math/tex" id="MathJax-Element-31">t</script>.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="strengths-of-tf-idf">Strengths of TF-IDF</h5>

<ul>
  <li>Simple and fast to compute.</li>
  <li>Strong baseline for keyword-heavy queries.</li>
  <li>Fully interpretable scoring.</li>
  <li>Requires no training data.</li>
</ul>

<h5 id="limitations-of-tf-idf">Limitations of TF-IDF</h5>

<ul>
  <li>
    <p>These limitations motivated more refined probabilistic ranking functions.</p>

    <ul>
      <li>Linear growth of TF causes term repetition to dominate scores.</li>
      <li>No document length normalization.</li>
      <li>Treats all term positions equally.</li>
      <li>Performs poorly on long documents and verbose queries.</li>
      <li>Fails completely on synonymy and paraphrasing.</li>
    </ul>
  </li>
</ul>

<h5 id="bm25-best-matching-25">BM25 (Best Matching 25)</h5>

<ul>
  <li>
    <p>BM25 is a probabilistic retrieval model that improves upon TF-IDF by addressing its key weaknesses. It introduces two critical refinements:</p>

    <ol>
      <li>
        <p><strong>Term frequency saturation</strong>: Additional occurrences of a term provide diminishing returns rather than linear gains.</p>
      </li>
      <li>
        <p><strong>Document length normalization</strong>: Longer documents are normalized to prevent unfair advantage due to sheer volume of text.</p>
      </li>
    </ol>
  </li>
  <li>
    <p>A common BM25 formulation is:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-32-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;BM25&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mtext&gt;IDF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x22C5;&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x22C5;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x22C5;&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;&amp;#x22C5;&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mtext&gt;avgdl&lt;/mtext&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-232" style="width: 29.326em; display: inline-block;"><span style="display: inline-block; position: relative; width: 24.43em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.732em, 1024.43em, 4.221em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-233"><span class="mtext" id="MathJax-Span-234" style="font-family: STIXGeneral-Regular;">BM25</span><span class="mo" id="MathJax-Span-235" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-236" style="font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-237" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-238" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-239" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-240" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="munderover" id="MathJax-Span-241" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px;"><span style="position: absolute; clip: rect(2.867em, 1001.2em, 4.638em, -999.997em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-242" style="font-family: STIXSizeOneSym; vertical-align: -0.518em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.492em, 1001.04em, 4.43em, -999.997em); top: -2.862em; left: 0.107em;"><span class="texatom" id="MathJax-Span-243"><span class="mrow" id="MathJax-Span-244"><span class="mi" id="MathJax-Span-245" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-246" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∈</span><span class="mi" id="MathJax-Span-247" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mtext" id="MathJax-Span-248" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">IDF</span><span class="mo" id="MathJax-Span-249" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-250" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-251" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-252" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">⋅</span><span class="mfrac" id="MathJax-Span-253" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 13.232em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1006.41em, 4.378em, -999.997em); top: -4.685em; left: 50%; margin-left: -3.227em;"><span class="mrow" id="MathJax-Span-254"><span class="mi" id="MathJax-Span-255" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.159em;"></span></span><span class="mo" id="MathJax-Span-256" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-257" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-258" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-259" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-260" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-261" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">⋅</span><span class="mo" id="MathJax-Span-262" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">(</span><span class="msubsup" id="MathJax-Span-263"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-264" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mn" id="MathJax-Span-265" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-266" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-267" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">1</span><span class="mo" id="MathJax-Span-268" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(2.659em, 1013.02em, 4.846em, -999.997em); top: -2.862em; left: 50%; margin-left: -6.56em;"><span class="mrow" id="MathJax-Span-269"><span class="mi" id="MathJax-Span-270" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.159em;"></span></span><span class="mo" id="MathJax-Span-271" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-272" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-273" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-274" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-275" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-276" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="msubsup" id="MathJax-Span-277" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-278" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mn" id="MathJax-Span-279" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-280" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">⋅</span><span class="mrow" id="MathJax-Span-281" style="padding-left: 0.263em;"><span class="mo" id="MathJax-Span-282" style="vertical-align: -0.414em;"><span style="font-family: STIXSizeTwoSym;">(</span></span><span class="mrow" id="MathJax-Span-283"><span class="mn" id="MathJax-Span-284" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-285" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">−</span><span class="mi" id="MathJax-Span-286" style="font-family: STIXGeneral-Italic; padding-left: 0.263em;">b</span><span class="mo" id="MathJax-Span-287" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mi" id="MathJax-Span-288" style="font-family: STIXGeneral-Italic; padding-left: 0.263em;">b</span><span class="mo" id="MathJax-Span-289" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">⋅</span><span class="mfrac" id="MathJax-Span-290" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 1.669em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.388em, 1000.73em, 4.326em, -999.997em); top: -4.529em; left: 50%; margin-left: -0.414em;"><span class="mrow" id="MathJax-Span-291"><span class="texatom" id="MathJax-Span-292"><span class="mrow" id="MathJax-Span-293"><span class="mo" id="MathJax-Span-294" style="font-size: 70.7%; font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-295" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-296"><span class="mrow" id="MathJax-Span-297"><span class="mo" id="MathJax-Span-298" style="font-size: 70.7%; font-family: STIXVariants;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1001.57em, 4.326em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.779em;"><span class="mtext" id="MathJax-Span-299" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">avgdl</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.67em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.669em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-300" style="vertical-align: -0.414em;"><span style="font-family: STIXSizeTwoSym;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1013.23em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 13.232em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -2.247em; border-left: 0px solid; width: 0px; height: 3.941em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>BM25</mtext><mo stretchy="false">(</mo><mi>q</mi><mo>,</mo><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>∈</mo><mi>q</mi></mrow></munder><mtext>IDF</mtext><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>⋅</mo><mfrac><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mi>d</mi><mo stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><msub><mi>k</mi><mn>1</mn></msub><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mi>d</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mi>k</mi><mn>1</mn></msub><mo>⋅</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>−</mo><mi>b</mi><mo>+</mo><mi>b</mi><mo>⋅</mo><mfrac><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow><mtext>avgdl</mtext></mfrac></mrow><mo>)</mo></mrow></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-32">\text{BM25}(q, d) =
\sum_{t \in q}
\text{IDF}(t) \cdot
\frac{f(t,d) \cdot (k_1 + 1)}
{f(t,d) + k_1 \cdot \left(1 - b + b \cdot \frac{|d|}{\text{avgdl}}\right)}</script>

    <ul>
      <li>
        <p>where:</p>

        <ul>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-33-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-301" style="width: 2.971em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.451em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1002.4em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-302"><span class="mi" id="MathJax-Span-303" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.159em;"></span></span><span class="mo" id="MathJax-Span-304" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-305" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-306" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-307" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-308" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mi>t</mi><mo>,</mo><mi>d</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-33">f(t,d)</script> is the frequency of term <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-34-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-309" style="width: 0.315em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-310"><span class="mi" id="MathJax-Span-311" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math></span></span><script type="math/tex" id="MathJax-Element-34">t</script> in document <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-35-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-312" style="width: 0.732em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-313"><span class="mi" id="MathJax-Span-314" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></span></span><script type="math/tex" id="MathJax-Element-35">d</script>,</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-36-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-315" style="width: 1.253em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.044em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1000.94em, 2.607em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-316"><span class="mo" id="MathJax-Span-317" style="font-family: STIXGeneral-Regular;">∣</span><span class="mi" id="MathJax-Span-318" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-319" style="font-family: STIXGeneral-Regular;">∣</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">∣</mo><mi>d</mi><mo stretchy="false">∣</mo></math></span></span><script type="math/tex" id="MathJax-Element-36">\mid d \mid</script> is the document length,</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-37-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mtext&gt;avgdl&lt;/mtext&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-320" style="width: 2.711em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.242em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1002.24em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-321"><span class="mtext" id="MathJax-Span-322" style="font-family: STIXGeneral-Regular;">avgdl</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>avgdl</mtext></math></span></span><script type="math/tex" id="MathJax-Element-37">\text{avgdl}</script> is the average document length,</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-38-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-323" style="width: 1.096em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-324"><span class="msubsup" id="MathJax-Span-325"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-326" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mn" id="MathJax-Span-327" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>k</mi><mn>1</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-38">k_1</script> controls TF saturation (typically <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-39-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;1.2&lt;/mn&gt;&lt;mo&gt;&amp;#x2264;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2264;&lt;/mo&gt;&lt;mn&gt;2.0&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-328" style="width: 6.878em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.732em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1005.73em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-329"><span class="mn" id="MathJax-Span-330" style="font-family: STIXGeneral-Regular;">1.2</span><span class="mo" id="MathJax-Span-331" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">≤</span><span class="msubsup" id="MathJax-Span-332" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-333" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mn" id="MathJax-Span-334" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-335" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">≤</span><span class="mn" id="MathJax-Span-336" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">2.0</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1.2</mn><mo>≤</mo><msub><mi>k</mi><mn>1</mn></msub><mo>≤</mo><mn>2.0</mn></math></span></span><script type="math/tex" id="MathJax-Element-39">1.2 \le k_1 \le 2.0</script>),</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-40-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-337" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-338"><span class="mi" id="MathJax-Span-339" style="font-family: STIXGeneral-Italic;">b</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi></math></span></span><script type="math/tex" id="MathJax-Element-40">b</script> controls length normalization (typically <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-41-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo&gt;&amp;#x2248;&lt;/mo&gt;&lt;mn&gt;0.75&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-340" style="width: 4.169em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.44em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1003.39em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-341"><span class="mi" id="MathJax-Span-342" style="font-family: STIXGeneral-Italic;">b</span><span class="mo" id="MathJax-Span-343" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">≈</span><span class="mn" id="MathJax-Span-344" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.75</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi><mo>≈</mo><mn>0.75</mn></math></span></span><script type="math/tex" id="MathJax-Element-41">b \approx 0.75</script>).</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="why-bm25-outperforms-tf-idf">Why BM25 Outperforms TF-IDF</h5>

<ul>
  <li>
    <p>BM25 remains the default lexical ranking function in most production search engines. It outperforms TF-IDF along the following dimensions:</p>

    <ul>
      <li>Prevents term stuffing from dominating rankings.</li>
      <li>Fairly compares short and long documents.</li>
      <li>More stable across heterogeneous corpora.</li>
      <li>Empirically strong across many domains without tuning.</li>
    </ul>
  </li>
</ul>

<h5 id="operational-characteristics-of-lexical-retrieval">Operational Characteristics of Lexical Retrieval</h5>

<ul>
  <li>
    <p><strong>Performance and scalability</strong>:</p>

    <ul>
      <li>Sub-millisecond scoring per document.</li>
      <li>Efficient inverted index structures.</li>
      <li>Scales to billions of documents.</li>
    </ul>
  </li>
  <li>
    <p><strong>Determinism</strong>:</p>

    <ul>
      <li>Identical inputs always produce identical rankings.</li>
      <li>No stochastic components or model drift.</li>
    </ul>
  </li>
  <li>
    <p><strong>Explainability</strong>:</p>

    <ul>
      <li>Rankings can be justified via term overlap and weights.</li>
      <li>Essential for regulated or high-stakes systems.</li>
    </ul>
  </li>
</ul>

<h5 id="advantages-of-lexical-retrieval">Advantages of Lexical Retrieval</h5>

<ul>
  <li>Extremely fast and resource-efficient.</li>
  <li>Robust to rare, technical, or newly introduced terms.</li>
  <li>Guarantees recall for exact matches.</li>
  <li>Transparent scoring behavior.</li>
  <li>Works exceptionally well for:
    <ul>
      <li>Identifiers (product IDs, SKUs, error codes, etc.)</li>
      <li>Entity names (proper nouns, etc.)</li>
      <li>Dates (timestamps, ranges, etc.)</li>
      <li>Abbreviations (e.g., API, HTTP, JWT, etc.)</li>
      <li>Domain-specific jargon (e.g., medicine names, chemical compounds, etc.)</li>
      <li>Legal clauses (e.g., “Section 3.2.1”, etc.) and citations (e.g., “17 U.S.C. § 512”, etc.)</li>
      <li>Short or underspecified queries</li>
    </ul>
  </li>
</ul>

<h5 id="limitations-of-lexical-retrieval">Limitations of Lexical Retrieval</h5>

<ul>
  <li>Lexical retrieval limitations are structural, not implementation flaws, and they are the primary reason semantic and hybrid retrieval methods emerged:
    <ul>
      <li>No understanding of meaning or intent.</li>
      <li>Cannot match synonyms or paraphrases.</li>
      <li>Sensitive to vocabulary mismatch.</li>
      <li>Brittle for natural language questions.</li>
      <li>Poor recall for descriptive or conversational queries.</li>
    </ul>
  </li>
</ul>

<h4 id="semantic-retrieval">Semantic Retrieval</h4>

<ul>
  <li>
    <p>Semantic retrieval, also commonly referred to as dense retrieval, neural retrieval, or embedding-based retrieval, is a modern approach to information retrieval that attempts to model the meaning and intent behind queries and documents rather than relying on exact lexical overlap.</p>
  </li>
  <li>
    <p>Instead of treating text as discrete symbols, semantic retrieval represents text as continuous vectors in a high-dimensional space. Relevance is determined by geometric proximity in this space, under the assumption that semantically similar texts lie close to each other.</p>
  </li>
</ul>

<h5 id="core-idea">Core Idea</h5>

<ul>
  <li>
    <p>Semantic retrieval reframes search as a similarity problem in vector space:</p>

    <ul>
      <li>Queries and documents are encoded into dense vectors.</li>
      <li>Similarity between vectors approximates semantic relatedness.</li>
      <li>Retrieval becomes a nearest-neighbor search problem.</li>
    </ul>
  </li>
  <li>
    <p>A common similarity measure is cosine similarity:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-42-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;cosine_sim&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2192;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x22C5;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2192;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2192;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2223;&amp;#x2223;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2192;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-345" style="width: 13.128em; display: inline-block;"><span style="display: inline-block; position: relative; width: 10.94em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.315em, 1010.94em, 3.544em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-346"><span class="mtext" id="MathJax-Span-347" style="font-family: STIXGeneral-Regular;">cosine_sim</span><span class="mo" id="MathJax-Span-348" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-349" style="font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-350" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-351" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-352" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-353" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-354" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.867em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(2.815em, 1001.83em, 4.378em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.935em;"><span class="mrow" id="MathJax-Span-355"><span class="texatom" id="MathJax-Span-356"><span class="mrow" id="MathJax-Span-357"><span class="munderover" id="MathJax-Span-358"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-359" style="font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.008em; left: 0.055em;"><span style="height: 0em; vertical-align: 0em; width: 0.471em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-360" style="font-family: STIXGeneral-Regular;">⃗&nbsp;<span style="height: 0em; vertical-align: 0em; margin-left: -0.258em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span class="mo" id="MathJax-Span-361" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">⋅</span><span class="texatom" id="MathJax-Span-362" style="padding-left: 0.263em;"><span class="mrow" id="MathJax-Span-363"><span class="munderover" id="MathJax-Span-364"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-365" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.268em; left: 0.107em;"><span style="height: 0em; vertical-align: 0em; width: 0.471em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-366" style="font-family: STIXGeneral-Regular;">⃗&nbsp;<span style="height: 0em; vertical-align: 0em; margin-left: -0.258em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(2.815em, 1002.61em, 4.378em, -999.997em); top: -3.018em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-367"><span class="mo" id="MathJax-Span-368" style="font-family: STIXGeneral-Regular;">∣</span><span class="texatom" id="MathJax-Span-369"><span class="mrow" id="MathJax-Span-370"><span class="munderover" id="MathJax-Span-371"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-372" style="font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.008em; left: 0.055em;"><span style="height: 0em; vertical-align: 0em; width: 0.471em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-373" style="font-family: STIXGeneral-Regular;">⃗&nbsp;<span style="height: 0em; vertical-align: 0em; margin-left: -0.258em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span class="mo" id="MathJax-Span-374" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣<span style="font-family: STIXGeneral-Regular; font-style: normal; font-weight: normal;">∣</span></span><span class="texatom" id="MathJax-Span-375" style="padding-left: 0.315em;"><span class="mrow" id="MathJax-Span-376"><span class="munderover" id="MathJax-Span-377"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-378" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.268em; left: 0.107em;"><span style="height: 0em; vertical-align: 0em; width: 0.471em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-379" style="font-family: STIXGeneral-Regular;">⃗&nbsp;<span style="height: 0em; vertical-align: 0em; margin-left: -0.258em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span class="mo" id="MathJax-Span-380" style="font-family: STIXGeneral-Regular;">∣</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.87em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.867em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.497em; border-left: 0px solid; width: 0px; height: 3.628em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>cosine_sim</mtext><mo stretchy="false">(</mo><mi>q</mi><mo>,</mo><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mrow class="MJX-TeXAtom-ORD"><mover><mi>q</mi><mo stretchy="false">→</mo></mover></mrow><mo>⋅</mo><mrow class="MJX-TeXAtom-ORD"><mover><mi>d</mi><mo stretchy="false">→</mo></mover></mrow></mrow><mrow><mo stretchy="false">∣</mo><mrow class="MJX-TeXAtom-ORD"><mover><mi>q</mi><mo stretchy="false">→</mo></mover></mrow><mo>∣∣</mo><mrow class="MJX-TeXAtom-ORD"><mover><mi>d</mi><mo stretchy="false">→</mo></mover></mrow><mo stretchy="false">∣</mo></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-42">\text{cosine_sim}(q, d) =
\frac{\vec{q} \cdot \vec{d}}
{\mid\vec{q}\mid \mid\vec{d}\mid}</script>

    <ul>
      <li>
        <p>where:</p>

        <ul>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-43-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2192;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-381" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.201em, 1000.52em, 2.503em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-382"><span class="texatom" id="MathJax-Span-383"><span class="mrow" id="MathJax-Span-384"><span class="munderover" id="MathJax-Span-385"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-386" style="font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.008em; left: 0.055em;"><span style="height: 0em; vertical-align: 0em; width: 0.471em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-387" style="font-family: STIXGeneral-Regular;">⃗&nbsp;<span style="height: 0em; vertical-align: 0em; margin-left: -0.258em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.316em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mover><mi>q</mi><mo stretchy="false">→</mo></mover></mrow></math></span></span><script type="math/tex" id="MathJax-Element-43">\vec{q}</script> is the query embedding,</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-44-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mover&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2192;&lt;/mo&gt;&lt;/mover&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-388" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.94em, 1000.52em, 2.294em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-389"><span class="texatom" id="MathJax-Span-390"><span class="mrow" id="MathJax-Span-391"><span class="munderover" id="MathJax-Span-392"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-393" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.268em; left: 0.107em;"><span style="height: 0em; vertical-align: 0em; width: 0.471em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-394" style="font-family: STIXGeneral-Regular;">⃗&nbsp;<span style="height: 0em; vertical-align: 0em; margin-left: -0.258em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.378em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mover><mi>d</mi><mo stretchy="false">→</mo></mover></mrow></math></span></span><script type="math/tex" id="MathJax-Element-44">\vec{d}</script> is the document embedding.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="vector-encoding">Vector Encoding</h5>

<ul>
  <li><strong>Encoder models</strong>:
    <ul>
      <li>
        <p>Queries and documents are passed through neural encoders, typically based on transformer architectures. Common encoder types include:</p>

        <ul>
          <li>Dual encoders (bi-encoders)</li>
          <li><a href="http://sbert.net/">Sentence transformers</a></li>
          <li>Domain-specific fine-tuned encoders</li>
        </ul>
      </li>
      <li>
        <p>In most production systems, queries and documents are encoded independently to allow precomputation of document embeddings.</p>
      </li>
    </ul>
  </li>
  <li><strong>Training signal</strong>:
    <ul>
      <li>
        <p>Encoders are trained using contrastive objectives that:</p>

        <ul>
          <li>Pull relevant query–document pairs closer</li>
          <li>Push irrelevant pairs farther apart</li>
        </ul>
      </li>
      <li>
        <p>A simplified contrastive loss can be expressed as:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-45-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;L&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;exp&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;sim&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;exp&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;sim&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;munder&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msup&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mi&gt;exp&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;sim&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-395" style="width: 24.482em; display: inline-block;"><span style="display: inline-block; position: relative; width: 20.367em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.576em, 1020.37em, 3.388em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-396"><span class="texatom" id="MathJax-Span-397"><span class="mrow" id="MathJax-Span-398"><span class="mi" id="MathJax-Span-399" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-400" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mo" id="MathJax-Span-401" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">−</span><span class="mi" id="MathJax-Span-402" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">log</span><span class="mo" id="MathJax-Span-403"></span><span class="mfrac" id="MathJax-Span-404" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 15.992em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.128em, 1006.3em, 4.378em, -999.997em); top: -4.685em; left: 50%; margin-left: -3.174em;"><span class="mrow" id="MathJax-Span-405"><span class="mi" id="MathJax-Span-406" style="font-family: STIXGeneral-Regular;">exp</span><span class="mo" id="MathJax-Span-407"></span><span class="mo" id="MathJax-Span-408" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-409" style="font-family: STIXGeneral-Regular;">sim</span><span class="mo" id="MathJax-Span-410" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-411" style="font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-412" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-413" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-414" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.576em;"><span class="mo" id="MathJax-Span-415" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-416" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-417" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.076em, 1015.84em, 4.482em, -999.997em); top: -3.279em; left: 50%; margin-left: -7.966em;"><span class="mrow" id="MathJax-Span-418"><span class="mi" id="MathJax-Span-419" style="font-family: STIXGeneral-Regular;">exp</span><span class="mo" id="MathJax-Span-420"></span><span class="mo" id="MathJax-Span-421" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-422" style="font-family: STIXGeneral-Regular;">sim</span><span class="mo" id="MathJax-Span-423" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-424" style="font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-425" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-426" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-427" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.32em; left: 0.576em;"><span class="mo" id="MathJax-Span-428" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-429" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-430" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-431" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="munderover" id="MathJax-Span-432" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 1.826em; height: 0px;"><span style="position: absolute; clip: rect(3.076em, 1000.84em, 4.43em, -999.997em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-433" style="font-family: STIXGeneral-Regular; vertical-align: 0.003em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.695em; left: 0.94em;"><span class="texatom" id="MathJax-Span-434"><span class="mrow" id="MathJax-Span-435"><span class="msubsup" id="MathJax-Span-436"><span style="display: inline-block; position: relative; width: 0.836em; height: 0px;"><span style="position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-437" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.32em; left: 0.419em;"><span class="mo" id="MathJax-Span-438" style="font-size: 50%; font-family: STIXGeneral-Regular;">−</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mi" id="MathJax-Span-439" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">exp</span><span class="mo" id="MathJax-Span-440"></span><span class="mo" id="MathJax-Span-441" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-442" style="font-family: STIXGeneral-Regular;">sim</span><span class="mo" id="MathJax-Span-443" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-444" style="font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-445" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-446" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-447" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.32em; left: 0.576em;"><span class="mo" id="MathJax-Span-448" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-449" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-450" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1015.99em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 15.992em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.309em; border-left: 0px solid; width: 0px; height: 3.066em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">L</mi></mrow><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mtext>sim</mtext><mo stretchy="false">(</mo><mi>q</mi><mo>,</mo><msup><mi>d</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mtext>sim</mtext><mo stretchy="false">(</mo><mi>q</mi><mo>,</mo><msup><mi>d</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><munder><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><msup><mi>d</mi><mo>−</mo></msup></mrow></munder><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mtext>sim</mtext><mo stretchy="false">(</mo><mi>q</mi><mo>,</mo><msup><mi>d</mi><mo>−</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-45">\mathcal{L} = -\log\frac{\exp(\text{sim}(q, d^+))}{\exp(\text{sim}(q, d^+)) + \sum_{d^-} \exp(\text{sim}(q, d^-))}</script>

        <ul>
          <li>where <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-46-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-451" style="width: 1.409em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.253em, 1001.15em, 2.294em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-452"><span class="msubsup" id="MathJax-Span-453"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-454" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.576em;"><span class="mo" id="MathJax-Span-455" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.066em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>d</mi><mo>+</mo></msup></math></span></span><script type="math/tex" id="MathJax-Element-46">d^+</script> is a relevant document and <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-47-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-456" style="width: 1.409em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.253em, 1001.15em, 2.294em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-457"><span class="msubsup" id="MathJax-Span-458"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-459" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.576em;"><span class="mo" id="MathJax-Span-460" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.066em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>d</mi><mo>−</mo></msup></math></span></span><script type="math/tex" id="MathJax-Element-47">d^-</script> are negatives.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Representation properties</strong>:
    <ul>
      <li>
        <p>Good semantic embeddings capture:</p>

        <ul>
          <li>Synonymy and paraphrasing</li>
          <li>Conceptual similarity</li>
          <li>Contextual meaning</li>
          <li>Cross-lingual alignment (in multilingual models)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="semantic-matching-and-retrieval">Semantic Matching and Retrieval</h5>

<ul>
  <li>
    <p>Once embeddings are computed:</p>

    <ul>
      <li>Documents are indexed in a vector index.</li>
      <li>At query time, the query embedding is generated.</li>
      <li>Approximate nearest neighbor search retrieves the top <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-48-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-461" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-462"><span class="mi" id="MathJax-Span-463" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-48">K</script> closest document vectors.</li>
    </ul>
  </li>
  <li>
    <p>This enables matches even when there is zero keyword overlap between query and document.</p>
  </li>
</ul>

<h5 id="approaches">Approaches</h5>

<ul>
  <li>Let’s look at three different types of retrieval: standard, sentence window, and auto-merging. Each of these approaches has specific strengths and weaknesses, and their suitability depends on the requirements of the RAG task, including the nature of the dataset, the complexity of the queries, and the desired balance between specificity and contextual understanding in the responses.</li>
</ul>

<h6 id="standardnaive-approach">Standard/Naive Approach</h6>

<ul>
  <li>As we see in the image below <a href="https://learn.deeplearning.ai/building-evaluating-advanced-rag/lesson/2/advanced-rag-pipeline">(source)</a>, the standard pipeline uses the same text chunk for indexing/embedding as well as the output synthesis.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/9.png" alt=""></p>

<ul>
  <li>
    <p>In the context of RAG, the advantages and disadvantages of the three approaches are as follows:</p>
  </li>
  <li>
    <p><strong>Advantages</strong>:</p>

    <ul>
      <li><strong>Simplicity and Efficiency</strong>: This method is straightforward and efficient, using the same text chunk for both embedding and synthesis, simplifying the retrieval process.</li>
      <li><strong>Uniformity in Data Handling</strong>: It maintains consistency in the data used across both retrieval and synthesis phases.</li>
    </ul>
  </li>
  <li>
    <p><strong>Disadvantages</strong>:</p>

    <ul>
      <li><strong>Limited Contextual Understanding</strong>: LLMs may require a larger window for synthesis to generate better responses, which this approach may not adequately provide.</li>
      <li><strong>Potential for Suboptimal Responses</strong>: Due to the limited context, the LLM might not have enough information to generate the most relevant and accurate responses.</li>
    </ul>
  </li>
</ul>

<h6 id="sentence-window-retrieval--small-to-large-retrieval">Sentence-Window Retrieval / Small-to-Large Retrieval</h6>
<ul>
  <li>The sentence-window approach breaks down documents into smaller units, such as sentences or small groups of sentences.</li>
  <li>It decouples the embeddings for retrieval tasks (which are smaller chunks stored in a Vector DB), but for synthesis it adds back in the context around the retrieved chunks, as seen in the image below <a href="https://learn.deeplearning.ai/building-evaluating-advanced-rag/lesson/2/advanced-rag-pipeline">(source)</a>.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/10.png" alt=""></p>

<ul>
  <li>During retrieval, we retrieve the sentences that are most relevant to the query via similarity search and replace the sentence with the full surrounding context (using a static sentence-window around the context, implemented by retrieving sentences surrounding the one being originally retrieved) as shown in the figure below <a href="https://learn.deeplearning.ai/building-evaluating-advanced-rag/lesson/2/advanced-rag-pipeline">(source)</a>.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/11.png" alt=""></p>

<ul>
  <li>
    <p><strong>Advantages</strong>:</p>

    <ul>
      <li><strong>Enhanced Specificity in Retrieval</strong>: By breaking documents into smaller units, it enables more precise retrieval of segments directly relevant to a query.</li>
      <li><strong>Context-Rich Synthesis</strong>: It reintroduces context around the retrieved chunks for synthesis, providing the LLM with a broader understanding to formulate responses.</li>
      <li><strong>Balanced Approach</strong>: This method strikes a balance between focused retrieval and contextual richness, potentially improving response quality.</li>
    </ul>
  </li>
  <li>
    <p><strong>Disadvantages</strong>:</p>

    <ul>
      <li><strong>Increased Complexity</strong>: Managing separate processes for retrieval and synthesis adds complexity to the pipeline.</li>
      <li><strong>Potential Contextual Gaps</strong>: There’s a risk of missing broader context if the surrounding information added back is not sufficiently comprehensive.</li>
    </ul>
  </li>
</ul>

<h6 id="auto-merging-retriever--hierarchical-retriever">Auto-merging Retriever / Hierarchical Retriever</h6>

<ul>
  <li>The image below <a href="https://learn.deeplearning.ai/building-evaluating-advanced-rag/lesson/2/advanced-rag-pipeline">(source)</a>, illustrates how auto-merging retrieval can work where it doesn’t retrieve a bunch of fragmented chunks as would happen with the naive approach.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/6.png" alt=""></p>

<ul>
  <li>The fragmentation in the naive approach would be worse with smaller chunk sizes as shown below <a href="https://learn.deeplearning.ai/building-evaluating-advanced-rag/lesson/2/advanced-rag-pipeline">(source)</a>.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/12.png" alt=""></p>

<ul>
  <li>Auto-merging retrieval aims to combine (or merge) information from multiple sources or segments of text to create a more comprehensive and contextually relevant response to a query. This approach is particularly useful when no single document or segment fully answers the query but rather the answer lies in combining information from multiple sources.</li>
  <li>It allows smaller chunks to be merged into bigger parent chunks. It does this via the following steps:
    <ol>
      <li>Define a hierarchy of smaller chunks linked to parent chunks.</li>
      <li>If the set of smaller chunks linking to a parent chunk exceeds some threshold (say, cosine similarity), then “merge” smaller chunks into the bigger parent chunk.</li>
    </ol>
  </li>
  <li>
    <p>The method will finally retrieve the parent chunk for better context.</p>
  </li>
  <li>
    <p><strong>Advantages</strong>:</p>

    <ul>
      <li><strong>Comprehensive Contextual Responses</strong>: By merging information from multiple sources, it creates responses that are more comprehensive and contextually relevant.</li>
      <li><strong>Reduced Fragmentation</strong>: This approach addresses the issue of fragmented information retrieval, common in the naive approach, especially with smaller chunk sizes.</li>
      <li><strong>Dynamic Content Integration</strong>: It dynamically combines smaller chunks into larger, more informative ones, enhancing the richness of the information provided to the LLM.</li>
    </ul>
  </li>
  <li>
    <p><strong>Disadvantages</strong>:</p>

    <ul>
      <li><strong>Complexity in Hierarchy and Threshold Management</strong>: The process of defining hierarchies and setting appropriate thresholds for merging is complex and critical for effective functioning.</li>
      <li><strong>Risk of Over-generalization</strong>: There’s a possibility of merging too much or irrelevant information, leading to responses that are too broad or off-topic.</li>
      <li><strong>Computational Intensity</strong>: This method might be more computationally intensive due to the additional steps in merging and managing the hierarchical structure of text chunks.</li>
    </ul>
  </li>
</ul>

<h6 id="contextual-retrieval">Contextual Retrieval</h6>

<ul>
  <li>For LLMs to deliver relevant and accurate responses, they must retrieve the right information from a knowledge base. Traditional RAG improves model accuracy by fetching relevant text chunks and appending them to the prompt. However, such methods often remove crucial context when encoding information, leading to failed retrievals and suboptimal outputs.</li>
  <li>Contextual Retrieval, introduced by <a href="https://www.anthropic.com/news/contextual-retrieval">Anthropic</a>, is an advanced technique designed to improve this process by ensuring that retrieved chunks maintain their original context. It employs contextual embeddings – embeddings that incorporate chunk-specific background information and contextual BM25 – an enhanced BM25 ranking that considers the broader document context.</li>
  <li>
    <p>By prepending contextual metadata to each document chunk before embedding, Contextual Retrieval significantly enhances search accuracy. This approach reduces failed retrievals by 49% and, when combined with re-ranking, by 67%.</p>
  </li>
  <li><strong>Why Context Matters in Retrieval</strong>:
    <ul>
      <li>Traditional RAG solutions divide documents into small chunks for efficient retrieval. However, these fragments often lose critical context. For example, the statement “The company’s revenue grew by 3% over the previous quarter” lacks information about which company or quarter it refers to. Contextual Retrieval solves this by embedding relevant metadata into each chunk.</li>
    </ul>
  </li>
  <li><strong>Implementation of Contextual Retrieval</strong>:
    <ul>
      <li>To implement Contextual Retrieval, a model like Claude 3 Haiku can generate concise context for each chunk. This context is then prepended before embedding and indexing, ensuring more precise retrieval. Developers can automate this process at scale using specialized retrieval pipelines.</li>
    </ul>
  </li>
  <li><strong>Prompt Used for Contextual Retrieval</strong>:
    <ul>
      <li>Anthropic’s method involves using Claude to generate a short, document-specific context for each chunk using the following prompt:
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code6"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code6">  &lt;document&gt;  
          
  &lt;/document&gt;  

  Here is the chunk we want to situate within the whole document:  

  &lt;chunk&gt;  
          
  &lt;/chunk&gt;  

  Please give a short, succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else.
</code></pre></div>        </div>
      </li>
      <li>This process automatically generates a concise contextualized description that is prepended to the chunk before embedding and indexing.</li>
    </ul>
  </li>
  <li><strong>Combining Contextual Retrieval with Re-ranking</strong>:
    <ul>
      <li>For maximum performance, Contextual Retrieval can be paired with re-ranking models, which filter and reorder retrieved chunks based on their relevance. This additional step enhances retrieval precision, ensuring only the most relevant chunks are passed to the LLM.</li>
    </ul>
  </li>
  <li>The following flowchart from Anthropic’s <a href="https://www.anthropic.com/news/contextual-retrieval">blog</a> shows the combined contextual retrieval and re-ranking stages which seek to maximize retrieval accuracy.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/contextual-retrieval.jpg" alt=""></p>

<ul>
  <li><strong>Key Takeaways</strong>:
    <ul>
      <li>Contextual Embeddings improve retrieval accuracy by preserving document meaning.</li>
      <li>BM25 + Contextualization enhances exact-match retrieval.</li>
      <li>Combining Contextual Retrieval with re-ranking further boosts retrieval effectiveness.</li>
      <li>Developers can implement Contextual Retrieval using prompt-based preprocessing and automated pipelines.</li>
    </ul>
  </li>
  <li>With Contextual Retrieval, LLM-powered knowledge systems can achieve greater accuracy, scalability, and relevance, unlocking new levels of performance in real-world applications.</li>
</ul>

<h5 id="using-approximate-nearest-neighbors-ann-for-retrieval">Using Approximate Nearest Neighbors (ANN) for Retrieval</h5>

<ul>
  <li>
    <p>The next step is to consider which Approximate Nearest Neighbors (ANN) algorithm and library to choose for <strong>large-scale vector similarity search in retrieval systems</strong>. ANN is preferred over exact nearest neighbor search because:</p>

    <ul>
      <li>Exact search scales linearly with corpus size and becomes prohibitively slow and expensive for large embedding collections.</li>
      <li>ANN trades a small, controllable loss in recall for orders-of-magnitude improvements in latency and throughput.</li>
      <li>Modern ANN methods are designed to meet strict production constraints (low latency, bounded memory, high QPS), which are critical for real-time RAG pipelines.</li>
    </ul>
  </li>
  <li>A useful way to compare and select an appropriate ANN approach is to reference <strong><a href="https://ann-benchmarks.com/">ANN-Benchmarks</a></strong>, which provides standardized evaluations of different algorithms across accuracy, latency, and resource trade-offs.</li>
  <li>A detailed discourse on the concept of ANN can be found in our <a href="../ann-similarity-search">ANN primer</a>.</li>
</ul>

<h5 id="advantages-of-semantic-retrieval">Advantages of Semantic Retrieval</h5>

<ul>
  <li>Strong handling of paraphrases and synonyms.</li>
  <li>Robust to vocabulary mismatch.</li>
  <li>Supports natural language and conversational queries.</li>
  <li>Effective for long, descriptive queries.</li>
  <li>Often works across languages without explicit translation.</li>
  <li>Recovers relevant content missed by lexical methods.</li>
</ul>

<h5 id="challenges">Challenges</h5>

<ul>
  <li>
    <p><strong>Computational cost</strong>:</p>

    <ul>
      <li>Embedding generation is expensive relative to lexical scoring.</li>
      <li>Nearest neighbor search is more complex than inverted index lookup.</li>
    </ul>
  </li>
  <li>
    <p><strong>Approximation trade-offs</strong>:</p>

    <ul>
      <li>Vector search typically uses approximate algorithms.</li>
      <li>Recall may be sacrificed for latency at scale.</li>
    </ul>
  </li>
  <li>
    <p><strong>Model dependence</strong>:</p>

    <ul>
      <li>Retrieval quality depends heavily on training data.</li>
      <li>Domain mismatch can degrade performance.</li>
      <li>Biases in training data propagate into retrieval results.</li>
    </ul>
  </li>
  <li>
    <p><strong>Maintenance complexity</strong>:</p>

    <ul>
      <li>Document embeddings must be recomputed when:
        <ul>
          <li>The corpus changes significantly</li>
          <li>The model is updated</li>
        </ul>
      </li>
      <li>Versioning embeddings and models adds operational overhead.</li>
    </ul>
  </li>
  <li>
    <p><strong>Precision issues</strong>:</p>

    <ul>
      <li>Semantic similarity can over-generalize.</li>
      <li>Exact constraints, identifiers, or negations may be missed.</li>
      <li>Rare or newly introduced terms may not be well represented.</li>
    </ul>
  </li>
</ul>

<h5 id="use-cases-where-semantic-retrieval-excels">Use-cases Where Semantic Retrieval Excels</h5>

<ul>
  <li>Exploratory or research-oriented search.</li>
  <li>Natural language question answering.</li>
  <li>Knowledge discovery and recall-heavy tasks.</li>
  <li>User-facing search with ambiguous or verbose queries.</li>
</ul>

<h5 id="use-cases-where-semantic-retrieval-struggles">Use-cases Where Semantic Retrieval Struggles</h5>

<ul>
  <li>
    <p>These strengths and weaknesses are complementary to lexical retrieval, which is why semantic retrieval is rarely deployed alone in high-reliability systems. Specifically the areas where semantic search struggles are as follows:</p>

    <ul>
      <li>Queries dominated by symbols, codes, or IDs.</li>
      <li>Legal, medical, or compliance-sensitive text requiring exact wording.</li>
      <li>Short, underspecified queries with little context.</li>
      <li>Scenarios demanding deterministic, explainable rankings.</li>
    </ul>
  </li>
</ul>

<h4 id="hybrid-retrieval-lexical--semantic">Hybrid Retrieval (Lexical + Semantic)</h4>

<ul>
  <li>
    <p>Hybrid retrieval combines lexical (sparse) and semantic (dense) retrieval to leverage the complementary strengths of both approaches. The core motivation is simple: real-world queries simultaneously contain exact terms that must be respected and implicit intent that must be inferred.</p>
  </li>
  <li>
    <p>A hybrid retrieval system combines the strengths of lexical and semantic methods to deliver more accurate and robust results by reducing the likelihood that either system’s blind spots dominate the final ranking.</p>
  </li>
  <li>
    <p>Hybrid systems are designed to minimize worst-case failure modes by ensuring that neither exact matching nor semantic understanding is relied on exclusively.</p>
  </li>
</ul>

<h5 id="why-hybrid-retrieval-is-necessary">Why Hybrid Retrieval is Necessary</h5>

<ul>
  <li>
    <p>Lexical and semantic retrieval fail in opposite ways:</p>

    <ul>
      <li>Lexical retrieval fails when vocabulary mismatch occurs.</li>
      <li>Semantic retrieval fails when exact wording, identifiers, or constraints matter.</li>
    </ul>
  </li>
  <li>
    <p>Hybrid retrieval exists to ensure:</p>

    <ul>
      <li>Exact matches are never lost.</li>
      <li>Semantic relevance is still captured.</li>
      <li>Recall and precision remain stable across query types.</li>
    </ul>
  </li>
  <li>
    <p>In practice, hybrid retrieval is not a single algorithm but a family of architectures.</p>
  </li>
</ul>

<h5 id="common-hybrid-retrieval-architectures">Common Hybrid Retrieval Architectures</h5>

<ul>
  <li>
    <p><strong>Two-stage hybrid retrieval</strong>: Lexical retrieval is used first to generate a high-recall candidate set, which is then reranked by a semantic model. This design prioritizes efficiency and recall safety while allowing deep semantic reasoning to operate only where it matters.</p>
  </li>
  <li>
    <p><strong>Parallel hybrid retrieval with fusion</strong>: Lexical and semantic retrievers run independently over the corpus, and their results are merged using score-based or rank-based fusion methods. This approach treats lexical and semantic signals as peers rather than stages in a pipeline.</p>
  </li>
  <li>
    <p><strong>Native hybrid scoring</strong>: Some systems integrate sparse and dense signals directly into a single retrieval model or query interface, blending term-based and embedding-based evidence during initial retrieval rather than combining results afterward.</p>
  </li>
</ul>

<h6 id="the-dominant-production-architecture-lexical-retrieval--semantic-re-ranking">The Dominant Production Architecture: Lexical Retrieval + Semantic Re-ranking</h6>

<ul>
  <li>
    <p>The most common hybrid architecture is a two-stage pipeline:</p>

    <ol>
      <li><strong>Candidate generation (lexical)</strong>:
        <ul>
          <li>
            <p>A lexical retriever (typically BM25) retrieves the top <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-49-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-464" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-465"><span class="mi" id="MathJax-Span-466" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-49">K</script> candidates based on exact term overlap.</p>
          </li>
          <li>
            <p>Typical values:</p>
            <ul>
              <li>
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-50-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mn&gt;100&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1000&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-467" style="width: 7.971em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.617em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1006.51em, 2.555em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-468"><span class="mi" id="MathJax-Span-469" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-470" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∈</span><span class="mo" id="MathJax-Span-471" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">[</span><span class="mn" id="MathJax-Span-472" style="font-family: STIXGeneral-Regular;">100</span><span class="mo" id="MathJax-Span-473" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-474" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">1000</span><span class="mo" id="MathJax-Span-475" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>K</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>100</mn><mo>,</mo><mn>1000</mn><mo stretchy="false">]</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-50">K \in [100, 1000]</script>
              </li>
              <li>Chosen to maximize recall while keeping downstream cost manageable</li>
            </ul>
          </li>
        </ul>
      </li>
      <li><strong>Semantic re-ranking (dense or cross-encoder)</strong>:
        <ul>
          <li>Semantic re-ranking models aim to improve the ordering of retrieved documents by more accurately modeling relevance between a query and a small candidate set.</li>
          <li>In practice, these models are used after an initial retrieval step and can be grouped both by how they encode query–document interactions and by the type of signals they incorporate (semantic, instructional, or metadata-driven).</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>
    <p>Conceptually:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-51-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Results&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mtext&gt;Rerank&lt;/mtext&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;semantic&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo maxsize=&quot;1.2em&quot; minsize=&quot;1.2em&quot;&gt;(&lt;/mo&gt;&lt;/mrow&gt;&lt;mtext&gt;BM25&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;Docs&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo maxsize=&quot;1.2em&quot; minsize=&quot;1.2em&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-476" style="width: 19.169em; display: inline-block;"><span style="display: inline-block; position: relative; width: 15.94em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(2.086em, 1015.78em, 3.753em, -999.997em); top: -3.174em; left: 0em;"><span class="mrow" id="MathJax-Span-477"><span class="mtext" id="MathJax-Span-478" style="font-family: STIXGeneral-Regular;">Results</span><span class="mo" id="MathJax-Span-479" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="msubsup" id="MathJax-Span-480" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 5.471em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1002.92em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mtext" id="MathJax-Span-481" style="font-family: STIXGeneral-Regular;">Rerank</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 2.867em;"><span class="texatom" id="MathJax-Span-482"><span class="mrow" id="MathJax-Span-483"><span class="mtext" id="MathJax-Span-484" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">semantic</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="texatom" id="MathJax-Span-485"><span class="mrow" id="MathJax-Span-486"><span class="mo" id="MathJax-Span-487" style="vertical-align: -0.258em;"><span><span style="font-size: 110%; font-family: STIXSizeOneSym;">(</span></span></span></span></span><span class="mtext" id="MathJax-Span-488" style="font-family: STIXGeneral-Regular;">BM25</span><span class="mo" id="MathJax-Span-489" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-490" style="font-family: STIXGeneral-Regular;">Docs</span><span class="mo" id="MathJax-Span-491" style="font-family: STIXGeneral-Regular;">)</span><span class="texatom" id="MathJax-Span-492"><span class="mrow" id="MathJax-Span-493"><span class="mo" id="MathJax-Span-494" style="vertical-align: -0.258em;"><span><span style="font-size: 110%; font-family: STIXSizeOneSym;">)</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.18em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.559em; border-left: 0px solid; width: 0px; height: 1.753em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Results</mtext><mo>=</mo><msub><mtext>Rerank</mtext><mrow class="MJX-TeXAtom-ORD"><mtext>semantic</mtext></mrow></msub><mrow class="MJX-TeXAtom-ORD"><mo maxsize="1.2em" minsize="1.2em">(</mo></mrow><mtext>BM25</mtext><mo stretchy="false">(</mo><mtext>Docs</mtext><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mo maxsize="1.2em" minsize="1.2em">)</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-51">\text{Results} =
\text{Rerank}_{\text{semantic}}
\big(
\text{BM25}(\text{Docs})
\big)</script>
  </li>
  <li>
    <p>This approach dominates because of its efficiency, recall-safety, easy of explainability, and compatibility with existing search infrastructure.</p>
  </li>
</ul>

<h5 id="parallel-hybrid-retrieval-and-score-fusion">Parallel Hybrid Retrieval and Score Fusion</h5>

<ul>
  <li>An alternative approach runs lexical and semantic retrieval independently, then fuses their rankings. This approach is common when re-ranking is too expensive or when vector databases expose native hybrid querying.</li>
</ul>

<h6 id="linear-score-fusion">Linear Score Fusion</h6>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-52-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;score&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;&amp;#x03B1;&lt;/mi&gt;&lt;mo&gt;&amp;#x22C5;&lt;/mo&gt;&lt;mtext&gt;BM25&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mi&gt;&amp;#x03B1;&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&amp;#x22C5;&lt;/mo&gt;&lt;msub&gt;&lt;mtext&gt;sim&lt;/mtext&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;semantic&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-495" style="width: 24.065em; display: inline-block;"><span style="display: inline-block; position: relative; width: 20.055em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1020em, 2.555em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-496"><span class="mtext" id="MathJax-Span-497" style="font-family: STIXGeneral-Regular;">score</span><span class="mo" id="MathJax-Span-498" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-499" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-500" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-501" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mi" id="MathJax-Span-502" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">α</span><span class="mo" id="MathJax-Span-503" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">⋅</span><span class="mtext" id="MathJax-Span-504" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">BM25</span><span class="mo" id="MathJax-Span-505" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-506" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-507" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-508" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mo" id="MathJax-Span-509" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">(</span><span class="mn" id="MathJax-Span-510" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-511" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">−</span><span class="mi" id="MathJax-Span-512" style="font-family: STIXGeneral-Italic; padding-left: 0.263em;">α</span><span class="mo" id="MathJax-Span-513" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-514" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">⋅</span><span class="msubsup" id="MathJax-Span-515" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 4.013em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1001.46em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mtext" id="MathJax-Span-516" style="font-family: STIXGeneral-Regular;">sim</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 1.461em;"><span class="texatom" id="MathJax-Span-517"><span class="mrow" id="MathJax-Span-518"><span class="mtext" id="MathJax-Span-519" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">semantic</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-520" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-521" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-522" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>score</mtext><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><mi>α</mi><mo>⋅</mo><mtext>BM25</mtext><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo><mo>⋅</mo><msub><mtext>sim</mtext><mrow class="MJX-TeXAtom-ORD"><mtext>semantic</mtext></mrow></msub><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-52">\text{score}(d) = \alpha \cdot \text{BM25}(d) + (1 - \alpha) \cdot \text{sim}_{\text{semantic}}(d)</script>

<ul>
  <li>
    <p>Challenges:</p>

    <ul>
      <li>Scores must be normalized</li>
      <li>Sensitive to scaling differences</li>
      <li>Requires tuning <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-53-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;&amp;#x03B1;&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-523" style="width: 0.784em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-524"><span class="mi" id="MathJax-Span-525" style="font-family: STIXGeneral-Italic;">α</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>α</mi></math></span></span><script type="math/tex" id="MathJax-Element-53">\alpha</script></li>
    </ul>
  </li>
</ul>

<h6 id="reciprocal-rank-fusion-rrf">Reciprocal Rank Fusion (RRF)</h6>

<ul>
  <li>
    <p>One of the most popular and robust fusion techniques used in hybrid retrieval is Reciprocal Rank Fusion (RRF). RRF merges the rankings from different retrieval models (for example, BM25 and a neural retriever) by assigning higher scores to documents that consistently rank well across systems, rather than relying on raw scores.</p>
  </li>
  <li>
    <p>RRF operates purely on rank positions, making it insensitive to score scale (i.e., it lacks the need for normalization unlike linear score fusion), distribution, or calibration differences between retrieval methods.</p>
  </li>
  <li>
    <p><strong>How RRF works:</strong></p>

    <ul>
      <li>Each retrieval system independently produces a ranked list of documents.</li>
      <li>Each document receives a contribution based on its rank position in each list.</li>
      <li>
        <p>Contributions are summed to produce a final fusion score.</p>
      </li>
      <li>
        <p>The RRF scoring function is:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-54-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;RRF Score&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mtext&gt;rank&lt;/mtext&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-526" style="width: 16.357em; display: inline-block;"><span style="display: inline-block; position: relative; width: 13.596em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.419em, 1013.6em, 3.596em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-527"><span class="mtext" id="MathJax-Span-528" style="font-family: STIXGeneral-Regular;">RRF Score</span><span class="mo" id="MathJax-Span-529" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-530" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-531" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-532" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="munderover" id="MathJax-Span-533" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px;"><span style="position: absolute; clip: rect(2.867em, 1001.2em, 4.638em, -999.997em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-534" style="font-family: STIXSizeOneSym; vertical-align: -0.518em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1000.94em, 4.273em, -999.997em); top: -2.862em; left: 0.107em;"><span class="texatom" id="MathJax-Span-535"><span class="mrow" id="MathJax-Span-536"><span class="mi" id="MathJax-Span-537" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-538" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">=</span><span class="mn" id="MathJax-Span-539" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.44em, 1000.32em, 4.169em, -999.997em); top: -5.206em; left: 0.471em;"><span class="texatom" id="MathJax-Span-540"><span class="mrow" id="MathJax-Span-541"><span class="mi" id="MathJax-Span-542" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mfrac" id="MathJax-Span-543" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 5.055em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-544" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1004.85em, 4.326em, -999.997em); top: -3.331em; left: 50%; margin-left: -2.445em;"><span class="mrow" id="MathJax-Span-545"><span class="mi" id="MathJax-Span-546" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-547" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="msubsup" id="MathJax-Span-548" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 2.034em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1001.77em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mtext" id="MathJax-Span-549" style="font-family: STIXGeneral-Regular;">rank</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 1.773em;"><span class="mi" id="MathJax-Span-550" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-551" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-552" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-553" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1005.05em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 5.055em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.559em; border-left: 0px solid; width: 0px; height: 3.566em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>RRF Score</mtext><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>n</mi></mrow></munderover><mfrac><mn>1</mn><mrow><mi>k</mi><mo>+</mo><msub><mtext>rank</mtext><mi>i</mi></msub><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-54">\text{RRF Score}(d) =
\sum_{i=1}^{n}
\frac{1}{k + \text{rank}_i(d)}</script>

        <ul>
          <li>
            <p>where:</p>

            <ul>
              <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-55-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-554" style="width: 0.732em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-555"><span class="mi" id="MathJax-Span-556" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></span></span><script type="math/tex" id="MathJax-Element-55">d</script> is the document,</li>
              <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-56-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mtext&gt;rank&lt;/mtext&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-557" style="width: 3.961em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.284em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1003.23em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-558"><span class="msubsup" id="MathJax-Span-559"><span style="display: inline-block; position: relative; width: 2.034em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1001.77em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mtext" id="MathJax-Span-560" style="font-family: STIXGeneral-Regular;">rank</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 1.773em;"><span class="mi" id="MathJax-Span-561" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-562" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-563" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-564" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mtext>rank</mtext><mi>i</mi></msub><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-56">\text{rank}_i(d)</script> is the rank position of document <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-57-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-565" style="width: 0.732em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-566"><span class="mi" id="MathJax-Span-567" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi></math></span></span><script type="math/tex" id="MathJax-Element-57">d</script> in the <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-58-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;th&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-568" style="width: 1.096em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.148em, 1000.89em, 2.294em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-569"><span class="msubsup" id="MathJax-Span-570"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.26em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-571" style="font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.263em;"><span class="texatom" id="MathJax-Span-572"><span class="mrow" id="MathJax-Span-573"><span class="mtext" id="MathJax-Span-574" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">th</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>i</mi><mrow class="MJX-TeXAtom-ORD"><mtext>th</mtext></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-58">i^{\text{th}}</script> ranked list,</li>
              <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-59-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-575" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-576"><span class="mi" id="MathJax-Span-577" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-59">k</script> is a smoothing constant (typically set to 60),</li>
              <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-60-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-578" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-579"><span class="mi" id="MathJax-Span-580" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-60">n</script> is the number of retrieval systems.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>The constant <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-61-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-581" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-582"><span class="mi" id="MathJax-Span-583" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-61">k</script> ensures that:</p>

        <ul>
          <li>Top-ranked documents dominate the contribution</li>
          <li>Differences among lower-ranked documents are compressed</li>
          <li>Noise from deep rankings does not overwhelm the fusion</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Intuition behind RRF:</strong></p>

    <ul>
      <li>The intuition behind RRF being especially well suited for hybrid lexical–semantic retrieval is as follows:
        <ul>
          <li>Documents that appear near the top in multiple rankings are strongly favored.</li>
          <li>A document that ranks moderately well in several systems often beats one that ranks extremely well in only one.</li>
          <li>Systems with very different scoring behavior can still be combined reliably.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Example:</strong></p>

    <ul>
      <li>
        <p>Suppose two retrieval systems return the following output results for a query:</p>

        <ul>
          <li>BM25: <code class="language-plaintext highlighter-rouge">[DocA, DocB, DocC, DocD, DocE]</code></li>
          <li>Neural Retriever: <code class="language-plaintext highlighter-rouge">[DocF, DocC, DocA, DocG, DocB]</code></li>
        </ul>
      </li>
      <li>We use <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-62-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;60&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-584" style="width: 3.284em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.711em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1002.71em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-585"><span class="mi" id="MathJax-Span-586" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-587" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-588" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">60</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>=</mo><mn>60</mn></math></span></span><script type="math/tex" id="MathJax-Element-62">k = 60</script>.</li>
      <li>
        <p>Note that if a document does not appear at a output of a retriever, it contributes <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-63-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-589" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-590"><span class="mn" id="MathJax-Span-591" style="font-family: STIXGeneral-Regular;">0</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>0</mn></math></span></span><script type="math/tex" id="MathJax-Element-63">0</script> from that list.</p>
      </li>
      <li>
        <p>RRF scores are computed as follows:</p>

        <ul>
          <li>
            <p><strong>DocA</strong> (Rank 1 in BM25, rank 3 in Neural Retriever):</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-64-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;RRF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;DocA&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;60&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;60&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;61&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;63&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;&amp;#x2248;&lt;/mo&gt;&lt;mn&gt;0.01639&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;0.01587&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.03226&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-592" style="width: 37.815em; display: inline-block;"><span style="display: inline-block; position: relative; width: 31.513em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1031.46em, 3.076em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-593"><span class="mtext" id="MathJax-Span-594" style="font-family: STIXGeneral-Regular;">RRF</span><span class="mo" id="MathJax-Span-595" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-596" style="font-family: STIXGeneral-Regular;">DocA</span><span class="mo" id="MathJax-Span-597" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-598" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-599" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.815em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-600" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1002.61em, 4.221em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-601"><span class="mn" id="MathJax-Span-602" style="font-family: STIXGeneral-Regular;">60</span><span class="mo" id="MathJax-Span-603" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-604" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">1</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.82em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.815em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-605" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mfrac" id="MathJax-Span-606" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 2.815em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-607" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1002.66em, 4.221em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-608"><span class="mn" id="MathJax-Span-609" style="font-family: STIXGeneral-Regular;">60</span><span class="mo" id="MathJax-Span-610" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-611" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">3</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.82em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.815em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-612" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-613" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-614" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.518em;"><span class="mn" id="MathJax-Span-615" style="font-family: STIXGeneral-Regular;">61</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-616" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mfrac" id="MathJax-Span-617" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-618" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.94em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.518em;"><span class="mn" id="MathJax-Span-619" style="font-family: STIXGeneral-Regular;">63</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-620" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">≈</span><span class="mn" id="MathJax-Span-621" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.01639</span><span class="mo" id="MathJax-Span-622" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-623" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">0.01587</span><span class="mo" id="MathJax-Span-624" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-625" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.03226</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.934em; border-left: 0px solid; width: 0px; height: 2.628em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>RRF</mtext><mo stretchy="false">(</mo><mtext>DocA</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>60</mn><mo>+</mo><mn>1</mn></mrow></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mn>60</mn><mo>+</mo><mn>3</mn></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>61</mn></mfrac><mo>+</mo><mfrac><mn>1</mn><mn>63</mn></mfrac><mo>≈</mo><mn>0.01639</mn><mo>+</mo><mn>0.01587</mn><mo>=</mo><mn>0.03226</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-64">\text{RRF}(\text{DocA})
= \frac{1}{60 + 1} + \frac{1}{60 + 3}
= \frac{1}{61} + \frac{1}{63}
\approx 0.01639 + 0.01587
= 0.03226</script>
          </li>
          <li>
            <p><strong>DocB</strong> (Rank 2 in BM25, rank 5 in Neural Retriever):</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-65-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;RRF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;DocB&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;60&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;60&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;62&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;65&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;&amp;#x2248;&lt;/mo&gt;&lt;mn&gt;0.01613&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;0.01538&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.03151&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-626" style="width: 37.763em; display: inline-block;"><span style="display: inline-block; position: relative; width: 31.461em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1031.36em, 3.076em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-627"><span class="mtext" id="MathJax-Span-628" style="font-family: STIXGeneral-Regular;">RRF</span><span class="mo" id="MathJax-Span-629" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-630" style="font-family: STIXGeneral-Regular;">DocB</span><span class="mo" id="MathJax-Span-631" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-632" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-633" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.815em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-634" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1002.71em, 4.221em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-635"><span class="mn" id="MathJax-Span-636" style="font-family: STIXGeneral-Regular;">60</span><span class="mo" id="MathJax-Span-637" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-638" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">2</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.82em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.815em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-639" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mfrac" id="MathJax-Span-640" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 2.815em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-641" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1002.66em, 4.221em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-642"><span class="mn" id="MathJax-Span-643" style="font-family: STIXGeneral-Regular;">60</span><span class="mo" id="MathJax-Span-644" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-645" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">5</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.82em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.815em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-646" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-647" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-648" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.99em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.518em;"><span class="mn" id="MathJax-Span-649" style="font-family: STIXGeneral-Regular;">62</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-650" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mfrac" id="MathJax-Span-651" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-652" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.94em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.518em;"><span class="mn" id="MathJax-Span-653" style="font-family: STIXGeneral-Regular;">65</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-654" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">≈</span><span class="mn" id="MathJax-Span-655" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.01613</span><span class="mo" id="MathJax-Span-656" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-657" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">0.01538</span><span class="mo" id="MathJax-Span-658" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-659" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.03151</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.934em; border-left: 0px solid; width: 0px; height: 2.628em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>RRF</mtext><mo stretchy="false">(</mo><mtext>DocB</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>60</mn><mo>+</mo><mn>2</mn></mrow></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mn>60</mn><mo>+</mo><mn>5</mn></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>62</mn></mfrac><mo>+</mo><mfrac><mn>1</mn><mn>65</mn></mfrac><mo>≈</mo><mn>0.01613</mn><mo>+</mo><mn>0.01538</mn><mo>=</mo><mn>0.03151</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-65">\text{RRF}(\text{DocB})
= \frac{1}{60 + 2} + \frac{1}{60 + 5}
= \frac{1}{62} + \frac{1}{65}
\approx 0.01613 + 0.01538
= 0.03151</script>
          </li>
          <li>
            <p><strong>DocC</strong> (Rank 3 in BM25, rank 2 in Neural Retriever):</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-66-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;RRF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;DocC&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;60&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;60&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;63&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;62&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;&amp;#x2248;&lt;/mo&gt;&lt;mn&gt;0.01587&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;0.01613&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.03200&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-660" style="width: 37.763em; display: inline-block;"><span style="display: inline-block; position: relative; width: 31.461em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1031.46em, 3.076em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-661"><span class="mtext" id="MathJax-Span-662" style="font-family: STIXGeneral-Regular;">RRF</span><span class="mo" id="MathJax-Span-663" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-664" style="font-family: STIXGeneral-Regular;">DocC</span><span class="mo" id="MathJax-Span-665" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-666" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-667" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.815em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-668" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1002.66em, 4.221em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-669"><span class="mn" id="MathJax-Span-670" style="font-family: STIXGeneral-Regular;">60</span><span class="mo" id="MathJax-Span-671" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-672" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">3</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.82em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.815em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-673" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mfrac" id="MathJax-Span-674" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 2.815em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-675" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1002.71em, 4.221em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-676"><span class="mn" id="MathJax-Span-677" style="font-family: STIXGeneral-Regular;">60</span><span class="mo" id="MathJax-Span-678" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-679" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">2</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.82em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.815em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-680" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-681" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-682" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.94em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.518em;"><span class="mn" id="MathJax-Span-683" style="font-family: STIXGeneral-Regular;">63</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-684" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mfrac" id="MathJax-Span-685" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-686" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.99em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.518em;"><span class="mn" id="MathJax-Span-687" style="font-family: STIXGeneral-Regular;">62</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-688" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">≈</span><span class="mn" id="MathJax-Span-689" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.01587</span><span class="mo" id="MathJax-Span-690" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-691" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">0.01613</span><span class="mo" id="MathJax-Span-692" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-693" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.03200</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.934em; border-left: 0px solid; width: 0px; height: 2.628em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>RRF</mtext><mo stretchy="false">(</mo><mtext>DocC</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>60</mn><mo>+</mo><mn>3</mn></mrow></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mn>60</mn><mo>+</mo><mn>2</mn></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>63</mn></mfrac><mo>+</mo><mfrac><mn>1</mn><mn>62</mn></mfrac><mo>≈</mo><mn>0.01587</mn><mo>+</mo><mn>0.01613</mn><mo>=</mo><mn>0.03200</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-66">\text{RRF}(\text{DocC})
= \frac{1}{60 + 3} + \frac{1}{60 + 2}
= \frac{1}{63} + \frac{1}{62}
\approx 0.01587 + 0.01613
= 0.03200</script>
          </li>
          <li>
            <p><strong>DocD</strong> (Rank 4 in BM25 only):</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-67-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;RRF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;DocD&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;60&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;64&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;&amp;#x2248;&lt;/mo&gt;&lt;mn&gt;0.01563&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-694" style="width: 19.378em; display: inline-block;"><span style="display: inline-block; position: relative; width: 16.148em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1016.1em, 3.076em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-695"><span class="mtext" id="MathJax-Span-696" style="font-family: STIXGeneral-Regular;">RRF</span><span class="mo" id="MathJax-Span-697" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-698" style="font-family: STIXGeneral-Regular;">DocD</span><span class="mo" id="MathJax-Span-699" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-700" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-701" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.815em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-702" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1002.71em, 4.221em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-703"><span class="mn" id="MathJax-Span-704" style="font-family: STIXGeneral-Regular;">60</span><span class="mo" id="MathJax-Span-705" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-706" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">4</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.82em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.815em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-707" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-708" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-709" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.99em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.518em;"><span class="mn" id="MathJax-Span-710" style="font-family: STIXGeneral-Regular;">64</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-711" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">≈</span><span class="mn" id="MathJax-Span-712" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.01563</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.934em; border-left: 0px solid; width: 0px; height: 2.628em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>RRF</mtext><mo stretchy="false">(</mo><mtext>DocD</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>60</mn><mo>+</mo><mn>4</mn></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>64</mn></mfrac><mo>≈</mo><mn>0.01563</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-67">\text{RRF}(\text{DocD})
= \frac{1}{60 + 4}
= \frac{1}{64}
\approx 0.01563</script>
          </li>
          <li>
            <p><strong>DocE</strong> (Rank 5 in BM25 only):</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-68-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;RRF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;DocE&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;60&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;65&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;&amp;#x2248;&lt;/mo&gt;&lt;mn&gt;0.01538&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-713" style="width: 19.273em; display: inline-block;"><span style="display: inline-block; position: relative; width: 16.044em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1015.99em, 3.076em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-714"><span class="mtext" id="MathJax-Span-715" style="font-family: STIXGeneral-Regular;">RRF</span><span class="mo" id="MathJax-Span-716" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-717" style="font-family: STIXGeneral-Regular;">DocE</span><span class="mo" id="MathJax-Span-718" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-719" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-720" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.815em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-721" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1002.66em, 4.221em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-722"><span class="mn" id="MathJax-Span-723" style="font-family: STIXGeneral-Regular;">60</span><span class="mo" id="MathJax-Span-724" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-725" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">5</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.82em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.815em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-726" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-727" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-728" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.94em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.518em;"><span class="mn" id="MathJax-Span-729" style="font-family: STIXGeneral-Regular;">65</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-730" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">≈</span><span class="mn" id="MathJax-Span-731" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.01538</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.934em; border-left: 0px solid; width: 0px; height: 2.628em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>RRF</mtext><mo stretchy="false">(</mo><mtext>DocE</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>60</mn><mo>+</mo><mn>5</mn></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>65</mn></mfrac><mo>≈</mo><mn>0.01538</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-68">\text{RRF}(\text{DocE})
= \frac{1}{60 + 5}
= \frac{1}{65}
\approx 0.01538</script>
          </li>
          <li>
            <p><strong>DocF</strong> (Rank 1 in Neural Retriever only):</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-69-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;RRF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;DocF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;60&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;61&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;&amp;#x2248;&lt;/mo&gt;&lt;mn&gt;0.01639&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-732" style="width: 19.221em; display: inline-block;"><span style="display: inline-block; position: relative; width: 15.992em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1015.94em, 3.076em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-733"><span class="mtext" id="MathJax-Span-734" style="font-family: STIXGeneral-Regular;">RRF</span><span class="mo" id="MathJax-Span-735" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-736" style="font-family: STIXGeneral-Regular;">DocF</span><span class="mo" id="MathJax-Span-737" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-738" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-739" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.815em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-740" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1002.61em, 4.221em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-741"><span class="mn" id="MathJax-Span-742" style="font-family: STIXGeneral-Regular;">60</span><span class="mo" id="MathJax-Span-743" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-744" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">1</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.82em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.815em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-745" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-746" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-747" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.518em;"><span class="mn" id="MathJax-Span-748" style="font-family: STIXGeneral-Regular;">61</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-749" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">≈</span><span class="mn" id="MathJax-Span-750" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.01639</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.934em; border-left: 0px solid; width: 0px; height: 2.628em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>RRF</mtext><mo stretchy="false">(</mo><mtext>DocF</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>60</mn><mo>+</mo><mn>1</mn></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>61</mn></mfrac><mo>≈</mo><mn>0.01639</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-69">\text{RRF}(\text{DocF})
= \frac{1}{60 + 1}
= \frac{1}{61}
\approx 0.01639</script>
          </li>
          <li>
            <p><strong>DocG</strong> (Rank 4 in Neural Retriever only):</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-70-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;RRF&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;DocG&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mrow&gt;&lt;mn&gt;60&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;64&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;&amp;#x2248;&lt;/mo&gt;&lt;mn&gt;0.01563&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-751" style="width: 19.378em; display: inline-block;"><span style="display: inline-block; position: relative; width: 16.148em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1016.1em, 3.076em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-752"><span class="mtext" id="MathJax-Span-753" style="font-family: STIXGeneral-Regular;">RRF</span><span class="mo" id="MathJax-Span-754" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-755" style="font-family: STIXGeneral-Regular;">DocG</span><span class="mo" id="MathJax-Span-756" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-757" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-758" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.815em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-759" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1002.71em, 4.221em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.352em;"><span class="mrow" id="MathJax-Span-760"><span class="mn" id="MathJax-Span-761" style="font-family: STIXGeneral-Regular;">60</span><span class="mo" id="MathJax-Span-762" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mn" id="MathJax-Span-763" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">4</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.82em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.815em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-764" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-765" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-766" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.99em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.518em;"><span class="mn" id="MathJax-Span-767" style="font-family: STIXGeneral-Regular;">64</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-768" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">≈</span><span class="mn" id="MathJax-Span-769" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.01563</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.934em; border-left: 0px solid; width: 0px; height: 2.628em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>RRF</mtext><mo stretchy="false">(</mo><mtext>DocG</mtext><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>60</mn><mo>+</mo><mn>4</mn></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>64</mn></mfrac><mo>≈</mo><mn>0.01563</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-70">\text{RRF}(\text{DocG})
= \frac{1}{60 + 4}
= \frac{1}{64}
\approx 0.01563</script>
          </li>
        </ul>
      </li>
      <li>
        <p>After computing scores for all documents, the final RRF ranking is obtained by sorting documents in descending order of their cumulative RRF scores.</p>
      </li>
      <li>This example illustrates the key property of RRF: documents that rank reasonably well across multiple retrieval systems (DocA, DocC, DocB) rise above documents that dominate only a single ranking, even if that dominance is at rank 1. Put simply, RRF rewards consistent relevance across retrieval strategies rather than dominance in a single system.</li>
    </ul>
  </li>
</ul>

<h5 id="advanced-variations">Advanced Variations</h5>

<ol>
  <li>
    <p><strong>Filtered parallel retrieval</strong>:</p>

    <ul>
      <li>Apply the same metadata filters</li>
      <li>Run lexical and semantic retrieval in parallel</li>
      <li>Fuse results with RRF</li>
      <li>Optionally rerank the fused set</li>
    </ul>
  </li>
  <li>
    <p><strong>Filter-aware rerankers</strong>:</p>

    <ul>
      <li>Metadata fields are appended to document text</li>
      <li>Allows rerankers to learn preferences (e.g., newer is better)</li>
      <li>Still respects hard filters upstream</li>
    </ul>
  </li>
  <li>
    <p><strong>Adaptive hybrid strategies</strong>:</p>

    <ul>
      <li>Short queries bias toward lexical</li>
      <li>Long natural language queries bias toward semantic</li>
      <li>Query classifiers dynamically adjust retrieval strategy</li>
    </ul>
  </li>
</ol>

<h5 id="common-pitfalls">Common Pitfalls</h5>

<ul>
  <li>Applying semantic retrieval before filtering, causing access violations</li>
  <li>Treating metadata as a scoring feature instead of a constraint</li>
  <li>Choosing <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-71-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-770" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-771"><span class="mi" id="MathJax-Span-772" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-71">K</script> too small, harming recall</li>
  <li>Over-relying on semantic similarity for exact-match queries</li>
  <li>Ignoring explainability and audit requirements</li>
</ul>

<h5 id="mental-model">Mental Model</h5>

<ul>
  <li>
    <p>Think in layers:</p>

    <ol>
      <li>Which documents are allowed? (metadata filtering)</li>
      <li>Which documents mention what the user said? (lexical recall)</li>
      <li>Which of those best match what the user meant? (semantic ranking)</li>
      <li>Which should be preferred? (re-ranking and boosting)</li>
    </ol>
  </li>
  <li>
    <p>Hybrid retrieval works because it preserves this separation of concerns.</p>
  </li>
</ul>

<h5 id="system-tuning">System Tuning</h5>

<ul>
  <li>Tuning a hybrid retrieval system is an exercise in balancing recall, precision, latency, cost, and operational complexity.</li>
  <li>There is no universally optimal configuration; instead, production systems are tuned based on query distribution, corpus characteristics, and downstream task requirements.</li>
</ul>

<h6 id="choosing-the-candidate-set-size-k">Choosing the Candidate Set Size (<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-72-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-773" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-774"><span class="mi" id="MathJax-Span-775" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-72">K</script>)</h6>

<ul>
  <li>
    <p>The parameter <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-73-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-776" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-777"><span class="mi" id="MathJax-Span-778" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-73">K</script> controls how many documents are retrieved by the first-stage retriever (usually BM25) before semantic processing.</p>
  </li>
  <li>
    <p><strong>Trade-offs</strong>:</p>

    <ul>
      <li>Smaller <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-74-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-779" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-780"><span class="mi" id="MathJax-Span-781" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-74">K</script> leads to lower latency and cost but increases the risk of missing relevant documents, since the semantic reranker has limited ability to recover items not present in the candidate set.</li>
      <li>Larger <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-75-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-782" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-783"><span class="mi" id="MathJax-Span-784" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-75">K</script> improves recall but increases semantic compute cost and typically exhibits diminishing returns beyond a certain threshold.</li>
    </ul>
  </li>
  <li>
    <p><strong>Practical guidelines</strong>:</p>

    <ul>
      <li>
        <p><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-76-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mn&gt;50&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;100&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-785" style="width: 6.773em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.628em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1005.52em, 2.555em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-786"><span class="mi" id="MathJax-Span-787" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-788" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∈</span><span class="mo" id="MathJax-Span-789" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">[</span><span class="mn" id="MathJax-Span-790" style="font-family: STIXGeneral-Regular;">50</span><span class="mo" id="MathJax-Span-791" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-792" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">100</span><span class="mo" id="MathJax-Span-793" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>50</mn><mo>,</mo><mn>100</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-76">K \in [50, 100]</script>: Suitable for narrow domains with high-quality lexical signals.</p>
      </li>
      <li>
        <p><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-77-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mn&gt;200&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;500&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-794" style="width: 7.346em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.096em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1005.99em, 2.555em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-795"><span class="mi" id="MathJax-Span-796" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-797" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∈</span><span class="mo" id="MathJax-Span-798" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">[</span><span class="mn" id="MathJax-Span-799" style="font-family: STIXGeneral-Regular;">200</span><span class="mo" id="MathJax-Span-800" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-801" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">500</span><span class="mo" id="MathJax-Span-802" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>200</mn><mo>,</mo><mn>500</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-77">K \in [200, 500]</script>: Common default for general-purpose search and RAG.</p>
      </li>
      <li>
        <p><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-78-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mn&gt;1000&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-803" style="width: 6.253em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.211em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1005.11em, 2.555em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-804"><span class="mi" id="MathJax-Span-805" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-806" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∈</span><span class="mo" id="MathJax-Span-807" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">[</span><span class="mn" id="MathJax-Span-808" style="font-family: STIXGeneral-Regular;">1000</span><span class="mo" id="MathJax-Span-809" style="font-family: STIXGeneral-Regular;">+</span><span class="mo" id="MathJax-Span-810" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>1000</mn><mo>+</mo><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-78">K \in [1000+]</script>: Used when recall is critical and latency budgets allow.</p>
      </li>
      <li>
        <p>A useful mental model is:</p>
      </li>
    </ul>

    <blockquote>
      <p>If a document does not appear in the top <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-79-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-811" style="width: 0.975em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.789em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.391em, 1000.79em, 2.317em, -999.998em); top: -2.174em; left: 0em;"><span class="mrow" id="MathJax-Span-812"><span class="mi" id="MathJax-Span-813" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.049em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.178em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.892em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-79">K</script> lexical results, semantic re-ranking cannot recover it.</p>
    </blockquote>
  </li>
</ul>

<h6 id="latency-and-cost-considerations">Latency and Cost Considerations</h6>

<ul>
  <li>Hybrid retrieval latency is additive across stages:</li>
</ul>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-80-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;total&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;filter&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;lexical&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;semantic&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;rerank&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-814" style="width: 19.794em; display: inline-block;"><span style="display: inline-block; position: relative; width: 16.461em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1016.46em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-815"><span class="msubsup" id="MathJax-Span-816"><span style="display: inline-block; position: relative; width: 1.878em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-817" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.576em;"><span class="texatom" id="MathJax-Span-818"><span class="mrow" id="MathJax-Span-819"><span class="mtext" id="MathJax-Span-820" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">total</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-821" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="msubsup" id="MathJax-Span-822" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.034em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-823" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.576em;"><span class="texatom" id="MathJax-Span-824"><span class="mrow" id="MathJax-Span-825"><span class="mtext" id="MathJax-Span-826" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">filter</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-827" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="msubsup" id="MathJax-Span-828" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 2.503em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-829" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.576em;"><span class="texatom" id="MathJax-Span-830"><span class="mrow" id="MathJax-Span-831"><span class="mtext" id="MathJax-Span-832" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">lexical</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-833" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="msubsup" id="MathJax-Span-834" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 3.128em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-835" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.576em;"><span class="texatom" id="MathJax-Span-836"><span class="mrow" id="MathJax-Span-837"><span class="mtext" id="MathJax-Span-838" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">semantic</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-839" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="msubsup" id="MathJax-Span-840" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 2.451em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-841" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.576em;"><span class="texatom" id="MathJax-Span-842"><span class="mrow" id="MathJax-Span-843"><span class="mtext" id="MathJax-Span-844" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">rerank</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>T</mi><mrow class="MJX-TeXAtom-ORD"><mtext>total</mtext></mrow></msub><mo>=</mo><msub><mi>T</mi><mrow class="MJX-TeXAtom-ORD"><mtext>filter</mtext></mrow></msub><mo>+</mo><msub><mi>T</mi><mrow class="MJX-TeXAtom-ORD"><mtext>lexical</mtext></mrow></msub><mo>+</mo><msub><mi>T</mi><mrow class="MJX-TeXAtom-ORD"><mtext>semantic</mtext></mrow></msub><mo>+</mo><msub><mi>T</mi><mrow class="MJX-TeXAtom-ORD"><mtext>rerank</mtext></mrow></msub></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-80">T_{\text{total}} =
T_{\text{filter}}
+ T_{\text{lexical}}
+ T_{\text{semantic}}
+ T_{\text{rerank}}</script>

<ul>
  <li>
    <p>Key optimization strategies include:</p>

    <ul>
      <li>Early filtering to shrink candidate sets</li>
      <li>Caching frequent query embeddings</li>
      <li>Applying rerankers only to the top subset (e.g., top 50)</li>
      <li>Adaptive pipelines based on query complexity</li>
    </ul>
  </li>
  <li>
    <p>Latency budgets often dictate architectural choices more than relevance metrics.</p>
  </li>
</ul>

<h6 id="query-aware-tuning">Query-aware Tuning</h6>

<ul>
  <li>
    <p>Many production systems dynamically adjust retrieval behavior:</p>

    <ul>
      <li>
        <p><strong>Short keyword queries</strong>: Bias toward lexical retrieval and smaller <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-81-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-845" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-846"><span class="mi" id="MathJax-Span-847" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-81">K</script></p>
      </li>
      <li>
        <p><strong>Long natural language queries</strong>: Increase <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-82-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-848" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-849"><span class="mi" id="MathJax-Span-850" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-82">K</script> and rely more on semantic re-ranking</p>
      </li>
      <li>
        <p><strong>Identifier-heavy queries</strong>: Skip semantic stages entirely</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Query classifiers or heuristics are often sufficient to enable this adaptivity.</p>
  </li>
</ul>

<h6 id="evaluation-and-tuning-methodology">Evaluation and Tuning Methodology</h6>

<ul>
  <li>
    <p>Hybrid systems are tuned using:</p>

    <ul>
      <li>Offline relevance judgments (NDCG, MRR, Recall@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-83-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-851" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-852"><span class="mi" id="MathJax-Span-853" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-83">k</script>)</li>
      <li>Online A/B testing</li>
      <li>Query-level error analysis</li>
    </ul>
  </li>
  <li>
    <p>Important metrics include:</p>

    <ul>
      <li>Recall@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-84-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-854" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-855"><span class="mi" id="MathJax-Span-856" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-84">k</script> after lexical retrieval</li>
      <li>Precision improvements from re-ranking</li>
      <li>Latency percentiles (P50, P95, P99)</li>
    </ul>
  </li>
  <li>
    <p>Tuning is iterative and tightly coupled to real query logs.</p>
  </li>
</ul>

<h5 id="hybrid-retrieval-in-rag-architectures">Hybrid Retrieval in RAG Architectures</h5>

<ul>
  <li>RAG systems rely on retrieval quality as a first-order determinant of generation quality. Hybrid retrieval has become the dominant retrieval strategy in RAG because it directly addresses the failure modes of both generation and retrieval models.</li>
</ul>

<h6 id="why-hybrid-retrieval-is-critical-for-rag">Why Hybrid Retrieval is Critical for RAG</h6>

<ul>
  <li>
    <p>Language models:</p>

    <ul>
      <li>Cannot invent missing facts reliably</li>
      <li>Are sensitive to irrelevant or misleading context</li>
      <li>Perform best when provided with precise, relevant grounding documents</li>
    </ul>
  </li>
  <li>
    <p>Hybrid retrieval ensures:</p>

    <ul>
      <li>Exact factual anchors are included</li>
      <li>Conceptually relevant context is not missed</li>
      <li>The model is not forced to hallucinate due to missing evidence</li>
    </ul>
  </li>
</ul>

<h6 id="canonical-rag-retrieval-pipeline">Canonical RAG Retrieval Pipeline</h6>

<ul>
  <li>
    <p>A typical hybrid RAG pipeline looks like:</p>

    <ol>
      <li>
        <p><strong>Metadata filtering</strong>: Apply access, language, document type, and recency constraints.</p>
      </li>
      <li>
        <p><strong>Lexical retrieval</strong>: Retrieve top <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-85-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-857" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-858"><span class="mi" id="MathJax-Span-859" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-85">K</script> documents using BM25.</p>
      </li>
      <li>
        <p><strong>Semantic re-ranking</strong>: Rerank candidates using a semantic model.</p>
      </li>
      <li>
        <p><strong>Context selection</strong>: Select top <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-86-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-860" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-861"><span class="mi" id="MathJax-Span-862" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi></math></span></span><script type="math/tex" id="MathJax-Element-86">N</script> documents or passages for generation.</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Formally:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-87-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Context&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mtext&gt;Top&lt;/mtext&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo maxsize=&quot;1.623em&quot; minsize=&quot;1.623em&quot;&gt;(&lt;/mo&gt;&lt;/mrow&gt;&lt;msub&gt;&lt;mtext&gt;Rerank&lt;/mtext&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;semantic&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;BM25&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;Docs&lt;/mtext&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mtext&gt;filters&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo maxsize=&quot;1.623em&quot; minsize=&quot;1.623em&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-863" style="width: 26.826em; display: inline-block;"><span style="display: inline-block; position: relative; width: 22.346em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(2.138em, 1022.24em, 4.326em, -999.997em); top: -3.487em; left: 0em;"><span class="mrow" id="MathJax-Span-864"><span class="mtext" id="MathJax-Span-865" style="font-family: STIXGeneral-Regular;">Context</span><span class="mo" id="MathJax-Span-866" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="msubsup" id="MathJax-Span-867" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 2.19em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1001.57em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mtext" id="MathJax-Span-868" style="font-family: STIXGeneral-Regular;">Top</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.747em; left: 1.617em;"><span class="mi" id="MathJax-Span-869" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="texatom" id="MathJax-Span-870"><span class="mrow" id="MathJax-Span-871"><span class="mo" id="MathJax-Span-872" style="vertical-align: -0.414em;"><span style="font-family: STIXSizeTwoSym;">(</span></span></span></span><span class="msubsup" id="MathJax-Span-873"><span style="display: inline-block; position: relative; width: 5.471em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1002.92em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mtext" id="MathJax-Span-874" style="font-family: STIXGeneral-Regular;">Rerank</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 2.867em;"><span class="texatom" id="MathJax-Span-875"><span class="mrow" id="MathJax-Span-876"><span class="mtext" id="MathJax-Span-877" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">semantic</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-878" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-879" style="font-family: STIXGeneral-Regular;">BM25</span><span class="mo" id="MathJax-Span-880" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-881" style="font-family: STIXGeneral-Regular;">Docs</span><span class="mo" id="MathJax-Span-882" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣</span><span class="mtext" id="MathJax-Span-883" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">filters</span><span class="mo" id="MathJax-Span-884" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-885" style="font-family: STIXGeneral-Regular;">)</span><span class="texatom" id="MathJax-Span-886"><span class="mrow" id="MathJax-Span-887"><span class="mo" id="MathJax-Span-888" style="vertical-align: -0.414em;"><span style="font-family: STIXSizeTwoSym;">)</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.492em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.872em; border-left: 0px solid; width: 0px; height: 2.316em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Context</mtext><mo>=</mo><msub><mtext>Top</mtext><mi>N</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo maxsize="1.623em" minsize="1.623em">(</mo></mrow><msub><mtext>Rerank</mtext><mrow class="MJX-TeXAtom-ORD"><mtext>semantic</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>BM25</mtext><mo stretchy="false">(</mo><mtext>Docs</mtext><mo>∣</mo><mtext>filters</mtext><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mo maxsize="1.623em" minsize="1.623em">)</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-87">\text{Context} =
\text{Top}_N
\Big(
\text{Rerank}_{\text{semantic}}
(
\text{BM25}(\text{Docs} \mid \text{filters})
)
\Big)</script>
  </li>
</ul>

<h6 id="failure-modes-avoided-by-hybrid-rag">Failure Modes Avoided by Hybrid RAG</h6>

<ul>
  <li>
    <p><strong>Semantic-only retrieval</strong>: Misses exact facts, dates, or identifiers.</p>
  </li>
  <li>
    <p><strong>Lexical-only retrieval</strong>: Misses paraphrased or implied information.</p>
  </li>
  <li>
    <p><strong>Unfiltered retrieval</strong>: Causes data leakage or compliance violations.</p>
  </li>
  <li>
    <p>Hybrid retrieval with three stages (<strong>metadata filtering, lexical retrieval, and semantic retrieval/ranking</strong>) minimizes all three.</p>
  </li>
</ul>

<h6 id="final-synthesis">Final Synthesis</h6>

<ul>
  <li>Hybrid retrieval is not an optimization but an architectural necessity: lexical retrieval anchors the system to exact facts, identifiers, and wording; semantic retrieval captures the user’s underlying intent and conceptual meaning; metadata filtering enforces correctness, safety, and access constraints; and re-ranking (covered in the <a href="#re-ranking">Re-ranking</a> section) maximizes usefulness by prioritizing the most relevant and coherent results for downstream consumption. Together, these components form a coherent pipeline in which each stage compensates for the limitations of the others, producing search behavior that is precise, robust, and reliable at scale.</li>
  <li>In RAG systems, generation quality is bounded by retrieval quality. Hybrid retrieval raises that bound by ensuring the language model sees the right information, for the right reasons, under the right constraints.</li>
</ul>

<h4 id="metadata-filtering">Metadata Filtering</h4>

<ul>
  <li>Metadata filtering is the process of restricting the searchable corpus using structured, non-textual attributes attached to documents (such as access rights, tenant identifiers, language, timestamps, or document type) before or during retrieval, so that only contextually valid documents are ever considered for ranking.</li>
  <li>Metadata filtering is applicable to lexical retrieval, semantic retrieval, and hybrid retrieval alike, and is typically applied first as hard constraints, meaning documents that fail these conditions are excluded entirely rather than merely penalized in scoring.</li>
  <li>Treating metadata as hard constraints is essential because constraints like access control, tenancy, jurisdiction, and language are correctness requirements, not relevance preferences, regardless of whether relevance is computed lexically, semantically, or via a hybrid approach.</li>
  <li>Applying hard filters early improves system efficiency by shrinking the candidate set before lexical matching, vector search, or expensive semantic scoring and reranking, which often dominate latency and cost.</li>
  <li>By separating hard constraints from ranking logic, metadata filtering simplifies auditing, debugging, and explainability, allowing the system to clearly state that relevance was computed only within an explicitly defined and policy-compliant subset of the corpus.</li>
</ul>

<h6 id="standard-pattern">Standard Pattern</h6>

<ol>
  <li>
    <p>Apply metadata filters</p>

    <ul>
      <li>
        <p>Examples:</p>

        <ul>
          <li>tenant_id = <code class="language-plaintext highlighter-rouge">X</code></li>
          <li>language = <code class="language-plaintext highlighter-rouge">"en"</code></li>
          <li>date ≥ <code class="language-plaintext highlighter-rouge">2024-01-01</code></li>
          <li>access_level ≤ <code class="language-plaintext highlighter-rouge">user_clearance</code></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Perform retrieval within the filtered set</p>

    <ul>
      <li>Lexical retrieval operates only on allowed documents</li>
      <li>Semantic retrieval or re-ranking is applied afterward (if used)</li>
      <li>Hybrid retrieval combines both within the same filtered universe</li>
    </ul>
  </li>
</ol>

<ul>
  <li>Formally:</li>
</ul>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-88-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Results&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mtext&gt;Rank&lt;/mtext&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo maxsize=&quot;1.2em&quot; minsize=&quot;1.2em&quot;&gt;(&lt;/mo&gt;&lt;/mrow&gt;&lt;mtext&gt;Docs&lt;/mtext&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mtext&gt;metadata filters&lt;/mtext&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo maxsize=&quot;1.2em&quot; minsize=&quot;1.2em&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-889" style="width: 19.638em; display: inline-block;"><span style="display: inline-block; position: relative; width: 16.357em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(2.086em, 1016.2em, 3.753em, -999.997em); top: -3.174em; left: 0em;"><span class="mrow" id="MathJax-Span-890"><span class="mtext" id="MathJax-Span-891" style="font-family: STIXGeneral-Regular;">Results</span><span class="mo" id="MathJax-Span-892" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mtext" id="MathJax-Span-893" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">Rank</span><span class="texatom" id="MathJax-Span-894"><span class="mrow" id="MathJax-Span-895"><span class="mo" id="MathJax-Span-896" style="vertical-align: -0.258em;"><span><span style="font-size: 110%; font-family: STIXSizeOneSym;">(</span></span></span></span></span><span class="mtext" id="MathJax-Span-897" style="font-family: STIXGeneral-Regular;">Docs</span><span class="mo" id="MathJax-Span-898" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣</span><span class="mtext" id="MathJax-Span-899" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">metadata filters</span><span class="texatom" id="MathJax-Span-900"><span class="mrow" id="MathJax-Span-901"><span class="mo" id="MathJax-Span-902" style="vertical-align: -0.258em;"><span><span style="font-size: 110%; font-family: STIXSizeOneSym;">)</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.18em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.559em; border-left: 0px solid; width: 0px; height: 1.753em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Results</mtext><mo>=</mo><mtext>Rank</mtext><mrow class="MJX-TeXAtom-ORD"><mo maxsize="1.2em" minsize="1.2em">(</mo></mrow><mtext>Docs</mtext><mo>∣</mo><mtext>metadata filters</mtext><mrow class="MJX-TeXAtom-ORD"><mo maxsize="1.2em" minsize="1.2em">)</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-88">\text{Results} =
\text{Rank}
\big(
\text{Docs} \mid \text{metadata filters}
\big)</script>

<ul>
  <li>This guarantees correctness by preventing data leakage, improves efficiency by reducing the search space early, and enables simpler reasoning and auditing by cleanly separating constraints from relevance scoring.</li>
</ul>

<h6 id="hard-filters-metadata-filtering-vs-soft-boosts-metadata-re-ranking">Hard Filters (Metadata Filtering) vs. Soft Boosts (Metadata Re-ranking)</h6>

<ul>
  <li>Hard filters are non-negotiable constraints such as access control, tenancy boundaries, jurisdictional limits, and language restrictions that must be satisfied for a document to be retrievable at all. These must be satisfied before retrieval, excluding documents entirely from the searchable corpus rather than affecting their rank.</li>
  <li>Soft boosts are preference signals such as recency, source authority, and content type that influence ranking after retrieval without excluding documents outright. This post-retrieval adjustment is commonly referred to as <strong>metadata re-ranking</strong>, where structured signals modify relevance scores rather than filter candidates.</li>
</ul>

<h3 id="re-ranking">Re-ranking</h3>

<ul>
  <li>Re-ranking is a critical refinement stage in modern Retrieval-Augmented Generation (RAG) pipelines, responsible for reordering a small candidate set of retrieved documents or passages to ensure that the most relevant content is prioritized for inclusion in the final prompt presented to the language model. While retrieval focuses on recall at scale, re-ranking emphasizes precision, making it a key determinant of generation quality.</li>
</ul>

<h4 id="re-ranking-in-multistage-retrieval-pipelines">Re-ranking in Multistage Retrieval Pipelines</h4>

<ul>
  <li>
    <p>In practice, re-ranking is applied after an initial retrieval stage has narrowed the corpus to a manageable shortlist. Because the candidate set is small—typically tens to hundreds of documents—computationally intensive but highly accurate re-ranking techniques become feasible.</p>
  </li>
  <li>
    <p>The figure below (<a href="https://weaviate.io/blog/cross-encoders-as-reranker">source</a>) illustrates a common multistage search pipeline used in RAG systems. In the first stage, a bi-encoder efficiently retrieves a shortlist of candidate documents from a large corpus. In the second stage, a re-ranker—often implemented as a cross-encoder—is applied to this reduced set to reassess and reorder the results based on deeper query–document interactions. This two-stage design combines the scalability of bi-encoder retrieval with the higher relevance accuracy of cross-encoder re-ranking, making it practical to deploy on large-scale datasets while still achieving strong ranking quality.</p>
  </li>
</ul>

<p><img src="/primers/ai/assets/RAG/multistage-search-pipeline.jpg" alt=""></p>

<ul>
  <li>This multistage architecture is foundational to modern RAG systems and motivates the different classes of re-rankers used in practice.</li>
</ul>

<h4 id="classes-of-semantic-re-ranking-models">Classes of Semantic Re-ranking Models</h4>

<ul>
  <li>
    <p>Modern RAG systems typically rely on three complementary classes of re-rankers, each addressing a distinct dimension of relevance:</p>

    <ul>
      <li><strong>Neural Learning-to-Rank (LTR) re-rankers</strong>, which model semantic relevance between queries and documents using learned ranking objectives.</li>
      <li><strong>Instruction-tuned re-rankers</strong>, which allow relevance criteria to be dynamically adjusted at runtime using natural language instructions.</li>
      <li><strong>Metadata-based re-rankers</strong>, which incorporate structured signals such as recency, authority, provenance, or document type to enforce policy and domain-specific constraints.</li>
    </ul>
  </li>
  <li>
    <p>Together, these approaches form a layered re-ranking strategy in which semantic relevance is established first and then refined to better align with user intent, organizational rules, and real-world constraints.</p>
  </li>
</ul>

<h4 id="learning-to-rank-paradigms">Learning-to-Rank Paradigms</h4>

<ul>
  <li>
    <p>Most re-ranking techniques fall under the umbrella of Learning-to-Rank (LTR), which differs based on how relevance is modeled and optimized:</p>

    <ul>
      <li><strong>Pointwise methods</strong> score each query–document pair independently, estimating absolute relevance.</li>
      <li><strong>Pairwise methods</strong> compare two documents at a time for a given query, learning relative preferences.</li>
      <li><strong>Listwise methods</strong> consider an entire ranked list jointly, optimizing ranking quality at the list level using task-specific loss functions.</li>
    </ul>
  </li>
  <li>
    <p>These paradigms can be implemented using different neural architectures, with trade-offs between computational cost, expressiveness, and ranking accuracy.</p>
  </li>
</ul>

<h4 id="neural-re-rankers">Neural Re-rankers</h4>

<ul>
  <li>Neural re-rankers form the core semantic ranking layer in most RAG systems. They are trained with explicit ranking objectives (pointwise, pairwise, or listwise) and are most commonly implemented using <strong>bi-encoder</strong> or <strong>cross-encoder</strong> architectures.</li>
  <li>Neural re-rankers can be structured based on the type of re-ranking mechanism they employ, reflecting both architectural choices and how relevance is computed. The most common category is cross-encoder–based re-rankers, within which different LTR paradigms—pointwise, pairwise, and listwise—are used. More recent architectures extend beyond traditional cross-encoders to support list-level reasoning and alternative decoding strategies.</li>
  <li>In practice, these differences manifest in how queries and candidate documents are jointly encoded and how relevance is computed, ranging from independent scoring of single query–document pairs to holistic reasoning over entire candidate lists.</li>
</ul>

<h5 id="bi-encoder-re-rankers-early-stage-or-lightweight-re-ranking">Bi-encoder Re-rankers (early-stage or Lightweight Re-ranking)</h5>

<ul>
  <li>
    <p>Bi-encoders (also known as dual-encoders) encode queries and documents independently into dense vectors and compute relevance using vector similarity.</p>

    <ul>
      <li>They are fast, scalable, and suitable for scoring large candidate sets.</li>
      <li>However, they cannot model fine-grained token-level interactions between query and document.</li>
      <li>Bi-encoders are typically trained as pointwise rankers; even when trained with pairwise or contrastive losses, they still score documents independently at inference time.</li>
      <li>While most commonly used at the retrieval stage, bi-encoders are also employed as an early re-ranking step (especially after a lexical retrieval stage), where efficient scoring over large candidate sets is required. Bi-encoders are also used as a lightweight re-ranking stage when latency constraints are strict, cross-encoders are too expensive, or infrastructure only supports embedding-based scoring. In these cases, the bi-encoder acts as a coarse reranker that improves ordering without the full cost of joint encoding.</li>
    </ul>
  </li>
  <li>
    <p>In these cases, the bi-encoder acts as a coarse semantic filter that improves ordering without incurring the cost of joint encoding.</p>
  </li>
</ul>

<h5 id="cross-encoder-re-rankers-late-stage-high-precision-re-ranking">Cross-encoder Re-rankers (late-stage, High-precision Re-ranking)</h5>

<ul>
  <li>
    <p>Cross-encoders jointly encode the query and document, allowing full attention between tokens and enabling highly accurate relevance estimation at the cost of higher computation.</p>

    <ul>
      <li>This allows them to capture fine-grained relevance signals such as negation, term dependencies, and contextual constraints.</li>
      <li>Cross-encoders are significantly more accurate than bi-encoders but computationally expensive.</li>
      <li>They are therefore applied only to small candidate sets (often dozens of documents) in the final re-ranking stage.</li>
      <li>Cross-encoders can be trained using pointwise, pairwise, or listwise LTR objectives.</li>
    </ul>
  </li>
  <li>
    <p>As a result, cross-encoders are the most common architecture for high-quality neural re-ranking in production RAG pipelines.</p>
  </li>
</ul>

<h5 id="example-models">Example Models</h5>

<ul>
  <li>This section organizes neural re-rankers by architectural family and learning paradigm, highlighting how pointwise, pairwise, and listwise approaches are implemented in modern systems.</li>
  <li>These formulations correspond to pointwise, pairwise, and listwise re-ranking approaches, each offering different trade-offs between expressiveness, computational cost, and ranking quality.</li>
</ul>

<h6 id="examples-cross-encoder-re-rankers">Examples: Cross-encoder Re-rankers</h6>

<ul>
  <li>
    <p><strong>Pointwise Re-ranker</strong>:</p>

    <ul>
      <li><strong>monoBERT</strong>, proposed by Nogueira et al. (2019) in <a href="https://arxiv.org/abs/1910.14424">Multi-Stage Document Ranking with BERT</a>, scores each document–query pair independently using BERT as a cross-encoder. The query is provided as sentence A and the document as sentence B in a single concatenated input sequence, allowing full self-attention between query and document tokens. After encoding, the final <code class="language-plaintext highlighter-rouge">[CLS]</code> representation is passed through a single linear layer followed by a sigmoid activation to produce a scalar relevance probability <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-89-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;relevant&lt;/mtext&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-903" style="width: 10.784em; display: inline-block;"><span style="display: inline-block; position: relative; width: 8.961em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1008.91em, 2.607em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-904"><span class="msubsup" id="MathJax-Span-905"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-906" style="font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.367em;"><span class="mi" id="MathJax-Span-907" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-908" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mi" id="MathJax-Span-909" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">P</span><span class="mo" id="MathJax-Span-910" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-911" style="font-family: STIXGeneral-Regular;">relevant</span><span class="mo" id="MathJax-Span-912" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣</span><span class="mi" id="MathJax-Span-913" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">q</span><span class="mo" id="MathJax-Span-914" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-915" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-916" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="mi" id="MathJax-Span-917" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-918" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mi>i</mi></msub><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mtext>relevant</mtext><mo>∣</mo><mi>q</mi><mo>,</mo><msub><mi>d</mi><mi>i</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-89">s_i = P(\text{relevant}\mid q, d_i)</script>. The model is trained with binary cross-entropy loss over relevant and non-relevant documents, making monoBERT a pointwise probabilistic relevance classifier with high effectiveness but high inference cost when applied to many document–query pairs.</li>
    </ul>
  </li>
  <li>
    <p><strong>Pairwise Re-ranker</strong>:</p>

    <ul>
      <li><strong>duoBERT</strong>, also proposed by Nogueira et al. (2019) in <a href="https://arxiv.org/abs/1910.14424">Multi-Stage Document Ranking with BERT</a>, is likewise a cross-encoder (not a bi-encoder) but operates in a pairwise ranking setting. The input consists of a single concatenated sequence with the query as sentence A and two candidate documents as sentences B and C. The resulting <code class="language-plaintext highlighter-rouge">[CLS]</code> representation is passed through a single linear layer followed by a sigmoid activation to produce a probability <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-90-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x227B;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-919" style="width: 9.273em; display: inline-block;"><span style="display: inline-block; position: relative; width: 7.711em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1007.66em, 2.711em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-920"><span class="msubsup" id="MathJax-Span-921"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-922" style="font-family: STIXGeneral-Italic;">p</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="texatom" id="MathJax-Span-923"><span class="mrow" id="MathJax-Span-924"><span class="mi" id="MathJax-Span-925" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-926" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-927" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-928" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mi" id="MathJax-Span-929" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">P</span><span class="mo" id="MathJax-Span-930" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-931"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-932" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="mi" id="MathJax-Span-933" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-934" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">≻</span><span class="msubsup" id="MathJax-Span-935" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-936" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="mi" id="MathJax-Span-937" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-938" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣</span><span class="mi" id="MathJax-Span-939" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">q</span><span class="mo" id="MathJax-Span-940" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>p</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>d</mi><mi>i</mi></msub><mo>≻</mo><msub><mi>d</mi><mi>j</mi></msub><mo>∣</mo><mi>q</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-90">p_{i,j} = P(d_i \succ d_j \mid q)</script>. Training uses binary cross-entropy loss applied to ordered (relevant, non-relevant) document pairs rather than individual documents, meaning the same loss form as monoBERT but in a pairwise preference formulation. This enables direct document–document comparisons under the same query, at an even higher computational cost than monoBERT.</li>
    </ul>
  </li>
  <li>
    <p><strong>Listwise Re-rankers</strong>:</p>

    <ul>
      <li>
        <p>Listwise re-rankers move beyond independent or pairwise scoring by modeling relevance across an entire ranked list simultaneously. This enables direct optimization of ranking metrics and better captures inter-document dependencies.</p>
      </li>
      <li>
        <p><strong>ListBERT</strong>, proposed by Kumar et al. (2022) in <a href="https://arxiv.org/abs/2206.15198">ListBERT: Learning to Rank E-commerce products with Listwise BERT</a>, brings a listwise learning paradigm to transformer-based ranking. Instead of scoring documents independently or in pairs, ListBERT considers a full list of documents simultaneously. It uses listwise loss functions tailored for ranking tasks (e.g., ListMLE, Softmax Cross Entropy) and was originally applied in the context of e-commerce to rank products effectively.</p>
      </li>
    </ul>
  </li>
</ul>

<h6 id="examples-encoder-decoder--decoder-based-listwise-re-rankers-fusion-in-decoder-architectures">Examples: Encoder-Decoder / Decoder-based Listwise Re-rankers (Fusion-in-Decoder Architectures)</h6>

<ul>
  <li>
    <p>A more recent class of listwise re-rankers leverages encoder–decoder architectures to jointly reason over multiple documents during decoding, rather than relying solely on encoder-side interactions.</p>
  </li>
  <li>
    <p>While <a href="https://arxiv.org/abs/1910.14424">monoBERT</a> by Nogueira et al. (2019) and <a href="https://arxiv.org/abs/1910.14424">duoBERT</a> by Nogueira et al. (2019) rely on traditional cross-encoder architectures, <a href="https://arxiv.org/abs/2206.15198">ListBERT</a> by Zhuang et al. (2022) and <a href="https://arxiv.org/abs/2402.15838">ListT5</a> by Yoon et al. (2024) introduce list-level reasoning through different mechanisms. ListBERT remains encoder-only with listwise loss functions, whereas ListT5 employs a Fusion-in-Decoder architecture adapted from T5, which is not a standard cross-encoder. Decoder-based listwise re-rankers are explained below:</p>

    <ul>
      <li>
        <p><strong>ListT5</strong> by Yoon et al. (2024), proposed in <a href="https://arxiv.org/abs/2402.15838">ListT5: Listwise Re-ranking with Fusion-in-Decoder Improves Zero-shot Retrieval</a>, advances listwise re-ranking by adapting the Fusion-in-Decoder (FiD) architecture from <a href="https://arxiv.org/abs/1910.10683">T5</a> by Raffel et al. (2019). Each candidate document is encoded independently together with the query, but the decoder jointly attends over the encoded representations of all candidates to generate relevance-aware outputs, enabling true listwise reasoning at decoding time. This architecture allows interactions across all documents in the candidate list without quadratic encoder costs and has shown strong performance in zero-shot and low-supervision retrieval settings with minimal labeled data.</p>
      </li>
      <li>
        <p><strong>REARANK</strong> by Zhang et al. (2025), introduced in <a href="https://arxiv.org/abs/2505.20046">REARANK: Reasoning Re-ranking Agent via Reinforcement Learning</a>, is an LLM-based <strong>listwise reranking agent</strong> that explicitly reasons about entire candidate sets before producing a ranked ordering. It leverages reinforcement learning and data augmentation to optimize a listwise objective, demonstrating strong performance with relatively few annotated samples and interpretable reasoning steps.</p>
      </li>
      <li>
        <p><strong>Rank-K</strong> by Yang et al. (2025), proposed in <a href="https://arxiv.org/abs/2505.14432">Rank-K: Test-Time Reasoning for Listwise Reranking</a>, prioposes a listwise passage reranking model that leverages reasoning language models at test time to compare and order multiple passages jointly, improving retrieval effectiveness and showing strong multilingual behavior in ranking.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>These decoder-based listwise re-rankers differ fundamentally from cross-encoder models like monoBERT and duoBERT: rather than producing independent relevance scores or pairwise comparisons, they perform global reasoning over an entire candidate set during decoding, trading higher memory usage and decoding cost for richer list-level interactions.</p>
  </li>
</ul>

<h5 id="domain-specific-adaptations">Domain-Specific Adaptations</h5>

<ul>
  <li>
    <p>Neural re-rankers can be further specialized through domain-specific adaptation, where models are fine-tuned or pretrained on corpora and relevance judgments drawn from a particular field. This aligns the re-ranker’s representations with domain-specific terminology, document structures, and relevance criteria that differ from general-purpose benchmarks (e.g., legal, healthcare, finance).</p>
  </li>
  <li>
    <p>For example, <strong><a href="https://arxiv.org/abs/2010.02559">Legal-BERT</a></strong> extends the BERT architecture through pretraining on large legal corpora and can be adapted as a re-ranker for tasks such as legal document ranking and case law search. Domain-aware ranking approaches that customize relevance based on industry semantics have shown improved performance in specialized fields like legal search. Additionally, models like <strong><a href="https://www.siliconflow.com/articles/en/Most-powerful-re-ranking-model-for-legal-documents">Qwen3-Reranker</a></strong> demonstrate how legal-focused re-rankers with long-context capabilities can improve relevance for complex legal document tasks.</p>
  </li>
  <li>
    <p>In the healthcare domain, dedicated models such as the ones proposed in <strong><a href="https://www.zeroentropy.dev/articles/best-reranker-healthcare">ZeroEntropy Reranker for Healthcare AI</a></strong> provide domain-specific re-ranking tuned to prioritize clinical guidelines, electronic health records, and medical research documents, helping surface the most authoritative and clinically relevant information in RAG workflows.</p>
  </li>
  <li>
    <p>Domain-specific rerankers are also emerging in finance and compliance applications, where tailored ranking models help improve fraud detection, policy retrieval, and compliance task relevance, demonstrating the broader applicability of specialized re-ranking beyond general semantic similarity.</p>
  </li>
  <li>
    <p>Similar domain-adapted re-rankers are being developed in technical domains where relevance depends on specialized vocabulary, regulatory context, or evidence standards. In these settings, domain-specific re-ranking helps reduce false positives, surface authoritative sources, and ensure that highly specialized documents are correctly prioritized within the final ranked list.</p>
  </li>
</ul>

<h4 id="instruction-following-re-ranking">Instruction-Following Re-ranking</h4>

<ul>
  <li>
    <p>A growing frontier in re-ranking is instruction-following re-ranking, which augments neural re-rankers with the ability to condition ranking behavior on natural language instructions. Instead of relying on a fixed notion of relevance learned during training, these models allow relevance criteria to be specified or adjusted at runtime, enabling more flexible and context-aware ranking decisions. This capability is particularly valuable in enterprise and production RAG systems where relevance often depends on business rules, trust constraints, or temporal considerations rather than semantic similarity alone.</p>
  </li>
  <li>
    <p>Instruction-following re-rankers are typically built on top of large language models or instruction-tuned cross-encoders, leveraging advances in instruction tuning and alignment. By treating ranking as a controllable task, they bridge the gap between traditional LTR objectives and prompt-based control paradigms discussed in work on instruction-tuned models such as <a href="https://arxiv.org/abs/2109.01652">Instruction Tuning</a> and <a href="https://arxiv.org/abs/2210.11416">FLAN</a>.</p>
  </li>
  <li>
    <p><strong>Examples of Natural Language Instructions</strong>:</p>

    <ul>
      <li>“Prioritize internal documentation over third-party sources. Favor the most recent information.”</li>
      <li>“Disregard news summaries. Emphasize detailed technical reports from trusted analysts.”</li>
      <li>“Prefer primary sources and official standards documents over community blog posts.”</li>
    </ul>
  </li>
  <li>
    <p><strong>Advantages</strong>:</p>

    <ul>
      <li><strong>Dynamic Relevance Modeling</strong>: Instructions enable runtime control over what relevance means, allowing the same retrieved candidate set to be re-ranked differently depending on user intent, task context, or organizational policy.</li>
      <li><strong>Conflict Resolution</strong>: Explicit instructions make it possible to resolve contradictory or overlapping sources by enforcing prioritization rules such as recency, authority, or provenance, complementing purely learned relevance signals.</li>
      <li><strong>Prompt Optimization</strong>: By ensuring that higher-quality and policy-compliant content appears earlier in the ranked list, instruction-following re-ranking helps maximize the utility of the limited context window, where the language model’s attention is most concentrated.</li>
    </ul>
  </li>
  <li>
    <p><strong>Implementation and Deployment</strong>:</p>

    <ul>
      <li>Instruction-following re-rankers are commonly deployed as a post-retrieval scoring layer that operates on a small shortlist of candidate documents. They are often exposed as standalone APIs or integrated modules within RAG pipelines, similar to conventional cross-encoder re-rankers but with an additional instruction input.</li>
      <li>A notable example is Contextual AI’s system described in <a href="https://contextual.ai/blog/introducing-instruction-following-reranker/">Introducing the World’s First Instruction-Following Reranker</a>, which demonstrates how natural language instructions can be combined with neural re-ranking to enforce enterprise-specific relevance constraints in real-world deployments.</li>
      <li>Instruction-following re-rankers can be combined with other techniques such as retriever ensembling, metadata-based filtering, or late chunking, effectively acting as the final curation layer before documents are assembled into the prompt sent to the language model.</li>
    </ul>
  </li>
</ul>

<h4 id="metadata-based-re-rankers">Metadata-Based Re-rankers</h4>

<ul>
  <li>
    <p>Metadata-based re-rankers incorporate structured, non-textual signals into the re-ranking stage to bias results toward documents that satisfy explicit criteria such as recency, authority, source type, or document provenance. Rather than replacing neural relevance scores, these signals are typically combined with semantic scores to produce a final ranking that better reflects practical relevance constraints in real-world systems.</p>
  </li>
  <li>
    <p>Common metadata signals include timestamps, source identifiers, publisher reputation, document type, access level, and usage statistics. These features are especially valuable in enterprise and regulated settings, where the most semantically relevant document may not be the most trustworthy or up to date. This idea aligns with classical ranking work that blends multiple relevance signals, such as BM25 variants with field or freshness boosts, and modern hybrid ranking systems discussed in <a href="https://link.springer.com/book/10.1007/978-3-642-14267-3">Learning to Rank for Information Retrieval</a> by Tie-Yan Liu.</p>
  </li>
  <li>
    <p><strong>Typical Re-ranking Criteria</strong>:</p>

    <ul>
      <li><strong>Recency</strong>: Favor newer documents using timestamp-based decay functions, particularly important for fast-changing domains such as news, finance, or internal documentation.</li>
      <li><strong>Authority and Source Trust</strong>: Prefer documents from curated or authoritative sources (e.g., internal wikis, official standards bodies) over third-party or user-generated content.</li>
      <li><strong>Document Type and Provenance</strong>: Boost primary sources, specifications, or policies while demoting summaries, duplicates, or low-signal content.</li>
    </ul>
  </li>
  <li>
    <p>In practice, metadata-based re-ranking is often implemented using rule-based or learned scoring functions layered on top of neural relevance scores. Search platforms such as Elasticsearch and OpenSearch expose this pattern through mechanisms like Elastic’s <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-function-score-query.html">function score queries</a>, enabling explicit weighting of freshness, popularity, or source fields during re-ranking.</p>
  </li>
  <li>
    <p>Metadata-based approaches are frequently combined with neural re-rankers rather than used in isolation. For example, a cross-encoder or instruction-following re-ranker may first score semantic relevance, after which metadata-based adjustments enforce hard or soft constraints on ordering. This hybrid strategy reflects best practices described in modern RAG system design discussions, including <a href="https://www.pinecone.io/learn/hybrid-search/">Introducing the hybrid index to enable keyword-aware semantic search</a> by Pinecone.</p>
  </li>
  <li>
    <p>Within RAG pipelines, metadata-based re-rankers often serve as a policy-enforcement layer, ensuring compliance with business rules and trust requirements while preserving the strengths of neural relevance modeling. When used alongside instruction-following re-rankers, metadata signals can either be encoded directly into instructions or applied as an explicit post-processing step, providing clear separation between semantic relevance and governance constraints.</p>
  </li>
</ul>

<h3 id="response-generation--synthesis">Response Generation / Synthesis</h3>

<ul>
  <li>The last step of the RAG pipeline is to generate responses back to the user. In this step, the model synthesizes the retrieved information with its pre-trained knowledge to generate coherent and contextually relevant responses. This process involves integrating the insights gleaned from various sources, ensuring accuracy and relevance, and crafting a response that is not only informative but also aligns with the user’s original query, maintaining a natural and conversational tone.</li>
  <li>Note that while creating the expanded prompt (with the retrieved top-<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-91-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-941" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-942"><span class="mi" id="MathJax-Span-943" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-91">k</script> chunks) for an LLM to make an informed response generation, a strategic placement of vital information at the beginning or end of input sequences could enhance the RAG system’s effectiveness and thus make the system more performant. This is summarized in the paper below.</li>
</ul>

<h4 id="lost-in-the-middle-how-language-models-use-long-contexts"><a href="https://arxiv.org/abs/2302.12345">Lost in the Middle: How Language Models Use Long Contexts</a></h4>
<ul>
  <li>While recent language models have the ability to take long contexts as input, relatively little is known about how well the language models use longer context.</li>
  <li>This paper by Liu et al. from Percy Liang’s lab at Stanford, UC Berkeley, and Samaya AI analyzes language model performance on two tasks that require identifying relevant information within their input contexts: multi-document question answering and key-value retrieval. Put simply, they analyze and evaluate how LLMs use the context by identifying relevant information within it.</li>
  <li>They tested open-source (MPT-30B-Instruct, LongChat-13B) and closed-source (OpenAI’s GPT-3.5-Turbo and Anthropic’s Claude 1.3) models. They used multi-document question-answering where the context included multiple retrieved documents and one correct answer, whose position was shuffled around. Key-value pair retrieval was carried out to analyze if longer contexts impact performance.</li>
  <li>They find that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts. In other words, their findings basically suggest that Retrieval-Augmentation (RAG) performance suffers when the relevant information to answer a query is presented in the middle of the context window with strong biases towards the beginning and the end of it.</li>
  <li>A summary of their learnings is as follows:
    <ul>
      <li>Best performance when the relevant information is at the beginning.</li>
      <li>Performance decreases with an increase in context length.</li>
      <li>Too many retrieved documents harm performance.</li>
      <li>Improving the retrieval and prompt creation step with a ranking stage could potentially boost performance by up to 20%.</li>
      <li>Extended-context models (GPT-3.5-Turbo vs. GPT-3.5-Turbo (16K)) are not better if the prompt fits the original context.</li>
    </ul>
  </li>
  <li>Considering that RAG retrieves information from an external database – which most commonly contains longer texts that are split into chunks. Even with split chunks, context windows get pretty large very quickly, at least much larger than a “normal” question or instruction. Furthermore, performance substantially decreases as the input context grows longer, even for explicitly long-context models. Their analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models.</li>
  <li>“There is no specific inductive bias in transformer-based LLM architectures that explains why the retrieval performance should be worse for text in the middle of the document. I suspect it is all because of the training data and how humans write: the most important information is usually in the beginning or the end (think paper Abstracts and Conclusion sections), and it’s then how LLMs parameterize the attention weights during training.” <a href="https://www.linkedin.com/feed/update/urn:li:activity:7083427280605089792/">(source)</a></li>
  <li>In other words, human text artifacts are often constructed in a way where the beginning and the end of a long text matter the most which could be a potential explanation to the characteristics observed in this work.</li>
  <li>You can also model this with the lens of two popular cognitive biases that humans face (primacy and recency bias), as in the following figure <a href="https://www.linkedin.com/feed/update/urn:li:activity:7083438672196362240/">(source)</a>.</li>
</ul>

<p><img src="../../../images/papers/LostMiddle2.jpeg" alt=""></p>

<ul>
  <li>The final conclusion is that combining retrieval with ranking (as in recommender systems) should yield the best performance in RAG for question answering.</li>
  <li>The following figure <a href="https://www.linkedin.com/feed/update/urn:li:activity:7083427280605089792/">(source)</a> shows an overview of the idea proposed in the paper: “LLMs are better at using info at beginning or end of input context”.</li>
</ul>

<p><img src="../../../images/papers/LostMiddle1.jpg" alt=""></p>

<ul>
  <li>The following figure from the paper illustrates the effect of changing the position of relevant information (document containing the answer) on multidocument question answering performance. Lower positions are closer to the start of the input context. Performance is generally highest when relevant information is positioned at the very start or very end of the context, and rapidly degrades when models must reason over information in the middle of their input context.</li>
</ul>

<p><img src="../../../images/papers/LostMiddle.jpg" alt=""></p>

<h4 id="the-needle-in-a-haystack-test">The “Needle in a Haystack” Test</h4>

<ul>
  <li>To understand the in-context retrieval ability of long-context LLMs over various parts of their prompt, a simple ‘needle in a haystack’ analysis could be conducted. This method involves embedding specific, targeted information (the ‘needle’) within a larger, more complex body of text (the ‘haystack’). The purpose is to test the LLM’s ability to identify and utilize this specific piece of information amidst a deluge of other data.</li>
  <li>In practical terms, the analysis could involve inserting a unique fact or data point into a lengthy, seemingly unrelated text. The LLM would then be tasked with tasks or queries that require it to recall or apply this embedded information. This setup mimics real-world situations where essential details are often buried within extensive content, and the ability to retrieve such details is crucial.</li>
  <li>The experiment could be structured to assess various aspects of the LLM’s performance. For instance, the placement of the ‘needle’ could be varied—early, middle, or late in the text—to see if the model’s retrieval ability changes based on information location. Additionally, the complexity of the surrounding ‘haystack’ can be modified to test the LLM’s performance under varying degrees of contextual difficulty. By analyzing how well the LLM performs in these scenarios, insights can be gained into its in-context retrieval capabilities and potential areas for improvement.</li>
  <li>This can be accomplished using the <a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack">Needle In A Haystack</a> library. The following plot shows OpenAI’s GPT-4-128K’s (top) and (bottom) performance with varying context length.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/GPT4_haystack.jpg" alt=""></p>

<p><img src="/primers/ai/assets/RAG/Claude_haystack.jpg" alt=""></p>

<ul>
  <li>The following figure <a href="https://www.anthropic.com/index/claude-2-1">(source)</a> shows Claude 2.1’s long context question answering errors based on the areas of the prompt context length. On an average, Claude 2.1 demonstrated a 30% reduction in incorrect answers compared to Claude 2.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/Claude_context.jpg" alt=""></p>

<ul>
  <li>However, in Anthropic’s <a href="https://www.anthropic.com/index/claude-2-1-prompting">Long context prompting for Claude 2.1</a> blog, Anthropic noted that adding “Here is the most relevant sentence in the context:” to the start of Claude’s response raised the score from 27% to 98% on the original evaluation! The figure below from the blog shows that Claude 2.1’s performance when retrieving an individual sentence across its full 200K token context window. This experiment uses the aforementioned prompt technique to guide Claude in recalling the most relevant sentence.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/Claude_haystack1.jpg" alt=""></p>

<h2 id="rag-in-multi-turn-chatbots-embedding-queries-for-retrieval">RAG in Multi-Turn Chatbots: Embedding Queries for Retrieval</h2>

<ul>
  <li>
    <p>In multi-turn chatbot environments, RAG must extend beyond addressing isolated, single-turn queries. Conversations are inherently dynamic—context accumulates, user objectives evolve, and intent may shift subtly across multiple interactions. This dynamic nature renders one design decision particularly critical: determining which input text should be embedded during the retrieval phase. This decision has a direct impact on both the relevance of the retrieved content and the overall quality of the generated response.</p>
  </li>
  <li>
    <p>In contrast to single-turn systems, where embedding the current user input may suffice, multi-turn RAG systems face a more fluid and complex challenge. Limiting retrieval inputs to only the most recent user message is computationally efficient but often insufficient for capturing the nuances of ongoing discourse. Incorporating recent conversational turns offers improved contextual grounding, while advanced techniques such as summarization and query rewriting can significantly enhance retrieval precision.</p>
  </li>
  <li>
    <p>There is no universally optimal approach—the most suitable strategy depends on factors such as the application’s specific requirements, available computational resources, and tolerance for system complexity. Nevertheless, the most robust implementations often adopt a layered methodology: integrating recent dialogue context, monitoring evolving user intent, and utilizing reformulated or enriched queries. This composite approach typically results in more accurate, contextually appropriate retrieval and, consequently, more coherent and effective responses.</p>
  </li>
  <li>
    <p>The following sections outlines the key strategies and considerations for query embedding in multi-turn RAG chatbot systems.</p>
  </li>
</ul>

<h3 id="embedding-the-latest-user-turn-only">Embedding the Latest User Turn Only</h3>

<ul>
  <li>The simplest approach is to embed just the latest user message. For example, if a user says, “What are the symptoms of Lyme disease?”, that exact sentence is passed to the retriever for embedding.</li>
  <li><strong>Pros</strong>:
    <ul>
      <li>Fast and computationally cheap.</li>
      <li>Reduces the risk of embedding irrelevant or stale context.</li>
    </ul>
  </li>
  <li><strong>Cons</strong>:
    <ul>
      <li>Ignores conversational context and prior turns, which may contain critical disambiguating details (e.g., “Is it common in dogs?” following a discussion about pets).</li>
    </ul>
  </li>
</ul>

<h3 id="embedding-concatenated-recent-turns-truncated-dialogue-history">Embedding Concatenated Recent Turns (Truncated Dialogue History)</h3>

<ul>
  <li>A more nuanced approach involves embedding the current user message along with a sliding window of recent turns (usually alternating user and assistant messages).</li>
  <li>For example:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code7"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code7">User: My dog has been acting strange lately.
Assistant: Can you describe the symptoms?
User: He’s tired, limping, and has a fever. Could it be Lyme disease?
</code></pre></div>    </div>
    <ul>
      <li>The retriever input would include all or part of the above.</li>
    </ul>
  </li>
  <li><strong>Pros</strong>:
    <ul>
      <li>Preserves immediate context that can significantly improve retrieval relevance.</li>
      <li>Especially useful for resolving pronouns and follow-up queries.</li>
    </ul>
  </li>
  <li><strong>Cons</strong>:
    <ul>
      <li>Can dilute the focus of the query if too many irrelevant prior turns are included.</li>
      <li>Risk of exceeding input length limits for embedding models.</li>
    </ul>
  </li>
</ul>

<h3 id="embedding-a-condensed-or-summarized-history">Embedding a Condensed or Summarized History</h3>

<ul>
  <li>In this strategy, prior turns are summarized into a condensed form before concatenation with the current turn. This reduces token count while preserving key context.</li>
  <li>Can be achieved using simple heuristics, hand-written rules, or another lightweight LLM summarization pass.</li>
  <li>For example:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code8"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code8">Condensed history: The user is concerned about their dog's health, showing signs of fatigue and limping.
Current query: Could it be Lyme disease?
</code></pre></div>    </div>
    <ul>
      <li>Embed the concatenated string: “The user is concerned… Could it be Lyme disease?”</li>
    </ul>
  </li>
  <li><strong>Pros</strong>:
    <ul>
      <li>Retains relevant prior context while minimizing noise.</li>
      <li>Helps improve retrieval accuracy for ambiguous follow-up questions.</li>
    </ul>
  </li>
  <li><strong>Cons</strong>:
    <ul>
      <li>Requires additional processing and potential summarization latency.</li>
      <li>Summarization quality can affect retrieval quality.</li>
    </ul>
  </li>
</ul>

<h3 id="embedding-structured-dialogue-state">Embedding Structured Dialogue State</h3>

<ul>
  <li>This approach formalizes the conversation history into a structured format (like intent, entities, or user goals), which is then appended to the latest query before embedding.</li>
  <li>For instance:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code9"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code9">[Intent: Diagnose pet illness] [Entity: Dog] [Symptoms: fatigue, limping, fever]
Query: Could it be Lyme disease?
</code></pre></div>    </div>
  </li>
  <li><strong>Pros</strong>:
    <ul>
      <li>Allows precision targeting of relevant documents, especially in domain-specific applications.</li>
      <li>Supports advanced reasoning by aligning with KBs or ontology-driven retrieval.</li>
    </ul>
  </li>
  <li><strong>Cons</strong>:
    <ul>
      <li>Requires reliable NLU and state-tracking pipelines.</li>
      <li>Adds system complexity.</li>
    </ul>
  </li>
</ul>

<h3 id="task-optimized-embedding-via-query-reformulation">Task-Optimized Embedding Via Query Reformulation</h3>

<ul>
  <li>Some systems apply a query rewriting model that reformulates the latest turn into a fully self-contained question, suitable for retrieval.</li>
  <li>For example, turning “What about dogs?” into “What are the symptoms of Lyme disease in dogs?”</li>
  <li>These reformulated queries are then embedded for retrieval.</li>
  <li><strong>Pros</strong>:
    <ul>
      <li>Ensures clarity and focus in queries passed to the retriever.</li>
      <li>Significantly boosts retrieval performance in ambiguous or shorthand follow-ups.</li>
    </ul>
  </li>
  <li><strong>Cons</strong>:
    <ul>
      <li>Introduces dependency on a high-quality rewrite model.</li>
      <li>Risk of introducing hallucination or incorrect reformulations.</li>
    </ul>
  </li>
</ul>

<h3 id="best-practices-and-considerations">Best Practices and Considerations</h3>

<ul>
  <li><strong>Window Size</strong>: Most systems use a sliding window of 1-3 previous turns depending on token limits and task specificity.</li>
  <li><strong>Query Length vs. Clarity Tradeoff</strong>: Longer queries with more context may capture nuance but risk introducing noise. Condensed or reformulated queries can help mitigate this.</li>
  <li><strong>Personalization</strong>: In some advanced setups, user profiles or long-term memory can be injected into the retrieval query, but this must be carefully curated to avoid privacy or relevance pitfalls.</li>
  <li><strong>System Goals</strong>: If the chatbot is task-oriented (e.g., booking travel), structured state may be best. If it is open-domain (e.g., a virtual assistant), concatenated dialogue or rewrite strategies tend to perform better.</li>
</ul>

<h2 id="component-wise-evaluation">Component-Wise Evaluation</h2>

<ul>
  <li>Component-wise evaluation in RAG systems for LLMs involves assessing individual components of the system separately. This approach typically examines the performance of the retrieval component, which fetches relevant information from a database or corpus, and the generation component, which synthesizes responses based on the retrieved data. By evaluating these components individually, researchers can identify specific areas for improvement in the overall RAG system, leading to more efficient and accurate information retrieval and response generation in LLMs.</li>
  <li>While metrics such as Context Precision, Context Recall, and Context Relevance provide insights into the performance of the retrieval component of the RAG system, Groundedness, and Answer Relevance offer a view into the quality of the generation.</li>
  <li>Specifically,
    <ul>
      <li><strong>Metrics to evaluate retrieval:</strong> Context Relevance, Context Recall, and Context Precision, which collectively assess the relevance, completeness, and accuracy of the information retrieved in response to a user’s query. Context Precision focuses on the system’s ability to rank relevant items higher, Context Recall evaluates how well the system retrieves all relevant parts of the context, and Context Relevance measures the alignment of retrieved information with the user’s query. These metrics ensure the effectiveness of the retrieval system in providing the most relevant and complete context for generating accurate responses.</li>
      <li><strong>Metrics to evaluate generation:</strong> Faithfulness and Answer Relevance, which measure the factual consistency of the generated answer with the given context and its relevance to the original question, respectively. Faithfulness focuses on the factual accuracy of the answer, ensuring all claims made can be inferred from the given context. Answer Relevance assesses how well the answer addresses the original question, penalizing incomplete or redundant responses. These metrics ensure the generation component produces contextually appropriate and semantically relevant answers.</li>
    </ul>
  </li>
  <li>The harmonic mean of these four aspects gives you the overall score (also called ragas score) which is a single measure of the performance of your RAG system across all the important aspects.</li>
  <li>Most of the measurements do not require any labeled data, making it easier for users to run it without worrying about building a human-annotated test dataset first. In order to run ragas all you need is a few questions and if your using context_recall, a reference answer.</li>
  <li>Overall, these metrics offer a comprehensive view of the RAG system’s retrieval performance, which can be implemented using libraries for evaluating RAG pipelines such as <a href="https://ragas.io/">Ragas</a> or <a href="https://www.trulens.org/">TruLens</a> and offer detailed insights about your RAG pipeline’s performance, focusing on the contextual and factual alignment of retrieved and generated content in response to user queries. Specifically, <a href="https://docs.ragas.io/en/latest/concepts/metrics/index.html">Ragas</a>, offers metrics tailored for evaluating each component of your RAG pipeline in isolation. This approach complements the broader, system-level end-to-end evaluation of your system (which is detailed in <a href="#end-to-end-evaluation">End-to-End Evaluation</a>), allowing for a deeper understanding of how well a RAG system performs in real-world scenarios where the intricacies of context and factual accuracy are paramount. The figure below <a href="https://docs.ragas.io/en/latest/concepts/metrics/index.html">(source)</a> shows the metrics that Ragas offers which are tailored for evaluating each component (retrieval, generation) of your RAG pipeline in isolation.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/RAGAS_Metrics.jpg" alt=""></p>

<ul>
  <li>The image below <a href="https://learn.deeplearning.ai/building-evaluating-advanced-rag/lesson/2/advanced-rag-pipeline">(source)</a>, shows the “triad” of metrics that can be used to evaluate RAG: Groundedness (also known as Faithfulness), Answer Relevance, and Context Relevance. Note that Context Precision and Context Recall are also important and were more recently introduced in a newer version of <a href="https://docs.ragas.io/en/latest/concepts/metrics/index.html">Ragas</a>.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/5.png" alt=""></p>

<h3 id="retrieval-metrics">Retrieval Metrics</h3>

<ul>
  <li>Evaluating the retrieval component of RAG in the context of LLMs involves assessing how effectively the system retrieves relevant information to support the generation of accurate and contextually appropriate responses.</li>
</ul>

<h4 id="context-precision">Context Precision</h4>

<ul>
  <li>
    <p><strong>Definition</strong>: Context Precision is a metric used to assess the accuracy of ranking ground-truth relevant items from the context higher in the results. It measures whether all the relevant chunks of information appear at the top ranks when responding to a query. Ideally all the relevant chunks must appear at the top ranks. The metric is scored between 0 and 1 using the question, ground truth, and the contexts, with higher scores indicating better precision.</p>
  </li>
  <li><strong>Evaluation Approach</strong>: Context Precision is calculated using the following steps:
    <ol>
      <li>For each chunk in the retrieved context, determine if it is relevant or not relevant based on the ground truth for the given question.</li>
      <li>
        <p>Compute Precision@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-92-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-944" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-945"><span class="mi" id="MathJax-Span-946" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-92">k</script> for each chunk in the context using the formula:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-93-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Precision@k&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;true positives@k&lt;/mtext&gt;&lt;mrow&gt;&lt;mtext&gt;true positives@k&lt;/mtext&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mtext&gt;false positives@k&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-947" style="width: 26.148em; display: inline-block;"><span style="display: inline-block; position: relative; width: 21.773em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1021.77em, 3.232em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-948"><span class="mtext" id="MathJax-Span-949" style="font-family: STIXGeneral-Regular;">Precision@k</span><span class="mo" id="MathJax-Span-950" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-951" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 15.211em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1006.77em, 4.378em, -999.997em); top: -4.685em; left: 50%; margin-left: -3.383em;"><span class="mtext" id="MathJax-Span-952" style="font-family: STIXGeneral-Regular;">true positives@k</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1015.11em, 4.378em, -999.997em); top: -3.331em; left: 50%; margin-left: -7.549em;"><span class="mrow" id="MathJax-Span-953"><span class="mtext" id="MathJax-Span-954" style="font-family: STIXGeneral-Regular;">true positives@k</span><span class="mo" id="MathJax-Span-955" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">+</span><span class="mtext" id="MathJax-Span-956" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">false positives@k</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1015.21em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 15.211em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.122em; border-left: 0px solid; width: 0px; height: 2.878em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Precision@k</mtext><mo>=</mo><mfrac><mtext>true positives@k</mtext><mrow><mtext>true positives@k</mtext><mo>+</mo><mtext>false positives@k</mtext></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-93">\text{Precision@k} = \frac{\text{true positives@k}}{\text{true positives@k} + \text{false positives@k}}</script>
      </li>
      <li>
        <p>Calculate the Context Precision@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-94-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-957" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-958"><span class="mi" id="MathJax-Span-959" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-94">k</script> by averaging the Precision@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-95-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-960" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-961"><span class="mi" id="MathJax-Span-962" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-95">k</script> values for all relevant items in the top <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-96-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-963" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-964"><span class="mi" id="MathJax-Span-965" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-96">K</script> results:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-97-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Context Precision@k&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/munderover&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mtext&gt;Precision@k&lt;/mtext&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mtext&gt;Total number of relevant items in the top&amp;#xA0;&lt;/mtext&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mtext&gt;&amp;#xA0;results&lt;/mtext&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-966" style="width: 36.096em; display: inline-block;"><span style="display: inline-block; position: relative; width: 30.055em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.315em, 1030.06em, 3.232em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-967"><span class="mtext" id="MathJax-Span-968" style="font-family: STIXGeneral-Regular;">Context Precision@k</span><span class="mo" id="MathJax-Span-969" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-970" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 20.107em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(2.919em, 1009.95em, 4.482em, -999.997em); top: -4.789em; left: 50%; margin-left: -4.997em;"><span class="mrow" id="MathJax-Span-971"><span class="munderover" id="MathJax-Span-972"><span style="display: inline-block; position: relative; width: 2.138em; height: 0px;"><span style="position: absolute; clip: rect(3.076em, 1000.84em, 4.43em, -999.997em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-973" style="font-family: STIXGeneral-Regular; vertical-align: 0.003em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -4.477em; left: 0.94em;"><span class="mi" id="MathJax-Span-974" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1001.25em, 4.169em, -999.997em); top: -3.695em; left: 0.94em;"><span class="texatom" id="MathJax-Span-975"><span class="mrow" id="MathJax-Span-976"><span class="mi" id="MathJax-Span-977" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-978" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">=</span><span class="mn" id="MathJax-Span-979" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-980" style="font-family: STIXGeneral-Regular;">(</span><span class="mtext" id="MathJax-Span-981" style="font-family: STIXGeneral-Regular;">Precision@k</span><span class="mo" id="MathJax-Span-982" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">×</span><span class="msubsup" id="MathJax-Span-983" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 0.836em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-984" style="font-family: STIXGeneral-Italic;">v</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mi" id="MathJax-Span-985" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-986" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1019.95em, 4.378em, -999.997em); top: -3.331em; left: 50%; margin-left: -9.997em;"><span class="mrow" id="MathJax-Span-987"><span class="mtext" id="MathJax-Span-988" style="font-family: STIXGeneral-Regular;">Total number of relevant items in the top&nbsp;</span><span class="mi" id="MathJax-Span-989" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mtext" id="MathJax-Span-990" style="font-family: STIXGeneral-Regular;">&nbsp;results</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1020.11em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 20.107em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.122em; border-left: 0px solid; width: 0px; height: 3.253em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Context Precision@k</mtext><mo>=</mo><mfrac><mrow><munderover><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mo stretchy="false">(</mo><mtext>Precision@k</mtext><mo>×</mo><msub><mi>v</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mtext>Total number of relevant items in the top&nbsp;</mtext><mi>k</mi><mtext>&nbsp;results</mtext></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-97">\text{Context Precision@k} = \frac{\sum_{k=1}^K (\text{Precision@k} \times v_k)}{\text{Total number of relevant items in the top } k \text{ results}}</script>

        <ul>
          <li>where <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-98-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-991" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-992"><span class="mi" id="MathJax-Span-993" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-98">k</script> is the total number of chunks in contexts and <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-99-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;{&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;}&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-994" style="width: 5.419em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.482em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1004.38em, 2.555em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-995"><span class="msubsup" id="MathJax-Span-996"><span style="display: inline-block; position: relative; width: 0.836em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-997" style="font-family: STIXGeneral-Italic;">v</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mi" id="MathJax-Span-998" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-999" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∈</span><span class="mo" id="MathJax-Span-1000" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">{</span><span class="mn" id="MathJax-Span-1001" style="font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-1002" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-1003" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">1</span><span class="mo" id="MathJax-Span-1004" style="font-family: STIXGeneral-Regular;">}</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>v</mi><mi>k</mi></msub><mo>∈</mo><mo fence="false" stretchy="false">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo fence="false" stretchy="false">}</mo></math></span></span><script type="math/tex" id="MathJax-Element-99">v_k \in \{0,1\}</script> is the relevance indicator at rank <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-100-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1005" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1006"><span class="mi" id="MathJax-Span-1007" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-100">k</script>.</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>
    <p><strong>Example</strong> <a href="https://docs.ragas.io/en/latest/concepts/metrics/context_precision.html">(source)</a>: Let’s consider an example of calculating context precision using a question and its corresponding ground truth.</p>

    <ul>
      <li><strong>Question</strong>: Where is France and what is its capital?</li>
      <li><strong>Ground Truth</strong>: France is in Western Europe, and its capital is Paris.</li>
      <li><strong>High Context Precision Example</strong>:
        <ul>
          <li>Contexts: <code class="language-plaintext highlighter-rouge">["France, in Western Europe, encompasses medieval cities, alpine villages, and Mediterranean beaches. Paris, its capital, is famed for its fashion houses, classical art museums including the Louvre and monuments like the Eiffel Tower", "The country is also renowned for its wines and sophisticated cuisine. Lascaux's ancient cave drawings, Lyon's Roman theater and the vast Palace of Versailles attest to its rich history."]</code></li>
        </ul>
      </li>
      <li><strong>Low Context Precision Example</strong>:
        <ul>
          <li>Contexts: <code class="language-plaintext highlighter-rouge">["The country is also renowned for its wines and sophisticated cuisine. Lascaux's ancient cave drawings, Lyon's Roman theater and", "France, in Western Europe, encompasses medieval cities, alpine villages, and Mediterranean beaches. Paris, its capital, is famed for its fashion houses, classical art museums including the Louvre and monuments like the Eiffel Tower"]</code></li>
        </ul>
      </li>
      <li>In this example, the calculation of context precision involves identifying relevant chunks related to the question and their ranking in the contexts. For the low context precision example:
        <ul>
          <li><strong>Precision@1</strong> = <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-101-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1008" style="width: 0.836em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.096em, 1000.68em, 2.659em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1009"><span class="mfrac" id="MathJax-Span-1010"><span style="display: inline-block; position: relative; width: 0.471em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -0.154em;"><span class="mn" id="MathJax-Span-1011" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.154em;"><span class="mn" id="MathJax-Span-1012" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1000.47em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.471em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>0</mn><mn>1</mn></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-101">\frac{0}{1}</script> = 0</li>
          <li><strong>Precision@2</strong> = <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-102-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1013" style="width: 0.836em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.096em, 1000.68em, 2.659em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1014"><span class="mfrac" id="MathJax-Span-1015"><span style="display: inline-block; position: relative; width: 0.471em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -0.154em;"><span class="mn" id="MathJax-Span-1016" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.154em;"><span class="mn" id="MathJax-Span-1017" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1000.47em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.471em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.628em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>1</mn><mn>2</mn></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-102">\frac{1}{2}</script> = 0.5</li>
          <li><strong>Context Precision</strong> = <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-103-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1018" style="width: 3.023em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.503em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.94em, 1002.5em, 2.659em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1019"><span class="mfrac" id="MathJax-Span-1020"><span style="display: inline-block; position: relative; width: 2.294em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.388em, 1002.14em, 4.273em, -999.997em); top: -4.529em; left: 50%; margin-left: -1.091em;"><span class="mrow" id="MathJax-Span-1021"><span class="mo" id="MathJax-Span-1022" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-1023" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0</span><span class="mo" id="MathJax-Span-1024" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-1025" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">0.5</span><span class="mo" id="MathJax-Span-1026" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.154em;"><span class="mn" id="MathJax-Span-1027" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1002.29em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.294em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.816em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mrow><mo stretchy="false">(</mo><mn>0</mn><mo>+</mo><mn>0.5</mn><mo stretchy="false">)</mo></mrow><mn>1</mn></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-103">\frac{(0 + 0.5)}{1}</script> = 0.5</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="context-recall">Context Recall</h4>

<ul>
  <li>
    <p><strong>Definition</strong>: Context Recall measures how well the retrieved context aligns with the annotated answer, treated as the ground truth. This metric is essential for assessing the accuracy of the retrieval system in identifying and ranking relevant information. It evaluate the performance of the retrieval system in identifying relevant information based on a sample query and its corresponding ground truth answer. The context recall score helps in understanding how much of the ground truth information is accurately retrieved from the context. The context recall score ranges from 0 to 1, with higher values indicating better performance.</p>
  </li>
  <li>
    <p><strong>Evaluation Approach</strong>: To estimate context recall, each sentence in the ground truth answer is analyzed to determine whether it can be attributed to the retrieved context. The ideal scenario is when all sentences in the ground truth answer are attributable to the retrieved context. The formula used for calculating context recall is:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-104-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Context Recall&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;mtext&gt;GT sentences attributable to context&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;mtext&gt;Total sentences in GT&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1028" style="width: 27.034em; display: inline-block;"><span style="display: inline-block; position: relative; width: 22.503em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1022.5em, 3.232em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1029"><span class="mtext" id="MathJax-Span-1030" style="font-family: STIXGeneral-Regular;">Context Recall</span><span class="mo" id="MathJax-Span-1031" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1032" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 15.107em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1014.9em, 4.378em, -999.997em); top: -4.685em; left: 50%; margin-left: -7.497em;"><span class="mrow" id="MathJax-Span-1033"><span class="mo" id="MathJax-Span-1034" style="font-family: STIXGeneral-Regular;">∣</span><span class="mtext" id="MathJax-Span-1035" style="font-family: STIXGeneral-Regular;">GT sentences attributable to context</span><span class="mo" id="MathJax-Span-1036" style="font-family: STIXGeneral-Regular;">∣</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1009.22em, 4.378em, -999.997em); top: -3.331em; left: 50%; margin-left: -4.685em;"><span class="mrow" id="MathJax-Span-1037"><span class="mo" id="MathJax-Span-1038" style="font-family: STIXGeneral-Regular;">∣</span><span class="mtext" id="MathJax-Span-1039" style="font-family: STIXGeneral-Regular;">Total sentences in GT</span><span class="mo" id="MathJax-Span-1040" style="font-family: STIXGeneral-Regular;">∣</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1015.11em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 15.107em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.122em; border-left: 0px solid; width: 0px; height: 2.816em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Context Recall</mtext><mo>=</mo><mfrac><mrow><mo stretchy="false">∣</mo><mtext>GT sentences attributable to context</mtext><mo stretchy="false">∣</mo></mrow><mrow><mo stretchy="false">∣</mo><mtext>Total sentences in GT</mtext><mo stretchy="false">∣</mo></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-104">\text{Context Recall} = \frac{\mid \text{GT sentences attributable to context} \mid}{\mid \text{Total sentences in GT} \mid}</script>
  </li>
  <li>
    <p><strong>Example</strong> <a href="https://docs.ragas.io/en/latest/concepts/metrics/context_recall.html">(source)</a>:</p>
    <ul>
      <li>Ground Truth Question: “Where is France and what is its capital?”</li>
      <li>
        <p>Ground Truth Answer: “France is in Western Europe and its capital is Paris.”</p>
      </li>
      <li><strong>High Context Recall Example</strong>:
        <ul>
          <li>Retrieved Context: “France, in Western Europe, encompasses medieval cities, alpine villages, and Mediterranean beaches. Paris, its capital, is famed for its fashion houses, classical art museums including the Louvre, and monuments like the Eiffel Tower.”</li>
        </ul>
      </li>
      <li><strong>Low Context Recall Example</strong>:
        <ul>
          <li>Retrieved Context: “France, in Western Europe, encompasses medieval cities, alpine villages, and Mediterranean beaches. The country is also renowned for its wines and sophisticated cuisine. Lascaux’s ancient cave drawings, Lyon’s Roman theater, and the vast Palace of Versailles attest to its rich history.”</li>
        </ul>
      </li>
      <li><strong>Calculation</strong>:
        <ul>
          <li><strong>Step 1</strong>: Break the ground truth answer into individual statements:
            <ul>
              <li>Statement 1: “France is in Western Europe.”</li>
              <li>Statement 2: “Its capital is Paris.”</li>
            </ul>
          </li>
          <li><strong>Step 2</strong>: Verify if each ground truth statement can be attributed to the retrieved context:
            <ul>
              <li>Statement 1: Yes (in both high and low context recall examples)</li>
              <li>Statement 2: No (in the low context recall example)</li>
            </ul>
          </li>
          <li>
            <p><strong>Step 3</strong>: Calculate context recall using the formula:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-105-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Context Recall&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mspace width=&quot;1em&quot; /&gt;&lt;mtext&gt;(for the low context recall example)&lt;/mtext&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1041" style="width: 31.148em; display: inline-block;"><span style="display: inline-block; position: relative; width: 25.94em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1025.89em, 3.023em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1042"><span class="mtext" id="MathJax-Span-1043" style="font-family: STIXGeneral-Regular;">Context Recall</span><span class="mo" id="MathJax-Span-1044" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1045" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 0.628em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-1046" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-1047" style="font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1000.63em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.628em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-1048" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-1049" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.5</span><span class="mspace" id="MathJax-Span-1050" style="height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-1051" style="font-family: STIXGeneral-Regular;">(for the low context recall example)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.872em; border-left: 0px solid; width: 0px; height: 2.566em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Context Recall</mtext><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>=</mo><mn>0.5</mn><mspace width="1em"></mspace><mtext>(for the low context recall example)</mtext></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-105">\text{Context Recall} = \frac{1}{2} = 0.5 \quad \text{(for the low context recall example)}</script>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="context-relevance">Context Relevance</h4>

<ul>
  <li><strong>Definition</strong>:
    <ul>
      <li>“Is the passage returned relevant for answering the given query?”</li>
      <li>Measures how well the context retrieved by the RAG system aligns with the user’s query. It specifically evaluates whether the retrieved information is relevant and appropriate for the given query, ensuring that only essential information is included to address the query effectively.</li>
    </ul>
  </li>
  <li><strong>Evaluation Approach</strong>: Involves a two-step procedure: first, the identification of relevant sentences using semantic similarity measures to produce a relevance score for each sentence. Can be measured with smaller BERT-style models, embedding distances, or with LLMs. The approach involves estimating the value of context relevance by identifying sentences within the retrieved context that are directly relevant for answering the given question. This is followed by the quantification of overall context relevance, where the final score is calculated using the formula:</li>
</ul>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display"><span class="MathJax MathJax_FullWidth" id="MathJax-Element-106-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Context Relevance&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;&amp;#xA0;Number of sentences that are relevant to the query within the retrieved context&lt;/mtext&gt;&lt;mtext&gt;&amp;#xA0;Total number of sentences in retrieved context&lt;/mtext&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1052" style="width: 100%; display: inline-block; min-width: 39.69em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(3.44em, 1033.08em, 6.982em, -999.997em); top: -4.268em; left: 0em; width: 100%;"><span class="mrow" id="MathJax-Span-1053"><span style="display: inline-block; position: relative; width: 100%; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1007.55em, 4.169em, -999.997em); top: -4.008em; left: 50%; margin-left: -3.799em;"><span class="mtext" id="MathJax-Span-1054" style="font-family: STIXGeneral-Regular;">Context Relevance</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(2.503em, 1033.08em, 4.846em, -999.997em); top: -2.133em; left: 50%; margin-left: -16.508em;"><span class="mo" id="MathJax-Span-1055" style="font-family: STIXGeneral-Regular;">=</span><span class="mfrac" id="MathJax-Span-1056" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 31.826em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1031.67em, 4.378em, -999.997em); top: -4.685em; left: 50%; margin-left: -15.831em;"><span class="mtext" id="MathJax-Span-1057" style="font-family: STIXGeneral-Regular;">&nbsp;Number of sentences that are relevant to the query within the retrieved context</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1018.86em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -9.424em;"><span class="mtext" id="MathJax-Span-1058" style="font-family: STIXGeneral-Regular;">&nbsp;Total number of sentences in retrieved context</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1031.83em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 31.826em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.273em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -3.122em; border-left: 0px solid; width: 0px; height: 4.003em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Context Relevance</mtext><mo>=</mo><mfrac><mtext>&nbsp;Number of sentences that are relevant to the query within the retrieved context</mtext><mtext>&nbsp;Total number of sentences in retrieved context</mtext></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-106">\text {Context Relevance} = \frac{\text { Number of sentences that are relevant to the query within the retrieved context}}{\text { Total number of sentences in retrieved context}}</script>

<ul>
  <li><strong>Examples</strong>:
    <ul>
      <li><em>High context relevance example</em>: For a question like “What is the capital of France?”, a highly relevant context would be “France, in Western Europe, encompasses medieval cities, alpine villages and Mediterranean beaches. Paris, its capital, is famed for its fashion houses, classical art museums including the Louvre and monuments like the Eiffel Tower.”</li>
      <li><em>Low context relevance example</em>: For the same question, a less relevant context would include additional, unrelated information such as “The country is also renowned for its wines and sophisticated cuisine. Lascaux’s ancient cave drawings, Lyon’s Roman theater and the vast Palace of Versailles attest to its rich history.”</li>
    </ul>
  </li>
  <li>This metric ensures that the RAG system provides concise and directly related information, enhancing the efficiency and accuracy of the response given to a specific query.</li>
</ul>

<h3 id="generation-metrics">Generation Metrics</h3>

<ul>
  <li>Evaluating the generation component of RAG in the context of LLMs involves assessing the ability of the system to seamlessly integrate retrieved information into coherent, contextually relevant, and linguistically accurate responses, ensuring a harmonious blend of retrieved data and generative language skills. Put simply, these metrics collectively provide a nuanced and multidimensional approach to evaluating RAG systems, emphasizing not just the retrieval of information but its contextual relevance, factual accuracy, and semantic alignment with user queries.</li>
</ul>

<h4 id="groundedness-aka-faithfulness">Groundedness (a.k.a. Faithfulness)</h4>

<ul>
  <li><strong>Definition</strong>: Groundedness (also known as Faithfulness) evaluates the factual consistency of a generated answer against a given context. It is measured based on the alignment between the answer and the retrieved context, with scores ranging from 0 to 1. A higher score indicates better factual consistency.</li>
  <li><strong>Evaluation Approach</strong>:
    <ul>
      <li>The faithfulness of a generated answer is determined by checking if all the atomic (stand-alone) claims made in the answer can be inferred from the provided context. The process involves identifying a set of atomic claims from the answer and cross-referencing each claim with the context to confirm if it can be inferred. The faithfulness score is calculated using the formula:</li>
    </ul>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display"><span class="MathJax MathJax_FullWidth" id="MathJax-Element-107-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Faithfulness score&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;Number of claims in the generated answer that can be inferred from the given context&lt;/mtext&gt;&lt;mtext&gt;Total number of claims in the generated answer&lt;/mtext&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1059" style="width: 100%; display: inline-block; min-width: 42.763em;"><span style="display: inline-block; position: relative; width: 100%; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(3.596em, 1035.63em, 7.346em, -999.997em); top: -4.424em; left: 0em; width: 100%;"><span class="mrow" id="MathJax-Span-1060"><span style="display: inline-block; position: relative; width: 100%; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1007.24em, 4.169em, -999.997em); top: -4.008em; left: 50%; margin-left: -3.643em;"><span class="mtext" id="MathJax-Span-1061" style="font-family: STIXGeneral-Regular;">Faithfulness score</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(2.503em, 1035.63em, 5.055em, -999.997em); top: -2.133em; left: 50%; margin-left: -17.81em;"><span class="mo" id="MathJax-Span-1062" style="font-family: STIXGeneral-Regular;">=</span><span class="mfrac" id="MathJax-Span-1063" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 34.378em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1034.27em, 4.378em, -999.997em); top: -4.685em; left: 50%; margin-left: -17.133em;"><span class="mtext" id="MathJax-Span-1064" style="font-family: STIXGeneral-Regular;">Number of claims in the generated answer that can be inferred from the given context</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1019.07em, 4.378em, -999.997em); top: -3.331em; left: 50%; margin-left: -9.529em;"><span class="mtext" id="MathJax-Span-1065" style="font-family: STIXGeneral-Regular;">Total number of claims in the generated answer</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1034.38em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 34.378em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.43em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -3.372em; border-left: 0px solid; width: 0px; height: 4.253em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Faithfulness score</mtext><mo>=</mo><mfrac><mtext>Number of claims in the generated answer that can be inferred from the given context</mtext><mtext>Total number of claims in the generated answer</mtext></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-107">\text{Faithfulness score} = \frac{\text{Number of claims in the generated answer that can be inferred from the given context}}{\text{Total number of claims in the generated answer}}</script>
  </li>
  <li>
    <p><strong>Example</strong> <a href="https://docs.ragas.io/en/latest/concepts/metrics/faithfulness.html">(source)</a>: 
<em>Question</em>: Where and when was Einstein born?
<em>Context</em>: Albert Einstein (born 14 March 1879) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time.</p>

    <ul>
      <li><strong>High faithfulness answer</strong>: Einstein was born in Germany on 14th March 1879.</li>
      <li>
        <p><strong>Low faithfulness answer</strong>: Einstein was born in Germany on 20th March 1879.</p>
      </li>
      <li>For the low faithfulness answer:
        <ul>
          <li><strong>Step 1</strong>: Break the generated answer into individual statements.
            <ul>
              <li>Statement 1: “Einstein was born in Germany.”</li>
              <li>Statement 2: “Einstein was born on 20th March 1879.”</li>
            </ul>
          </li>
          <li><strong>Step 2</strong>: Verify if each statement can be inferred from the given context.
            <ul>
              <li>Statement 1: Yes</li>
              <li>Statement 2: No</li>
            </ul>
          </li>
          <li>
            <p><strong>Step 3</strong>: Calculate the faithfulness score using the formula.</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-108-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Faithfulness&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1066" style="width: 11.253em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.378em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1009.33em, 3.023em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1067"><span class="mtext" id="MathJax-Span-1068" style="font-family: STIXGeneral-Regular;">Faithfulness</span><span class="mo" id="MathJax-Span-1069" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1070" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 0.628em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-1071" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-1072" style="font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1000.63em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.628em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-1073" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-1074" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.5</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.872em; border-left: 0px solid; width: 0px; height: 2.566em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Faithfulness</mtext><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>=</mo><mn>0.5</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-108">\text{Faithfulness} = \frac{1}{2} = 0.5</script>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="answer-relevance">Answer Relevance</h4>

<ul>
  <li><strong>Definition</strong>:
    <ul>
      <li>The Answer Relevance metric evaluates how closely the generated answer aligns with the given query/prompt. This assessment focuses on the pertinence of the response, penalizing answers that are incomplete or contain redundant information. Higher scores indicate better relevance. The overarching concept behind answer relevance is that if the answer correctly addresses the question, it is likely that the original question can be accurately reconstructed from the answer alone.</li>
      <li>Answer relevance is reference free metric. If you’re looking to compare ground truth answer with generated answer refer to <a href="#answer-correctness">Answer Correctness</a>.</li>
      <li>The image below <a href="https://learn.deeplearning.ai/building-evaluating-advanced-rag/lesson/2/advanced-rag-pipeline">(source)</a> shows the output format of Answer Relevance.</li>
    </ul>

    <p><img src="/primers/ai/assets/RAG/7.png" alt=""></p>
  </li>
  <li><strong>Evaluation Approach</strong>:
    <ul>
      <li>Answer Relevance is quantified by calculating the mean cosine similarity between the original question and a set of generated questions based on the provided answer. Specifically, the metric is defined as follows:</li>
    </ul>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display"><span class="MathJax" id="MathJax-Element-109-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;merror&gt;&lt;mtext&gt;\text{Answer&amp;#xA0;Relevance}&amp;#xA0;=&amp;#xA0;\frac{1}{N}&amp;#xA0;\sum_{i=1}^N&amp;#xA0;\cos&amp;#xA0;(E_{g_i},&amp;#xA0;E_o)&amp;#xA0;\\=&amp;#xA0;\frac{1}{N}&amp;#xA0;\sum_{i=1}^N&amp;#xA0;\frac{E_{g_i}&amp;#xA0;\cdot&amp;#xA0;E_o}{\left\mid&amp;#xA0;E_{g_i}\right\mid&amp;#xA0;\left\mid&amp;#xA0;E_o\right\mid}&lt;/mtext&gt;&lt;/merror&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><span class="math" id="MathJax-Span-1075" aria-hidden="true" style="vertical-align: 0.211em;"><span class="noError" id="MathJax-Span-1076" style="display: inline-block;">\text{Answer&nbsp;Relevance}&nbsp;=&nbsp;\frac{1}{N}&nbsp;\sum_{i=1}^N&nbsp;\cos&nbsp;(E_{g_i},&nbsp;E_o)&nbsp;\\<br>=&nbsp;\frac{1}{N}&nbsp;\sum_{i=1}^N&nbsp;\frac{E_{g_i}&nbsp;\cdot&nbsp;E_o}{\left\mid&nbsp;E_{g_i}\right\mid&nbsp;\left\mid&nbsp;E_o\right\mid}</span></span><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><merror><mtext>\text{Answer&nbsp;Relevance}&nbsp;=&nbsp;\frac{1}{N}&nbsp;\sum_{i=1}^N&nbsp;\cos&nbsp;(E_{g_i},&nbsp;E_o)&nbsp;\\=&nbsp;\frac{1}{N}&nbsp;\sum_{i=1}^N&nbsp;\frac{E_{g_i}&nbsp;\cdot&nbsp;E_o}{\left\mid&nbsp;E_{g_i}\right\mid&nbsp;\left\mid&nbsp;E_o\right\mid}</mtext></merror></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-109">\text{Answer Relevance} = \frac{1}{N} \sum_{i=1}^N \cos (E_{g_i}, E_o) \\
= \frac{1}{N} \sum_{i=1}^N \frac{E_{g_i} \cdot E_o}{\left\mid E_{g_i}\right\mid \left\mid E_o\right\mid}</script>

    <ul>
      <li>where:
        <ul>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-110-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1077" style="width: 1.513em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.253em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1001.25em, 2.607em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1078"><span class="msubsup" id="MathJax-Span-1079"><span style="display: inline-block; position: relative; width: 1.253em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1080" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.628em;"><span class="texatom" id="MathJax-Span-1081"><span class="mrow" id="MathJax-Span-1082"><span class="msubsup" id="MathJax-Span-1083"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px;"><span style="position: absolute; clip: rect(3.544em, 1000.32em, 4.326em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1084" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">g</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.367em;"><span class="mi" id="MathJax-Span-1085" style="font-size: 50%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><msub><mi>g</mi><mi>i</mi></msub></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-110">E_{g_i}</script> is the embedding of the generated question <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-111-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1086" style="width: 0.315em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1087"><span class="mi" id="MathJax-Span-1088" style="font-family: STIXGeneral-Italic;">i</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi></math></span></span><script type="math/tex" id="MathJax-Element-111">i</script>.</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-112-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1089" style="width: 1.253em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.044em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1001.04em, 2.451em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1090"><span class="msubsup" id="MathJax-Span-1091"><span style="display: inline-block; position: relative; width: 1.044em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1092" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.628em;"><span class="mi" id="MathJax-Span-1093" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">o</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>E</mi><mi>o</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-112">E_o</script> is the embedding of the original question.</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-113-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1094" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1095"><span class="mi" id="MathJax-Span-1096" style="font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi></math></span></span><script type="math/tex" id="MathJax-Element-113">N</script> is the number of generated questions, typically set to 3 by default.</li>
        </ul>
      </li>
      <li>It is important to note that although the score generally ranges from 0 to 1, it is not strictly limited to this range due to the cosine similarity measure, which can range from -1 to 1. This metric does not rely on a reference answer and is purely focused on the relevance of the generated answer to the original question. If comparing the ground truth answer with the generated answer is required, one should refer to the “answer correctness” metric.</li>
      <li>An answer is considered relevant if it directly and appropriately responds to the original question. This metric does not consider the factual accuracy of the answer but rather penalizes cases where the answer is incomplete or contains unnecessary details. The process involves prompting a Large Language Model (LLM) to generate appropriate questions based on the provided answer and then measuring the mean cosine similarity between these questions and the original question. The idea is that a highly relevant answer should allow the LLM to generate questions that closely align with the original question.</li>
    </ul>
  </li>
  <li><strong>Example</strong>:
    <ul>
      <li><strong>Question</strong>: Where is France and what is its capital?</li>
      <li><strong>Low relevance answer</strong>: France is in Western Europe.</li>
      <li><strong>High relevance answer</strong>: France is in Western Europe and Paris is its capital.</li>
    </ul>
  </li>
  <li><strong>Calculation Steps</strong>:
    <ol>
      <li><strong>Step 1</strong>: Generate <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-114-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1097" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1098"><span class="mi" id="MathJax-Span-1099" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-114">n</script> variants of the question from the provided answer using an LLM. For example:
        <ul>
          <li>Question 1: “In which part of Europe is France located?”</li>
          <li>Question 2: “What is the geographical location of France within Europe?”</li>
          <li>Question 3: “Can you identify the region of Europe where France is situated?”</li>
        </ul>
      </li>
      <li><strong>Step 2</strong>: Calculate the mean cosine similarity between these generated questions and the original question.</li>
    </ol>
  </li>
</ul>

<h4 id="answer-semantic-similarity">Answer Semantic Similarity</h4>

<ul>
  <li><strong>Category</strong>: Answer Quality and Semantic Alignment</li>
  <li><strong>Requirement</strong>: Access to ground truth answers is necessary to evaluate the semantic similarity of generated responses accurately.</li>
  <li><strong>Definition</strong>: Evaluates the degree of semantic similarity between the generated answer by the RAG system and the ground truth. This metric specifically assesses how closely the meaning of the generated answer mirrors that of the ground truth.</li>
  <li><strong>Measurement Methods</strong>: This metric is measured using cross-encoder models designed to calculate the semantic similarity score. These models analyze the semantic content of both the generated answer and the ground truth.</li>
  <li>
    <p><strong>Evaluation Approach</strong>: The approach involves comparing the generated answer with the ground truth to determine the extent of semantic overlap. The semantic similarity is quantified on a scale from 0 to 1, where higher scores indicate a greater alignment between the generated answer and the ground truth. The formula for Answer Semantic Similarity is implicitly based on the evaluation of semantic overlap rather than a direct formula.</p>
  </li>
  <li><strong>BERTScore</strong>:
    <ul>
      <li>Uses contextual embeddings from pre-trained BERT models to match tokens in the candidate and reference text.</li>
      <li>Computes precision, recall, and F1 scores by aligning embeddings based on cosine similarity, capturing nuanced semantic overlap.</li>
    </ul>
  </li>
  <li><strong>MoverScore</strong>:
    <ul>
      <li>Extends BERTScore by incorporating Earth Mover’s Distance (EMD) to assess the minimal semantic “effort” needed to transform one text into another.</li>
      <li>Leverages both contextual embeddings and IDF weighting to emphasize important content over common filler words.</li>
    </ul>
  </li>
  <li><strong>Advantages of MoverScore over BERTScore</strong>:
    <ul>
      <li>Better captures the global semantic flow between texts by considering word importance and distribution, not just local alignment.</li>
      <li>More robust in handling paraphrased or reordered sentences, where BERTScore may undervalue semantic similarity due to token-level matching.</li>
    </ul>
  </li>
  <li><strong>Example</strong>:
    <ul>
      <li><strong>Ground truth</strong>: Albert Einstein’s theory of relativity revolutionized our understanding of the universe.</li>
      <li><strong>High similarity answer</strong>: Einstein’s groundbreaking theory of relativity transformed our comprehension of the cosmos.</li>
      <li><strong>Low similarity answer</strong>: Isaac Newton’s laws of motion greatly influenced classical physics.</li>
    </ul>
  </li>
  <li>In this metric, a higher score reflects a better quality of the generated response in terms of its semantic closeness to the ground truth, indicating a more accurate and contextually relevant answer.</li>
</ul>

<h4 id="bleu-score">BLEU Score</h4>

<ul>
  <li><strong>Category</strong>: N-gram Precision-Based Evaluation</li>
  <li><strong>Requirement</strong>: Access to ground truth references is necessary to evaluate the BLEU score.</li>
  <li><strong>Definition</strong>: BLEU (Bilingual Evaluation Understudy) is a metric that evaluates the quality of text by comparing a candidate translation to one or more reference translations. It measures the precision of n-grams in the candidate text that appear in the reference texts, with a brevity penalty to penalize overly short translations.</li>
  <li><strong>Measurement Methods</strong>: BLEU calculates modified n-gram precision for n-grams up to a specified length (commonly 4). It also applies a brevity penalty to account for short candidate translations that might otherwise score artificially high.</li>
  <li>
    <p><strong>Evaluation Approach</strong>: The BLEU score is computed using the formula:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-115-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;BLEU&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mtext&gt;BP&lt;/mtext&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mi&gt;exp&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;N&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1100" style="width: 17.346em; display: inline-block;"><span style="display: inline-block; position: relative; width: 14.43em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(2.19em, 1014.33em, 5.576em, -999.997em); top: -4.112em; left: 0em;"><span class="mrow" id="MathJax-Span-1101"><span class="mtext" id="MathJax-Span-1102" style="font-family: STIXGeneral-Regular;">BLEU</span><span class="mo" id="MathJax-Span-1103" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mtext" id="MathJax-Span-1104" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">BP</span><span class="mo" id="MathJax-Span-1105" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">×</span><span class="mi" id="MathJax-Span-1106" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">exp</span><span class="mo" id="MathJax-Span-1107"></span><span class="mrow" id="MathJax-Span-1108"><span class="mo" id="MathJax-Span-1109" style="vertical-align: -0.779em;"><span style="font-family: STIXSizeFourSym;">(</span></span><span class="mrow" id="MathJax-Span-1110"><span class="munderover" id="MathJax-Span-1111"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px;"><span style="position: absolute; clip: rect(2.867em, 1001.2em, 4.638em, -999.997em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-1112" style="font-family: STIXSizeOneSym; vertical-align: -0.518em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1001.1em, 4.273em, -999.997em); top: -2.862em; left: 0.055em;"><span class="texatom" id="MathJax-Span-1113"><span class="mrow" id="MathJax-Span-1114"><span class="mi" id="MathJax-Span-1115" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-1116" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">=</span><span class="mn" id="MathJax-Span-1117" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.284em, 1000.52em, 4.169em, -999.997em); top: -5.206em; left: 0.367em;"><span class="texatom" id="MathJax-Span-1118"><span class="mrow" id="MathJax-Span-1119"><span class="mi" id="MathJax-Span-1120" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-1121" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 1.096em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1122" style="font-family: STIXGeneral-Italic;">w</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.68em;"><span class="mi" id="MathJax-Span-1123" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mi" id="MathJax-Span-1124" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">log</span><span class="mo" id="MathJax-Span-1125"></span><span class="msubsup" id="MathJax-Span-1126" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1127" style="font-family: STIXGeneral-Italic;">p</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="mi" id="MathJax-Span-1128" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-1129" style="vertical-align: -0.779em;"><span style="font-family: STIXSizeFourSym;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.117em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.622em; border-left: 0px solid; width: 0px; height: 3.816em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>BLEU</mtext><mo>=</mo><mtext>BP</mtext><mo>×</mo><mi>exp</mi><mo>⁡</mo><mrow><mo>(</mo><mrow><munderover><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>N</mi></mrow></munderover><msub><mi>w</mi><mi>n</mi></msub><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>n</mi></msub></mrow><mo>)</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-115">\text{BLEU} = \text{BP} \times \exp\left( \sum_{n=1}^{N} w_n \log p_n \right)</script>

    <ul>
      <li>where:
        <ul>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-116-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mtext&gt;BP&lt;/mtext&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1130" style="width: 1.461em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.201em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1001.2em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1131"><span class="mtext" id="MathJax-Span-1132" style="font-family: STIXGeneral-Regular;">BP</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>BP</mtext></math></span></span><script type="math/tex" id="MathJax-Element-116">\text{BP}</script> is the brevity penalty.</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-117-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1133" style="width: 1.148em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1000.94em, 2.503em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1134"><span class="msubsup" id="MathJax-Span-1135"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1136" style="font-family: STIXGeneral-Italic;">p</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="mi" id="MathJax-Span-1137" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>p</mi><mi>n</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-117">p_n</script> is the modified n-gram precision.</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-118-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1138" style="width: 1.357em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.096em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1001.1em, 2.451em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1139"><span class="msubsup" id="MathJax-Span-1140"><span style="display: inline-block; position: relative; width: 1.096em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1141" style="font-family: STIXGeneral-Italic;">w</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.68em;"><span class="mi" id="MathJax-Span-1142" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>w</mi><mi>n</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-118">w_n</script> is the weight for each n-gram (typically uniform).</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Example</strong>:
    <ul>
      <li><strong>Reference</strong>: The cat is on the mat.</li>
      <li><strong>Candidate</strong>: The cat is on mat.</li>
      <li><strong>Unigram Precision</strong>: 5 matches out of 5 words = 1.0</li>
      <li><strong>Bigram Precision</strong>: 4 matches out of 4 bigrams = 1.0</li>
      <li><strong>Trigram Precision</strong>: 3 matches out of 3 trigrams = 1.0</li>
      <li><strong>4-gram Precision</strong>: 2 matches out of 2 four-grams = 1.0</li>
      <li><strong>Brevity Penalty</strong>: Applied due to shorter length.</li>
      <li><strong>BLEU Score</strong>: Calculated by combining precisions and brevity penalty.</li>
      <li>In this example, despite high n-gram precision, the brevity penalty reduces the BLEU score to account for the missing word “the” before “mat.”</li>
    </ul>
  </li>
</ul>

<h4 id="rouge-score">ROUGE Score</h4>

<ul>
  <li><strong>Category</strong>: Recall-Oriented N-gram Evaluation</li>
  <li><strong>Requirement</strong>: Access to ground truth references is necessary to evaluate the ROUGE score.</li>
  <li><strong>Definition</strong>: ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is a set of metrics used to evaluate automatic summarization and machine translation by comparing the overlap of n-grams between the candidate and reference texts.</li>
  <li><strong>Measurement Methods</strong>: Common variants include:
    <ul>
      <li><strong>ROUGE-N</strong>: Measures overlap of n-grams.</li>
      <li><strong>ROUGE-L</strong>: Measures the longest common subsequence.</li>
      <li><strong>ROUGE-S</strong>: Measures skip-bigram overlap.</li>
    </ul>
  </li>
  <li>
    <p><strong>Evaluation Approach</strong>: For ROUGE-N, the recall is calculated as:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-119-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;ROUGE-N&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;Number of matching n-grams&lt;/mtext&gt;&lt;mtext&gt;Total number of n-grams in reference&lt;/mtext&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1143" style="width: 25.263em; display: inline-block;"><span style="display: inline-block; position: relative; width: 21.044em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1021.04em, 3.232em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1144"><span class="mtext" id="MathJax-Span-1145" style="font-family: STIXGeneral-Regular;">ROUGE-N</span><span class="mo" id="MathJax-Span-1146" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1147" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 15.159em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1011.83em, 4.378em, -999.997em); top: -4.685em; left: 50%; margin-left: -5.935em;"><span class="mtext" id="MathJax-Span-1148" style="font-family: STIXGeneral-Regular;">Number of matching n-grams</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1015em, 4.378em, -999.997em); top: -3.331em; left: 50%; margin-left: -7.497em;"><span class="mtext" id="MathJax-Span-1149" style="font-family: STIXGeneral-Regular;">Total number of n-grams in reference</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1015.16em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 15.159em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.122em; border-left: 0px solid; width: 0px; height: 2.878em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>ROUGE-N</mtext><mo>=</mo><mfrac><mtext>Number of matching n-grams</mtext><mtext>Total number of n-grams in reference</mtext></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-119">\text{ROUGE-N} = \frac{\text{Number of matching n-grams}}{\text{Total number of n-grams in reference}}</script>
  </li>
  <li><strong>Example</strong>:
    <ul>
      <li><strong>Reference</strong>: “The cat is on the mat.”</li>
      <li><strong>Candidate</strong>: “The cat is on mat.”</li>
      <li><strong>ROUGE-1 (Unigram) Recall</strong>: 5 matches out of 6 unigrams = 0.833</li>
      <li><strong>ROUGE-2 (Bigram) Recall</strong>: 4 matches out of 5 bigrams = 0.8</li>
      <li>In this example, the candidate misses the unigram “the” before “mat,” affecting the recall scores.</li>
    </ul>
  </li>
</ul>

<h4 id="string-presence">String Presence</h4>

<ul>
  <li><strong>Category</strong>: Keyword or Phrase Matching</li>
  <li><strong>Requirement</strong>: Access to ground truth references is necessary to evaluate string presence.</li>
  <li><strong>Definition</strong>: The String Presence metric checks if the generated response contains specific reference text, such as certain keywords or phrases. It is useful in scenarios where ensuring the inclusion of particular content is essential.</li>
  <li><strong>Measurement Methods</strong>: This is a binary metric that returns 1 if the reference string is present in the response and 0 otherwise.</li>
  <li><strong>Evaluation Approach</strong>: The presence of the reference string is verified within the candidate response.</li>
  <li><strong>Example</strong>:
    <ul>
      <li><strong>Reference</strong>: “climate change”</li>
      <li><strong>Candidate</strong>: The recent study highlights the impacts of climate change on polar bears.</li>
      <li><strong>String Presence Score</strong>: 1 (since “climate change” is present in the candidate).</li>
    </ul>
  </li>
</ul>

<h4 id="exact-match">Exact Match</h4>

<ul>
  <li><strong>Category</strong>: Strict Matching Evaluation</li>
  <li><strong>Requirement</strong>: Access to ground truth references is necessary to evaluate exact matches.</li>
  <li><strong>Definition</strong>: The Exact Match metric assesses whether the generated response is identical to the reference text. It is particularly useful in scenarios requiring precise outputs, such as predefined answers or specific commands.</li>
  <li><strong>Measurement Methods</strong>: This binary metric returns 1 if the candidate text matches the reference text exactly and 0 otherwise.</li>
  <li><strong>Evaluation Approach</strong>: A direct comparison is made between the candidate and reference texts.</li>
  <li><strong>Example</strong>:
    <ul>
      <li><strong>Reference</strong>: <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-120-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1150" style="width: 4.221em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.492em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.201em, 1003.49em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1151"><span class="mi" id="MathJax-Span-1152" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1153" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mi" id="MathJax-Span-1154" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">m</span><span class="msubsup" id="MathJax-Span-1155"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1156" style="font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.471em;"><span class="mn" id="MathJax-Span-1157" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>E</mi><mo>=</mo><mi>m</mi><msup><mi>c</mi><mn>2</mn></msup></math></span></span><script type="math/tex" id="MathJax-Element-120">E=mc^2</script></li>
      <li><strong>Candidate</strong>: <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-121-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1158" style="width: 4.221em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.492em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.201em, 1003.49em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1159"><span class="mi" id="MathJax-Span-1160" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1161" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mi" id="MathJax-Span-1162" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">m</span><span class="msubsup" id="MathJax-Span-1163"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1164" style="font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.372em; left: 0.471em;"><span class="mn" id="MathJax-Span-1165" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>E</mi><mo>=</mo><mi>m</mi><msup><mi>c</mi><mn>2</mn></msup></math></span></span><script type="math/tex" id="MathJax-Element-121">E=mc^2</script></li>
      <li><strong>Exact Match Score</strong>: 1 (since the candidate matches the reference exactly).</li>
    </ul>
  </li>
</ul>

<h4 id="context-entities-recall">Context Entities Recall</h4>

<ul>
  <li>
    <p><strong>Definition</strong>: Context Entities Recall is a metric that measures the recall of entities from the retrieved context compared to the ground truth. It calculates the fraction of entities in the ground truth that are also present in the context. This metric is crucial for scenarios where accurate entity retrieval is essential, such as tourism help desks or historical question answering.</p>
  </li>
  <li><strong>Evaluation Approach</strong>:
    <ul>
      <li>To compute this metric, two sets are used:
        <ul>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-122-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1166" style="width: 1.669em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.357em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1001.36em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1167"><span class="mi" id="MathJax-Span-1168" style="font-family: STIXGeneral-Italic;">G</span><span class="mi" id="MathJax-Span-1169" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>G</mi><mi>E</mi></math></span></span><script type="math/tex" id="MathJax-Element-122">GE</script> (Ground Truth Entities): The set of entities present in the ground truth.</li>
          <li><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-123-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1170" style="width: 1.565em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1001.3em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1171"><span class="mi" id="MathJax-Span-1172" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-1173" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>C</mi><mi>E</mi></math></span></span><script type="math/tex" id="MathJax-Element-123">CE</script> (Context Entities): The set of entities present in the retrieved context.</li>
        </ul>
      </li>
      <li>
        <p>The Context Entities Recall is calculated using the formula:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-124-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Context Entity Recall&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;&amp;#x2229;&lt;/mo&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1174" style="width: 17.607em; display: inline-block;"><span style="display: inline-block; position: relative; width: 14.638em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1014.64em, 3.232em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1175"><span class="mtext" id="MathJax-Span-1176" style="font-family: STIXGeneral-Regular;">Context Entity Recall</span><span class="mo" id="MathJax-Span-1177" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1178" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 4.586em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1004.33em, 4.378em, -999.997em); top: -4.685em; left: 50%; margin-left: -2.237em;"><span class="mrow" id="MathJax-Span-1179"><span class="texatom" id="MathJax-Span-1180"><span class="mrow" id="MathJax-Span-1181"><span class="mo" id="MathJax-Span-1182" style="font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-1183" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-1184" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1185" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">∩</span><span class="mi" id="MathJax-Span-1186" style="font-family: STIXGeneral-Italic; padding-left: 0.263em;">G</span><span class="mi" id="MathJax-Span-1187" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-1188"><span class="mrow" id="MathJax-Span-1189"><span class="mo" id="MathJax-Span-1190" style="font-family: STIXVariants;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1001.88em, 4.378em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.987em;"><span class="mrow" id="MathJax-Span-1191"><span class="texatom" id="MathJax-Span-1192"><span class="mrow" id="MathJax-Span-1193"><span class="mo" id="MathJax-Span-1194" style="font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-1195" style="font-family: STIXGeneral-Italic;">G</span><span class="mi" id="MathJax-Span-1196" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-1197"><span class="mrow" id="MathJax-Span-1198"><span class="mo" id="MathJax-Span-1199" style="font-family: STIXVariants;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1004.59em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 4.586em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.122em; border-left: 0px solid; width: 0px; height: 2.816em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Context Entity Recall</mtext><mo>=</mo><mfrac><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>C</mi><mi>E</mi><mo>∩</mo><mi>G</mi><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>G</mi><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow></mfrac></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-124">\text{Context Entity Recall} = \frac{|CE \cap GE|}{|GE|}</script>

        <ul>
          <li>where, <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-125-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo&gt;&amp;#x2229;&lt;/mo&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1200" style="width: 5.263em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.378em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1004.27em, 2.607em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-1201"><span class="mo" id="MathJax-Span-1202" style="font-family: STIXGeneral-Regular;">∣</span><span class="mi" id="MathJax-Span-1203" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-1204" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1205" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">∩</span><span class="mi" id="MathJax-Span-1206" style="font-family: STIXGeneral-Italic; padding-left: 0.263em;">G</span><span class="mi" id="MathJax-Span-1207" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1208" style="font-family: STIXGeneral-Regular;">∣</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">∣</mo><mi>C</mi><mi>E</mi><mo>∩</mo><mi>G</mi><mi>E</mi><mo stretchy="false">∣</mo></math></span></span><script type="math/tex" id="MathJax-Element-125">\mid CE \cap GE\mid</script> represents the number of entities common to both the context and the ground truth, while <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-126-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;&amp;#x2223;&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1209" style="width: 2.19em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.826em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1001.72em, 2.607em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-1210"><span class="mo" id="MathJax-Span-1211" style="font-family: STIXGeneral-Regular;">∣</span><span class="mi" id="MathJax-Span-1212" style="font-family: STIXGeneral-Italic;">G</span><span class="mi" id="MathJax-Span-1213" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1214" style="font-family: STIXGeneral-Regular;">∣</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">∣</mo><mi>G</mi><mi>E</mi><mo stretchy="false">∣</mo></math></span></span><script type="math/tex" id="MathJax-Element-126">\mid GE\mid</script> is the total number of entities in the ground truth.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Example</strong> <a href="https://docs.ragas.io/en/latest/concepts/metrics/context_entities_recall.html">(source)</a>:
    <ul>
      <li>
        <p><strong>Ground Truth</strong>: The Taj Mahal is an ivory-white marble mausoleum on the right bank of the river Yamuna in the Indian city of Agra. It was commissioned in 1631 by the Mughal emperor Shah Jahan to house the tomb of his favorite wife, Mumtaz Mahal.</p>
      </li>
      <li>
        <p><strong>High Entity Recall Context</strong>: The Taj Mahal is a symbol of love and architectural marvel located in Agra, India. It was built by the Mughal emperor Shah Jahan in memory of his beloved wife, Mumtaz Mahal. The structure is renowned for its intricate marble work and beautiful gardens surrounding it.</p>
      </li>
      <li>
        <p><strong>Low Entity Recall Context</strong>: The Taj Mahal is an iconic monument in India. It is a UNESCO World Heritage Site and attracts millions of visitors annually. The intricate carvings and stunning architecture make it a must-visit destination.</p>
      </li>
      <li><strong>Calculation</strong>:
        <ul>
          <li><strong>Entities in Ground Truth (GE)</strong>: <code class="language-plaintext highlighter-rouge">['Taj Mahal', 'Yamuna', 'Agra', '1631', 'Shah Jahan', 'Mumtaz Mahal']</code></li>
          <li><strong>Entities in High Entity Recall Context (CE1)</strong>: <code class="language-plaintext highlighter-rouge">['Taj Mahal', 'Agra', 'Shah Jahan', 'Mumtaz Mahal', 'India']</code></li>
          <li><strong>Entities in Low Entity Recall Context (CE2)</strong>: <code class="language-plaintext highlighter-rouge">['Taj Mahal', 'UNESCO', 'India']</code></li>
        </ul>
      </li>
      <li>
        <p><strong>Context Entity Recall - 1</strong>:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-127-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Context Entity Recall - 1&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;&amp;#x2229;&lt;/mo&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;4&lt;/mn&gt;&lt;mn&gt;6&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.666&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1215" style="width: 26.409em; display: inline-block;"><span style="display: inline-block; position: relative; width: 21.982em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1021.93em, 3.232em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1216"><span class="mtext" id="MathJax-Span-1217" style="font-family: STIXGeneral-Regular;">Context Entity Recall - 1</span><span class="mo" id="MathJax-Span-1218" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1219" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 5.107em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1004.85em, 4.378em, -999.997em); top: -4.685em; left: 50%; margin-left: -2.497em;"><span class="mrow" id="MathJax-Span-1220"><span class="texatom" id="MathJax-Span-1221"><span class="mrow" id="MathJax-Span-1222"><span class="mo" id="MathJax-Span-1223" style="font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-1224" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-1225" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mn" id="MathJax-Span-1226" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-1227" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">∩</span><span class="mi" id="MathJax-Span-1228" style="font-family: STIXGeneral-Italic; padding-left: 0.263em;">G</span><span class="mi" id="MathJax-Span-1229" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-1230"><span class="mrow" id="MathJax-Span-1231"><span class="mo" id="MathJax-Span-1232" style="font-family: STIXVariants;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1001.88em, 4.378em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.987em;"><span class="mrow" id="MathJax-Span-1233"><span class="texatom" id="MathJax-Span-1234"><span class="mrow" id="MathJax-Span-1235"><span class="mo" id="MathJax-Span-1236" style="font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-1237" style="font-family: STIXGeneral-Italic;">G</span><span class="mi" id="MathJax-Span-1238" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-1239"><span class="mrow" id="MathJax-Span-1240"><span class="mo" id="MathJax-Span-1241" style="font-family: STIXVariants;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1005.11em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 5.107em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-1242" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1243" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 0.628em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-1244" style="font-family: STIXGeneral-Regular;">4</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-1245" style="font-family: STIXGeneral-Regular;">6</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1000.63em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.628em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-1246" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-1247" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.666</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.122em; border-left: 0px solid; width: 0px; height: 2.816em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Context Entity Recall - 1</mtext><mo>=</mo><mfrac><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>C</mi><mi>E</mi><mn>1</mn><mo>∩</mo><mi>G</mi><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>G</mi><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow></mfrac><mo>=</mo><mfrac><mn>4</mn><mn>6</mn></mfrac><mo>=</mo><mn>0.666</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-127">\text{Context Entity Recall - 1} = \frac{|CE1 \cap GE|}{|GE|} = \frac{4}{6} = 0.666</script>
      </li>
      <li>
        <p><strong>Context Entity Recall - 2</strong>:</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-128-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtext&gt;Context Entity Recall - 2&lt;/mtext&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;&amp;#x2229;&lt;/mo&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;6&lt;/mn&gt;&lt;/mfrac&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0.166&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1248" style="width: 26.409em; display: inline-block;"><span style="display: inline-block; position: relative; width: 21.982em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.68em, 1021.93em, 3.232em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1249"><span class="mtext" id="MathJax-Span-1250" style="font-family: STIXGeneral-Regular;">Context Entity Recall - 2</span><span class="mo" id="MathJax-Span-1251" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1252" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 5.107em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1004.85em, 4.378em, -999.997em); top: -4.685em; left: 50%; margin-left: -2.497em;"><span class="mrow" id="MathJax-Span-1253"><span class="texatom" id="MathJax-Span-1254"><span class="mrow" id="MathJax-Span-1255"><span class="mo" id="MathJax-Span-1256" style="font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-1257" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-1258" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mn" id="MathJax-Span-1259" style="font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-1260" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">∩</span><span class="mi" id="MathJax-Span-1261" style="font-family: STIXGeneral-Italic; padding-left: 0.263em;">G</span><span class="mi" id="MathJax-Span-1262" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-1263"><span class="mrow" id="MathJax-Span-1264"><span class="mo" id="MathJax-Span-1265" style="font-family: STIXVariants;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1001.88em, 4.378em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.987em;"><span class="mrow" id="MathJax-Span-1266"><span class="texatom" id="MathJax-Span-1267"><span class="mrow" id="MathJax-Span-1268"><span class="mo" id="MathJax-Span-1269" style="font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-1270" style="font-family: STIXGeneral-Italic;">G</span><span class="mi" id="MathJax-Span-1271" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-1272"><span class="mrow" id="MathJax-Span-1273"><span class="mo" id="MathJax-Span-1274" style="font-family: STIXVariants;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1005.11em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 5.107em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-1275" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1276" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 0.628em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-1277" style="font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.258em;"><span class="mn" id="MathJax-Span-1278" style="font-family: STIXGeneral-Regular;">6</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1000.63em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.628em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="mo" id="MathJax-Span-1279" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-1280" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">0.166</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.122em; border-left: 0px solid; width: 0px; height: 2.816em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Context Entity Recall - 2</mtext><mo>=</mo><mfrac><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>C</mi><mi>E</mi><mn>2</mn><mo>∩</mo><mi>G</mi><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>G</mi><mi>E</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mn>6</mn></mfrac><mo>=</mo><mn>0.166</mn></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-128">\text{Context Entity Recall - 2} = \frac{|CE2 \cap GE|}{|GE|} = \frac{1}{6} = 0.166</script>
      </li>
      <li>The first context demonstrates a higher entity recall, indicating better entity coverage in comparison to the ground truth. If these contexts were generated by different retrieval mechanisms, the first mechanism would be deemed superior for applications where entity accuracy is crucial.</li>
    </ul>
  </li>
</ul>

<!-- ### End-to-End Evaluation

- Evaluating the end-to-end performance of a pipeline is also crucial, as it directly affects the user experience. Ragas provides metrics that can be employed to assess the overall performance of your pipeline, ensuring a comprehensive evaluation.

#### Answer Semantic Similarity

- **Category**: Answer Quality and Semantic Alignment
- **Requirement**: Access to ground truth answers is necessary to evaluate the semantic similarity of generated responses accurately.
- **Definition**: Evaluates the degree of semantic similarity between the generated answer by the RAG system and the ground truth. This metric specifically assesses how closely the meaning of the generated answer mirrors that of the ground truth.
- **Measurement Methods**: This metric is measured using cross-encoder models designed to calculate the semantic similarity score. These models analyze the semantic content of both the generated answer and the ground truth.
- **Evaluation Approach**: The approach involves comparing the generated answer with the ground truth to determine the extent of semantic overlap. The semantic similarity is quantified on a scale from 0 to 1, where higher scores indicate a greater alignment between the generated answer and the ground truth. The formula for Answer Semantic Similarity is implicitly based on the evaluation of semantic overlap rather than a direct formula.

- **BERTScore**:
  - Uses contextual embeddings from pre-trained BERT models to match tokens in the candidate and reference text.
  - Computes precision, recall, and F1 scores by aligning embeddings based on cosine similarity, capturing nuanced semantic overlap.

- **MoverScore**:
  - Extends BERTScore by incorporating Earth Mover’s Distance (EMD) to assess the minimal semantic "effort" needed to transform one text into another.
  - Leverages both contextual embeddings and IDF weighting to emphasize important content over common filler words.

- **Advantages of MoverScore over BERTScore**:
  - Better captures the global semantic flow between texts by considering word importance and distribution, not just local alignment.
  - More robust in handling paraphrased or reordered sentences, where BERTScore may undervalue semantic similarity due to token-level matching.

- **Example**:
  - **Ground truth**: Albert Einstein’s theory of relativity revolutionized our understanding of the universe.
  - **High similarity answer**: Einstein’s groundbreaking theory of relativity transformed our comprehension of the cosmos.
  - **Low similarity answer**: Isaac Newton’s laws of motion greatly influenced classical physics.

- In this metric, a higher score reflects a better quality of the generated response in terms of its semantic closeness to the ground truth, indicating a more accurate and contextually relevant answer.

#### Answer Correctness

- **Category**: Answer Accuracy and Correctness
- **Definition**: This metric assesses the accuracy of the answer generated by the RAG system in comparison to the ground truth. It emphasizes not just the semantic similarity but also the factual correctness of the generated answer relative to the ground truth.
- **Measurement Methods**: The evaluation of answer correctness involves a combination of assessing semantic similarity and factual similarity. These aspects are integrated using a weighted scheme, which can include the use of cross-encoder models or other sophisticated methods for semantic analysis. Users can also apply a threshold value to interpret the scores in a binary manner.
- **Evaluation Approach**: The approach entails comparing the generated answer with the ground truth to evaluate both semantic and factual alignment. The combined assessment of these two aspects results in the answer correctness score, which ranges from 0 to 1, where higher scores denote greater accuracy and alignment with the ground truth.

- Example: 
  - **Ground truth**: Einstein was born in 1879 in Germany.
  - **High answer correctness example**: In 1879, in Germany, Einstein was born.
  - **Low answer correctness example**: In Spain, Einstein was born in 1879.

- This metric highlights the importance of not just understanding the context and content of the user's query (as in the context relevance evaluation) but also ensuring that the answers provided are factually and semantically aligned with the established truth, thereby ensuring a high-quality response from the RAG system.

#### Summarization Score

- **Definition**: Summarization Score evaluates how effectively a summary/response encapsulates the essential information from the context. This metric ensures that the summary includes all critical details present in the original text, offering a comprehensive overview.
- **Evaluation Approach**:

  1. **Keyphrase Extraction**: Important keyphrases are extracted from the context. These keyphrases represent crucial information that the summary should ideally include.
  2. **Question Generation**: Based on these keyphrases, a set of questions is formulated. These questions are designed so that the context answers "yes" (1) to all of them.
  3. **Answer Comparison**: The same questions are then asked of the summary. The Summarization Score is calculated as the ratio of correctly answered questions (where the answer is 1) to the total number of questions.

    - **Question-Answer Score Calculation**:
    
    $$
    \text{QA score} = \frac{\text{Number of correctly answered questions}}{\text{Total number of questions}}
    $$

  4. **Conciseness Score** (Optional): To discourage excessively long summaries that merely replicate the context, a conciseness score can be introduced. This score penalizes longer summaries, rewarding those that are concise yet complete.

    - **Conciseness Score Calculation**:
    
    $$
    \text{Conciseness score} = \frac{\text{Length of summary}}{\text{Length of context}}
    $$

  5. **Final Summarization Score**: If the conciseness score is used, the final score is the average of the QA score and the conciseness score.

    - **Final Score Calculation**:
    
    $$
    \text{Summarization Score} = \frac{\text{QA score} + \text{Conciseness score}}{2}
    $$

- **Example** [(source)](https://docs.ragas.io/en/latest/concepts/metrics/summarization_score.html): 
  - **Summary**: JPMorgan Chase & Co. is an American multinational finance company headquartered in New York City. It is the largest bank in the United States and the world’s largest by market capitalization as of 2023. Founded in 1799, it is a major provider of investment banking services, with US$3.9 trillion in total assets, and ranked #1 in the Forbes Global 2000 ranking in 2023.
  - **Keyphrases**: `["JPMorgan Chase & Co.", "American multinational finance company", "headquartered in New York City", "largest bank in the United States", "world’s largest bank by market capitalization", "founded in 1799", "major provider of investment banking services", "US$3.9 trillion in total assets", "ranked #1 in Forbes Global 2000 ranking"]`
  - **Questions**: `["Is JPMorgan Chase & Co. an American multinational finance company?", "Is JPMorgan Chase & Co. headquartered in New York City?", "Is JPMorgan Chase & Co. the largest bank in the United States?", "Is JPMorgan Chase & Co. the world’s largest bank by market capitalization as of 2023?", "Is JPMorgan Chase & Co. considered systemically important by the Financial Stability Board?", "Was JPMorgan Chase & Co. founded in 1799 as the Chase Manhattan Company?", "Is JPMorgan Chase & Co. a major provider of investment banking services?", "Is JPMorgan Chase & Co. the fifth-largest bank in the world by assets?", "Does JPMorgan Chase & Co. operate the largest investment bank by revenue?", "Was JPMorgan Chase & Co. ranked #1 in the Forbes Global 2000 ranking?", "Does JPMorgan Chase & Co. provide investment banking services?"]`
  - **Answers**: `["0", "1", "1", "1", "0", "0", "1", "1", "1", "1", "1"]`
  - In this example, the QA score is calculated based on how many questions the summary answers correctly, reflecting its accuracy and relevance to the context.
  
#### Context Entities Recall

- **Definition**: Context Entities Recall is a metric that measures the recall of entities from the retrieved context compared to the ground truth. It calculates the fraction of entities in the ground truth that are also present in the context. This metric is crucial for scenarios where accurate entity retrieval is essential, such as tourism help desks or historical question answering.

- **Evaluation Approach**:
  - To compute this metric, two sets are used:
    - $$GE$$ (Ground Truth Entities): The set of entities present in the ground truth.
    - $$CE$$ (Context Entities): The set of entities present in the retrieved context.

  - The Context Entities Recall is calculated using the formula:
  
    $$
    \text{Context Entity Recall} = \frac{|CE \cap GE|}{|GE|}
    $$

    - where, $$|CE \cap GE|$$ represents the number of entities common to both the context and the ground truth, while $$|GE|$$ is the total number of entities in the ground truth.

- **Example** [(source)](https://docs.ragas.io/en/latest/concepts/metrics/context_entities_recall.html): 
  - **Ground Truth**: The Taj Mahal is an ivory-white marble mausoleum on the right bank of the river Yamuna in the Indian city of Agra. It was commissioned in 1631 by the Mughal emperor Shah Jahan to house the tomb of his favorite wife, Mumtaz Mahal.

  - **High Entity Recall Context**: The Taj Mahal is a symbol of love and architectural marvel located in Agra, India. It was built by the Mughal emperor Shah Jahan in memory of his beloved wife, Mumtaz Mahal. The structure is renowned for its intricate marble work and beautiful gardens surrounding it.

  - **Low Entity Recall Context**: The Taj Mahal is an iconic monument in India. It is a UNESCO World Heritage Site and attracts millions of visitors annually. The intricate carvings and stunning architecture make it a must-visit destination.

  - **Calculation**:
    - **Entities in Ground Truth (GE)**: `['Taj Mahal', 'Yamuna', 'Agra', '1631', 'Shah Jahan', 'Mumtaz Mahal']`
    - **Entities in High Entity Recall Context (CE1)**: `['Taj Mahal', 'Agra', 'Shah Jahan', 'Mumtaz Mahal', 'India']`
    - **Entities in Low Entity Recall Context (CE2)**: `['Taj Mahal', 'UNESCO', 'India']`

  - **Context Entity Recall - 1**:
  
    $$
    \text{Context Entity Recall - 1} = \frac{|CE1 \cap GE|}{|GE|} = \frac{4}{6} = 0.666
    $$

  - **Context Entity Recall - 2**:
  
    $$
    \text{Context Entity Recall - 2} = \frac{|CE2 \cap GE|}{|GE|} = \frac{1}{6} = 0.166
    $$

  - The first context demonstrates a higher entity recall, indicating better entity coverage in comparison to the ground truth. If these contexts were generated by different retrieval mechanisms, the first mechanism would be deemed superior for applications where entity accuracy is crucial. -->

<h2 id="multimodal-input-handling">Multimodal Input Handling</h2>

<ul>
  <li>RAG traditionally focuses on textual inputs. However, real-world scenarios frequently involve multimodal inputs, particularly text combined with images. Consider queries such as “What brand are the shoes in this image?”, “Describe the issue shown in the screenshot and suggest how to fix it”, and “Provide nutritional details for the meal shown here.” Addressing these queries requires handling both text and visual elements simultaneously.</li>
  <li>Integrating multimodal embeddings in RAG systems enables robust and precise handling of queries containing both visual and textual elements, significantly enhancing retrieval accuracy and the overall quality of generated responses.</li>
</ul>

<h3 id="flow-of-multimodal-input">Flow of Multimodal Input</h3>

<ol>
  <li><strong>Query Input</strong>:
    <ul>
      <li>The user submits a query comprising text and an image. For example, a user might upload a picture of a jacket alongside the text query, “Is this jacket available in waterproof material?”</li>
    </ul>
  </li>
  <li><strong>Embedding Multimodal Input</strong>:
    <ul>
      <li>Both text and image inputs need to be converted into embeddings to capture their semantic essence. This typically involves:
        <ul>
          <li><strong>Text Embedding</strong>: Utilizing models like Sentence-BERT or GPT embeddings to create dense vectors representing the semantic meaning of the textual query.</li>
          <li><strong>Image Embedding</strong>: Using visual embedding models such as CLIP (Contrastive Language-Image Pre-training), ViT (Vision Transformer), or ResNet variants. These models process images to create dense vector representations capturing visual features.</li>
        </ul>
      </li>
      <li>The resulting embeddings are then concatenated or fused into a single multimodal embedding vector. This fusion captures both the textual semantics and the visual features coherently.</li>
    </ul>
  </li>
  <li><strong>Storage and Retrieval from Vector Database</strong>:
    <ul>
      <li>The multimodal embeddings are stored in a vector database, similar to text-only scenarios.</li>
      <li>During retrieval, multimodal embeddings derived from user queries are compared against the stored embeddings in the database.</li>
    </ul>
  </li>
  <li><strong>Similarity Matching via Cosine Similarity</strong>:
    <ul>
      <li>Retrieval involves computing cosine similarity between the multimodal query embedding and the embeddings stored in the vector database.</li>
      <li>Cosine similarity effectively measures semantic and visual similarity, ensuring retrieved items closely align with both textual context and visual content of the query.</li>
    </ul>
  </li>
  <li><strong>Ranked Results and Response Generation</strong>:
    <ul>
      <li>Items with the highest similarity scores – provide specific product details (e.g., material information, waterproof ratings) – are retrieved and ranked according to relevance.</li>
      <li>These ranked results are then fed into an LLM to synthesize contextually accurate and visually informed responses. The final response leverages the multimodal context to precisely answer queries such as material specifications or availability in different sizes or colors, with a coherent respons such ase: “Yes, this particular jacket model is made from Gore-Tex, which is fully waterproof.”</li>
    </ul>
  </li>
</ol>

<h3 id="benefits-of-multimodal-embeddings-in-rag">Benefits of Multimodal Embeddings in RAG</h3>

<ul>
  <li><strong>Enhanced User Experience</strong>: Allows users to naturally query using images, which often conveys more information than text alone.</li>
  <li><strong>Precision and Relevance</strong>: Combining textual semantics and visual features significantly enhances retrieval accuracy.</li>
  <li><strong>Scalable Solution</strong>: Multimodal embeddings can seamlessly integrate with existing vector databases, offering scalability and performance optimization.</li>
</ul>

<h2 id="multimodal-rag">Multimodal RAG</h2>

<ul>
  <li>Many documents contain a mixture of content types, including text and images. Yet, information captured in images is lost in most RAG applications. With the emergence of multimodal LLMs, like GPT-4V, it is worth considering how to utilize images in RAG.</li>
  <li>Here are three ways to use images in RAG:
    <ul>
      <li><strong>Option 1:</strong>
        <ul>
          <li>Use multimodal embeddings (such as CLIP) to embed images and text.</li>
          <li>Retrieve both using similarity search.</li>
          <li>Pass raw images and text chunks to a multimodal LLM for answer synthesis.</li>
        </ul>
      </li>
      <li><strong>Option 2:</strong>
        <ul>
          <li>Use a multimodal LLM (such as GPT-4V, LLaVA, or Fuyu-8b) to produce text summaries from images.</li>
          <li>Embed and retrieve text.</li>
          <li>Pass text chunks to an LLM for answer synthesis.</li>
        </ul>
      </li>
      <li><strong>Option 3:</strong>
        <ul>
          <li>Use a multimodal LLM (such as GPT-4V, LLaVA, or Fuyu-8b) to produce text summaries from images.</li>
          <li>Embed and retrieve image summaries with a reference to the raw image. You can use a <a href="https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector">multi-vector retriever</a> with a Vector DB such as <a href="https://www.trychroma.com/">Chroma</a> to store raw text and images along with their summaries for retrieval.</li>
          <li>Pass raw images and text chunks to a multimodal LLM for answer synthesis.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Option 2 is appropriate for cases when a multi-modal LLM cannot be used for answer synthesis (e.g., cost, etc).</li>
  <li>The following figure <a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Multi_modal_RAG.ipynb?ref=blog.langchain.dev">(source)</a> offers an overview of all three aforementioned options.</li>
</ul>

<p><img src="/primers/ai/assets/RAG/MMRAG.jpg" alt=""></p>

<ul>
  <li>LangChain offers cookbooks for <a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/multi_modal_RAG_chroma.ipynb">Option 1</a> and <a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Multi_modal_RAG.ipynb?ref=blog.langchain.dev">Option 3</a>.</li>
  <li>The following infographic <a href="https://www.linkedin.com/in/ravitjain/">(source)</a> also offers a top-level overview of Multimodal RAG:</li>
</ul>

<p><img src="/primers/ai/assets/RAG/MMRAG2.gif" alt=""></p>

<h2 id="agentic-retrieval-augmented-generation">Agentic Retrieval-Augmented Generation</h2>

<ul>
  <li>
    <p>Agent-based Retrieval-Augmented Generation (RAG), or Agentic RAG, represents an advanced approach in AI that enhances the traditional RAG pipeline with intelligent agents. In conventional RAG systems, an AI model queries a knowledge base to retrieve relevant information and generate responses. However, Agentic RAG extends beyond this by employing AI agents capable of orchestrating multi-step retrieval processes, utilizing external tools, and dynamically adapting to the query. This added layer of autonomy enables advanced reasoning, decision-making, and adaptability, allowing the system to handle complex queries and diverse data sources with greater precision and responsiveness.</p>
  </li>
  <li>
    <p>By integrating AI agents, Agentic RAG transforms traditional RAG, providing a flexible, intelligent solution for nuanced, real-world inquiries. This shift enables organizations to deploy AI systems with a higher degree of accuracy, flexibility, and intelligence, allowing them to tackle intricate tasks and deliver more precise results across a wide range of applications.</p>
  </li>
</ul>

<h3 id="how-agentic-rag-works">How Agentic RAG Works</h3>

<ul>
  <li>
    <p>In an agentic RAG system, AI agents play key roles in the retrieval process, using specialized tools to retrieve context-sensitive information. Unlike traditional RAG, where retrieval functions are static, agentic RAG allows dynamic selection and operation of tools based on query requirements. Retrieval agents may utilize tools such as:</p>

    <ol>
      <li><strong>Vector Search Engines</strong>: Retrieve information from vectorized data in databases.</li>
      <li><strong>Web Search Tools</strong>: Access live web data for up-to-date, contextually relevant information.</li>
      <li><strong>Calculators</strong>: Perform computations for queries that require accurate calculation.</li>
      <li><strong>APIs for Software Programs</strong>: Programmatically retrieve information from applications like email or chat programs to access user-specific data.</li>
    </ol>
  </li>
  <li>
    <p>In the context of Agentic RAG, the retrieval process is “agentic,” meaning agents are capable of reasoning and decision-making regarding which sources and tools to use, based on the specific requirements of the query. This flexibility elevates their tool usage beyond simple retrieval, allowing for a more dynamic and adaptive response.</p>
  </li>
</ul>

<h3 id="agentic-decision-making-in-retrieval">Agentic Decision-Making in Retrieval</h3>

<ul>
  <li>
    <p>The decision-making process of retrieval agents encompasses several key actions, including:</p>

    <ul>
      <li><strong>Deciding Whether to Retrieve</strong>: Assessing if additional information is necessary for the query.</li>
      <li><strong>Choosing the Appropriate Tool</strong>: Selecting the most suitable tool (e.g., a vector search engine or web search) based on the query.</li>
      <li><strong>Query Formulation</strong>: Refining or rephrasing the query to enhance retrieval accuracy.</li>
      <li><strong>Evaluating Retrieved Results</strong>: Reviewing the retrieved information to determine sufficiency, and whether further retrieval is needed.</li>
    </ul>
  </li>
</ul>

<h3 id="agentic-rag-architectures-single-agent-vs-multi-agent-systems">Agentic RAG Architectures: Single-Agent vs. Multi-Agent Systems</h3>

<ul>
  <li>Agentic RAG can be implemented with a single agent or multiple agents, each offering unique strengths.</li>
</ul>

<h4 id="single-agent-rag-router">Single-Agent RAG (Router)</h4>

<ul>
  <li>The simplest implementation of agentic RAG involves a single agent functioning as a “router.” This agent determines the appropriate source or tool for retrieving information based on the query. The single agent toggles between different options, such as a vector database, web search, or an API. This setup provides a versatile retrieval process, enabling access to multiple data sources beyond a single vector search tool.</li>
  <li>As shown in the figure below (<a href="https://weaviate.io/blog/what-is-agentic-rag">source</a>), the single-agent RAG system (router) architecture involves a single agent serving as a “router,” dynamically selecting the best tool or source based on the query, enabling efficient information retrieval across multiple data channels.</li>
</ul>

<p><img src="/primers/ai/assets/agents/Single_Agent_RAG_System_Router.png" alt="Agentic RAG Visual Summary"></p>

<h4 id="multi-agent-rag-systems">Multi-Agent RAG Systems</h4>

<ul>
  <li>
    <p>For more complex queries, multi-agent RAG systems provide additional flexibility. These systems feature a “master agent” that coordinates several specialized retrieval agents, such as:</p>

    <ul>
      <li><strong>Internal Data Retrieval Agent</strong>: Retrieves information from proprietary, internal databases.</li>
      <li><strong>Personal Data Retrieval Agent</strong>: Accesses user-specific information, such as emails or chat history.</li>
      <li><strong>Public Data Retrieval Agent</strong>: Conducts web searches for up-to-date public information.</li>
    </ul>
  </li>
  <li>
    <p>By utilizing multiple agents tailored to specific sources or tasks, multi-agent RAG systems can deliver comprehensive, accurate responses across diverse channels.</p>
  </li>
  <li>
    <p>As shown in the figure below (<a href="https://weaviate.io/blog/what-is-agentic-rag">source</a>), the multi-agent RAG system architecture utilizes multiple specialized retrieval agents to access different sources and tools, offering a flexible and comprehensive approach to complex queries.</p>
  </li>
</ul>

<p><img src="/primers/ai/assets/agents/Multi_Agent_RAG_System.png" alt="Agentic RAG Visual Summary"></p>

<h3 id="beyond-retrieval-expanding-agentic-rags-capabilities">Beyond Retrieval: Expanding Agentic RAG’s Capabilities</h3>

<ul>
  <li>
    <p>Agentic RAG systems can incorporate agents for tasks beyond retrieval, including:</p>

    <ul>
      <li><strong>Validating Information</strong>: Cross-referencing data across sources to ensure accuracy.</li>
      <li><strong>Performing Multi-step Reasoning</strong>: Following logical steps to address complex queries before generating responses.</li>
      <li><strong>Updating System Memory</strong>: Tracking and retaining user-specific preferences or past queries, enabling personalized and context-aware responses.</li>
    </ul>
  </li>
  <li>
    <p>By expanding its capabilities beyond simple retrieval, Agentic RAG delivers a powerful, context-sensitive AI solution capable of handling intricate, real-world applications.</p>
  </li>
</ul>

<h3 id="agentic-rag-vs-vanilla-rag-key-differences">Agentic RAG vs. Vanilla RAG: Key Differences</h3>

<ul>
  <li>While both vanilla and agentic RAG systems aim to retrieve information and generate responses, agentic RAG introduces several significant enhancements:</li>
</ul>

<div align="center">
<table class="tg">
 <thead>
<tr>
<th class="tg-hcenter-valign-first"><strong>Feature</strong></th>
<th class="tg-hcenter-valign-first"><strong>Vanilla RAG</strong></th>
<th class="tg-hcenter-valign-second"><strong>Agentic RAG</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="tg-tleft-valign-first">Access to External Tools</td>
<td class="tg-tleft-valign-first">No</td>
<td class="tg-tleft-valign-second">Yes – Utilizes external tools like vector search engines, web search tools, calculators, and APIs.</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Query Pre-processing</td>
<td class="tg-tleft-valign-first">No</td>
<td class="tg-tleft-valign-second">Yes – Agents dynamically refine, rephrase, and adapt queries for optimized retrieval.</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Decision-making in Retrieval</td>
<td class="tg-tleft-valign-first">Limited to direct retrieval from knowledge base</td>
<td class="tg-tleft-valign-second">Agents autonomously decide if retrieval is needed, select tools, and adapt based on query complexity and source type.</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Multi-step Retrieval Process</td>
<td class="tg-tleft-valign-first">No</td>
<td class="tg-tleft-valign-second">Yes – Agents perform multi-step, adaptive retrieval processes involving various sources or tool combinations.</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Data Validation</td>
<td class="tg-tleft-valign-first">No</td>
<td class="tg-tleft-valign-second">Yes – Information is cross-referenced across sources to validate accuracy, supporting complex, real-world responses.</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Dynamic Tool Selection</td>
<td class="tg-tleft-valign-first">Static retrieval tools only</td>
<td class="tg-tleft-valign-second">Dynamic – Agents choose specific tools (e.g., vector search, APIs) based on query needs.</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Adaptability to Query</td>
<td class="tg-tleft-valign-first">Limited</td>
<td class="tg-tleft-valign-second">Highly adaptive – Agents select and operate tools based on real-time assessment of query requirements.</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Types of Agents</td>
<td class="tg-tleft-valign-first">Not applicable</td>
<td class="tg-tleft-valign-second">Multiple specialized agents, such as internal data retrieval, personal data retrieval, public data retrieval.</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Single-Agent vs. Multi-Agent System</td>
<td class="tg-tleft-valign-first">Not applicable</td>
<td class="tg-tleft-valign-second">Single-agent router or multi-agent systems, with “master” and specialized agents for complex queries.</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Reasoning and Logic Capability</td>
<td class="tg-tleft-valign-first">No</td>
<td class="tg-tleft-valign-second">Yes – Supports multi-step reasoning, allowing logical sequence handling before generating responses.</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Memory and Personalization</td>
<td class="tg-tleft-valign-first">Limited to immediate query</td>
<td class="tg-tleft-valign-second">Yes – Capable of updating memory to retain user preferences or history, allowing personalized responses.</td>
</tr>
<tr>
<td class="tg-tleft-valign-first">Real-world Applications</td>
<td class="tg-tleft-valign-first">Primarily static responses from a fixed database</td>
<td class="tg-tleft-valign-second">Supports a wide range of real-world applications by responding to complex, nuanced inquiries with context sensitivity.</td>
</tr>
</tbody>
</table>
</div>

<ul>
  <li>Drawing a parallel with problem-solving, agentic RAG offers capabilities akin to having a smartphone in hand—equipped with multiple apps and tools to help answer a question—whereas vanilla RAG is akin to being in a library with limited resources.</li>
</ul>

<h3 id="implementing-agentic-rag-key-approaches">Implementing Agentic RAG: Key Approaches</h3>

<ul>
  <li>To implement agentic RAG, developers can use either language models with function calling or agent frameworks, each providing specific advantages in terms of flexibility and control.</li>
  <li>Both methods—function calling in language models and agent frameworks—enable agentic RAG, though each has unique benefits:
    <ul>
      <li><strong>Function Calling</strong> provides control over each tool interaction, suitable for cases with specific tool chains or simple agent setups.</li>
      <li><strong>Agent Frameworks</strong> offer pre-built integrations and routing logic, ideal for larger, multi-agent architectures.</li>
    </ul>
  </li>
  <li>Using these implementations, developers can build flexible and adaptive agentic RAG pipelines, enhancing retrieval, reasoning, and response generation capabilities for AI-driven applications.</li>
</ul>

<h4 id="language-models-with-function-calling">Language Models with Function Calling</h4>

<ul>
  <li>Function calling allows language models to interact directly with external tools. For example, OpenAI’s function calling for GPT-4 or Cohere’s connectors API lets developers connect language models to databases, calculators, and other services. This interaction involves defining a function (such as querying a database), passing it to the model via a schema, and routing the model’s queries through the defined functions. This approach enables the model to leverage specific tools as needed, based on the query.</li>
</ul>

<h4 id="agent-frameworks">Agent Frameworks</h4>

<ul>
  <li>Several agent frameworks—such as LangChain, LlamaIndex, CrewAI—simplify agentic RAG implementation by providing pre-built templates and tool integrations. Key features include:
    <ul>
      <li><strong>LangChain</strong>: Offers support for language model tools, and its LCEL and LangGraph frameworks integrate these tools seamlessly.</li>
      <li><strong>LlamaIndex</strong>: Provides a QueryEngineTool to streamline retrieval tasks.</li>
      <li><strong>CrewAI</strong>: A leading framework for multi-agent setups, which supports shared tool access among agents.</li>
    </ul>
  </li>
</ul>

<h3 id="enterprise-driven-adoption">Enterprise-driven Adoption</h3>

<ul>
  <li>Organizations are increasingly transitioning to agentic RAG to gain more autonomous and accurate AI-driven systems. Enterprises such as Microsoft and Replit have introduced agents to enhance task completion and software development assistance. With agentic RAG, companies can build AI applications capable of handling diverse, real-time data sources, providing robust and adaptable responses for complex queries and tasks.</li>
</ul>

<h3 id="benefits">Benefits</h3>

<ul>
  <li>The primary benefits of agentic RAG include:
    <ul>
      <li><strong>Enhanced Retrieval Accuracy</strong>: By routing queries through specialized agents, agentic RAG can provide more accurate responses.</li>
      <li><strong>Autonomous Task Performance</strong>: Agents can perform multi-step reasoning, independently solving complex problems.</li>
      <li><strong>Improved Collaboration</strong>: These systems can better assist users by handling more varied and personalized queries.</li>
    </ul>
  </li>
</ul>

<h3 id="limitations">Limitations</h3>

<ul>
  <li>Agentic RAG does present challenges, such as:
    <ul>
      <li><strong>Increased Latency</strong>: Running multiple agents and interacting with tools can add delays to the response.</li>
      <li><strong>Reliability of Agents</strong>: Depending on the LLM’s reasoning capabilities, agents may fail to complete certain tasks accurately.</li>
      <li><strong>Complexity in Error Handling</strong>: Systems need robust fallback mechanisms to recover if an agent fails to retrieve or process data.</li>
    </ul>
  </li>
</ul>

<h3 id="code">Code</h3>

<ul>
  <li>Implementing agentic RAG requires setting up an agent framework capable of handling tool integrations and coordinating retrieval processes. This section walks through an example code setup, demonstrating both language models with function calling and agent frameworks for building an agentic RAG pipeline.</li>
</ul>

<h4 id="implementing-agentic-rag-with-function-calling">Implementing Agentic RAG with Function Calling</h4>

<ul>
  <li>
    <p>Function calling in language models allows them to interact with tools by defining functions that retrieve data from external sources. This method leverages API calls, database queries, and computation tools to enrich the response with dynamic data.</p>
  </li>
  <li>
    <p>Here’s an example implementation using a function for retrieval from a database via the Weaviate vector search API.</p>
  </li>
</ul>

<h5 id="define-the-function-for-retrieval">Define the Function for Retrieval</h5>

<ul>
  <li>To start, we define a function that uses Weaviate’s hybrid search to query a database and retrieve relevant results.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code10"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code10"><span class="k">def</span> <span class="nf">get_search_results</span><span class="p">(</span><span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="s">"""Sends a query to Weaviate's Hybrid Search. Parses the response into a formatted string."""</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">blogs</span><span class="p">.</span><span class="n">query</span><span class="p">.</span><span class="n">hybrid</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># Retrieve top 5 results based on the query
</span>    <span class="n">stringified_response</span> <span class="o">=</span> <span class="s">""</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">objects</span><span class="p">):</span>
        <span class="n">stringified_response</span> <span class="o">+=</span> <span class="sa">f</span><span class="s">"Search Result </span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">:</span><span class="se">\n</span><span class="s">"</span>
        <span class="k">for</span> <span class="n">prop</span> <span class="ow">in</span> <span class="n">o</span><span class="p">.</span><span class="n">properties</span><span class="p">:</span>
            <span class="n">stringified_response</span> <span class="o">+=</span> <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">prop</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">o</span><span class="p">.</span><span class="n">properties</span><span class="p">[</span><span class="n">prop</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span>
        <span class="n">stringified_response</span> <span class="o">+=</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span>

    <span class="k">return</span> <span class="n">stringified_response</span>
</code></pre></div></div>

<h5 id="define-the-tools-schema">Define the Tools Schema</h5>

<ul>
  <li>Next, we define a tools schema that connects the function to the language model. This schema tells the model how to use the function for retrieving data.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code11"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code11"><span class="n">tools_schema</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s">'type'</span><span class="p">:</span> <span class="s">'function'</span><span class="p">,</span>
    <span class="s">'function'</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">'name'</span><span class="p">:</span> <span class="s">'get_search_results'</span><span class="p">,</span>
        <span class="s">'description'</span><span class="p">:</span> <span class="s">'Get search results for a provided query.'</span><span class="p">,</span>
        <span class="s">'parameters'</span><span class="p">:</span> <span class="p">{</span>
          <span class="s">'type'</span><span class="p">:</span> <span class="s">'object'</span><span class="p">,</span>
          <span class="s">'properties'</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">'query'</span><span class="p">:</span> <span class="p">{</span>
              <span class="s">'type'</span><span class="p">:</span> <span class="s">'string'</span><span class="p">,</span>
              <span class="s">'description'</span><span class="p">:</span> <span class="s">'The search query.'</span><span class="p">,</span>
            <span class="p">},</span>
          <span class="p">},</span>
          <span class="s">'required'</span><span class="p">:</span> <span class="p">[</span><span class="s">'query'</span><span class="p">],</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">}]</span>
</code></pre></div></div>

<h5 id="setting-up-the-interaction-loop">Setting up the Interaction Loop</h5>

<ul>
  <li>To ensure the model can call the tool multiple times (if needed), we set up a loop that enables the model to interact with tools and retrieve data iteratively until it has all necessary information.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code12"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code12"><span class="k">def</span> <span class="nf">ollama_generation_with_tools</span><span class="p">(</span><span class="n">user_message</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">tools_schema</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">tool_mapping</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"llama3.1"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[{</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"user"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="n">user_message</span><span class="p">}]</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">ollama</span><span class="p">.</span><span class="n">chat</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="n">tools_schema</span><span class="p">)</span>
    
    <span class="c1"># Check if the model needs to use a tool
</span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">response</span><span class="p">[</span><span class="s">"message"</span><span class="p">].</span><span class="n">get</span><span class="p">(</span><span class="s">"tool_calls"</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">response</span><span class="p">[</span><span class="s">"message"</span><span class="p">][</span><span class="s">"content"</span><span class="p">]</span>
    
    <span class="c1"># Handle tool calls and retrieve information
</span>    <span class="k">for</span> <span class="n">tool</span> <span class="ow">in</span> <span class="n">response</span><span class="p">[</span><span class="s">"message"</span><span class="p">][</span><span class="s">"tool_calls"</span><span class="p">]:</span>
        <span class="n">function_to_call</span> <span class="o">=</span> <span class="n">tool_mapping</span><span class="p">[</span><span class="n">tool</span><span class="p">[</span><span class="s">"function"</span><span class="p">][</span><span class="s">"name"</span><span class="p">]]</span>
        <span class="n">function_response</span> <span class="o">=</span> <span class="n">function_to_call</span><span class="p">(</span><span class="n">tool</span><span class="p">[</span><span class="s">"function"</span><span class="p">][</span><span class="s">"arguments"</span><span class="p">][</span><span class="s">"query"</span><span class="p">])</span>
        <span class="n">messages</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"tool"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="n">function_response</span><span class="p">})</span>
    
    <span class="c1"># Generate final response after tool calls
</span>    <span class="n">final_response</span> <span class="o">=</span> <span class="n">ollama</span><span class="p">.</span><span class="n">chat</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">final_response</span><span class="p">[</span><span class="s">"message"</span><span class="p">][</span><span class="s">"content"</span><span class="p">]</span>
</code></pre></div></div>

<h5 id="executing-the-agentic-rag-query">Executing the Agentic RAG Query</h5>

<ul>
  <li>Finally, we run the function, allowing the language model to interact with the <code class="language-plaintext highlighter-rouge">get_search_results</code> tool.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code13"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code13"><span class="n">tool_mapping</span> <span class="o">=</span> <span class="p">{</span><span class="s">"get_search_results"</span><span class="p">:</span> <span class="n">get_search_results</span><span class="p">}</span>  <span class="c1"># Maps tool name to function
</span><span class="n">response</span> <span class="o">=</span> <span class="n">ollama_generation_with_tools</span><span class="p">(</span>
    <span class="s">"How is HNSW different from DiskANN?"</span><span class="p">,</span>
    <span class="n">tools_schema</span><span class="o">=</span><span class="n">tools_schema</span><span class="p">,</span>
    <span class="n">tool_mapping</span><span class="o">=</span><span class="n">tool_mapping</span>
<span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>This setup enables the language model to retrieve dynamic information and perform tool-based retrievals as needed.</li>
</ul>

<h4 id="implementing-agentic-rag-with-agent-frameworks">Implementing Agentic RAG with Agent Frameworks</h4>

<ul>
  <li>Using agent frameworks streamlines the implementation process by providing templates and pre-built modules for multi-agent orchestration. Here’s how to set up an agentic RAG pipeline using LangChain as an example.</li>
</ul>

<h5 id="step-1-define-agents-and-tools">Step 1: Define Agents and Tools</h5>

<ul>
  <li>LangChain simplifies agentic RAG by managing tools and routing tasks. First, define the agents and register the tools they will use.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code14"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code14"><span class="kn">from</span> <span class="nn">langchain.tools</span> <span class="kn">import</span> <span class="n">WebSearchTool</span><span class="p">,</span> <span class="n">DatabaseTool</span><span class="p">,</span> <span class="n">CalculatorTool</span>
<span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">Agent</span>

<span class="c1"># Define tools for retrieval
</span><span class="n">web_search_tool</span> <span class="o">=</span> <span class="n">WebSearchTool</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="s">"YOUR_WEB_SEARCH_API_KEY"</span><span class="p">)</span>
<span class="n">database_tool</span> <span class="o">=</span> <span class="n">DatabaseTool</span><span class="p">(</span><span class="n">db_client</span><span class="o">=</span><span class="s">"your_database_client"</span><span class="p">)</span>
<span class="n">calculator_tool</span> <span class="o">=</span> <span class="n">CalculatorTool</span><span class="p">()</span>

<span class="c1"># Set up an agent with a routing function
</span><span class="n">retrieval_agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span>
    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">web_search_tool</span><span class="p">,</span> <span class="n">database_tool</span><span class="p">,</span> <span class="n">calculator_tool</span><span class="p">],</span>
    <span class="n">routing_function</span><span class="o">=</span><span class="s">"retrieve_and_select_tool"</span>
<span class="p">)</span>
</code></pre></div></div>

<h5 id="step-2-configure-agent-routing">Step 2: Configure Agent Routing</h5>

<ul>
  <li>Set up the routing function to let the agent decide which tool to use based on the input query.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code15"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code15"><span class="k">def</span> <span class="nf">retrieve_and_select_tool</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
    <span class="k">if</span> <span class="s">"calculate"</span> <span class="ow">in</span> <span class="n">query</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">calculator_tool</span>
    <span class="k">elif</span> <span class="s">"web"</span> <span class="ow">in</span> <span class="n">query</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">web_search_tool</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">database_tool</span>
</code></pre></div></div>

<h5 id="step-3-chain-agents-for-multi-agent-rag">Step 3: Chain Agents for Multi-Agent RAG</h5>

<ul>
  <li>In multi-agent RAG, you might have a “master agent” that routes queries to specialized agents based on query type. Here’s how to set up a master agent to coordinate multiple agents.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code16"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code16"><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">MultiAgent</span>

<span class="c1"># Define specialized agents
</span><span class="n">internal_agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">database_tool</span><span class="p">],</span> <span class="n">routing_function</span><span class="o">=</span><span class="s">"database_retrieval"</span><span class="p">)</span>
<span class="n">public_agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">web_search_tool</span><span class="p">],</span> <span class="n">routing_function</span><span class="o">=</span><span class="s">"web_retrieval"</span><span class="p">)</span>

<span class="c1"># Create a master agent to coordinate retrieval
</span><span class="n">master_agent</span> <span class="o">=</span> <span class="n">MultiAgent</span><span class="p">(</span><span class="n">agents</span><span class="o">=</span><span class="p">[</span><span class="n">internal_agent</span><span class="p">,</span> <span class="n">public_agent</span><span class="p">])</span>

<span class="c1"># Function to handle a query using master agent
</span><span class="k">def</span> <span class="nf">handle_query_with_master_agent</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">master_agent</span><span class="p">.</span><span class="n">handle_query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="running-the-multi-agent-query">Running the Multi-Agent Query</h5>

<ul>
  <li>Finally, to test the system, input a query and let the master agent route it appropriately:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code17"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code17"><span class="n">response</span> <span class="o">=</span> <span class="n">handle_query_with_master_agent</span><span class="p">(</span><span class="s">"Find recent studies on neural networks"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="disadvantages-of-agentic-rag">Disadvantages of Agentic RAG</h3>

<ul>
  <li>
    <p>Despite its advantages, agentic RAG comes with several limitations that should be carefully considered, particularly for time-sensitive applications:</p>

    <ol>
      <li>
        <p><strong>Increased Latency</strong>: The inherent complexity of agentic RAG often translates to longer response times. Each query may require multiple tool interactions and sequential retrieval steps, which increase the latency significantly. This can hinder the system’s usability in environments where quick responses are crucial, such as real-time support systems or conversational interfaces.</p>
      </li>
      <li>
        <p><strong>Higher Computational Cost</strong>: Agentic RAG systems often involve multiple calls to LLMs and other external tools. These calls cumulatively drive up computational costs, making it less efficient and potentially prohibitive for high-traffic applications. This expense adds to operational concerns, especially if the system must process large volumes of queries.</p>
      </li>
      <li>
        <p><strong>Production Feasibility</strong>: Due to the latency and cost concerns, agentic RAG may not be ideal for production applications requiring rapid and continuous output. In such cases, vanilla RAG, which offers more direct and faster response generation, might be more suitable.</p>
      </li>
    </ol>
  </li>
  <li>
    <p>While these drawbacks limit agentic RAG’s use in certain scenarios, its capability to generate high-quality, well-researched responses can make it worthwhile in contexts where response time is less critical and information accuracy is paramount.</p>
  </li>
</ul>

<h3 id="summary">Summary</h3>

<ul>
  <li>Agentic RAG refers to an agent-based implementation of RAG. AI agents are entities tasked with accomplishing specific objectives. These agents are often equipped with memory and tools, which they can utilize to carry out their tasks effectively. Among these tools, one significant capability is the ability to retrieve information from various sources, such as web searches or internal documents.</li>
  <li>In the context of agentic RAG, the “retrieval becomes agentic.” This implies that the AI agent is capable of reasoning and making decisions regarding which sources are most appropriate for retrieving the required information. The agent’s tool usage evolves beyond simple information retrieval, becoming more flexible and dynamic.</li>
  <li>The distinction between standard and agentic RAG can be summarized as follows:
    <ul>
      <li><strong>Common RAG</strong>: The user input prompts a single call to a database, retrieving additional information in response to the query.</li>
      <li><strong>Agentic RAG</strong>: The agent is able to deliberate on which source is the most suitable for retrieving information based on the query, providing a more sophisticated and adaptable approach.</li>
    </ul>
  </li>
  <li>The following figure (<a href="https://www.linkedin.com/in/804250ab/">source</a>) offers a visual summary of Agentic RAG:</li>
</ul>

<p><img src="/primers/ai/assets/RAG/AgenticRAG.jpg" alt=""></p>

<h2 id="rag-vs-long-context-windows">RAG vs. Long Context Windows</h2>

<h3 id="computational-cost">Computational Cost</h3>

<ul>
  <li>Processing extremely long contexts incurs substantial computational overhead. For instance, utilizing a 10 million token context window with state-of-the-art models like Llama 4 demands considerable hardware resources—approximately 32 H100 GPUs—which translates to over $100 per hour in inference costs. The key-value (KV) cache alone can exceed 1 terabyte of VRAM. These requirements pose a significant barrier to the practical deployment of long-context inference systems at scale, especially for organizations with limited infrastructure budgets.</li>
</ul>

<h3 id="inference-latency-and-throughput">Inference Latency and Throughput</h3>

<ul>
  <li>As the number of tokens increases, the latency of inference rises proportionally, often leading to a considerable decline in throughput. Even when hardware resources are available, this degradation in response time can negatively impact user experience in latency-sensitive applications such as virtual assistants, search engines, or real-time analytics systems.</li>
</ul>

<h3 id="contextual-comprehension-and-model-training-limitations">Contextual Comprehension and Model Training Limitations</h3>

<ul>
  <li>Although large context windows are theoretically capable of accommodating vast amounts of input data, current LLMs are typically trained on much smaller maximum context lengths—commonly up to 128,000 tokens. Consequently, performance across the full extent of a 10 million token context window is unproven and likely suboptimal. Empirical studies suggest that retrieval accuracy tends to diminish for information placed in the middle of a long context due to a phenomenon informally referred to as the “Lost in the Middle” effect. Therefore, while long-context architectures offer the promise of expanded capacity, their practical utility is constrained by training regimes and architectural bottlenecks.</li>
</ul>

<h3 id="rag-as-a-targeted-cost-efficient-solution">RAG As a Targeted, Cost-Efficient Solution</h3>

<ul>
  <li>In contrast, RAG provides a principled and efficient mechanism for narrowing down relevant content from a large corpus before conditioning the model’s generative process. By introducing a retrieval stage that identifies and ranks the most pertinent information, RAG minimizes unnecessary context, optimizes for response accuracy, and reduces memory and compute demands. This retrieval-first approach allows RAG systems to operate effectively within the token limitations of current LLMs, while maintaining scalability and affordability.</li>
</ul>

<h2 id="improving-rag-systems">Improving RAG Systems</h2>

<ul>
  <li>To enhance and refine RAG systems, consider the following methods that help contribute to more accurate and contextually relevant results, each accompanied by comprehensive guides and practical implementations:
    <ul>
      <li><strong>Re-ranking Retrieved Results</strong>: A fundamental and effective method involves employing a Re-ranking Model to refine the results obtained through initial retrieval. This approach prioritizes more relevant results, thereby improving the overall quality of the generated content. MonoT5, MonoBERT, DuoBERT, etc. are examples of deep models that can be used as re-rankers. For a detailed exploration of this technique, refer to the <a href="https://blog.lancedb.com/simplest-method-to-improve-rag-pipeline-re-ranking-cf6eaec6d544">guide and code example</a> provided by Mahesh Deshwal. A detailed discourse on re-ranking is available in the <a href="#re-ranking">Re-ranking</a> section.</li>
      <li><strong>FLARE Technique</strong>: Subsequent to re-ranking, one should explore the FLARE methodology. This technique dynamically queries the internet (could also be a local knowledge base) whenever the confidence level of a segment of the generated content falls below a specified threshold. This overcomes a significant limitation of conventional RAG systems, which typically query the knowledge base only at the outset and subsequently produce the final output. Akash Desai’s <a href="https://blog.lancedb.com/better-rag-with-active-retrieval-augmented-generation-flare-3b66646e2a9f">guide and code walkthrough</a> offer an insightful understanding and practical application of this technique. More on the FLARE technique in the <a href="#active-retrieval-augmented-generation">Active Retrieval Augmented Generation</a> section.</li>
      <li><strong>HyDE Approach</strong>: Finally, the HyDE technique introduces an innovative concept of generating a hypothetical document in response to a query. This document is then converted into an embedding vector. The uniqueness of this method lies in using the vector to identify a similar neighborhood within the corpus embedding space, thereby retrieving analogous real documents based on vector similarity. To delve into this method, refer to Akash Desai’s <a href="https://blog.lancedb.com/advanced-rag-precise-zero-shot-dense-retrieval-with-hyde-0946c54dfdcb">guide and code implementation</a>. More on the HyDE technique in the <a href="https://aman.ai/papers/#precise-zero-shot-dense-retrieval-without-relevance-labels">Precise Zero-Shot Dense Retrieval Without Relevance Labels</a> section.</li>
      <li><strong>REFRAG (REpresentation For RAG)</strong>: A framework designed to improve latency and efficiency in RAG systems by leveraging the sparsity and block-diagonal attention patterns of retrieved contexts. Instead of feeding full token sequences from retrieved passages, REFRAG compresses them into pre-computed chunk embeddings and selectively expands important chunks during decoding using a lightweight reinforcement learning policy. This compression-aware decoding reduces both memory and computational overhead without modifying the base LLM architecture. Experiments show that REFRAG achieves up to 30.85× faster time-to-first-token and extends context capacity by 16×, with no loss in perplexity or downstream accuracy across RAG, multi-turn conversation, and summarization tasks. The following figure from the paper shows the main design of REFRAG. The input context is chunked and processed by the light-weight encoder to produce chunk embeddings, which are precomputable for efficient reuse. A light-weight RL policy decides a few chunks to expand. These chunk embeddings along with the token embeddings of the question input are fed to the decoder.</li>
    </ul>

    <p><img src="../../../images/papers/REFRAG.jpg" alt="Figure 1 Placeholder: The main design of REFRAG"></p>
  </li>
</ul>

<h2 id="rag-20">RAG 2.0</h2>

<ul>
  <li><a href="https://contextual.ai/introducing-rag2/">RAG 2.0</a>, unveiled by <a href="https://contextual.ai">Contextual AI</a>, represents a significant advancement in robust AI systems for enterprise use, optimizing the entire system end-to-end unlike its predecessor. This new generation introduces Contextual Language Models (CLMs) which not only surpass the original RAG benchmarks but also outperform the strongest available models based on GPT-4, across various industry benchmarks, demonstrating superior performance in open domain question-answering and specialized tasks like truth verification.</li>
  <li>The introduction of RAG 2.0 marks a departure from the use of off-the-shelf models and disjointed components, which characterized previous systems as brittle and suboptimal for production environments. Instead, RAG 2.0 end-to-end optimizes the language model and retriever as a single system.</li>
  <li>Key improvements are evident in real-world applications where RAG 2.0 CLMs have been deployed. Using Google Cloud’s latest ML infrastructure, these models have shown significant accuracy enhancements, particularly in sectors like finance and law, highlighting their potential in specialized domains.</li>
  <li>Further comparisons reveal that RAG 2.0 significantly outperforms traditional long-context models, providing higher accuracy with less computational demand. This makes RAG 2.0 particularly appealing for scaling in production environments.</li>
  <li>Overall, RAG 2.0’s innovative approach not only pushes the boundaries of generative AI in production settings but also demonstrates its superiority through extensive benchmarks and real-world deployments, inviting enterprises to join in its ongoing development and application.</li>
</ul>

<h2 id="rag-benchmarks">RAG Benchmarks</h2>

<ul>
  <li>
    <p>RAG systems can be evaluated using <strong>retrieval-only benchmarks</strong> and <strong>end-to-end RAG benchmarks</strong>, where the latter jointly evaluate <strong>retrieval quality, grounded generation, and reasoning</strong>.</p>
  </li>
  <li>Retrieval-only benchmarks isolate the retriever and measure how well relevant documents are found, independent of generation.</li>
  <li>End-to-end RAG benchmarks evaluate the full pipeline including the <strong>retrieval and generation components</strong>, across settings such as open-domain QA, multi-hop reasoning, and grounded long-form generation. They probe different failure modes: <strong>retrieval quality</strong> (did the system fetch the right evidence?), <strong>generation quality</strong> (is the answer correct and fluent?), and <strong>grounding/faithfulness</strong> (is the answer supported by retrieved evidence?).</li>
  <li>Common evaluation metrics include recall@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-129-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1281" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1282"><span class="mi" id="MathJax-Span-1283" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-129">k</script>, MRR@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-130-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1284" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1285"><span class="mi" id="MathJax-Span-1286" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-130">k</script>, and NDCG for retrieval; EM and F1 for QA; and provenance precision/recall, citation accuracy, and faithfulness for grounded generation.</li>
  <li>Retrieval leaderboards track continual progress on ranking quality, while newer end-to-end benchmarks increasingly emphasize <strong>factual grounding, citation accuracy, and reasoning over retrieved documents</strong>.</li>
</ul>

<h3 id="retrieval-only-evaluation">Retrieval-Only Evaluation</h3>

<ul>
  <li>
    <p>These benchmarks are primarily used to evaluate retrieval quality in isolation, but are often components of RAG pipelines. The most common ones are listed below:</p>

    <ul>
      <li><strong>BEIR</strong>:
        <ul>
          <li>Introduced or proposed in <a href="https://arxiv.org/abs/2104.08663">BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models</a> by Thakur et al. (2021). A diverse suite of IR tasks designed to test retriever generalization across domains.</li>
          <li><strong>Evaluation framework:</strong> <a href="https://github.com/beir-cellar/beir">BEIR GitHub Repository</a></li>
          <li><strong>Typical metrics:</strong> NDCG@10, Recall@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-131-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1287" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1288"><span class="mi" id="MathJax-Span-1289" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-131">k</script>, Precision@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-132-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1290" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1291"><span class="mi" id="MathJax-Span-1292" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-132">k</script></li>
        </ul>
      </li>
      <li><strong>MS MARCO</strong>:
        <ul>
          <li>Introduced or proposed in <a href="https://arxiv.org/abs/2105.04021">MS MARCO: Benchmarking Ranking Models in the Large-Data Regime</a> by Craswell et al. (2021). A large-scale passage and document ranking benchmark derived from real Bing search queries.</li>
          <li><strong>Official leaderboards:</strong> <a href="https://microsoft.github.io/MSMARCO-Passage-Ranking-Submissions/leaderboard/">MS MARCO Passage Ranking Leaderboard</a></li>
          <li><strong>Typical metrics:</strong> MRR@10, NDCG@10, Recall@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-133-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1293" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1294"><span class="mi" id="MathJax-Span-1295" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-133">k</script></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="end-to-end-evaluation-retrieval--generation">End-to-End Evaluation (Retrieval + Generation)</h3>

<ul>
  <li>
    <p>These benchmarks evaluate retrieval as an integral part of the task and explicitly test grounded generation, reasoning, and faithfulness. The most common ones are listed below:</p>

    <ul>
      <li><strong>Natural Questions (Open-Domain QA)</strong>:
        <ul>
          <li>Introduced or proposed in <a href="https://aclanthology.org/Q19-1026.pdf">Natural Questions: A Benchmark for Question Answering Research</a> by Kwiatkowski et al. (2019). Real Google search queries with annotated answers; commonly used in open-domain QA and RAG setups where retrieval recall directly affects generation quality.</li>
          <li><strong>Community leaderboards:</strong> <a href="https://llm-stats.com/benchmarks/natural-questions">Natural Questions on LLM-Stats</a></li>
          <li><strong>Typical metrics:</strong> EM, F1, retrieval recall</li>
        </ul>
      </li>
      <li><strong>TriviaQA</strong>:
        <ul>
          <li>Introduced or proposed in <a href="https://arxiv.org/abs/1705.03551">TriviaQA: A Large-Scale Distantly Supervised Challenge Dataset for Reading Comprehension</a> by Joshi et al. (2017). Tests retrieval robustness and answer generation from noisy, long documents.</li>
          <li><strong>Typical metrics:</strong> EM, F1, evidence recall</li>
        </ul>
      </li>
      <li><strong>HotpotQA</strong>:
        <ul>
          <li>Introduced or proposed in <a href="https://arxiv.org/abs/1809.09600">HotpotQA: A Dataset for Diverse, Explainable Multi-Hop Question Answering</a> by Yang et al. (2018). Requires multi-hop retrieval and reasoning across multiple documents, making retrieval errors directly visible in generation quality.</li>
          <li><strong>Project page:</strong> <a href="https://hotpotqa.github.io/">HotpotQA</a></li>
          <li><strong>Typical metrics:</strong> EM, F1, supporting fact recall</li>
        </ul>
      </li>
      <li><strong>KILT</strong>:
        <ul>
          <li>Introduced or proposed in <a href="https://arxiv.org/abs/2009.02252">KILT: A Benchmark for Knowledge-Intensive Language Tasks</a> by Petroni et al. (2021). A unified benchmark that explicitly evaluates both answer correctness and evidence provenance across multiple tasks.</li>
          <li><strong>Official benchmark and leaderboards:</strong> <a href="https://ai.meta.com/tools/kilt/">KILT Benchmark Page</a></li>
          <li><strong>Typical metrics:</strong> EM, F1, provenance precision and recall</li>
        </ul>
      </li>
      <li><strong>FRAMES</strong>:
        <ul>
          <li>Introduced or proposed in <a href="https://arxiv.org/html/2409.12941v3">FRAMES: Fact, Fetch, and Reason for RAG Evaluation</a> by Liu et al. (2024). Designed specifically for RAG, with a strong emphasis on factual grounding, evidence usage, and reasoning in long-form answers.</li>
          <li><strong>Typical metrics:</strong> grounded answer accuracy, provenance correctness, faithfulness scores</li>
        </ul>
      </li>
      <li><strong>RAGBench</strong>:
        <ul>
          <li>Introduced or proposed in <a href="https://arxiv.org/abs/2407.11005">RAGBench: A Large-Scale Explainable Benchmark for Retrieval-Augmented Generation</a> by Friel et al. (2024). A large multi-domain benchmark aimed at holistic, explainable evaluation of retrieval and generation together.</li>
          <li><strong>Typical metrics:</strong> answer correctness, explanation alignment, retrieval–generation interaction scores</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="selected-papers">Selected Papers</h2>

<h3 id="retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks"><a href="https://arxiv.org/abs/2005.11401v4">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></h3>

<p><img src="/primers/ai/assets/RAG/2.png" alt=""></p>

<ul>
  <li>The paper by Lewis et al. from Facebook AI Research, University College London, and New York University, introduces Retrieval-Augmented Generation (RAG) models combining pre-trained parametric and non-parametric memory for language generation tasks.</li>
  <li>Addressing limitations of large pre-trained language models, such as difficulty in accessing and precisely manipulating knowledge, RAG models merge a pre-trained sequence-to-sequence (seq2seq) model with a dense vector index of Wikipedia, accessed by a neural retriever.</li>
  <li>The RAG framework encompasses two models: RAG-Sequence, using the same retrieved document for the entire sequence, and RAG-Token, allowing different passages for each token.</li>
  <li>The retrieval component, Dense Passage Retriever (DPR), uses a bi-encoder architecture with BERT-based document and query encoders. The generator component utilizes BART-large, a pre-trained seq2seq transformer with 400M parameters.</li>
  <li>RAG models were trained jointly on the retriever and generator components without direct supervision on which documents to retrieve, using stochastic gradient descent with Adam. The training used a Wikipedia dump as the non-parametric knowledge source, split into 21M 100-word chunks.</li>
  <li>A summary of the methods and models used for query/document embedding and retrieval, as well as the end-to-end structure of the RAG framework is as below:
    <ol>
      <li><strong>Query/Document Embedding:</strong>
        <ul>
          <li>The retrieval component, Dense Passage Retriever (DPR), follows a bi-encoder architecture.</li>
          <li>DPR uses BERTBASE as the foundation for both document and query encoders.</li>
          <li>For a document <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-134-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1296" style="width: 0.576em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.47em, 2.451em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1297"><span class="mi" id="MathJax-Span-1298" style="font-family: STIXGeneral-Italic;">z</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 0.753em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>z</mi></math></span></span><script type="math/tex" id="MathJax-Element-134">z</script>, a dense representation <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-135-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1299" style="width: 2.034em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.669em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1001.62em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1300"><span class="mi" id="MathJax-Span-1301" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-1302" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1303" style="font-family: STIXGeneral-Italic;">z</span><span class="mo" id="MathJax-Span-1304" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-135">d(z)</script> is produced by a document encoder, <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-136-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1305" style="width: 3.544em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.919em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1002.92em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1306"><span class="mi" id="MathJax-Span-1307" style="font-family: STIXGeneral-Italic;">B</span><span class="mi" id="MathJax-Span-1308" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-1309" style="font-family: STIXGeneral-Italic;">R</span><span class="msubsup" id="MathJax-Span-1310"><span style="display: inline-block; position: relative; width: 0.992em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1311" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.576em;"><span class="mi" id="MathJax-Span-1312" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi><mi>E</mi><mi>R</mi><msub><mi>T</mi><mi>d</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-136">BERT_d</script>.</li>
          <li>For a query <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-137-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1313" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1314"><span class="mi" id="MathJax-Span-1315" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></span></span><script type="math/tex" id="MathJax-Element-137">x</script>, a query representation <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-138-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1316" style="width: 2.034em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.669em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1001.62em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1317"><span class="mi" id="MathJax-Span-1318" style="font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-1319" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1320" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1321" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-138">q(x)</script> is produced by a query encoder, <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-139-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1322" style="width: 3.544em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.919em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1002.92em, 2.659em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1323"><span class="mi" id="MathJax-Span-1324" style="font-family: STIXGeneral-Italic;">B</span><span class="mi" id="MathJax-Span-1325" style="font-family: STIXGeneral-Italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-1326" style="font-family: STIXGeneral-Italic;">R</span><span class="msubsup" id="MathJax-Span-1327"><span style="display: inline-block; position: relative; width: 0.992em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1328" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.576em;"><span class="mi" id="MathJax-Span-1329" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi><mi>E</mi><mi>R</mi><msub><mi>T</mi><mi>q</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-139">BERT_q</script>.</li>
          <li>The embeddings are created such that relevant documents for a given query are close in the embedding space, allowing effective retrieval.</li>
        </ul>
      </li>
      <li><strong>Retrieval Process:</strong>
        <ul>
          <li>The retrieval process involves calculating the top-<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-140-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1330" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1331"><span class="mi" id="MathJax-Span-1332" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-140">k</script> documents with the highest prior probability, which is essentially a Maximum Inner Product Search (MIPS) problem.</li>
          <li>The MIPS problem is solved approximately in sub-linear time to efficiently retrieve relevant documents.</li>
        </ul>
      </li>
      <li><strong>End-to-End Structure:</strong>
        <ul>
          <li>The RAG model uses the input sequence <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-141-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1333" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1334"><span class="mi" id="MathJax-Span-1335" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></span></span><script type="math/tex" id="MathJax-Element-141">x</script> to retrieve text documents <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-142-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1336" style="width: 0.576em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.47em, 2.451em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1337"><span class="mi" id="MathJax-Span-1338" style="font-family: STIXGeneral-Italic;">z</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 0.753em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>z</mi></math></span></span><script type="math/tex" id="MathJax-Element-142">z</script>, which are then used as additional context for generating the target sequence <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-143-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1339" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1340"><span class="mi" id="MathJax-Span-1341" style="font-family: STIXGeneral-Italic;">y</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-143">y</script>.</li>
          <li>The generator component is modeled using BART-large, a pre-trained seq2seq transformer with 400M parameters. BART-large combines the input <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-144-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1342" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1343"><span class="mi" id="MathJax-Span-1344" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></span></span><script type="math/tex" id="MathJax-Element-144">x</script>with the retrieved content <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-145-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1345" style="width: 0.576em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.47em, 2.451em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1346"><span class="mi" id="MathJax-Span-1347" style="font-family: STIXGeneral-Italic;">z</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 0.753em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>z</mi></math></span></span><script type="math/tex" id="MathJax-Element-145">z</script> for generation.</li>
          <li>The RAG-Sequence model uses the same retrieved document for generating the complete sequence, while the RAG-Token model can use different passages per token.</li>
          <li>The training process involves jointly training the retriever and generator components without direct supervision on what document should be retrieved. The training minimizes the negative marginal log-likelihood of each target using stochastic gradient descent with Adam.</li>
          <li>Notably, the document encoder BERTd is kept fixed during training, avoiding the need for periodic updates of the document index.</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>The following figure from the paper illustrates an overview of the proposed approach. They combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and fine-tune end-to-end. For query <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-146-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1348" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1349"><span class="mi" id="MathJax-Span-1350" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></span></span><script type="math/tex" id="MathJax-Element-146">x</script>, they use Maximum Inner Product Search (MIPS) to find the top-<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-147-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1351" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1352"><span class="mi" id="MathJax-Span-1353" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-147">K</script> documents <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-148-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1354" style="width: 0.836em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1000.68em, 2.451em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1355"><span class="msubsup" id="MathJax-Span-1356"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.37em, 4.273em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1357" style="font-family: STIXGeneral-Italic;">z</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.367em;"><span class="mi" id="MathJax-Span-1358" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>z</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-148">z_i</script>. For final prediction <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-149-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1359" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1360"><span class="mi" id="MathJax-Span-1361" style="font-family: STIXGeneral-Italic;">y</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-149">y</script>, they treat <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-150-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;z&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1362" style="width: 0.576em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.47em, 2.451em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1363"><span class="mi" id="MathJax-Span-1364" style="font-family: STIXGeneral-Italic;">z</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 0.753em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>z</mi></math></span></span><script type="math/tex" id="MathJax-Element-150">z</script> as a latent variable and marginalize over seq2seq predictions given different documents.</li>
</ul>

<p><img src="../../../images/papers/RAG.jpg" alt=""></p>

<ul>
  <li>In open-domain QA tasks, RAG established new state-of-the-art results, outperforming both parametric seq2seq models and task-specific retrieve-and-extract architectures. RAG models showed the ability to generate correct answers even when the right answer wasn’t in any retrieved document.</li>
  <li>RAG-Sequence surpassed BART in Open MS-MARCO NLG, indicating less hallucination and more factually correct text generation. RAG-Token outperformed RAG-Sequence in Jeopardy question generation, demonstrating higher factuality and specificity.</li>
  <li>On the FEVER fact verification task, RAG models achieved results close to state-of-the-art models that require more complex architectures and intermediate retrieval supervision.</li>
  <li>This study showcases the effectiveness of hybrid generation models, combining parametric and non-parametric memories, offering new directions in combining these components for a range of NLP tasks.</li>
  <li><a href="https://github.com/huggingface/transformers/blob/master/examples/rag/">Code</a>; <a href="https://huggingface.co/rag/">interactive demo</a>.</li>
</ul>

<h3 id="active-retrieval-augmented-generation"><a href="https://arxiv.org/abs/2305.06983">Active Retrieval Augmented Generation</a></h3>

<ul>
  <li>Despite the remarkable ability of large language models (LLMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output.</li>
  <li>Augmenting LLMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval-augmented LLMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout the generation process is essential. There have been some past efforts to retrieve information multiple times while generating outputs, which mostly retrieve documents at fixed intervals using the previous context as queries.</li>
  <li>This paper from Jiang et al. at CMU, Sea AI Lab, and Meta AI in EMNLP 2023 presents Forward-Looking Active REtrieval augmented generation (FLARE), a method addressing the tendency of large language models (LLMs) to produce factually inaccurate content.</li>
  <li>FLARE iteratively uses predictions of upcoming sentences to actively decide when and what to retrieve across the generation process, enhancing LLMs with dynamic, multi-stage external information retrieval.</li>
  <li>Unlike traditional retrieve-and-generate models that use fixed intervals or input-based retrieval, FLARE targets continual information gathering for long text generation, reducing hallucinations and factual inaccuracies.</li>
  <li>The system triggers retrieval when generating low-confidence tokens, determined by a probability threshold. This anticipates future content, forming queries to retrieve relevant documents for regeneration.</li>
  <li>The following figure from the paper illustrates FLARE. Starting with the user input <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-151-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1365" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1366"><span class="mi" id="MathJax-Span-1367" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi></math></span></span><script type="math/tex" id="MathJax-Element-151">x</script> and initial retrieval results <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-152-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1368" style="width: 1.357em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.096em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1001.1em, 2.451em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1369"><span class="msubsup" id="MathJax-Span-1370"><span style="display: inline-block; position: relative; width: 1.096em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1371" style="font-family: STIXGeneral-Italic;">D</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.732em;"><span class="mi" id="MathJax-Span-1372" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>D</mi><mi>x</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-152">D_x</script>, FLARE iteratively generates a temporary next sentence (shown in gray italic) and check whether it contains low-probability tokens (indicated with underline). If so (step 2 and 3), the system retrieves relevant documents and regenerates the sentence.</li>
</ul>

<p><img src="../../../images/papers/ARAG.jpg" alt=""></p>

<ul>
  <li>FLARE was tested on four long-form, knowledge-intensive generation tasks/datasets, exhibiting superior or competitive performance, demonstrating its effectiveness in addressing the limitations of existing retrieval-augmented LLMs.</li>
  <li>The model is adaptable to existing LLMs, as shown with its implementation on GPT-3.5, and employs off-the-shelf retrievers and the Bing search engine.</li>
  <li><a href="https://github.com/jzbjyb/FLARE">Code</a>.</li>
</ul>

<h3 id="murag-multimodal-retrieval-augmented-generator"><a href="https://arxiv.org/abs/2210.02928">MuRAG: Multimodal Retrieval-Augmented Generator</a></h3>

<ul>
  <li>This paper by Chen et al. from Google Research proposes Multimodal Retrieval-Augmented Transformer (MuRAG), which looks to extend the retrieval process beyond text to include other modalities like images or structured data, which can then be used alongside textual information to inform the generation process.</li>
  <li>MuRAG’s magic lies in its two-phase training approach: pre-training and fine-tuning, each carefully crafted to build the model’s ability to tap into a vast expanse of multimodal knowledge.</li>
  <li>The key goal of MuRAG is to incorporate both visual and textual knowledge into language models to improve their capability for multimodal question answering.</li>
  <li>MuRAG is distinct in its ability to access an external non-parametric multimodal memory (images and texts) to enhance language generation, addressing the limitations of text-only retrieval in previous models.</li>
  <li>MuRAG has a dual-encoder architecture combines pre-trained visual transformer (ViT) and a text encoder (T5) models to create a backbone encoder, enabling the encoding of image-text pairs, image-only, and text-only inputs into a unified/joint multimodal representation.</li>
  <li>MuRAG is pre-trained on a mixture of image-text data (LAION, Conceptual Captions) and text-only data (PAQ, VQA). It uses a contrastive loss for retrieving relevant knowledge and a generation loss for answer prediction. It employs a two-stage training pipeline: initial training with small in-batch memory followed by training with a large global memory.</li>
  <li>During the retriever stage, MuRAG takes a query <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-153-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1373" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1374"><span class="mi" id="MathJax-Span-1375" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></span></span><script type="math/tex" id="MathJax-Element-153">q</script> of any modality as input and retrieves from a memory <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-154-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;M&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1376" style="width: 0.888em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.68em, 2.398em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1377"><span class="texatom" id="MathJax-Span-1378"><span class="mrow" id="MathJax-Span-1379"><span class="mi" id="MathJax-Span-1380" style="font-family: STIXNonUnicode-Italic;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">M</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-154">\mathcal{M}</script> of image-text pairs. Specifically, we apply the backbone encoder <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-155-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1381" style="width: 0.836em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1000.68em, 2.503em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1382"><span class="msubsup" id="MathJax-Span-1383"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1384" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.159em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.263em;"><span class="mi" id="MathJax-Span-1385" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">θ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>f</mi><mi>θ</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-155">f_\theta</script> to encode a query <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-156-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1386" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1387"><span class="mi" id="MathJax-Span-1388" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></span></span><script type="math/tex" id="MathJax-Element-156">q</script>, and use maximum inner product search (MIPS) over all of the memory candidates <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-157-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;M&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1389" style="width: 3.284em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.711em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1002.66em, 2.451em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-1390"><span class="mi" id="MathJax-Span-1391" style="font-family: STIXGeneral-Italic;">m</span><span class="mo" id="MathJax-Span-1392" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∈</span><span class="texatom" id="MathJax-Span-1393" style="padding-left: 0.315em;"><span class="mrow" id="MathJax-Span-1394"><span class="mi" id="MathJax-Span-1395" style="font-family: STIXNonUnicode-Italic;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>m</mi><mo>∈</mo><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">M</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-157">m \in \mathcal{M}</script> to find the top-<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-158-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1396" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1397"><span class="mi" id="MathJax-Span-1398" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-158">k</script> nearest neighbors <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-159-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;Top&lt;/mi&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;M&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;&amp;#x22EF;&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1399" style="width: 13.544em; display: inline-block;"><span style="display: inline-block; position: relative; width: 11.253em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1011.15em, 2.815em, -999.997em); top: -2.393em; left: 0em;"><span class="mrow" id="MathJax-Span-1400"><span class="msubsup" id="MathJax-Span-1401"><span style="display: inline-block; position: relative; width: 2.19em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1001.57em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1402" style="font-family: STIXGeneral-Regular;">Top</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.747em; left: 1.617em;"><span class="mi" id="MathJax-Span-1403" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1404"></span><span class="mo" id="MathJax-Span-1405" style="font-family: STIXGeneral-Regular;">(</span><span class="texatom" id="MathJax-Span-1406"><span class="mrow" id="MathJax-Span-1407"><span class="mi" id="MathJax-Span-1408" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-1409" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣</span><span class="mi" id="MathJax-Span-1410" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">q</span><span class="mo" id="MathJax-Span-1411" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-1412" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mrow" id="MathJax-Span-1413" style="padding-left: 0.315em;"><span class="mo" id="MathJax-Span-1414" style="vertical-align: 0.003em;"><span style="font-family: STIXGeneral-Regular;">[</span></span><span class="mrow" id="MathJax-Span-1415"><span class="msubsup" id="MathJax-Span-1416"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1417" style="font-family: STIXGeneral-Italic;">m</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.732em;"><span class="mn" id="MathJax-Span-1418" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1419" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-1420" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">⋯</span><span class="mo" id="MathJax-Span-1421" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">,</span><span class="msubsup" id="MathJax-Span-1422" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1423" style="font-family: STIXGeneral-Italic;">m</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.732em;"><span class="mi" id="MathJax-Span-1424" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-1425" style="vertical-align: 0.003em;"><span style="font-family: STIXGeneral-Regular;">]</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.398em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>Top</mi><mi>K</mi></msub><mo>⁡</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">M</mi></mrow><mo>∣</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>[</mo><mrow><msub><mi>m</mi><mn>1</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><msub><mi>m</mi><mi>k</mi></msub></mrow><mo>]</mo></mrow></math></span></span><script type="math/tex" id="MathJax-Element-159">\operatorname{Top}_K(\mathcal{M} \mid q)=\left[m_1, \cdots, m_k\right]</script>. Formally, we define <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-160-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;Top&lt;/mi&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;M&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1426" style="width: 5.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.951em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1004.9em, 2.659em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-1427"><span class="msubsup" id="MathJax-Span-1428"><span style="display: inline-block; position: relative; width: 2.19em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1001.57em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1429" style="font-family: STIXGeneral-Regular;">Top</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.747em; left: 1.617em;"><span class="mi" id="MathJax-Span-1430" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1431"></span><span class="mo" id="MathJax-Span-1432" style="font-family: STIXGeneral-Regular;">(</span><span class="texatom" id="MathJax-Span-1433"><span class="mrow" id="MathJax-Span-1434"><span class="mi" id="MathJax-Span-1435" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-1436" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣</span><span class="mi" id="MathJax-Span-1437" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">q</span><span class="mo" id="MathJax-Span-1438" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>Top</mi><mi>K</mi></msub><mo>⁡</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">M</mi></mrow><mo>∣</mo><mi>q</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-160">\operatorname{Top}_K(\mathcal{M} \mid q)</script> as follows:</li>
</ul>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-161-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;msub&gt;&lt;mi&gt;Top&lt;/mi&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;M&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mi&gt;Top&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mo&gt;&amp;#x2208;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;M&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/munder&gt;&lt;mspace width=&quot;1em&quot; /&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;C&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;L&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;S&lt;/mi&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x22C5;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;C&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;L&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;S&lt;/mi&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1439" style="width: 21.565em; display: inline-block;"><span style="display: inline-block; position: relative; width: 17.971em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.409em, 1017.97em, 3.44em, -999.997em); top: -2.237em; left: 0em;"><span class="mrow" id="MathJax-Span-1440"><span class="msubsup" id="MathJax-Span-1441"><span style="display: inline-block; position: relative; width: 2.19em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1001.57em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1442" style="font-family: STIXGeneral-Regular;">Top</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.747em; left: 1.617em;"><span class="mi" id="MathJax-Span-1443" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1444"></span><span class="mo" id="MathJax-Span-1445" style="font-family: STIXGeneral-Regular;">(</span><span class="texatom" id="MathJax-Span-1446"><span class="mrow" id="MathJax-Span-1447"><span class="mi" id="MathJax-Span-1448" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-1449" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣</span><span class="mi" id="MathJax-Span-1450" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">q</span><span class="mo" id="MathJax-Span-1451" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-1452" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="munder" id="MathJax-Span-1453" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.826em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1001.57em, 4.378em, -999.997em); top: -4.008em; left: 0.107em;"><span class="mi" id="MathJax-Span-1454" style="font-family: STIXGeneral-Regular;">Top</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1001.77em, 4.326em, -999.997em); top: -3.122em; left: 0em;"><span class="mrow" id="MathJax-Span-1455"><span class="mi" id="MathJax-Span-1456" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">m</span><span class="mo" id="MathJax-Span-1457" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∈</span><span class="texatom" id="MathJax-Span-1458"><span class="mrow" id="MathJax-Span-1459"><span class="mi" id="MathJax-Span-1460" style="font-size: 70.7%; font-family: STIXNonUnicode-Italic;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mspace" id="MathJax-Span-1461" style="height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;"></span><span class="msubsup" id="MathJax-Span-1462" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1463" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.159em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.263em;"><span class="mi" id="MathJax-Span-1464" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">θ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1465" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1466" style="font-family: STIXGeneral-Italic;">q</span><span class="msubsup" id="MathJax-Span-1467"><span style="display: inline-block; position: relative; width: 2.19em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.26em, 4.326em, -999.997em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-1468" style="font-family: STIXGeneral-Regular;">)</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.315em;"><span class="texatom" id="MathJax-Span-1469"><span class="mrow" id="MathJax-Span-1470"><span class="mo" id="MathJax-Span-1471" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">[</span><span class="texatom" id="MathJax-Span-1472"><span class="mrow" id="MathJax-Span-1473"><span class="mi" id="MathJax-Span-1474" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">C</span><span class="mi" id="MathJax-Span-1475" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">L</span><span class="mi" id="MathJax-Span-1476" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">S</span></span></span><span class="mo" id="MathJax-Span-1477" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">]</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1478" style="font-family: STIXGeneral-Regular; padding-left: 0.263em;">⋅</span><span class="msubsup" id="MathJax-Span-1479" style="padding-left: 0.263em;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1480" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.159em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.263em;"><span class="mi" id="MathJax-Span-1481" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">θ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1482" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1483" style="font-family: STIXGeneral-Italic;">m</span><span class="msubsup" id="MathJax-Span-1484"><span style="display: inline-block; position: relative; width: 2.19em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.26em, 4.326em, -999.997em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-1485" style="font-family: STIXGeneral-Regular;">)</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.315em;"><span class="texatom" id="MathJax-Span-1486"><span class="mrow" id="MathJax-Span-1487"><span class="mo" id="MathJax-Span-1488" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">[</span><span class="texatom" id="MathJax-Span-1489"><span class="mrow" id="MathJax-Span-1490"><span class="mi" id="MathJax-Span-1491" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">C</span><span class="mi" id="MathJax-Span-1492" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">L</span><span class="mi" id="MathJax-Span-1493" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">S</span></span></span><span class="mo" id="MathJax-Span-1494" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">]</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.242em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.309em; border-left: 0px solid; width: 0px; height: 2.191em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>Top</mi><mi>K</mi></msub><mo>⁡</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">M</mi></mrow><mo>∣</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mi>Top</mi><mrow><mi>m</mi><mo>∈</mo><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">M</mi></mrow></mrow></munder><mspace width="1em"></mspace><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>q</mi><msub><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">[</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="normal">C</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">S</mi></mrow><mo stretchy="false">]</mo></mrow></msub><mo>⋅</mo><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>m</mi><msub><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">[</mo><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="normal">C</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">S</mi></mrow><mo stretchy="false">]</mo></mrow></msub></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-161">\operatorname{Top}_K(\mathcal{M} \mid q)=\underset{m \in \mathcal{M}}{\operatorname{Top}} \quad f_\theta(q)_{[\mathrm{CLS}]} \cdot f_\theta(m)_{[\mathrm{CLS}]}</script>

<ul>
  <li>
    <p>During the reader stage, the retrievals (the raw image patches) are combined with the query <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-162-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1495" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1496"><span class="mi" id="MathJax-Span-1497" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></span></span><script type="math/tex" id="MathJax-Element-162">q</script> as an augmented input <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-163-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mo&gt;[&lt;/mo&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;&amp;#x22EF;&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1498" style="width: 7.294em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.044em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1005.94em, 2.763em, -999.997em); top: -2.393em; left: 0em;"><span class="mrow" id="MathJax-Span-1499"><span class="mrow" id="MathJax-Span-1500"><span class="mo" id="MathJax-Span-1501" style="vertical-align: 0.003em;"><span style="font-family: STIXGeneral-Regular;">[</span></span><span class="mrow" id="MathJax-Span-1502"><span class="msubsup" id="MathJax-Span-1503"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1504" style="font-family: STIXGeneral-Italic;">m</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.732em;"><span class="mn" id="MathJax-Span-1505" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1506" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-1507" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">⋯</span><span class="mo" id="MathJax-Span-1508" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">,</span><span class="msubsup" id="MathJax-Span-1509" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1510" style="font-family: STIXGeneral-Italic;">m</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.732em;"><span class="mi" id="MathJax-Span-1511" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1512" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-1513" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">q</span></span><span class="mo" id="MathJax-Span-1514" style="vertical-align: 0.003em;"><span style="font-family: STIXGeneral-Regular;">]</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.398em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>[</mo><mrow><msub><mi>m</mi><mn>1</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><msub><mi>m</mi><mi>k</mi></msub><mo>,</mo><mi>q</mi></mrow><mo>]</mo></mrow></math></span></span><script type="math/tex" id="MathJax-Element-163">\left[m_1, \cdots, m_k, q\right]</script>, which is fed to the backbone encoder <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-164-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1515" style="width: 0.836em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1000.68em, 2.503em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1516"><span class="msubsup" id="MathJax-Span-1517"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1518" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.159em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.263em;"><span class="mi" id="MathJax-Span-1519" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">θ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>f</mi><mi>θ</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-164">f_\theta</script> to produce retrievalaugmented encoding. The decoder model <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-165-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1520" style="width: 1.148em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1000.94em, 2.503em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1521"><span class="msubsup" id="MathJax-Span-1522"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1523" style="font-family: STIXGeneral-Italic;">g</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="mi" id="MathJax-Span-1524" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">θ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>g</mi><mi>θ</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-165">g_\theta</script> uses attention over this representation to generate textual outputs <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-166-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;y&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;&amp;#x22EF;&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1525" style="width: 6.773em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.628em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.878em, 1005.63em, 2.867em, -999.997em); top: -2.497em; left: 0em;"><span class="mrow" id="MathJax-Span-1526"><span class="texatom" id="MathJax-Span-1527"><span class="mrow" id="MathJax-Span-1528"><span class="mi" id="MathJax-Span-1529" style="font-family: STIXGeneral; font-weight: bold;">y</span></span></span><span class="mo" id="MathJax-Span-1530" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="msubsup" id="MathJax-Span-1531" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1532" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mn" id="MathJax-Span-1533" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1534" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-1535" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">⋯</span><span class="mo" id="MathJax-Span-1536" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">,</span><span class="msubsup" id="MathJax-Span-1537" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1538" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mi" id="MathJax-Span-1539" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.503em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="bold">y</mi></mrow><mo>=</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><msub><mi>y</mi><mi>n</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-166">\mathbf{y}=y_1, \cdots, y_n</script> token by token.</p>

<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-167-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/msub&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;&amp;#x03B8;&lt;/mi&gt;&lt;/msub&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;Top&lt;/mi&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;&amp;#x2061;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;M&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;;&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;:&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="text-align: center; position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1540" style="width: 24.326em; display: inline-block;"><span style="display: inline-block; position: relative; width: 20.263em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.878em, 1020.11em, 3.44em, -999.997em); top: -2.914em; left: 0em;"><span class="mrow" id="MathJax-Span-1541"><span class="mi" id="MathJax-Span-1542" style="font-family: STIXGeneral-Italic;">p</span><span class="mrow" id="MathJax-Span-1543" style="padding-left: 0.211em;"><span class="mo" id="MathJax-Span-1544" style="vertical-align: -0.206em;"><span style="font-family: STIXSizeOneSym;">(</span></span><span class="mrow" id="MathJax-Span-1545"><span class="msubsup" id="MathJax-Span-1546"><span style="display: inline-block; position: relative; width: 0.732em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1547" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mi" id="MathJax-Span-1548" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1549" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣</span><span class="msubsup" id="MathJax-Span-1550" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.565em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1551" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="texatom" id="MathJax-Span-1552"><span class="mrow" id="MathJax-Span-1553"><span class="mi" id="MathJax-Span-1554" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-1555" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mn" id="MathJax-Span-1556" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-1557" style="vertical-align: -0.206em;"><span style="font-family: STIXSizeOneSym;">)</span></span></span><span class="mo" id="MathJax-Span-1558" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="msubsup" id="MathJax-Span-1559" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1560" style="font-family: STIXGeneral-Italic;">g</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="mi" id="MathJax-Span-1561" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">θ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mrow" id="MathJax-Span-1562" style="padding-left: 0.211em;"><span class="mo" id="MathJax-Span-1563" style="vertical-align: -0.206em;"><span style="font-family: STIXSizeOneSym;">(</span></span><span class="mrow" id="MathJax-Span-1564"><span class="msubsup" id="MathJax-Span-1565"><span style="display: inline-block; position: relative; width: 0.732em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1566" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mi" id="MathJax-Span-1567" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1568" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣</span><span class="msubsup" id="MathJax-Span-1569" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 0.68em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1570" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.159em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.263em;"><span class="mi" id="MathJax-Span-1571" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">θ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mrow" id="MathJax-Span-1572" style="padding-left: 0.211em;"><span class="mo" id="MathJax-Span-1573" style="vertical-align: -0.206em;"><span style="font-family: STIXSizeOneSym;">(</span></span><span class="mrow" id="MathJax-Span-1574"><span class="msubsup" id="MathJax-Span-1575"><span style="display: inline-block; position: relative; width: 2.19em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1001.57em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1576" style="font-family: STIXGeneral-Regular;">Top</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.747em; left: 1.617em;"><span class="mi" id="MathJax-Span-1577" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1578"></span><span class="mo" id="MathJax-Span-1579" style="font-family: STIXGeneral-Regular;">(</span><span class="texatom" id="MathJax-Span-1580"><span class="mrow" id="MathJax-Span-1581"><span class="mi" id="MathJax-Span-1582" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span class="mo" id="MathJax-Span-1583" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">∣</span><span class="mi" id="MathJax-Span-1584" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">q</span><span class="mo" id="MathJax-Span-1585" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-1586" style="font-family: STIXGeneral-Regular;">;</span><span class="mi" id="MathJax-Span-1587" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">q</span></span><span class="mo" id="MathJax-Span-1588" style="vertical-align: -0.206em;"><span style="font-family: STIXSizeOneSym;">)</span></span></span><span class="mo" id="MathJax-Span-1589" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">;</span><span class="msubsup" id="MathJax-Span-1590" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 2.086em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1591" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="texatom" id="MathJax-Span-1592"><span class="mrow" id="MathJax-Span-1593"><span class="mn" id="MathJax-Span-1594" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-1595" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">:</span><span class="mi" id="MathJax-Span-1596" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-1597" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mn" id="MathJax-Span-1598" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-1599" style="vertical-align: -0.206em;"><span style="font-family: STIXSizeOneSym;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.919em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.628em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>p</mi><mrow><mo>(</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>∣</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><mo>)</mo></mrow><mo>=</mo><msub><mi>g</mi><mi>θ</mi></msub><mrow><mo>(</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>∣</mo><msub><mi>f</mi><mi>θ</mi></msub><mrow><mo>(</mo><mrow><msub><mi>Top</mi><mi>K</mi></msub><mo>⁡</mo><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">M</mi></mrow><mo>∣</mo><mi>q</mi><mo stretchy="false">)</mo><mo>;</mo><mi>q</mi></mrow><mo>)</mo></mrow><mo>;</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mn>1</mn><mo>:</mo><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><mo>)</mo></mrow></math></span></span></div><script type="math/tex; mode=display" id="MathJax-Element-167">p\left(y_i \mid y_{i-1}\right)=g_\theta\left(y_i \mid f_\theta\left(\operatorname{Top}_K(\mathcal{M} \mid q) ; q\right) ; y_{1: i-1}\right)</script>

    <ul>
      <li>where <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-168-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1600" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1601"><span class="mi" id="MathJax-Span-1602" style="font-family: STIXGeneral-Italic;">y</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-168">y</script> is decoded from a given vocabulary <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-169-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;V&lt;/mi&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1603" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.398em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1604"><span class="texatom" id="MathJax-Span-1605"><span class="mrow" id="MathJax-Span-1606"><span class="mi" id="MathJax-Span-1607" style="font-family: STIXNonUnicode-Italic;"><span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">V</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-169">\mathcal{V}</script>.</li>
    </ul>
  </li>
  <li>
    <p>The figure below from the original paper <a href="https://arxiv.org/abs/2210.02928">(source)</a> shows how the model taps into an external repository to retrieve a diverse range of knowledge encapsulated within both images and textual fragments. This multimodal information is then employed to enhance the generative process. The upper section outlines the setup for the pre-training phase, whereas the lower section specifies the framework for the fine-tuning phase.</p>
  </li>
</ul>

<p><img src="../../../images/papers/MuRAG.jpg" alt=""></p>

<ul>
  <li>The process can be summarized as follows:
    <ul>
      <li>For retrieval, MuRAG uses maximum inner product search to find the top-<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-170-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1608" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1609"><span class="mi" id="MathJax-Span-1610" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-170">k</script> most relevant image-text pairs from the memory given a question. The “memory” here refers to the external knowledge base that the model can retrieve information from. Specifically, the memory contains a large collection of image-text pairs that are encoded offline by the backbone encoder prior to training.</li>
      <li>During training and inference, given a question, MuRAG’s retriever module will search through this memory to find the most relevant image-text pairs using maximum inner product search.</li>
      <li>The memory serves as the knowledge source and can contain various types of multimodal data like images with captions, passages of text, tables, etc. that are related to the downstream task.</li>
      <li>For example, when fine-tuning on the WebQA dataset, the memory contains 1.1 million image-text pairs extracted from Wikipedia that the model can retrieve from to answer questions.</li>
      <li>So in summary, the memory is the large non-parametric external knowledge base encoded in a multimodal space that MuRAG learns to retrieve relevant knowledge from given a question, in order to augment its language generation capabilities. The memory provides the world knowledge to complement what is stored implicitly in the model’s parameters.</li>
      <li>For reading, the retrieved multimodal context is combined with the question embedding and fed into the decoder to generate an answer.</li>
    </ul>
  </li>
  <li>MuRAG achieves state-of-the-art results on two multimodal QA datasets - WebQA and MultimodalQA, outperforming text-only methods by 10-20% accuracy. It demonstrates the value of incorporating both visual and textual knowledge.</li>
  <li>Key limitations are the reliance on large-scale pre-training data, computational costs, and issues in visual reasoning like counting objects. But overall, MuRAG represents an important advance in building visually-grounded language models.</li>
</ul>

<h3 id="hypothetical-document-embeddings-hyde"><a href="https://arxiv.org/abs/2212.10496">Hypothetical Document Embeddings (HyDE)</a></h3>

<ul>
  <li>Published in <a href="https://arxiv.org/abs/2212.10496">Precise Zero-Shot Dense Retrieval without Relevance Labels</a> by Gao et al. from CMU and University of Waterloo, proposes an innovative approach called Hypothetical Document Embeddings (HyDE) for effective zero-shot dense retrieval in the absence of relevance labels. HyDE leverages an instruction-following language model, such as InstructGPT, to generate a hypothetical document that captures relevance patterns, although it may contain factual inaccuracies. An unsupervised contrastive encoder, like Contriever, then encodes this document into an embedding vector to identify similar real documents in the corpus embedding space, effectively filtering out incorrect details.</li>
  <li>The implementation of HyDE combines InstructGPT (a GPT-3 model) and Contriever models, utilizing OpenAI playground’s default temperature setting for generation. For English retrieval tasks, the English-only Contriever model was used, while for non-English tasks, the multilingual mContriever was employed.</li>
  <li>The following image from the paper illustrates the HyDE model. Documents snippets are shown. HyDE serves all types of queries without changing the underlying GPT-3 and Contriever/mContriever models.</li>
</ul>

<p><img src="../../../images/papers/HyDE.jpg" alt=""></p>

<ul>
  <li>Experiments were conducted using the Pyserini toolkit. The results demonstrate HyDE’s significant improvement over the state-of-the-art unsupervised dense retriever Contriever, with strong performance comparable to fine-tuned retrievers across various tasks and languages. Specifically, in web search and low-resource tasks, HyDE showed sizable improvements in precision and recall-oriented metrics. It remained competitive even compared to fine-tuned models, particularly in terms of recall. In multilingual retrieval, HyDE improved the mContriever model and outperformed non-Contriever models fine-tuned on MS-MARCO. However, there were some performance gaps with fine-tuned mContrieverFT, likely due to under-training in non-English languages.</li>
  <li>Further analysis explored the effects of using different generative models and fine-tuned encoders with HyDE. Larger language models brought greater improvements, and the use of fine-tuned encoders with HyDE showed that less powerful instruction language models could impact the performance of the fine-tuned retriever.</li>
  <li>One possible pitfall of HyDE is that it can potentially “hallucinate” in the sense that it generates hypothetical documents that may contain invented or inaccurate details. This phenomenon occurs because HyDE uses an instruction-following language model, like InstructGPT, to generate a document based on a query. The generated document is intended to capture the relevance patterns of the query, but since it’s created without direct reference to real-world data, it can include false or fictional information. This aspect of HyDE is a trade-off for its ability to operate in zero-shot retrieval scenarios, where it creates a contextually relevant but not necessarily factually accurate document to guide the retrieval process.</li>
  <li>In conclusion, the paper introduces a new paradigm of interaction between language models and dense encoders/retrievers, showing that relevance modeling and instruction understanding can be effectively handled by a powerful and flexible language model. This approach eliminates the need for relevance labels, offering practical utility in the initial stages of a search system’s life, and paving the way for further advancements in tasks like multi-hop retrieval/QA and conversational search.</li>
</ul>

<h3 id="ragas-automated-evaluation-of-retrieval-augmented-generation"><a href="https://arxiv.org/abs/2309.15217">RAGAS: Automated Evaluation of Retrieval Augmented Generation</a></h3>

<ul>
  <li>This paper by Es et al. from Exploding Gradients, Cardiff University, and AMPLYFI introduces RAGAS, a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) systems.</li>
  <li>RAGAS focuses on evaluating the performance of RAG systems in dimensions such as the effectiveness of the retrieval system in providing relevant context, the LLM’s ability to utilize this context, and the overall quality of generation.</li>
  <li>The framework proposes a suite of metrics to evaluate these dimensions without relying on ground truth human annotations.</li>
  <li>RAGAS focuses on three quality aspects: Faithfulness, Answer Relevance, and Context Relevance.
    <ul>
      <li><strong>Faithfulness</strong>: Defined as the extent to which the generated answer is grounded in the provided context. It’s measured using the formula:
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-171-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1611" style="width: 3.701em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(0.992em, 1003.08em, 2.867em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1612"><span class="mi" id="MathJax-Span-1613" style="font-family: STIXGeneral-Italic;">F<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="mo" id="MathJax-Span-1614" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1615" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.044em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.388em, 1000.84em, 4.326em, -999.997em); top: -4.529em; left: 50%; margin-left: -0.466em;"><span class="mrow" id="MathJax-Span-1616"><span class="texatom" id="MathJax-Span-1617"><span class="mrow" id="MathJax-Span-1618"><span class="mo" id="MathJax-Span-1619" style="font-size: 70.7%; font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-1620" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">V<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="texatom" id="MathJax-Span-1621"><span class="mrow" id="MathJax-Span-1622"><span class="mo" id="MathJax-Span-1623" style="font-size: 70.7%; font-family: STIXVariants;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1000.73em, 4.326em, -999.997em); top: -3.591em; left: 50%; margin-left: -0.414em;"><span class="mrow" id="MathJax-Span-1624"><span class="texatom" id="MathJax-Span-1625"><span class="mrow" id="MathJax-Span-1626"><span class="mo" id="MathJax-Span-1627" style="font-size: 70.7%; font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-1628" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-1629"><span class="mrow" id="MathJax-Span-1630"><span class="mo" id="MathJax-Span-1631" style="font-size: 70.7%; font-family: STIXVariants;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1001.04em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.044em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.684em; border-left: 0px solid; width: 0px; height: 2.003em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mo>=</mo><mfrac><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>V</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow><mrow><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>S</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></mrow></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-171">F = \frac{|V|}{|S|}</script>
where, <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-172-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;V&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1632" style="width: 1.721em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.669em, 1001.3em, 2.867em, -999.997em); top: -2.497em; left: 0em;"><span class="mrow" id="MathJax-Span-1633"><span class="texatom" id="MathJax-Span-1634"><span class="mrow" id="MathJax-Span-1635"><span class="mo" id="MathJax-Span-1636" style="font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-1637" style="font-family: STIXGeneral-Italic;">V<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span class="texatom" id="MathJax-Span-1638"><span class="mrow" id="MathJax-Span-1639"><span class="mo" id="MathJax-Span-1640" style="font-family: STIXVariants;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.503em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>V</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></math></span></span><script type="math/tex" id="MathJax-Element-172">|V|</script> is the number of statements supported by the context and <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-173-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1641" style="width: 1.461em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.201em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.669em, 1001.1em, 2.867em, -999.997em); top: -2.497em; left: 0em;"><span class="mrow" id="MathJax-Span-1642"><span class="texatom" id="MathJax-Span-1643"><span class="mrow" id="MathJax-Span-1644"><span class="mo" id="MathJax-Span-1645" style="font-family: STIXVariants;">|</span></span></span><span class="mi" id="MathJax-Span-1646" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="texatom" id="MathJax-Span-1647"><span class="mrow" id="MathJax-Span-1648"><span class="mo" id="MathJax-Span-1649" style="font-family: STIXVariants;">|</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.503em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>S</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow></math></span></span><script type="math/tex" id="MathJax-Element-173">|S|</script> is the total number of statements extracted from the answer.</li>
      <li><strong>Answer Relevance</strong>: This metric assesses how well the answer addresses the given question. It’s calculated by generating potential questions from the answer and measuring their similarity to the original question using the formula:
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-174-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mfrac&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;/munderover&gt;&lt;mtext&gt;sim&lt;/mtext&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1650" style="width: 11.513em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.586em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.148em, 1009.53em, 2.711em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1651"><span class="mi" id="MathJax-Span-1652" style="font-family: STIXGeneral-Italic;">A</span><span class="mi" id="MathJax-Span-1653" style="font-family: STIXGeneral-Italic;">R</span><span class="mo" id="MathJax-Span-1654" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1655" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 0.471em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -0.154em;"><span class="mn" id="MathJax-Span-1656" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.544em, 1000.32em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.154em;"><span class="mi" id="MathJax-Span-1657" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1000.47em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.471em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span><span class="munderover" id="MathJax-Span-1658" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 2.034em; height: 0px;"><span style="position: absolute; clip: rect(3.076em, 1000.84em, 4.43em, -999.997em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-1659" style="font-family: STIXGeneral-Regular; vertical-align: 0.003em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.544em, 1000.42em, 4.169em, -999.997em); top: -4.477em; left: 0.94em;"><span class="texatom" id="MathJax-Span-1660"><span class="mrow" id="MathJax-Span-1661"><span class="mi" id="MathJax-Span-1662" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1001.1em, 4.169em, -999.997em); top: -3.695em; left: 0.94em;"><span class="texatom" id="MathJax-Span-1663"><span class="mrow" id="MathJax-Span-1664"><span class="mi" id="MathJax-Span-1665" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-1666" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">=</span><span class="mn" id="MathJax-Span-1667" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mtext" id="MathJax-Span-1668" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">sim</span><span class="mo" id="MathJax-Span-1669" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1670" style="font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-1671" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-1672" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1673" style="font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="mi" id="MathJax-Span-1674" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1675" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.628em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi><mi>R</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow class="MJX-TeXAtom-ORD"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>n</mi></mrow></munderover><mtext>sim</mtext><mo stretchy="false">(</mo><mi>q</mi><mo>,</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-174">AR = \frac{1}{n} \sum_{i=1}^{n} \text{sim}(q, q_i)</script>
where <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-175-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1676" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1677"><span class="mi" id="MathJax-Span-1678" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></span></span><script type="math/tex" id="MathJax-Element-175">q</script> is the original question, <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-176-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1679" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1000.78em, 2.503em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1680"><span class="msubsup" id="MathJax-Span-1681"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1682" style="font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="mi" id="MathJax-Span-1683" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>q</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-176">q_i</script> are the generated questions, and sim denotes the cosine similarity between their embeddings.</li>
      <li><strong>Context Relevance</strong>: Measures the extent to which the retrieved context contains only the information necessary to answer the question. It is quantified using the proportion of extracted relevant sentences to the total sentences in the context:
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-177-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mtext&gt;number of extracted sentences&lt;/mtext&gt;&lt;mrow&gt;&lt;mtext&gt;total number of sentences in&amp;#xA0;&lt;/mtext&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1684" style="width: 14.638em; display: inline-block;"><span style="display: inline-block; position: relative; width: 12.19em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.148em, 1012.19em, 2.867em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1685"><span class="mi" id="MathJax-Span-1686" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-1687" style="font-family: STIXGeneral-Italic;">R</span><span class="mo" id="MathJax-Span-1688" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1689" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 9.43em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.388em, 1008.54em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -4.268em;"><span class="mtext" id="MathJax-Span-1690" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">number of extracted sentences</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1009.27em, 4.326em, -999.997em); top: -3.643em; left: 50%; margin-left: -4.633em;"><span class="mrow" id="MathJax-Span-1691"><span class="mtext" id="MathJax-Span-1692" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">total number of sentences in&nbsp;</span><span class="mi" id="MathJax-Span-1693" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">c</span><span class="mo" id="MathJax-Span-1694" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1695" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-1696" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1009.43em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 9.43em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.684em; border-left: 0px solid; width: 0px; height: 1.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>C</mi><mi>R</mi><mo>=</mo><mfrac><mtext>number of extracted sentences</mtext><mrow><mtext>total number of sentences in&nbsp;</mtext><mi>c</mi><mo stretchy="false">(</mo><mi>q</mi><mo stretchy="false">)</mo></mrow></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-177">CR = \frac{\text{number of extracted sentences}}{\text{total number of sentences in } c(q)}</script></li>
    </ul>
  </li>
  <li>The paper validates RAGAS using the WikiEval dataset, demonstrating its alignment with human judgments in evaluating these aspects.</li>
  <li>The authors argue that RAGAS contributes to faster and more efficient evaluation cycles for RAG systems, which is vital due to the rapid adoption of LLMs.</li>
  <li>RAGAS is validated using the WikiEval dataset, which includes question-context-answer triples annotated with human judgments for faithfulness, answer relevance, and context relevance.</li>
  <li>The evaluation shows that RAGAS aligns closely with human judgments, particularly in assessing faithfulness and answer relevance.</li>
  <li><a href="https://github.com/explodinggradients/ragas">Code</a>.</li>
</ul>

<h3 id="fine-tuning-or-retrieval-comparing-knowledge-injection-in-llms"><a href="https://arxiv.org/abs/2312.05934">Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs</a></h3>

<ul>
  <li>This paper by Ovadia et al. from Microsoft presents an insightful comparison of knowledge injection methods in large language models (LLMs). The core question addressed is whether unsupervised fine-tuning (USFT) is more effective than retrieval-augmented generation (RAG) for improving LLM performance on knowledge-intensive tasks.</li>
  <li>The researchers focus on LLMs’ ability to memorize, understand, and retrieve factual data, using a knowledge base scraped from Wikipedia and a dataset of current events questions created with GPT-4. The study employs models like Llama2-7B, Mistral-7B, and Orca2-7B, evaluating them on tasks from the Massively Multitask Language Understanding Evaluation (MMLU) benchmark and a current events dataset.</li>
  <li>Two methods of knowledge injection are explored: fine-tuning, which continues the model’s pre-training process using task-specific data, and retrieval-augmented generation (RAG), which uses external knowledge sources to enhance LLMs’ responses. The paper also delves into supervised, unsupervised, and reinforcement learning-based fine-tuning methods.</li>
  <li>The key finding is that RAG outperforms unsupervised fine-tuning in knowledge injection. RAG, which uses external knowledge sources, is notably more effective in terms of knowledge injection than USFT alone and even more so than a combination of RAG and fine-tuning, particularly in scenarios where questions directly corresponded to the auxiliary dataset. This suggests that USFT may not be as efficient in embedding new knowledge into the model’s parameters.</li>
  <li>The figure below from the paper shows a visualization of the knowledge injection framework.</li>
</ul>

<p><img src="../../../images/papers/FTorRAG.jpg" alt=""></p>

<ul>
  <li>Note that USFT in this context is a direct continuation of pre-training (hence also called continued pre-training in literature), predicting the next token on the dataset. Interestingly, fine-tuning with multiple paraphrases of the same fact significantly improves the baseline performance, indicating the importance of repetition and varied presentation of information for effective knowledge assimilation.</li>
  <li>The authors created a knowledge base by scraping Wikipedia articles relevant to various topics, which was used for both fine-tuning and RAG. Additionally, a dataset of multiple-choice questions about current events was generated using GPT-4, with paraphrases created to augment this dataset.</li>
  <li>Limitations of the study include the exclusive focus on unsupervised fine-tuning, without exploring supervised fine-tuning or reinforcement learning from human feedback (RLHF). The study also notes a high variance in accuracy performance across experiments, making it challenging to ascertain the statistical significance of the results.</li>
  <li>The paper also questions why baseline models don’t achieve a 25% accuracy rate for multiple-choice questions with four options, suggesting that the tasks may not represent truly “unseen” knowledge. Moreover, the research primarily assesses straightforward knowledge or fact tasks, without delving into reasoning capabilities.</li>
  <li>In summary, while fine-tuning can be beneficial, RAG is identified as a superior method for knowledge injection in LLMs, especially for tasks involving new information. The results highlight the potential of using diverse fine-tuning techniques and auxiliary knowledge bases for further research in this domain.</li>
</ul>

<h3 id="dense-x-retrieval-what-retrieval-granularity-should-we-use"><a href="https://arxiv.org/pdf/2312.06648">Dense X Retrieval: What Retrieval Granularity Should We Use?</a></h3>

<ul>
  <li>One crucial choice in RAG pipeline design is chunking: should it be sentence level, passage level, or chapter level? This choice significantly impacts your retrieval and response generation performance.</li>
  <li>This paper by Chen et al. from the University of Washington, Tencent AI Lab, University of Pennsylvania, Carnegie Mellon University introduces a novel approach to dense retrieval in open-domain NLP tasks by using “propositions” as retrieval units, instead of the traditional document passages or sentences. A proposition is defined as an atomic expression within text, encapsulating a distinct factoid in a concise, self-contained natural language format. This change in retrieval granularity has a significant impact on both retrieval and downstream task performances.</li>
  <li>Propositions follow three key principles:
    <ol>
      <li>Each proposition encapsulates a distinct meaning, collectively representing the semantics of the entire text.</li>
      <li>They are minimal and indivisible, ensuring precision and clarity.</li>
      <li>Each proposition is contextualized and self-contained, including all necessary text context (like coreferences) for full understanding.</li>
    </ol>
  </li>
  <li>The authors developed a text generation model, named “Propositionizer,” to segment Wikipedia pages into propositions. This model was fine-tuned in two steps, starting with prompting GPT-4 for paragraph-to-propositions pairs generation, followed by fine-tuning a Flan-T5-large model.</li>
  <li>The effectiveness of propositions as retrieval units was evaluated using the FACTOIDWIKI dataset, a processed English Wikipedia dump segmented into passages, sentences, and propositions. Experiments were conducted on five open-domain QA datasets: Natural Questions (NQ), TriviaQA (TQA), Web Questions (WebQ), SQuAD, and Entity Questions (EQ). Six different dense retriever models were compared: SimCSE, Contriever, DPR, ANCE, TAS-B, and GTR.</li>
  <li>The figure below from the paper illustrates the fact that that segmenting and indexing a retrieval corpus on the proposition level can be a simple yet effective strategy to increase dense retrievers’ generalization performance at inference time <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-178-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1697" style="width: 3.023em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.503em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1002.45em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1698"><span class="mo" id="MathJax-Span-1699" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1700" style="font-family: STIXGeneral-Italic;">A</span><span class="mo" id="MathJax-Span-1701" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-1702" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">B</span><span class="mo" id="MathJax-Span-1703" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-178">(A, B)</script>. We empirically compare the retrieval and downstream open-domain QA tasks performance when dense retrievers work with Wikipedia indexed at the level of 100-word passage, sentence or proposition <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-179-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;D&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1704" style="width: 3.023em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.503em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1002.45em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1705"><span class="mo" id="MathJax-Span-1706" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-1707" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1708" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-1709" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">D</span><span class="mo" id="MathJax-Span-1710" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mi>C</mi><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-179">(C, D)</script>.</li>
</ul>

<p><img src="../../../images/papers/DXR.jpg" alt=""></p>

<ul>
  <li>Results:
    <ol>
      <li><strong>Passage Retrieval Performance:</strong> Proposition-based retrieval consistently outperformed sentence and passage-level retrieval across all datasets and models. This was particularly evident with unsupervised retrievers like SimCSE and Contriever, which showed an average Recall@5 improvement of 12.0% and 9.3%, respectively.</li>
      <li><strong>Cross-Task Generalization:</strong> The advantage of proposition retrieval was most pronounced in cross-task generalization settings, especially for queries about less common entities. It showed significant improvement over other granularities in datasets not seen during the training of the retriever models.</li>
      <li><strong>Downstream QA Performance:</strong> In the retrieve-then-read setting, proposition-based retrieval led to stronger downstream QA performance. This was true for both unsupervised and supervised retrievers, with notable improvements in exact match (EM) scores.</li>
      <li><strong>Density of Question-Related Information:</strong> Propositions proved to offer a higher density of relevant information, resulting in the correct answers appearing more frequently within the top-l retrieved words. This was a significant advantage over sentence and passage retrieval, particularly in the range of 100-200 words.</li>
      <li><strong>Error Analysis:</strong> The study also highlighted the types of errors typical to each retrieval granularity. For example, passage-level retrieval often struggled with entity ambiguity, while proposition retrieval faced challenges in multi-hop reasoning tasks.</li>
    </ol>
  </li>
  <li>The figure plot from the paper shows that retrieving by propositions yields the best retrieval performance in both passage retrieval task and downstream open-domain QA task, e.g. with Contriever or GTR as the backbone retriever.</li>
</ul>

<p><img src="../../../images/papers/DXR2.jpg" alt=""></p>

<ul>
  <li>The research demonstrates that using propositions as retrieval units significantly improves dense retrieval performance and downstream QA task accuracy, outperforming traditional passage and sentence-based methods. The introduction of FACTOIDWIKI, with its 250 million propositions, is expected to facilitate future research in information retrieval.</li>
</ul>

<h3 id="ares-an-automated-evaluation-framework-for-retrieval-augmented-generation-systems"><a href="https://arxiv.org/abs/2311.09476v1">ARES: an Automated Evaluation Framework for Retrieval-Augmented Generation Systems</a></h3>

<ul>
  <li>This paper by Saad-Falcon et al. from Stanford University and UC Berkeley, the paper introduces ARES (Automated RAG Evaluation System) for evaluating Retrieval-Augmented Generation (RAG) systems in terms of context relevance, answer faithfulness, and answer relevance.</li>
  <li>ARES generates synthetic training data using a language model and fine-tunes lightweight LM judges to assess individual RAG components. It utilizes a small set of human-annotated data points for prediction-powered inference (PPI), enabling statistical guarantees for its predictions.</li>
  <li>The framework has three stages:
    <ol>
      <li><strong>LLM Generation of Synthetic Dataset</strong>: ARES uses generative LLMs (like FLAN-T5 XXL) to create synthetic datasets of question-answer pairs derived from target corpus passages. This stage includes both positive and negative examples for training.</li>
      <li><strong>Preparing LLM Judges</strong>: Separate lightweight LM models are fine-tuned for three classification tasks - context relevance, answer faithfulness, and answer relevance - using the synthetic dataset. These models are tuned using a contrastive learning objective.</li>
      <li><strong>Ranking RAG Systems with Confidence Intervals</strong>:
        <ul>
          <li>After preparing the LLM judges, the next step involves using them to score and rank various RAG systems. This process begins with ARES sampling in-domain query-document-answer triples from each RAG approach. The judges then label each triple, assessing context relevance, answer faithfulness, and answer relevance. These labels are averaged for each in-domain triple to evaluate the performance of the RAG systems across the three metrics.</li>
          <li>While average scores could be reported as quality metrics for each RAG system, these scores are based on unlabeled data and predictions from synthetically-trained LLM judges, which may introduce noise. An alternative is to rely solely on a small human preference validation set for evaluation, examining the extent to which each RAG system aligns with human annotations. However, this method requires labeling outputs from each RAG system separately, which can be time-consuming and expensive.</li>
          <li>To enhance the precision of the evaluation, ARES employs prediction-powered inference (PPI). PPI is a statistical method that narrows the confidence interval of predictions on a small annotated dataset by utilizing predictions on a larger, non-annotated dataset. It combines labeled datapoints and ARES judge predictions on non-annotated datapoints to construct tighter confidence intervals for RAG system performance.</li>
          <li>PPI involves using LLM judges on the human preference validation set to learn a rectifier function. This function constructs a confidence set of the ML model’s performance, taking into account each ML prediction in the larger non-annotated dataset. The confidence set helps create a more precise confidence interval for the average performance of the ML model (e.g., its context relevance, answer faithfulness, or answer relevance accuracy). By integrating the human preference validation set with a larger set of datapoints with ML predictions, PPI develops reliable confidence intervals for ML model performance, outperforming traditional inference methods.</li>
          <li>The PPI rectifier function addresses errors made by the LLM judge and generates confidence bounds for the success and failure rates of the RAG system. It estimates performances in context relevance, answer faithfulness, and answer relevance. PPI also allows for estimating confidence intervals with a specified probability level; in these experiments, a standard 95% alpha is used.</li>
          <li>Finally, the accuracy confidence interval for each component of the RAG is determined, and the midpoints of these intervals are used to rank the RAG systems. This ranking enables a comparison of different RAG systems and configurations within the same system, aiding in identifying the optimal approach for a specific domain.
            <ul>
              <li>In summary, ARES employs PPI to score and rank RAG systems, using human preference validation sets to calculate confidence intervals. PPI operates by first generating predictions for a large sample of data points, followed by human annotation of a small subset. These annotations are used to calculate confidence intervals for the entire dataset, ensuring accuracy in the system’s evaluation capabilities.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ol>
  </li>
  <li>To implement ARES for scoring a RAG system and comparing to other RAG configurations, three components are needed:
    <ul>
      <li>A human preference validation set of annotated query, document, and answer triples for the evaluation criteria (e.g. context relevance, answer faithfulness, and/or answer relevance). There should be at least 50 examples but several hundred examples is ideal.</li>
      <li>A set of few-shot examples for scoring context relevance, answer faithfulness, and/or answer relevance in your system.</li>
      <li>A much larger set of unlabeled query-document-answer triples outputted by your RAG system for scoring.</li>
    </ul>
  </li>
  <li>The figure below from the paper shows an overview of ARES: As inputs, the ARES pipeline requires an in-domain passage set, a human preference validation set of 150 annotated datapoints or more, and five few-shot examples of in-domain queries and answers, which are used for prompting LLMs in synthetic data generation. To prepare our LLM judges for evaluation, we first generate synthetic queries and answers from the corpus passages. Using our generated training triples and a constrastive learning framework, we fine-tune an LLM to classify query–passage–answer triples across three criteria: context relevance, answer faithfulness, and answer relevance. Finally, we use the LLM judge to evaluate RAG systems and generate confidence bounds for the ranking using PPI and the human preference validation set.</li>
</ul>

<p><img src="../../../images/papers/ARES.jpg" alt=""></p>

<ul>
  <li>Experiments conducted on datasets from KILT and SuperGLUE demonstrate ARES’s accuracy in evaluating RAG systems, outperforming existing automated evaluation approaches like RAGAS. ARES is effective across various domains, maintaining accuracy even with domain shifts in queries and documents.</li>
  <li>The paper highlights the strengths of ARES in cross-domain applications and its limitations, such as its inability to generalize across drastic domain shifts (e.g., language changes, text-to-code). It also explores the potential of using GPT-4 for generating labels as a replacement for human annotations in the PPI process.</li>
  <li>ARES code and datasets are available for replication and deployment at <a href="https://github.com/stanford-futuredata/ARES">GitHub</a>.</li>
  <li><a href="https://github.com/stanford-futuredata/ares">Code</a></li>
</ul>

<h3 id="seven-failure-points-when-engineering-a-retrieval-augmented-generation-system"><a href="https://arxiv.org/abs/2401.05856">Seven Failure Points When Engineering a Retrieval Augmented Generation System</a></h3>

<ul>
  <li>This technical report by Barnett et al. from the Applied Artificial Intelligence Institute, Deakin University, Australia, explores failure points in the implementation of Retrieval Augmented Generation (RAG) systems. based on three case studies in diverse domains: research, education, and biomedical.</li>
  <li>RAG systems, which integrate retrieval mechanisms with Large Language Models (LLMs) to generate contextually relevant responses, are scrutinized for their operational challenges. The paper identifies seven key failure points in RAG systems:
    <ul>
      <li><strong>FP1 Missing Relevant Content:</strong> The first failure case is when asking a question that cannot be answered from the available documents. In the happy case the RAG system will respond with something like “Sorry, I don’t know”. However, for questions that are related to the content but don’t have answers the system could be fooled into giving a response.</li>
      <li><strong>FP2 Missed the Top Ranked Documents:</strong> The answer to the question is in the document but did not rank highly enough to be returned to the user. In theory, all documents are ranked and used in the next steps. However, in practice only the top <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-180-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1711" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1712"><span class="mi" id="MathJax-Span-1713" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-180">K</script> documents are returned where <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-181-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1714" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1715"><span class="mi" id="MathJax-Span-1716" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-181">K</script> is a value selected based on performance.</li>
      <li><strong>FP3 Not in Context - Consolidation Strategy Limitations:</strong> Documents with the answer were retrieved from the database but did not make it into the context for generating an answer. This occurs when many documents are returned from the database and a consolidation process takes place to retrieve the answer.</li>
      <li><strong>FP4 Not Extracted Here:</strong> the answer is present in the context, but the large language model failed to extract out the correct answer. Typically, this occurs when there is too much noise or contradicting information in the context.</li>
      <li><strong>FP5 Wrong Format:</strong> The question involved extracting information in a certain format such as a table or list and the large language model ignored the instruction.</li>
      <li><strong>FP6 Incorrect Specificity:</strong> The answer is returned in the response but is not specific enough or is too specific to address the user’s need. This occurs when the RAG system designers have a desired outcome for a given question such as teachers for students. In this case, specific educational content should be provided with answers not just the answer. Incorrect specificity also occurs when users are not sure how to ask a question and are too general.</li>
      <li><strong>FP7 Incomplete Responses:</strong> Incomplete answers are not incorrect but miss some of the information even though that information was in the context and available for extraction. An example question such as “What are the key points covered in documents A, B and C?” A better approach is to ask these questions separately.</li>
    </ul>
  </li>
  <li>The study also emphasizes the importance of real-time validation and the evolving robustness of RAG systems. It concludes with suggestions for future research directions, highlighting the significance of chunking, embeddings, and the trade-offs between RAG systems and fine-tuning LLMs.</li>
  <li>The following image from the paper shows the Indexing and Query processes required for creating a Retrieval Augmented Generation (RAG) system. The indexing
process is typically done at development time and queries at runtime. Failure points identified in this study are shown in red boxes. All required stages are underlined.</li>
</ul>

<p><img src="../../../images/papers/RAG7.jpg" alt=""></p>

<ul>
  <li>Moreover, the paper provides insights into the challenges faced in implementing RAG systems, such as handling diverse document types, query preprocessing, and the need for continuous calibration and monitoring of these systems. These findings are derived from practical experiences and offer valuable guidance for practitioners in the field.</li>
</ul>

<h3 id="raptor-recursive-abstractive-processing-for-tree-organized-retrieval"><a href="https://arxiv.org/abs/2401.18059">RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval</a></h3>

<ul>
  <li>This paper by Sarthi et al. from Manning’s Lab at Stanford, published in ICLR 2024, introduces RAPTOR, a novel approach for retrieval-augmented language models. RAPTOR addresses the limitation of existing retrieval methods that primarily fetch short text chunks, hindering comprehensive document understanding. It constructs a tree by recursively embedding, clustering, and summarizing text chunks, offering multi-level summarization and facilitating efficient information retrieval from extensive documents.</li>
  <li>At its core, RAPTOR employs a tree structure starting from leaf nodes (text chunks) and builds up to the root through successive clustering and summarization. This method allows the model to access information at various abstraction levels, significantly enhancing performance on complex, multi-step reasoning tasks. When combined with GPT-4, RAPTOR achieved a 20% absolute accuracy improvement on the QuALITY benchmark over previous state-of-the-art models.</li>
  <li>Some key insights into why using a tree-structure lets your RAG pipeline handle more complex questions:
    <ol>
      <li>Cluster semantically related chunks to dynamically identify distinct topics within your documents.</li>
      <li>Create new chunks by summarizing clusters.</li>
      <li>Mix high-level and low-level chunks during retrieval, to dynamically surface relevant information depending on the query.</li>
    </ol>
  </li>
  <li>The model utilizes SBERT for embedding text chunks and Gaussian Mixture Models (GMMs) for clustering, allowing flexible groupings of related content. Summarization is performed by a language model (GPT-3.5-turbo), producing summaries that guide the construction of higher tree levels. This recursive process creates a scalable and computationally efficient system that linearly scales in both token expenditure and build time, as detailed in the scalability analysis.</li>
  <li>Querying within RAPTOR’s tree employs two strategies: tree traversal and collapsed tree, with the latter showing superior flexibility and effectiveness in preliminary tests on the QASPER dataset. The model’s innovative clustering mechanism, highlighted in an ablation study, proves essential for capturing thematic content and outperforms standard retrieval methods.</li>
  <li>The figure below from the paper shows the tree construction process: RAPTOR recursively clusters chunks of text based on their vector embeddings and generates text summaries of those clusters, constructing a tree from the bottom up. Nodes clustered together are siblings; a parent node contains the text summary of that cluster.</li>
</ul>

<p><img src="../../../images/papers/RAPTOR.jpg" alt=""></p>

<ul>
  <li>Experimental results across various datasets (NarrativeQA, QASPER, QuALITY) demonstrate RAPTOR’s effectiveness, setting new benchmarks and outperforming existing retrieval-augmented models. The paper’s qualitative analysis illustrates RAPTOR’s ability to retrieve relevant information for thematic questions, showcasing its superiority over Dense Passage Retrieval (DPR) methods in handling complex queries.</li>
  <li>The paper includes a comprehensive reproducibility statement, detailing the use of publicly available language models and datasets, ensuring that the community can replicate and extend upon RAPTOR’s findings.</li>
</ul>

<h3 id="the-power-of-noise-redefining-retrieval-for-rag-systems"><a href="https://arxiv.org/abs/2401.14887">The Power of Noise: Redefining Retrieval for RAG Systems</a></h3>

<ul>
  <li>This paper by Cuconasu et al. from Sapienza University of Rome, Technology Innovation Institute, and University of Pisa introduces a comprehensive study on Retrieval-Augmented Generation (RAG) systems, highlighting the significant influence of Information Retrieval (IR) components on RAG’s performance, beyond the generative abilities of Large Language Models (LLMs).</li>
  <li>Their research investigates the characteristics required in a retriever for optimal RAG prompt formulation, emphasizing the balance between relevant, related, and irrelevant documents.</li>
  <li>The study reveals that including irrelevant documents surprisingly enhances RAG system performance by over 30% in accuracy, challenging the assumption that only relevant and related documents should be retrieved. This finding underscores the potential of integrating seemingly noise-adding strategies to improve RAG system outputs, thereby laying the groundwork for future research in IR and language model integration.</li>
  <li>The experimental methodology employed involves a detailed examination of the Natural Questions dataset, testing various configurations of document relevance and placement within the RAG prompt. This methodological rigor allows the researchers to dissect the impact of document type (gold, relevant, related, irrelevant) and position on the accuracy of RAG system responses, with attention to how these factors influence LLM’s generative performance.</li>
  <li>Insights from the experiments led to the formulation of strategies for optimizing RAG systems, proposing a nuanced approach to document retrieval that includes a mix of relevant and intentionally irrelevant documents. This approach aims to maximize system performance within the context size constraints of LLMs, offering a novel perspective on the integration of retrieval processes with generative language models for enhanced factual accuracy and context awareness.</li>
  <li>The study’s findings challenge traditional IR strategies and suggest a paradigm shift towards the inclusion of controlled noise in the retrieval process for language generation tasks. The researchers advocate for further exploration into the mechanisms by which irrelevant documents improve RAG system performance, highlighting the need for new IR techniques tailored to the unique demands of language generation models.</li>
</ul>

<h3 id="multihop-rag-benchmarking-retrieval-augmented-generation-for-multi-hop-queries"><a href="https://arxiv.org/abs/2401.15391">MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries</a></h3>

<ul>
  <li>This paper by Tang et al. from the Hong Kong University of Science and Technology introduces MultiHop-RAG, a novel dataset and benchmark for evaluating Retrieval-Augmented Generation (RAG) systems on multi-hop queries. These queries necessitate retrieving and reasoning over multiple pieces of evidence, a challenge not adequately addressed by existing RAG systems.</li>
  <li>MultiHop-RAG consists of a knowledge base derived from English news articles, multi-hop queries, their answers, and the supporting evidence required for those answers. This dataset aims to mimic real-world applications where complex queries involving multiple pieces of information are common.</li>
  <li>The figure below from the paper shows the RAG flow with a multi-hop query.</li>
</ul>

<p><img src="../../../images/papers/MultiHop-RAG.jpg" alt=""></p>

<ul>
  <li>The authors categorize multi-hop queries into four types: Inference, Comparison, Temporal, and Null queries. The first three types — Inference, Comparison, and Temporal — require the retrieval and analysis of evidence from multiple sources, encompassing tasks like inferring relationships, comparing data points, and sequencing events over time. The Null query represents a scenario where the query cannot be derived from the knowledge base. This category is crucial for assessing whether an LLM might hallucinate an answer to a multi-hop query when the retrieved text lacks relevance. Each type requires a distinct retrieval and reasoning strategy over the evidence, with Null queries designed to test the model’s ability to refrain from generating an answer when the query cannot be resolved with the available knowledge.</li>
  <li>They define a multi-hop query as one that requires retrieving and reasoning over multiple pieces of supporting evidence to provide an answer. In other words, for a multi-hop query <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-182-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1717" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1718"><span class="mi" id="MathJax-Span-1719" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></span></span><script type="math/tex" id="MathJax-Element-182">q</script>, the chunks in the retrieval set <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-183-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;R&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1720" style="width: 1.565em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1001.3em, 2.607em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1721"><span class="msubsup" id="MathJax-Span-1722"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.84em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="texatom" id="MathJax-Span-1723"><span class="mrow" id="MathJax-Span-1724"><span class="mi" id="MathJax-Span-1725" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.836em;"><span class="mi" id="MathJax-Span-1726" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">R</mi></mrow><mi>q</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-183">\mathcal{R}_q</script> collectively provide an answer to <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-184-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1727" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1728"><span class="mi" id="MathJax-Span-1729" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></span></span><script type="math/tex" id="MathJax-Element-184">q</script>. For example, the query “Which company among Google, Apple, and Nvidia reported the largest profit margins in their third-quarter reports for 2023?” requires 1) retrieving relevant pieces of evidence related to profit margins from the reports of the three companies; 2) generating an answer by comparing and reasoning from the multiple pieces of retrieved evidence. This differs from a singlehop query such as “What is Google’s profit margin in the third-quarter reports for 2023 ,” where the answer can be directly derived from a single piece of evidence.</li>
  <li>Based on the queries commonly used in realworld RAG systems, they identify four types of multi-hop queries. For each type, they present a hypothetical query within the context of a financial RAG system, where the knowledge base consists of a collection of annual reports.
    <ul>
      <li><strong>Inference query:</strong> For such a query <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-185-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1730" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1731"><span class="mi" id="MathJax-Span-1732" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></span></span><script type="math/tex" id="MathJax-Element-185">q</script>, the answer is deduced through reasoning from the retrieval set <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-186-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;R&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1733" style="width: 1.565em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1001.3em, 2.607em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1734"><span class="msubsup" id="MathJax-Span-1735"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.84em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="texatom" id="MathJax-Span-1736"><span class="mrow" id="MathJax-Span-1737"><span class="mi" id="MathJax-Span-1738" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.836em;"><span class="mi" id="MathJax-Span-1739" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">R</mi></mrow><mi>q</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-186">\mathcal{R}_q</script>. An example of an inference query might be: Which report discusses the supply chain risk of Apple, the 2019 annual report or the 2020 annual report?</li>
      <li><strong>Comparison query:</strong> For such a query <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-187-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1740" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1741"><span class="mi" id="MathJax-Span-1742" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></span></span><script type="math/tex" id="MathJax-Element-187">q</script>, the answer requires a comparison of evidence within the retrieval set <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-188-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;R&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1743" style="width: 1.565em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1001.3em, 2.607em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1744"><span class="msubsup" id="MathJax-Span-1745"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.84em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="texatom" id="MathJax-Span-1746"><span class="mrow" id="MathJax-Span-1747"><span class="mi" id="MathJax-Span-1748" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.836em;"><span class="mi" id="MathJax-Span-1749" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">R</mi></mrow><mi>q</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-188">\mathcal{R}_q</script>. For instance, a comparison query might ask: Did Netflix or Google report higher revenue for the year 2023?”</li>
      <li><strong>Temporal query:</strong> For such a query <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-189-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1750" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1751"><span class="mi" id="MathJax-Span-1752" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></span></span><script type="math/tex" id="MathJax-Element-189">q</script>, the answer requires an analysis of the temporal information of the retrieved chunks. For example, a temporal query may ask: Did Apple introduce the AirTag tracking device before or after the launch of the 5th generation iPad Pro?</li>
      <li><strong>Null query:</strong> For such as query <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-190-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1753" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1754"><span class="mi" id="MathJax-Span-1755" style="font-family: STIXGeneral-Italic;">q</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>q</mi></math></span></span><script type="math/tex" id="MathJax-Element-190">q</script>, the answer cannot be derived from the retrieved set <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-191-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;&gt;R&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1756" style="width: 1.565em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1001.3em, 2.607em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1757"><span class="msubsup" id="MathJax-Span-1758"><span style="display: inline-block; position: relative; width: 1.305em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.84em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="texatom" id="MathJax-Span-1759"><span class="mrow" id="MathJax-Span-1760"><span class="mi" id="MathJax-Span-1761" style="font-family: STIXNonUnicode-Italic;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.836em;"><span class="mi" id="MathJax-Span-1762" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mrow class="MJX-TeXAtom-ORD"><mi class="MJX-tex-caligraphic" mathvariant="script">R</mi></mrow><mi>q</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-191">\mathcal{R}_q</script>. They include the null query to assess the generation quality, especially regarding the issue of hallucination. For a null query, even though a retrieved set is provided, an LLM should produce a null response instead of hallucinating an answer. For example, assuming ABCS is a non-existent company, a null query might ask: What are the sales of company ABCS as reported in its 2022 and 2023 annual reports?</li>
    </ul>
  </li>
  <li>The dataset was created using GPT-4 to generate multi-hop queries from a pool of factual sentences extracted from news articles. The queries were then validated for quality and relevance. This process ensures the dataset’s utility in benchmarking the capability of RAG systems to handle complex queries beyond the capacity of current systems.</li>
  <li>Experimental results demonstrate that existing RAG methods struggle with multi-hop query retrieval and answering, underscoring the necessity for advancements in this area. The benchmarking also explores the effectiveness of different embedding models for evidence retrieval and the reasoning capabilities of various state-of-the-art Large Language Models (LLMs) including GPT-4, PaLM, and Llama2-70B, revealing significant room for improvement.</li>
  <li>The authors hope that MultiHop-RAG will encourage further research and development in RAG systems, particularly those capable of sophisticated multi-hop reasoning, thereby enhancing the practical utility of LLMs in complex information-seeking tasks.</li>
  <li><a href="https://github.com/yixuantt/MultiHop-RAG/">Code</a></li>
</ul>

<h3 id="rag-vs-fine-tuning-pipelines-tradeoffs-and-a-case-study-on-agriculture"><a href="https://arxiv.org/abs/2401.08406">RAG vs. Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture</a></h3>

<ul>
  <li>This paper by Balaguer et al. from Microsoft, delves into two prevalent approaches for incorporating proprietary and domain-specific data into Large Language Models (LLMs): Retrieval-Augmented Generation (RAG) and Fine-Tuning. RAG augments prompts with external data, whereas Fine-Tuning embeds additional knowledge directly into the model. The paper outlines a comprehensive pipeline for both approaches, evaluating their effectiveness on multiple popular LLMs including Llama2-13B, GPT-3.5, and GPT-4.</li>
  <li>The research particularly focuses on agriculture, an industry with relatively limited AI penetration, proposing a disruptive application: providing location-specific insights to farmers. The pipeline stages include data acquisition, PDF information extraction, question and answer generation using this data, and leveraging GPT-4 for result evaluation. Metrics are introduced to assess the performance of the RAG and Fine-Tuning pipeline stages.</li>
  <li>The figure below from the paper shows the methodology pipeline. Domain-specific datasets are collected, and the content and structure of the documents are extracted. This information is then fed to the Q&amp;A generation step. Synthesized question-answer pairs are used to fine-tune the LLMs. Models are evaluated with and without RAG under different GPT-4-based metrics.</li>
</ul>

<p><img src="../../../images/papers/RAGvsFT2.jpg" alt=""></p>

<ul>
  <li>Experimental results from an agricultural dataset highlight the pipeline’s capability in capturing geography-specific knowledge. Fine-Tuning demonstrated a significant accuracy increase of over 6 percentage points, a benefit that accumulates with RAG, further enhancing accuracy by 5 percentage points. One experiment showcased the fine-tuned model’s ability to leverage information across geographies to answer specific questions, boosting answer similarity from 47% to 72%.</li>
  <li>The paper presents an in-depth comparison of answers from GPT-4, Bing Chat, and agronomist experts to the same query across different U.S. states, revealing the models’ generic responses versus the experts’ nuanced, location-specific answers. This comparative analysis underscores the potential of fine-tuning and RAG in producing more contextually appropriate responses for industry-specific applications.</li>
  <li>The proposed methodology aims at generating domain-specific questions and answers to create a valuable knowledge resource for industries requiring specific contextual and adaptive responses. Through an extensive evaluation involving benchmarks from major agriculture-producing countries, the study establishes a baseline understanding of model performance in the agricultural context and explores the impact of spatial shift on knowledge encoding and the benefits of spatially-scoped fine-tuning.</li>
  <li>Additionally, the research investigates the implications of retrieval techniques and fine-tuning on LLM performance. It identifies RAG as particularly effective in contexts requiring domain-specific knowledge and fine-tuning as beneficial for imparting new skills to models, albeit at a higher initial cost. This work serves as a foundation for applying RAG and fine-tuning techniques across industries, demonstrating their utility in enhancing model efficiency from the Q&amp;A generation process onwards.</li>
</ul>

<h3 id="raft-adapting-language-model-to-domain-specific-rag"><a href="https://arxiv.org/abs/2403.10131">RAFT: Adapting Language Model to Domain Specific RAG</a></h3>

<ul>
  <li>This paper by Zhang et al. from UC Berkeley introduces Retrieval Augmented Fine Tuning (RAFT) as a method to adapt pre-trained Large Language Models (LLMs) for domain-specific Retrieval Augmented Generation (RAG), focusing on “open-book” in-domain settings. By training the model to identify and ignore distractor documents while citing relevant information from pertinent documents, RAFT enhances the model’s reasoning capability and its ability to answer questions based on a specific set of documents.</li>
  <li>The concept draws an analogy to preparing for an open-book exam, where RAFT simulates the conditions of such an exam by incorporating both relevant and irrelevant (distractor) documents during training. This contrasts with existing methods that either do not leverage the opportunity to learn from domain-specific documents or fail to prepare the model for the dynamics of RAG in an open-book test setting.</li>
  <li>The figure below from the paper draws an analogy to how best to prepare for an exam? (a) Fine-tuning based approaches implement “studying” by either directly “memorizing” the input documents or answering practice QA without referencing the documents. (b) Alternatively, incontext retrieval methods fail to leverage the learning opportunity afforded by the fixed domain and are equivalent to taking an open-book exam without studying. While these approaches leverage in-domain learning, they fail to prepare for open-book tests. In contrast, (c) RAFT leverages fine-tuning with question-answer pairs while referencing the documents in a simulated imperfect retrieval setting — thereby effectively preparing for the open-book exam setting.</li>
</ul>

<p><img src="../../../images/papers/RAFT.jpg" alt=""></p>

<ul>
  <li>The methodology involves creating training data that includes a question, a set of documents (with one or more being relevant to the question), and a CoT-style answer derived from the relevant document(s). The paper explores the impact of including distractor documents in the training set and the proportion of training data that should contain the oracle document.</li>
  <li>The figure below from the paper shows an overview of RAFT. The top-left figure depicts our approach of adapting LLMs to reading solution from a set of positive and negative documents in contrast to standard RAG setup where models are trained based on the retriever outputs, which is a mixture of both memorization and reading. At test time, all methods follow the standard RAG setting, provided with a top-k retrieved documents in the context.</li>
</ul>

<p><img src="../../../images/papers/RAFT2.jpg" alt=""></p>

<ul>
  <li>Experiments conducted across PubMed, HotpotQA, and Gorilla datasets demonstrate RAFT’s effectiveness. It consistently outperforms both supervised fine-tuning and RAG across these datasets, particularly highlighting the importance of the chain-of-thought (CoT) style responses in improving model performance.</li>
  <li>Results from various experiments indicate that mixing a fraction of the training data without the oracle document in its context is beneficial for in-domain RAG tasks. Moreover, training with a balance of relevant and irrelevant documents at test time shows that RAFT can generalize well to different numbers of retrieved documents, enhancing robustness against inaccuracies in retrieval.</li>
  <li>RAFT’s approach is compared against several baselines, including LLaMA-7B with and without RAG, domain-specific fine-tuning with 0-shot prompting (DSF), and DSF with RAG. Across different datasets, RAFT demonstrates significant improvements, underscoring its potential in domain-specific applications.</li>
  <li>The paper also discusses related works, highlighting advancements in retrieval-augmented language models, memorization versus generalization in LLMs, and fine-tuning strategies for adapting LLMs to specific tasks. RAFT’s contribution lies in its focus on preparing LLMs for domain-specific RAG by effectively leveraging both relevant and distractor documents during training.</li>
  <li>The study posits RAFT as a valuable strategy for adapting pre-trained LLMs to domain-specific tasks, especially where leveraging external documents is crucial. By training models to discern relevant information from distractors and generating CoT-style answers, RAFT significantly enhances the model’s ability to perform in open-book exam settings, paving the way for more nuanced and effective domain-specific applications of LLMs.</li>
  <li><a href="https://gorilla.cs.berkeley.edu/blogs/9_raft.html">Project page</a>; <a href="https://github.com/ShishirPatil/gorilla/tree/main/raft">Code</a></li>
</ul>

<h3 id="corrective-retrieval-augmented-generation"><a href="https://arxiv.org/abs/2401.15884">Corrective Retrieval Augmented Generation</a></h3>

<ul>
  <li>The paper by Yan et al. from the University of Science and Technology of China, UCLA, and Google Research, proposed Corrective Retrieval Augmented Generation (CRAG) which addresses the challenge of hallucinations and inaccuracies in large language models (LLMs) by proposing a novel framework that enhances the robustness of retrieval-augmented generation (RAG) methods.</li>
  <li>CRAG introduces a lightweight retrieval evaluator that assesses the quality of documents retrieved for a query and triggers actions based on a confidence degree, aiming to correct or enhance the retrieval process. The framework also incorporates large-scale web searches to augment the pool of retrieved documents, ensuring a broader spectrum of relevant and accurate information.</li>
  <li>A key feature of CRAG is its decompose-then-recompose algorithm, which processes the retrieved documents to highlight crucial information while discarding irrelevant content. This method significantly improves the model’s ability to utilize the retrieved documents effectively, enhancing the quality and accuracy of the generated text.</li>
  <li>The figure below from the paper shows an overview of CRAG at inference. A retrieval evaluator is constructed to evaluate the relevance of the
retrieved documents to the input, and estimate a confidence degree based on which different knowledge retrieval actions of <code class="language-plaintext highlighter-rouge">{Correct, Incorrect, Ambiguous}</code> can be triggered.</li>
</ul>

<p><img src="../../../images/papers/CRAG.jpg" alt=""></p>

<ul>
  <li>CRAG is designed to be plug-and-play, allowing seamless integration with various RAG-based approaches. Extensive experiments across four datasets demonstrate CRAG’s ability to significantly enhance the performance of RAG-based methods in both short- and long-form generation tasks, showcasing its adaptability and generalizability.</li>
  <li>The study identifies scenarios where conventional RAG approaches may falter due to inaccurate retrievals. CRAG addresses this by enabling self-correction and efficient utilization of retrieved documents, marking a significant step towards improving the reliability and effectiveness of RAG methods.</li>
  <li>Limitations acknowledged include the ongoing challenge of accurately detecting and correcting erroneous knowledge. The necessity of fine-tuning a retrieval evaluator and the potential biases introduced by web searches are highlighted as areas for future improvement.</li>
  <li><a href="https://github.com/HuskyInSalt/CRAG">Code</a></li>
</ul>

<h3 id="fine-tuning-vs-retrieval-augmented-generation-for-less-popular-knowledge"><a href="https://arxiv.org/abs/2403.01432">Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge</a></h3>

<ul>
  <li>This paper by Soudani et al. from Radboud University and the University of Amsterdam investigates the efficacy of Retrieval Augmented Generation (RAG) and fine-tuning (FT) on enhancing the performance of large language models (LLMs) for question answering (QA) tasks involving low-frequency factual knowledge. The authors conducted a comprehensive comparison to determine which approach is more beneficial for customizing LLMs to handle less popular entities, using a dataset characterized by a wide range of entity popularity levels. They found that fine-tuning significantly improves performance across entities of varying popularity, with notable gains in the most and least popular groups. Conversely, RAG was observed to surpass other methods, particularly when combined with FT in smaller models, although its advantage diminishes in base models and is non-existent in larger models.</li>
  <li>The evaluation setup included a diverse range of factors such as model size, retrieval models, quality of synthetic data generation, and fine-tuning method (PEFT vs. full fine-tuning). The findings underscored the importance of advancements in retrieval and data augmentation techniques for the success of both RAG and FT strategies. For FT, two data augmentation methods were used to generate synthetic training data: an End-to-End approach utilizing a model trained for paragraph-level QA generation and a Prompt method using LLMs for QA generation.</li>
  <li>For RAG, various retrieval models were employed to enhance the LLM’s response generation by providing additional context from a document corpus. The performance of the retrieval models played a significant role in the effectiveness of the RAG approach. The study also highlighted the role of synthetic data quality over quantity, with models trained on prompt-generated data outperforming those trained on E2E-generated data.</li>
  <li>The figure below from the paper shows a correlation between subject entity popularity in a question and the effects of RAG and FT on FlanT5-
small performance in open-domain question answering. FT markedly improves accuracy in the initial and final buckets relative to others (indicated by the pink line).</li>
</ul>

<p><img src="../../../images/papers/FTvsRAG.jpg" alt=""></p>

<h3 id="hgot-hierarchical-graph-of-thoughts-for-retrieval-augmented-in-context-learning-in-factuality-evaluation"><a href="https://arxiv.org/abs/2402.09390">HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation</a></h3>

<ul>
  <li>This paper by Fang et al. from Queen’s University introduce a novel structured, multi-layered graph approach named Hierarchical Graph of Thoughts (HGOT). This framework aims to mitigate hallucinations in large language models (LLMs) by enhancing the retrieval of relevant information for in-context learning. HGOT uses emergent planning capabilities of LLMs to decompose complex queries into manageable sub-queries. The divide-and-conquer strategy simplifies problem-solving and improves the relevance and accuracy of retrieved information.</li>
  <li>HGOT incorporates a unique self-consistency majority voting mechanism for answer selection. This mechanism uses citation recall and precision metrics to evaluate the quality of thoughts, thus directly linking the credibility of an answer to the thought’s quality. The approach employs a scoring mechanism for evaluating retrieved passages, considering citation frequency and quality, self-consistency confidence, and the retrieval module’s ranking.</li>
  <li>The figure below from the paper shows an illustrative example of HGOT in answering a factual question. (The abbreviations employed are as
follows: Instr.: Instructions, Q: Question, Ctx.: Context or References, Resp.: ChatGPT’s Response, PL: Plan, D: Dependencies, CI: Confidence, Ans.: Answer, Thot.: Thought)</li>
</ul>

<p><img src="../../../images/papers/HGOT.jpg" alt=""></p>

<ul>
  <li>The effectiveness of HGOT is validated against several other retrieval-augmented methods like Demonstrate-Search-Predict (DSP) and ReAct, showing an improvement of up to 7% on datasets such as FEVER, Open-SQuAD, and HotPotQA. This demonstrates HGOT’s enhanced capability for factuality in LLM responses.</li>
  <li>In terms of implementation, HGOT utilizes emergent planning abilities of LLMs to create hierarchical graphs, which organizes the thought process more efficiently and reduces the likelihood of error propagation across multiple reasoning layers. The framework adjusts majority voting by weighting responses based on the quality of their associated citations, and employs a scoring system that factors in multiple qualities of retrieved passages to ensure high-quality, relevant informational support for LLM responses.</li>
</ul>

<h3 id="how-faithful-are-rag-models-quantifying-the-tug-of-war-between-rag-and-llms-internal-prior"><a href="https://arxiv.org/abs/2404.10198">How Faithful are RAG Models? Quantifying the Tug-of-war Between RAG and LLMs’ Internal Prior</a></h3>

<ul>
  <li>This paper by Wu et al. from from Stanford investigates the effectiveness of Retrieval Augmented Generation (RAG) frameworks in moderating the behavior of Large Language Models (LLMs) when confronted with conflicting information. It centers on the dynamic between an LLM’s pre-existing knowledge and the information retrieved via RAG, particularly when discrepancies arise.</li>
  <li>The authors conducted a systematic study using models like GPT-4 and GPT-3.5, simulating scenarios where the models were provided with both accurate and deliberately perturbed information across six distinct datasets. The paper confirms that while correct information typically corrects LLM outputs (with a 94% accuracy rate), incorrect data leads to errors if the model’s internal prior is weak.</li>
  <li>The study introduces a novel experimental setup where documents are systematically modified to test LLM reliance on prior knowledge versus retrieved content. Changes ranged from numerical modifications (e.g., altering drug dosages or dates by specific multipliers or intervals) to categorical shifts in names and locations, assessing model response variations.</li>
  <li>The figure below from the paper shows a schematic of generating modified documents for each dataset. A question is posed to the LLM with and without a reference document containing information relevant to the query. This document is then perturbed to contain modified information and given as context to the LLM. They then observe whether the LLM prefers the modified information or its own prior answer.</li>
</ul>

<p><img src="../../../images/papers/RAGfaithful.jpg" alt=""></p>

<ul>
  <li>Key findings include an inverse correlation between the likelihood of an LLM adhering to retrieved information and its internal confidence, quantified through token probabilities. Models with stronger priors demonstrated greater resistance to misleading RAG content, reverting to their initial responses.</li>
  <li>Additionally, the paper discusses the influence of different prompting strategies on RAG adherence. The ‘strict’ prompting led to higher reliance on retrieved content, whereas ‘loose’ prompting allowed more independent reasoning from the models, highlighting the importance of prompt design in RAG systems.</li>
  <li>Results across the datasets illustrated varying degrees of RAG effectiveness, influenced by the model’s confidence level. This nuanced exploration of RAG dynamics provides insights into improving the reliability of LLMs in practical applications, emphasizing the delicate balance needed in integrating RAG to mitigate errors and hallucinations in model outputs.</li>
</ul>

<h3 id="adaptive-rag-learning-to-adapt-retrieval-augmented-large-language-models-through-question-complexity"><a href="https://arxiv.org/abs/2403.14403">Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models Through Question Complexity</a></h3>

<ul>
  <li>This paper by Jeong et al. from KAIST presents a novel framework named Adaptive-RAG for dynamic adjustment of retrieval strategies in Large Language Models (LLMs) based on the complexity of incoming queries. This allows for efficient and accurate responses across different query complexities.</li>
  <li>The system categorizes queries into simple, moderate, and complex, each requiring different retrieval strategies: non-retrieval, single-step retrieval, and multi-step retrieval, respectively. The determination of query complexity is facilitated by a classifier trained on automatically labeled data.</li>
  <li>The figure below from the paper shows a conceptual comparison of different retrieval-augmented LLM approaches to question answering. (A) In response to a query, this single-step approach retrieves relevant documents and then generates an answer. However, it may not be sufficient for complex queries that require multi-step reasoning. (B) This multi-step approach iteratively retrieves documents and generates intermediate answers, which is powerful yet largely inefficient for the simple query since it requires multiple accesses to both LLMs and retrievers. (C) Their adaptive approach can select the most suitable strategy for retrieval-augmented LLMs, ranging from iterative, to single, to even no retrieval approaches, based on the complexity of given queries determined by our classifier.</li>
</ul>

<p><img src="../../../images/papers/Adaptive-RAG.jpg" alt=""></p>

<ul>
  <li>Adaptive-RAG was validated across multiple open-domain QA datasets, showing significant improvements in both efficiency and accuracy over existing models. It employs a blend of iterative and single-step retrieval processes tailored to the specific needs of a query, which optimizes resource use and response time.</li>
  <li>The implementation utilizes a secondary smaller language model as a classifier to predict query complexity. The classifier is trained on datasets synthesized without human labeling, using model predictions and inherent dataset biases to automatically generate training labels.</li>
  <li>Experimental results demonstrate that Adaptive-RAG efficiently allocates resources, handling complex queries with detailed retrieval while effectively answering simpler queries directly through the LLM, thus avoiding unnecessary computation.</li>
  <li>Additionally, Adaptive-RAG’s flexibility is highlighted in its ability to interchange between different retrieval strategies without altering the underlying model architecture or parameters, providing a scalable solution adaptable to varied query complexities.</li>
</ul>

<h3 id="richrag-crafting-rich-responses-for-multi-faceted-queries-in-retrieval-augmented-generation"><a href="https://arxiv.org/abs/2406.12566">RichRAG: Crafting Rich Responses for Multi-faceted Queries in Retrieval-Augmented Generation</a></h3>

<ul>
  <li>This paper by Wang et al. from the Gaoling School of Artificial Intelligence, Renmin University of China, and Baichuan Intelligent Technology, addresses the need for rich and comprehensive responses to broad, open-ended queries in retrieval-augmented generation (RAG).</li>
  <li>The authors propose a novel framework, RichRAG, to handle complex user queries that have multiple sub-intents. RichRAG consists of three main components: a sub-aspect explorer, a multi-faceted retriever, and a generative list-wise ranker.</li>
  <li>The sub-aspect explorer identifies potential sub-aspects of the input queries. This module leverages large language models (LLMs) for their extensive world knowledge and language understanding capabilities. It generates sub-aspects by fine-tuning on training queries using a next token prediction (NTP) loss function.</li>
  <li>The multi-faceted retriever builds a candidate pool of external documents related to the identified sub-aspects. It retrieves top-N documents for each sub-aspect and combines these into a diverse candidate pool, ensuring broad coverage of the query’s various aspects.</li>
  <li>The generative list-wise ranker sorts the top-k most valuable documents from the candidate pool. Built on a seq-to-seq model structure (T5), it models global interactions among candidates and sub-aspects, using a parallel encoding process and a pooling operation to extract relevance representations. The ranker generates a list of document IDs optimized through supervised fine-tuning and reinforcement learning stages.</li>
  <li>The supervised fine-tuning stage uses a greedy algorithm to build silver target ranking lists based on a coverage utility function, ensuring the ranker can generate comprehensive lists.</li>
  <li>The reinforcement learning stage aligns the ranker’s output with LLM preferences by using a reward function based on the quality and coverage of the generated responses. The Direct Preference Optimization (DPO) algorithm is employed, with training pairs created through a unilateral significance sampling strategy (US3) to ensure valuable and reliable training data.</li>
  <li>The figure below from the paper illustrates the overall framework of RichRAG. We describe the training stages of our ranker at the bottom.</li>
</ul>

<p><img src="../../../images/papers/RichRAG.jpg" alt=""></p>

<ul>
  <li>Experimental results on WikiPassageQA and WikiAsp datasets demonstrate RichRAG’s effectiveness in generating comprehensive responses. The framework shows superior performance in terms of Rouge and Com-Rouge scores compared to existing methods.</li>
  <li>RichRAG significantly improves the quality of responses to multi-faceted queries by explicitly modeling sub-aspects and aligning ranking lists with LLM preferences. The efficiency and robustness of the ranker are validated through various experiments, confirming its advantage in handling complex search scenarios.</li>
</ul>

<h3 id="hiqa-a-hierarchical-contextual-augmentation-rag-for-massive-documents-qa"><a href="https://arxiv.org/abs/2402.01767">HiQA: a Hierarchical Contextual Augmentation RAG for Massive Documents QA</a></h3>

<ul>
  <li>This paper by Chen et al. from introduces HiQA, an advanced multi-document question-answering (MDQA) framework to tackle the challenge of retrieving accurate information from extensive, indistinguishable documents. It incorporates cascading metadata and a multi-route retrieval mechanism to enhance the precision and relevance of knowledge retrieval.</li>
  <li>The paper outlines the methodology comprising three main components: Markdown Formatter (MF), Hierarchical Contextual Augmentor (HCA), and Multi-Route Retriever (MRR). MF converts documents into markdown format, enriching them with structured metadata. HCA further augments document segments with hierarchical metadata, and MRR utilizes a combination of vector similarity, Elasticsearch, and keyword matching for improved retrieval accuracy.</li>
  <li>The following figure from the paper illustrates of the proposed contextual text enhancement. The contextual structure can improve text alignment with the query for better matching in multi-documents scenarios.</li>
</ul>

<p><img src="../../../images/papers/HiQA.jpg" alt=""></p>

<ul>
  <li>A novel dataset, MasQA, is introduced to evaluate the performance of MDQA systems, highlighting the framework’s superiority in handling massive documents through extensive experiments.</li>
  <li>Ablation studies demonstrate the individual contribution of each component to the system’s overall effectiveness, with a focus on the HCA’s role in improving retrieval precision.</li>
  <li>Theoretical exploration into the impact of HCA on the distribution of document segments within the embedding space supports the framework’s approach, indicating enhanced retrieval accuracy and the avoidance of information loss associated with hard partitioning methods.</li>
</ul>

<h3 id="refrag-rethinking-rag-based-decoding"><a href="https://arxiv.org/abs/2509.01092">REFRAG: Rethinking RAG Based Decoding</a></h3>

<ul>
  <li>
    <p>This paper by Lin et al. from Meta Superintelligence Labs, the National University of Singapore, and Rice University presents REpresentation For RAG <strong>(REFRAG)</strong>, a novel framework designed to accelerate decoding in RAG by compressing context tokens into chunk-level embeddings, significantly reducing latency and memory overhead without altering the underlying decoder architecture.</p>
  </li>
  <li>
    <p><strong>Motivation</strong>: While large language models (LLMs) excel at contextual learning in tasks like RAG, long context sequences dramatically increase inference latency—especially the time-to-first-token (TTFT)—due to quadratic scaling in attention computation and key-value (KV) cache memory usage. In RAG specifically, the majority of the context consists of retrieved documents, many of which are only marginally relevant, leading to block-diagonal attention patterns that are sparsely connected. The authors argue that most of this computation is wasteful and propose a method to exploit this sparsity.</p>
  </li>
  <li>
    <p><strong>Core Idea</strong>: Instead of feeding full tokenized contexts to the decoder, REFRAG replaces these with <strong>precomputed, compressed chunk embeddings</strong> derived from a lightweight encoder (e.g., RoBERTa). A selective RL-based policy determines which chunks need full token expansion and which can remain compressed. This greatly reduces the decoder input size and hence latency, especially TTFT.</p>
  </li>
  <li>
    <p><strong>Architecture and Implementation</strong>:</p>

    <ul>
      <li>
        <p><strong>Components</strong>:</p>

        <ul>
          <li><strong>Decoder</strong>: A standard decoder-only model (e.g., LLaMA-2).</li>
          <li><strong>Encoder</strong>: Lightweight encoder (e.g., RoBERTa-Base or -Large) to compute chunk embeddings.</li>
          <li><strong>Chunking</strong>: The context (retrieved passages) is divided into <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-192-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/mfrac&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1763" style="width: 3.023em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.503em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.305em, 1002.5em, 2.763em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1764"><span class="mi" id="MathJax-Span-1765" style="font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1766" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mfrac" id="MathJax-Span-1767" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 0.471em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;"><span style="position: absolute; clip: rect(3.544em, 1000.26em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -0.154em;"><span class="mi" id="MathJax-Span-1768" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.154em;"><span class="mi" id="MathJax-Span-1769" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(0.836em, 1000.47em, 1.201em, -999.997em); top: -1.247em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.471em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.044em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.559em; border-left: 0px solid; width: 0px; height: 1.503em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi><mo>=</mo><mfrac><mi>s</mi><mi>k</mi></mfrac></math></span></span><script type="math/tex" id="MathJax-Element-192">L = \frac{s}{k}</script> chunks of size <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-193-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1770" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1771"><span class="mi" id="MathJax-Span-1772" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-193">k</script> tokens. Each chunk is encoded into a vector representation via the encoder.</li>
          <li><strong>Projection Layer</strong>: Aligns encoder outputs to the decoder’s token embedding dimension.</li>
        </ul>
      </li>
      <li>
        <p><strong>Input Pipeline</strong>:</p>

        <ul>
          <li>
            <p>Given a prompt <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-194-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1773" style="width: 9.378em; display: inline-block;"><span style="display: inline-block; position: relative; width: 7.815em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1007.71em, 2.659em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1774"><span class="mi" id="MathJax-Span-1775" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1776" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mo" id="MathJax-Span-1777" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">[</span><span class="msubsup" id="MathJax-Span-1778"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1779" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mn" id="MathJax-Span-1780" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1781" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-1782" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1783" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mn" id="MathJax-Span-1784" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1785" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-1786" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1787" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1788" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1789" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">,</span><span class="msubsup" id="MathJax-Span-1790" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1791" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mi" id="MathJax-Span-1792" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1793" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>x</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>x</mi><mi>q</mi></msub><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-194">x = [x_1, x_2, ..., x_q]</script> and a context <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-195-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1794" style="width: 6.826em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.68em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1005.58em, 2.659em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1795"><span class="mo" id="MathJax-Span-1796" style="font-family: STIXGeneral-Regular;">[</span><span class="msubsup" id="MathJax-Span-1797"><span style="display: inline-block; position: relative; width: 1.721em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1798" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="texatom" id="MathJax-Span-1799"><span class="mrow" id="MathJax-Span-1800"><span class="mi" id="MathJax-Span-1801" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-1802" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mn" id="MathJax-Span-1803" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1804" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-1805" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1806" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1807" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1808" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">,</span><span class="msubsup" id="MathJax-Span-1809" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 0.992em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1810" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mi" id="MathJax-Span-1811" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1812" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><msub><mi>x</mi><mrow class="MJX-TeXAtom-ORD"><mi>q</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>x</mi><mi>T</mi></msub><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-195">[x_{q+1}, ..., x_T]</script>:</p>

            <ul>
              <li>The context is chunked into <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-196-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;&amp;#x2217;&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;&amp;#x2217;&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;&amp;#x2212;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1813" style="width: 13.544em; display: inline-block;"><span style="display: inline-block; position: relative; width: 11.253em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1011.15em, 2.659em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1814"><span class="msubsup" id="MathJax-Span-1815"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1816" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.68em;"><span class="mi" id="MathJax-Span-1817" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1818" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mo" id="MathJax-Span-1819" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">[</span><span class="msubsup" id="MathJax-Span-1820"><span style="display: inline-block; position: relative; width: 2.242em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1821" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="texatom" id="MathJax-Span-1822"><span class="mrow" id="MathJax-Span-1823"><span class="mi" id="MathJax-Span-1824" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-1825" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-1826" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1827" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∗</span><span class="mi" id="MathJax-Span-1828" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1829" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-1830" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1831" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1832" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1833" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">,</span><span class="msubsup" id="MathJax-Span-1834" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 3.909em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1835" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="texatom" id="MathJax-Span-1836"><span class="mrow" id="MathJax-Span-1837"><span class="mi" id="MathJax-Span-1838" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span class="mo" id="MathJax-Span-1839" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-1840" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1841" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∗</span><span class="mi" id="MathJax-Span-1842" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-1843" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">+</span><span class="mi" id="MathJax-Span-1844" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1845" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mn" id="MathJax-Span-1846" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1847" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>C</mi><mi>i</mi></msub><mo>=</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mrow class="MJX-TeXAtom-ORD"><mi>q</mi><mo>+</mo><mi>k</mi><mo>∗</mo><mi>i</mi></mrow></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>x</mi><mrow class="MJX-TeXAtom-ORD"><mi>q</mi><mo>+</mo><mi>k</mi><mo>∗</mo><mi>i</mi><mo>+</mo><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-196">C_i = [x_{q+k*i}, ..., x_{q+k*i+k-1}]</script>.</li>
              <li>The encoder produces a chunk embedding <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-197-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1848" style="width: 6.513em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.419em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1005.37em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1849"><span class="msubsup" id="MathJax-Span-1850"><span style="display: inline-block; position: relative; width: 0.732em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1851" style="font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mi" id="MathJax-Span-1852" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1853" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="msubsup" id="MathJax-Span-1854" style="padding-left: 0.315em;"><span style="display: inline-block; position: relative; width: 1.878em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1855" style="font-family: STIXGeneral-Italic;">M<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.836em;"><span class="texatom" id="MathJax-Span-1856"><span class="mrow" id="MathJax-Span-1857"><span class="mi" id="MathJax-Span-1858" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-1859" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">n</span><span class="mi" id="MathJax-Span-1860" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">c</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1861" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1862"><span style="display: inline-block; position: relative; width: 0.94em; height: 0px;"><span style="position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1863" style="font-family: STIXGeneral-Italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.68em;"><span class="mi" id="MathJax-Span-1864" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1865" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>c</mi><mi>i</mi></msub><mo>=</mo><msub><mi>M</mi><mrow class="MJX-TeXAtom-ORD"><mi>e</mi><mi>n</mi><mi>c</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>C</mi><mi>i</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-197">c_i = M_{enc}(C_i)</script>.</li>
              <li>This is projected: <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-198-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;&amp;#x03D5;&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1866" style="width: 5.003em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1004.12em, 2.607em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1867"><span class="msubsup" id="MathJax-Span-1868"><span style="display: inline-block; position: relative; width: 1.044em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1869" style="font-family: STIXGeneral-Italic;">e</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="texatom" id="MathJax-Span-1870"><span class="mrow" id="MathJax-Span-1871"><span class="msubsup" id="MathJax-Span-1872"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px;"><span style="position: absolute; clip: rect(3.544em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1873" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.904em; left: 0.315em;"><span class="mi" id="MathJax-Span-1874" style="font-size: 50%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1875" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mi" id="MathJax-Span-1876" style="font-family: STIXGeneral-Italic; padding-left: 0.315em;">ϕ</span><span class="mo" id="MathJax-Span-1877" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-1878"><span style="display: inline-block; position: relative; width: 0.732em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1879" style="font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mi" id="MathJax-Span-1880" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1881" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><msub><mi>c</mi><mi>i</mi></msub></mrow></msub><mo>=</mo><mi>ϕ</mi><mo stretchy="false">(</mo><msub><mi>c</mi><mi>i</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-198">e_{c_i} = \phi(c_i)</script>.</li>
              <li>The decoder then operates on <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-199-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mo stretchy=&quot;false&quot;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;.&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;msub&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;L&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo stretchy=&quot;false&quot;&gt;]&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1882" style="width: 11.773em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.794em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1009.69em, 2.659em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1883"><span class="mo" id="MathJax-Span-1884" style="font-family: STIXGeneral-Regular;">[</span><span class="msubsup" id="MathJax-Span-1885"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1886" style="font-family: STIXGeneral-Italic;">e</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mn" id="MathJax-Span-1887" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1888" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-1889" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1890" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1891" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1892" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">,</span><span class="msubsup" id="MathJax-Span-1893" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 0.888em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1894" style="font-family: STIXGeneral-Italic;">e</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="mi" id="MathJax-Span-1895" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">q</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1896" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-1897" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1898" style="font-family: STIXGeneral-Italic;">e</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="texatom" id="MathJax-Span-1899"><span class="mrow" id="MathJax-Span-1900"><span class="msubsup" id="MathJax-Span-1901"><span style="display: inline-block; position: relative; width: 0.628em; height: 0px;"><span style="position: absolute; clip: rect(3.544em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1902" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.904em; left: 0.315em;"><span class="mn" id="MathJax-Span-1903" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1904" style="font-family: STIXGeneral-Regular;">,</span><span class="mo" id="MathJax-Span-1905" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1906" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1907" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">.</span><span class="mo" id="MathJax-Span-1908" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">,</span><span class="msubsup" id="MathJax-Span-1909" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 1.148em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1910" style="font-family: STIXGeneral-Italic;">e</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.471em;"><span class="texatom" id="MathJax-Span-1911"><span class="mrow" id="MathJax-Span-1912"><span class="msubsup" id="MathJax-Span-1913"><span style="display: inline-block; position: relative; width: 0.628em; height: 0px;"><span style="position: absolute; clip: rect(3.544em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1914" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.904em; left: 0.315em;"><span class="mi" id="MathJax-Span-1915" style="font-size: 50%; font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1916" style="font-family: STIXGeneral-Regular;">]</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><msub><mi>e</mi><mn>1</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>e</mi><mi>q</mi></msub><mo>,</mo><msub><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><msub><mi>c</mi><mn>1</mn></msub></mrow></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><msub><mi>c</mi><mi>L</mi></msub></mrow></msub><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-199">[e_1, ..., e_q, e_{c_1}, ..., e_{c_L}]</script>.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p><strong>Selective Compression</strong>:</p>

        <ul>
          <li>A lightweight RL policy (trained using next-paragraph prediction perplexity as a reward signal) decides which chunks should be expanded into full tokens versus retained as embeddings.</li>
          <li>This enables flexible “compress-anywhere” capabilities without sacrificing autoregressiveness.</li>
        </ul>
      </li>
      <li>
        <p><strong>Training</strong>:</p>

        <ol>
          <li><strong>Reconstruction Task</strong>: Initially freezes the decoder and trains the encoder and projection layer to reconstruct original tokens from embeddings.</li>
          <li><strong>Continual Pre-Training (CPT)</strong>: Uses next-paragraph prediction, allowing the decoder to learn from the encoder’s chunk representations.</li>
          <li><strong>Curriculum Learning</strong>: Gradually increases chunk complexity during training.</li>
          <li><strong>Instruction-Tuning</strong>: Adapts the model to specific downstream applications (RAG, multi-turn conversation, summarization).</li>
        </ol>
      </li>
      <li>
        <p><strong>Loss Function</strong>: Cross-entropy on next-token prediction during both reconstruction and CPT stages; policy gradients (e.g., PPO) for RL-based selective compression.</p>
      </li>
      <li>
        <p><strong>Datasets</strong>:</p>

        <ul>
          <li>Pretraining: 20B tokens from SlimPajama’s Book and ArXiv subsets.</li>
          <li>Evaluation: PG19, ProofPile, SlimPajama holdouts.</li>
          <li>Fine-tuning: RAG benchmarks including MS MARCO, MMLU, BoolQ, CommonsenseQA, and others.</li>
        </ul>
      </li>
      <li>
        <p><strong>Benchmarking</strong>:</p>

        <ul>
          <li>Compared against CEPE, REPLUG, and LLaMA-2-7B (with or without full context).</li>
          <li>Compression rates: <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-200-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;8&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;16&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;32&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1917" style="width: 6.148em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1005.11em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1918"><span class="mi" id="MathJax-Span-1919" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1920" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-1921" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">8</span><span class="mo" id="MathJax-Span-1922" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-1923" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">16</span><span class="mo" id="MathJax-Span-1924" style="font-family: STIXGeneral-Regular;">,</span><span class="mn" id="MathJax-Span-1925" style="font-family: STIXGeneral-Regular; padding-left: 0.211em;">32</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>=</mo><mn>8</mn><mo>,</mo><mn>16</mn><mo>,</mo><mn>32</mn></math></span></span><script type="math/tex" id="MathJax-Element-200">k = 8, 16, 32</script>.</li>
          <li>Context lengths evaluated: 4096, 8192, 16384.</li>
        </ul>
      </li>
      <li>
        <p><strong>Performance</strong>:</p>

        <ul>
          <li>TTFT improved by <strong>30.85×</strong> over LLaMA and <strong>3.75×</strong> over CEPE at <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-201-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;32&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1926" style="width: 3.284em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.711em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1002.71em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1927"><span class="mi" id="MathJax-Span-1928" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1929" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-1930" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">32</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>=</mo><mn>32</mn></math></span></span><script type="math/tex" id="MathJax-Element-201">k=32</script>.</li>
          <li>Maintains or improves log-perplexity relative to CEPE across datasets.</li>
          <li>Enables <strong>16× longer context</strong> with equal or better accuracy.</li>
        </ul>
      </li>
      <li>
        <p><strong>Generalization</strong>:</p>

        <ul>
          <li>Effective in RAG, multi-turn conversations, and long document summarization.</li>
          <li>REFRAG16 with RL-based chunk selection often outperforms REFRAG8 trained with full compression, despite being trained at a higher compression rate.</li>
        </ul>
      </li>
      <li>
        <p><strong>Model Scalability</strong>:</p>

        <ul>
          <li>
            <p>Tested with LLaMA-2-7B/13B and LLaMA-3 variants.</p>
          </li>
          <li>
            <p>Larger decoders improve performance more than larger encoders, with limited benefit observed from encoder scaling beyond RoBERTa-Base.</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>The following figure from the paper shows the main design of REFRAG. The input context is chunked and processed by the light-weight encoder to produce chunk embeddings, which are precomputable for efficient reuse. A light-weight RL policy decide few chunks to expand. These chunk embeddings along with the token embeddings of the question input are fed to the decoder.</p>
  </li>
</ul>

<p><img src="../../../images/papers/REFRAG.jpg" alt=""></p>

<ul>
  <li>
    <p><strong>Comparison to CEPE</strong>:</p>

    <ul>
      <li>CEPE reduces KV memory but sacrifices causal structure, making it incompatible with multi-turn tasks.</li>
      <li>REFRAG preserves autoregressive decoding and supports chunk compression at arbitrary positions, enabling broader use cases.</li>
    </ul>
  </li>
  <li>
    <p><a href="https://github.com/facebookresearch/refrag">Code</a></p>
  </li>
</ul>

<h3 id="fact-fetch-and-reason-a-unified-evaluation-of-retrieval-augmented-generation"><a href="https://arxiv.org/abs/2409.12941">Fact, Fetch, and Reason: a Unified Evaluation of Retrieval-Augmented Generation</a></h3>

<ul>
  <li>
    <p>This paper by Krishna et al. from Harvard, Google DeepMind, and Meta introduces <strong>FRAMES</strong> (Factuality, Retrieval, And reasoning MEasurement Set), a comprehensive benchmark designed to evaluate Retrieval-Augmented Generation (RAG) systems in a unified manner across factual accuracy, retrieval capability, and reasoning proficiency.</p>
  </li>
  <li>
    <p>While prior benchmarks have assessed these components in isolation, FRAMES uniquely integrates them into a single dataset with 824 human-annotated multi-hop questions derived from Wikipedia, each requiring reasoning over multiple documents and types of inference like numerical or temporal reasoning. The authors aim to reflect real-world RAG use cases more accurately and expose current limitations in state-of-the-art LLMs when used in complex question answering tasks.</p>
  </li>
  <li>
    <p><strong>Dataset Composition and Design</strong>:</p>

    <ul>
      <li>
        <p><strong>Input</strong>: Multi-hop, factoid-style questions requiring synthesis of 2–15 Wikipedia articles. All questions are standalone and context-independent, avoiding binary answers and minimizing ambiguity.</p>
      </li>
      <li>
        <p><strong>Reasoning Types</strong>: Each question is tagged with one or more of five reasoning categories: Numerical Reasoning, Tabular Reasoning, Multiple Constraints, Temporal Reasoning, and Post-Processing.</p>
      </li>
      <li>
        <p><strong>Annotation Method</strong>: Initial synthetic question generation via LLMs was tested but discarded due to high hallucination rates; final dataset was constructed by expert human annotators using prompts that enforce multi-hop reasoning across multiple sources.</p>
      </li>
      <li>
        <p><strong>Quality Control</strong>:</p>

        <ul>
          <li>Re-annotation for correctness and Wikipedia-grounded answers.</li>
          <li>Contextual disambiguation to handle temporally sensitive queries.</li>
          <li>Exclusion of questions with low output entropy or excessive ambiguity.</li>
          <li>Oracle context provision for upper-bound evaluation.</li>
        </ul>
      </li>
      <li>
        <p><strong>Comparison</strong>: The dataset covers reasoning and retrieval scenarios not comprehensively addressed by other datasets such as TruthfulQA, HotpotQA, and NaturalQuestions, as shown in Table 1 of the paper.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Evaluation Framework and Implementation</strong>:</p>

    <ul>
      <li>
        <p><strong>Single-Step Baselines</strong>:</p>

        <ul>
          <li>
            <p><strong>Naive Prompt</strong>: Direct question to LLM without retrieval.</p>
          </li>
          <li>
            <p><strong>BM25-Retrieved Prompt</strong>: Adds top-k BM25-scored Wikipedia documents to context.</p>
          </li>
          <li>
            <p><strong>Oracle Prompt</strong>: Adds ground-truth human-labeled Wikipedia articles.</p>
          </li>
          <li>
            <p><strong>LLMs Tested</strong>: Gemini-Pro-1.5, Gemini-Flash-1.5, Gemma2-27B, LLaMA3.2-3B, Qwen2.5-3B.</p>
          </li>
          <li>
            <p><strong>Evaluation</strong>: Conducted via LLM-based auto-rater aligned with human evaluations (accuracy 0.96, Cohen’s Kappa 0.889).</p>
          </li>
          <li>
            <p><strong>Findings</strong>:</p>

            <ul>
              <li>Accuracy without retrieval: 0.408.</li>
              <li>With 2-doc BM25 retrieval: 0.452; with 4-doc: 0.474.</li>
              <li>Oracle performance: 0.729.</li>
              <li>Major failure modes: Numerical, Tabular, Post-Processing reasoning.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p><strong>Multi-Step Pipeline (Algorithm 1)</strong>:</p>

        <ul>
          <li>
            <p><strong>Input</strong>: Question and instruction to generate <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-202-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1931" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1932"><span class="mi" id="MathJax-Span-1933" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-202">k</script> search queries iteratively over <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-203-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1934" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1935"><span class="mi" id="MathJax-Span-1936" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-203">n</script> steps, retrieving <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-204-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;docs&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1937" style="width: 2.294em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1001.88em, 2.451em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1938"><span class="msubsup" id="MathJax-Span-1939"><span style="display: inline-block; position: relative; width: 1.878em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1940" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="texatom" id="MathJax-Span-1941"><span class="mrow" id="MathJax-Span-1942"><span class="mtext" id="MathJax-Span-1943" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">docs</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>n</mi><mrow class="MJX-TeXAtom-ORD"><mtext>docs</mtext></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-204">n_{\text{docs}}</script> Wikipedia articles per query via BM25.</p>
          </li>
          <li>
            <p><strong>Process</strong>:</p>

            <ul>
              <li>
                <p>For each of <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-205-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1944" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1945"><span class="mi" id="MathJax-Span-1946" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-205">n</script> iterations:</p>

                <ul>
                  <li>Generate <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-206-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1947" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1948"><span class="mi" id="MathJax-Span-1949" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-206">k</script> search queries.</li>
                  <li>Retrieve <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-207-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;docs&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1950" style="width: 2.294em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.565em, 1001.88em, 2.451em, -999.997em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-1951"><span class="msubsup" id="MathJax-Span-1952"><span style="display: inline-block; position: relative; width: 1.878em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1953" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="texatom" id="MathJax-Span-1954"><span class="mrow" id="MathJax-Span-1955"><span class="mtext" id="MathJax-Span-1956" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">docs</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>n</mi><mrow class="MJX-TeXAtom-ORD"><mtext>docs</mtext></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-207">n_{\text{docs}}</script> articles for each query.</li>
                  <li>Add only new documents to context.</li>
                </ul>
              </li>
              <li>
                <p>Final inference is based on the cumulative retrieved context.</p>
              </li>
            </ul>
          </li>
          <li>
            <p><strong>Vanilla vs. Search Planning</strong>:</p>

            <ul>
              <li>Vanilla: No instruction for query diversity or planfulness.</li>
              <li>Search Planning: Adds examples and constraints (e.g., no repeated queries, chain-of-thought guidance).</li>
            </ul>
          </li>
          <li>
            <p><strong>Best Configuration</strong>: <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-208-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mtext&gt;docs&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;10&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1957" style="width: 11.253em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.378em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1009.38em, 2.503em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1958"><span class="mi" id="MathJax-Span-1959" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-1960" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-1961" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">5</span><span class="mo" id="MathJax-Span-1962" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-1963" style="font-family: STIXGeneral-Italic; padding-left: 0.211em;">n</span><span class="mo" id="MathJax-Span-1964" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-1965" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">5</span><span class="mo" id="MathJax-Span-1966" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-1967" style="padding-left: 0.211em;"><span style="display: inline-block; position: relative; width: 1.878em; height: 0px;"><span style="position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-1968" style="font-family: STIXGeneral-Italic;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.852em; left: 0.523em;"><span class="texatom" id="MathJax-Span-1969"><span class="mrow" id="MathJax-Span-1970"><span class="mtext" id="MathJax-Span-1971" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">docs</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-1972" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">=</span><span class="mn" id="MathJax-Span-1973" style="font-family: STIXGeneral-Regular; padding-left: 0.315em;">10</span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi><mo>=</mo><mn>5</mn><mo>,</mo><mi>n</mi><mo>=</mo><mn>5</mn><mo>,</mo><msub><mi>n</mi><mrow class="MJX-TeXAtom-ORD"><mtext>docs</mtext></mrow></msub><mo>=</mo><mn>10</mn></math></span></span><script type="math/tex" id="MathJax-Element-208">k=5, n=5, n_{\text{docs}}=10</script> achieved 0.66 accuracy — approaching the Oracle upper bound.</p>
          </li>
          <li>
            <p><strong>Insights</strong>:</p>

            <ul>
              <li>Vanilla multi-step retrieval modestly improves performance (~0.45 to ~0.52).</li>
              <li>With search planning, performance increases substantially to 0.66.</li>
              <li>Multi-step setup is computationally expensive (6 serial LLM calls per question).</li>
              <li>Numerical and post-processing reasoning remain weak spots, even with oracle contexts.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Core Contributions</strong>:</p>

    <ul>
      <li>Introduces <strong>FRAMES</strong>, the first unified benchmark assessing factuality, retrieval, and reasoning in a single end-to-end setup.</li>
      <li>Shows that current LLMs—even with access to relevant knowledge—struggle significantly with complex reasoning tasks.</li>
      <li>Proposes a reproducible multi-step retrieval framework with interpretable improvements using BM25 and planning-enhanced querying.</li>
    </ul>
  </li>
  <li>
    <p><strong>Future Directions</strong>:</p>

    <ul>
      <li>Improved retrieval via dense retrievers (e.g., ColBERT, SimCSE).</li>
      <li>Enhanced reasoning through supervision methods (e.g., Toolformer, PRM-800K, DSPy).</li>
      <li>Exploration of domain diversity and real-time retrieval extensions.</li>
      <li>Mitigation of training data contamination due to overlap with Wikipedia.</li>
    </ul>
  </li>
  <li>
    <p>The following figure from the paper shows an example from the FRAMES dataset, highlighting the core capabilities needed by a system (Factuality, Retrieval, Reasoning) to answer the question.</p>
  </li>
</ul>

<p><img src="../../../images/papers/FRAMES.jpg" alt=""></p>

<ul>
  <li><a href="https://huggingface.co/datasets/google/frames-benchmark">Dataset</a></li>
</ul>

<h3 id="long-form-factuality-in-large-language-models"><a href="https://arxiv.org/abs/2403.18802">Long-form Factuality in Large Language Models</a></h3>

<ul>
  <li>
    <p>This paper by Jerry Wei et al. from Google DeepMind introduces <strong>LongFact</strong>, a new benchmark designed to evaluate the <strong>long-form factuality</strong> of large language models (LLMs), and proposes a novel automatic evaluation framework called <strong>Search-Augmented Factuality Evaluator (SAFE)</strong>. The paper also introduces a new factuality metric called <strong>F1@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-209-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1974" style="width: 0.622em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.519em; height: 0px; font-size: 121%;"><span style="position: absolute; clip: rect(1.346em, 1000.52em, 2.327em, -999.997em); top: -2.167em; left: 0em;"><span class="mrow" id="MathJax-Span-1975"><span class="mi" id="MathJax-Span-1976" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.172em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-209">k</script></strong> that combines factual precision and recall based on an ideal number of facts expected by a user.</p>
  </li>
  <li>
    <p><strong>Motivation</strong>: Existing factuality benchmarks primarily assess short-form responses or focus narrowly on specific domains. Evaluating long-form, open-ended responses is challenging due to the wide variability of facts, lack of reference answers, and the difficulty of fine-grained annotation.</p>
  </li>
  <li>
    <p><strong>LongFact Benchmark</strong>:</p>

    <ul>
      <li>Generated using GPT-4, LongFact consists of 2,280 prompts across 38 topics, divided into two tasks: <strong>LongFact-Objects</strong> and <strong>LongFact-Concepts</strong>.</li>
      <li>Prompts are designed to elicit multi-paragraph responses rich in factual content.</li>
      <li>Covers a broad spectrum including STEM, social sciences, humanities, and general knowledge, offering extensive domain coverage for factuality evaluation.</li>
    </ul>
  </li>
  <li>
    <p><strong>SAFE: Search-Augmented Factuality Evaluator</strong>:</p>

    <ul>
      <li>SAFE uses an LLM (GPT-3.5-Turbo) as an agent to perform a multi-step factuality evaluation.</li>
      <li>
        <p><strong>Pipeline</strong>:</p>

        <ol>
          <li><strong>Decomposition</strong>: Break down model responses into individual atomic facts.</li>
          <li><strong>Self-Containment</strong>: Replace vague pronouns or references with explicit entities.</li>
          <li><strong>Relevance Check</strong>: Determine whether each fact is relevant to the original prompt.</li>
          <li><strong>Search and Verification</strong>: Use the Serper.dev API to send search queries to Google, retrieve top results, and iteratively reason whether each fact is supported or not.</li>
        </ol>
      </li>
      <li>Facts are labeled as “supported,” “not supported,” or “irrelevant.” Only supported and not supported facts are used in final scoring.</li>
    </ul>
  </li>
  <li>
    <p>The following figure from the paper shows how SAFE splits a response into atomic facts, revises them, evaluates relevance, and checks factual support using Google Search.</p>
  </li>
</ul>

<p><img src="../../../images/papers/Long-form-factuality-in-LLMs.jpg" alt=""></p>

<ul>
  <li>
    <p><strong>F1@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-210-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1977" style="width: 0.622em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.519em; height: 0px; font-size: 121%;"><span style="position: absolute; clip: rect(1.346em, 1000.52em, 2.327em, -999.997em); top: -2.167em; left: 0em;"><span class="mrow" id="MathJax-Span-1978"><span class="mi" id="MathJax-Span-1979" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.172em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-210">k</script> Metric</strong>:</p>

    <ul>
      <li>Proposes an extension of the standard F1 score to long-form factuality.</li>
      <li><strong>Precision</strong>: Fraction of supported facts over total rated (supported + not supported).</li>
      <li><strong>Recall</strong>: Fraction of supported facts up to a user-defined ideal number of facts, <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-211-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;K&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1980" style="width: 0.94em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1981"><span class="mi" id="MathJax-Span-1982" style="font-family: STIXGeneral-Italic;">K<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.055em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>K</mi></math></span></span><script type="math/tex" id="MathJax-Element-211">K</script>.</li>
      <li>Defined as:
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-212-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;merror&gt;&lt;mtext&gt;\text{F1@\)k\(}(y)&amp;#xA0;=&amp;#xA0;\frac{2&amp;#xA0;\cdot&amp;#xA0;\text{Precision}(y)&amp;#xA0;\cdot&amp;#xA0;\text{Recall}_K(y)}{\text{Precision}(y)&amp;#xA0;+&amp;#xA0;\text{Recall}_K(y)}&lt;/mtext&gt;&lt;/merror&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><span class="math" id="MathJax-Span-1983" aria-hidden="true" style=""><span class="noError" id="MathJax-Span-1984" style="display: inline-block;">\text{F1@\)k\(}(y)&nbsp;=&nbsp;\frac{2&nbsp;\cdot&nbsp;\text{Precision}(y)&nbsp;\cdot&nbsp;\text{Recall}_K(y)}{\text{Precision}(y)&nbsp;+&nbsp;\text{Recall}_K(y)}</span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><merror><mtext>\text{F1@\)k\(}(y)&nbsp;=&nbsp;\frac{2&nbsp;\cdot&nbsp;\text{Precision}(y)&nbsp;\cdot&nbsp;\text{Recall}_K(y)}{\text{Precision}(y)&nbsp;+&nbsp;\text{Recall}_K(y)}</mtext></merror></math></span></span><script type="math/tex" id="MathJax-Element-212">\text{F1@\)k\(}(y) = \frac{2 \cdot \text{Precision}(y) \cdot \text{Recall}_K(y)}{\text{Precision}(y) + \text{Recall}_K(y)}</script></li>
      <li>Offers a tradeoff between factual density and desired length of response.</li>
    </ul>
  </li>
  <li>
    <p><strong>Key Results</strong>:</p>

    <ul>
      <li>SAFE achieves 72% agreement with human annotators (from Min et al., 2023) and outperforms humans in 76% of disagreement cases.</li>
      <li>It is over <strong>20× cheaper</strong> than human annotation ($0.19 per response vs. $4.00).</li>
      <li>
        <p>Benchmarked 13 LLMs (e.g., GPT-4-Turbo, Gemini-Ultra, Claude-3, PaLM-2) using LongFact.</p>

        <ul>
          <li>Larger models generally perform better on long-form factuality.</li>
          <li><strong>Top performers</strong> on F1@<span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-213-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1985" style="width: 0.628em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;"><span style="position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;"><span class="mrow" id="MathJax-Span-1986"><span class="mi" id="MathJax-Span-1987" style="font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.19em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-213">k</script> include GPT-4-Turbo, Gemini-Ultra, and PaLM-2-L-IT-RLHF.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Implementation Details</strong>:</p>

    <ul>
      <li>SAFE uses GPT-3.5-Turbo for reasoning and Serper API for Google Search.</li>
      <li>Search steps capped at 5 per fact; top-3 results are retrieved per query.</li>
      <li>Open-source implementation: <a href="https://github.com/google-deepmind/long-form-factuality">GitHub - long-form-factuality</a></li>
    </ul>
  </li>
  <li>
    <p><strong>Limitations and Future Work</strong>:</p>

    <ul>
      <li>SAFE depends on the quality of Google Search and the LLM’s reasoning ability.</li>
      <li>May fail in expert domains (e.g., law, medicine) or when relevant content is hard to find.</li>
      <li>Future work may improve recall handling, robustness to repetition, and use of domain-specific search sources.</li>
    </ul>
  </li>
</ul>

<h2 id="references">References</h2>

<ul>
  <li><a href="https://huggingface.co/blog/fsommers/document-similarity-[ColPali](https://arxiv.org/abs/2407.01449)">Document Similarity Search with [ColPali](https://arxiv.org/abs/2407.01449)</a></li>
  <li><a href="https://weaviate.io/blog/late-chunking">Late Chunking: Balancing Precision and Cost in Long Context Retrieval</a></li>
  <li><a href="https://jina.ai/news/late-chunking-in-long-context-embedding-models/">Late Chunking in Long-Context Embedding Models</a></li>
  <li><a href="https://weaviate.io/blog/what-is-agentic-rag">Weaviate Blog: What is Agentic RAG?</a></li>
  <li><a href="https://www.anthropic.com/news/contextual-retrieval">Anthropic: Introducing Contextual Retrieval</a></li>
</ul>

<h2 id="citation">Citation</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code18"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code18">@article{Chadha2020DistilledRAG,
  title   = {Retrieval Augmented Generation},
  author  = {Chadha, Aman and Jain, Vinija},
  journal = {Distilled AI},
  year    = {2020},
  note    = {\url{https://aman.ai}}
}
</code></pre></div></div>

  </article>

</div>

      </div>
    </div><ins class="adsbygoogle adsbygoogle-noablate" data-adsbygoogle-status="done" style="display: none !important;" data-ad-status="unfilled"><div id="aswift_0_host" style="border: none; height: 0px; width: 0px; margin: 0px; padding: 0px; position: relative; visibility: visible; background-color: transparent; display: inline-block;"><iframe id="aswift_0" name="aswift_0" style="left:0;position:absolute;top:0;border:0;width:undefinedpx;height:undefinedpx;min-height:auto;max-height:none;min-width:auto;max-width:none;" sandbox="allow-forms allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-top-navigation-by-user-activation" frameborder="0" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" allow="attribution-reporting; run-ad-auction" src="https://googleads.g.doubleclick.net/pagead/ads?client=ca-pub-5905744527956213&amp;output=html&amp;adk=1812271804&amp;adf=3025194257&amp;lmt=1766895470&amp;plaf=1%3A2%2C2%3A2%2C7%3A2&amp;plat=1%3A128%2C2%3A128%2C3%3A128%2C4%3A128%2C8%3A128%2C9%3A32776%2C16%3A8388608%2C17%3A32%2C24%3A32%2C25%3A32%2C30%3A1048576%2C32%3A32%2C41%3A32%2C42%3A32&amp;format=0x0&amp;url=https%3A%2F%2Faman.ai%2Fprimers%2Fai%2FRAG%2F&amp;pra=5&amp;asro=0&amp;aiapm=0.1542&amp;aiapmd=0.1423&amp;aiapmi=0.16&amp;aiapmid=1&amp;aiact=0.5423&amp;aiactd=0.7&amp;aicct=0.7&amp;aicctd=0.5799&amp;ailct=0.5849&amp;ailctd=0.65&amp;aimart=4&amp;aimartd=4&amp;aieuf=1&amp;aicrs=1&amp;uach=WyIiLCIiLCIiLCIiLCIiLG51bGwsMCxudWxsLCIiLG51bGwsMF0.&amp;abgtt=6&amp;dt=1766922862840&amp;bpp=2&amp;bdt=24&amp;idt=74&amp;shv=r20251211&amp;mjsv=m202512100101&amp;ptt=9&amp;saldr=aa&amp;abxe=1&amp;cookie_enabled=1&amp;eoidce=1&amp;nras=1&amp;correlator=4370910023905&amp;frm=20&amp;pv=2&amp;u_tz=330&amp;u_his=50&amp;u_h=600&amp;u_w=800&amp;u_ah=600&amp;u_aw=800&amp;u_cd=24&amp;u_sd=1&amp;dmc=8&amp;adx=-12245933&amp;ady=-12245933&amp;biw=800&amp;bih=600&amp;scr_x=0&amp;scr_y=0&amp;eid=31095903%2C31096042%2C95376242%2C95376583%2C95378750&amp;oid=2&amp;pvsid=4960643054650815&amp;tmod=112874479&amp;uas=0&amp;nvt=1&amp;fsapi=1&amp;fc=1920&amp;brdim=22%2C22%2C22%2C22%2C800%2C0%2C756%2C556%2C800%2C600&amp;vis=1&amp;rsz=%7C%7Cs%7C&amp;abl=NS&amp;fu=33792&amp;bc=31&amp;bz=0.95&amp;psd=W251bGwsW251bGwsbnVsbCxudWxsLCJkZXByZWNhdGVkX2thbm9uIl1d&amp;ifi=1&amp;uci=a!1&amp;fsb=1&amp;dtd=77" data-google-container-id="a!1" tabindex="0" title="Advertisement" aria-label="Advertisement" data-load-complete="true"></iframe></div></ins>

    <footer class="site-footer">
   <div align="center" class="wrap">
      <div align="center" class="footer-col-1 column">
         <ul>
            <li>
               
               <span class="icon github">
                  <a href="https://github.com/amanchadha">
                     <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                        <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                           c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                           c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                           c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                           C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                           c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                           c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                           c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                           c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"></path>
                     </svg>
                  </a>
               </span>
               <!-- <span class="username">amanchadha</span> -->
                | 
               <a href="https://citations.amanchadha.com/">
                  <svg version="1.1" class="mail-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                     <image id="image0" width="16" height="16" x="0" y="0" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABJoAAAVjBAMAAABzrVjQAAAABGdBTUEAALGPC/xhBQAAACBjSFJN
                        AAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAElBMVEX///+xsLCxsLCxsLCx
                        sLD///+bxiTSAAAABHRSTlMAAKP3FWDuDwAAAAFiS0dEAIgFHUgAAAAJcEhZcwAACxMAAAsTAQCa
                        nBgAAAAHdElNRQfkBwQDMic2f+cwAAA03klEQVR42u2dW3IdOZJEu81mAcMqbOCacQMy0wImVNr/
                        msZKKpVeuHkzEA8PIPx8douAh+MkkmKR1H/+QwghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQ
                        QgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIeQQ/vt2KOMzyeH/GtiE7rgP/3u+TQPdcRukgU3o
                        jtsgb+fbNNAlt+GtgU3ojtsgDWxCd9yGT2/n2zTQJbfhrYFN6I7bIA1sGuiS2/DWwCZ0x214a2DT
                        QJfcBelgE7rkNrw1sAndcRukgU0DXXIXvsl0tE3oktvwb+MH2zTQJXdBOtiELrkL32U62KaBbrkL
                        P3R+rE1/oEvugnSwCV1yF/76sfRTbRrolrvwU+un2oQuuQvSwaaBbrkLP9d+qE3okrvwS+1n2jTQ
                        LTdBOtj0J7rlLvxa/JE2oUvugnSwaaBbbsJvMh1pE7rlLvze/IE2DXTLTZAWNqFbbsKnSfXn2TTQ
                        NTdh1v1xNg10y02QFjahW+7CtPzTbBrolpswb/80m9AtN0Fa2DTQNTfhSf2H2YRuuQmPFja9o2vu
                        gTzr/yibBrrmJjw9gKNsQrfcBGlh00DX3IPnMh1lE7rmJlycwEE2DXTNPZAeNqFrbsLVEZxj00d0
                        zT24PINjbBromnsgPWxC19yE60M4xaaBrrkHL07hFJvQNfdAetg00D334NUxHGITuuYeSA+b0DU3
                        oYdNA11zE3rYhG65Cy1sGuiWu9DCJnTJbehg00CX3IYGNg10x31oYBO64kacb9NAV9yI821CN9yJ
                        420a6IY7cbxN6IJbcbpNA11wKw63ib8YPJXDbULX24yzbRroeptxtk3odrtxtE0D3W43jrYJXW47
                        TrbpHV1uOw62aaC77cfBNqGrbci5Ng10tQ051yZ0sx051qaBbrYjx9qELrYlp9qE7rUnh9o00L32
                        5FCb0LU25UybBrrWppxpE7rVrhxp00C32pUjbUKX2pYTbfqILrUtB9o00J325UCb0JW2YEz/1/Ns
                        GqpWyBIy5v/zcTahi27Bk2f2OJuGqhWyhDSx6Q900R2QtyY2oYtuwVsTm4aqFbKEdLEJXXQLnj+2
                        Z9k0VK2QJS6aPssmdNEdkC42DVUtZImrqk+yaahaIUtIF5vQRXfgr8sn9yCbhqoWssR12QfZhC66
                        A//qMq7/7+1tGqpayBIv2j7HJnTRHfhuy3jx/29u01DVQlaQV3WfYtNQ1UKWeNn3KTahi+7Aj66M
                        l39iY5uGqhayxOvCD7EJXXQHPnSxaahqISvIjcbPsAnddAfuPL9H2PSObroBv4gy7vyhLW0aqlrI
                        Erc6P8EmdNEdeHSxaahqISvIvdIPsAnddAduPsL72zRUtZAV5Gbr+9uEbroDd5/h7W1CF92BSe1j
                        +gd3t2moaiEryO3ed7cJ3XQH7j/Fm9s0VLWQFeR+8ZvbhG66AZ8Uj/HeNg1VL2QFTfN724RuugFP
                        BBmaP7yHTeimO/Ck+jH9wzvbNFS1kBVE1f3ONqGbbsBTPYbuj9e3aah6ISsoy9/YJnTTDXhux1D+
                        +eo2DVUvZAVt+9vaxF8MHs+FHEP7AbVtQjfdgCs3hvojKts0VL2QFfT972oTuukGXKox9B9S16ah
                        6oWssHAAm9qEbroBK4/znjYNVS9kAVk5gS1tGqpeyApLR7ClTeimG/DKi7H0URVtGqpeyAJ/rZ3B
                        jjahq27A4hO9oU1D1QtZ4KUVb3+ufVw9m9BVN8BwBJvZNNBVn49YTuDyg6vZNG71QQy8kOnlx29k
                        E7rqBpgPYBubBrrq8xHzATxfoZhN6Kob4HAAm9g00FWfj1wewLttjVo2oas+H3E5gC1sekd3fT7X
                        BzBurvLMyUo23Z2FLCPXJ3B7nQ1sQlfdAK8TqG/TQFd9Pg+vE5DyNqGr/p1fAn5E57EiL05gWFeq
                        Y9P9UVLYIqTLTN95v71SeZvQVd+tfaDDLSOOR1Dcpo/oru+XPtAJF3l5Bua1qthU5oReulQqrYbX
                        Y5kXq2ITuur7ldfKe58bj4m5pyI2DXTXVx1N+dO+W7XZhnm1Ijahq/6C6DJ/ROf1Hm6Yl6thk2aO
                        MPZM7TidZp7KNqGr/nzjR8yK5r7JnWmGYr3CNqGr/qx+yxVK7jfeMC9YwSbNFMi2N9bJ/Rzq2oSu
                        2iBThfBu8w3zigVs0gyBLHtfnW7ON8xLFrAJ3bVNpgL5X3JzkGHuDG+TZoYQPlknQA/wCrk5xzCv
                        CbcJ/4vB7TOgJ3AacCjWLGoTumoHmQo8EVfI3TGGeVG0TZoJQjhjigtuy3SATft0vatOMUOUtAl9
                        Ck4yFf5RQMWEw7ws2CZ01+dM4jDhUCxb0SZNfnDVm+oUdRoFbUJ/x5mYJ1g8i5oTaiYoaBO4avOX
                        LevrFDZAPZvQ9XvPAx5ngqjyD/PKSJu2qtr5NFJQfgegJn85m9DlnzeRcUJN/HI2gasW8wDlRjJO
                        OMxr42zSZI/gxJlsE2rSy3QFmE3o4h8hU4GH+gnRhh/mxWE27Vb1HmP9gP7rH8PcH8omTfIITp3L
                        MqEmu0xXQNkErlrMAxQdzDLhMC8PskkTPIJzJzNMqIku0xVANoGrFvMAZUczTDjM62NsQncdOZvm
                        TMKQ6OTzDSA2oQtf6vo24OG+EH4s8wohNm3Z9T7jrT4uw7wDwiZN6jpd7zPf6uOiyT3vEGETumsx
                        T1B8wMda7GHuEGCTJnQIp08oCbHnewBswladcDWhR1xNPcwl5tv0EVt1wtUEvpwkI/V8k3SboEWb
                        ytaAHDDlaOYtptuE7NlWdtTBlJlPE1qmK2TbBKzZ3LYG2HiynllzNvNtsm2CtezQdtTJuJKUeV5j
                        sk2wkj3aVgEaTwyRNYcz3yfXJvwvOrK0reIjZj5L5GHuMdcmTMOvWwhAczR+pEWe95hqE6Zhv7pV
                        IKYTU2LN8cx3SrUJUbBn3WFn40Ve4nmRmTYh+r1VQgzbTac5n/lWmTbl1/sb0SOuHo4Lkhh4vlei
                        Tent+vetI3u6zAOaN5lnkyZrFGKeovDE5uE0eeeb5dmUW+2c2Aktp1NhOE1ema6QZlNytYoK4kgd
                        7kPqEc2rTLMptVlVBXFojqfAbJq48+2ybMos9imRA07ZazbNGcl0hSybkr1RNBCJ5nzws2nSzvdL
                        simv1uDGlaTNln1I8y5zbNLkrN24ko87jaY5JZmukGNTvjkTlv6N+sQDMiDmoNqw8x1TbErqNKVy
                        JTmj5R/TvMwUmxDuRFUeeELLiDmmOut8ywybUhp9TdR41yQM5vUK15yTTFfIsAlkz635w/kYP5lX
                        1GFuM8Gmd4w99+YPR3NE4ME0UeebxtsUX+c9YqZ7zT6DaU5KpivE2wTTJ6r0wDNaQcwJV5LOdw23
                        KbrM/NK1xM7l+I/saY5qXme4TUiDfuQRMh2+AcegQ7GtTFeItkmTcJfWK1Ug5nhrQef7RtsENegH
                        nP/V1TIdeOYcin1lukKwTViFXk6fg+aUkGNpcs43jrUpsEclD//hCrQg5myrOec7x9qEdug7/rNV
                        qME35lDsLNMVQm3SxAvGX5ECPYg52XLM+dahNqEVCus98Jg0AGPOC420KarEBcQ8jImYoR7A85oX
                        GmkTWqEfcPcj7pyMB5qUcr55oE1og37E3Y8CXbiHHIrNZbpCnE2abNGIeRojW8ykObH57nE2oQ2K
                        bT7woG6CDTlvNMymgP4qNa9lh5E0RybTFcJsQgsUXT24DjEn+p1h3j/KJk2yeAKqB/ch5kS2jPP9
                        g2zC/2Lw6Oq1eM8UEHGYKw2yCe3PndFz8Z4pIOIwVxpjkyZXAhF2oCsRcyJTxPn2MTah9fmFCDvg
                        nfgnHIrdZbpCiE2aWBnE6KGk/lCaY5PpCiE2oe25NXk2mrPCTKVJON89wibv3ur1vsKf5afSnNt8
                        9wCbNKFS8O99Ce+x3ANqDm7eaYBNaHnia48/rPUDTQo439zfJu/S7MQJAi1GzIkMAeeb+9uEdud3
                        4gTBNuOdbyj2lukK7jZpIuUg5pmceHcezDuf5ujmpbrbhHbn7uAANKeFGEyTb763t03ejRUsfZ3i
                        g2nObr63s02aQFnEGqKh+GSaw5PpCs42oc1J6DzpuACTaeLJdAVfm7zrqth5oXrEnGg53nxrX5vQ
                        4kyJdgTXj5gD/cQwb+1qkyZOGs6Vm3h3ns03neb45q262oQWRzE3Bs153QGXbt6qp03vaHEUc4Mo
                        Pdsw7+xokyZMIr6NGyk9m+YA5zs72oTW5gkZkoQcWPpwmnAyXcHPJu+iShaeeWDpw2nCyXQFP5vQ
                        1qQUbsZ5ODEH+oFh3tjNJk2UVJI0uYnzcGIOtHiE843dbEJLk9J37ollT6fJNt/Yyya0NDl9557Y
                        HVDZ5rU62eRdkh9imCoC5/E8o2kOcV6rk01oZ7Rj4yg83jDv62OTJkcyiaIgqhJzoLVo8319bEIr
                        c0GiKO5HljyfJppMV3Cxybuhom37UHc+zTHKdAUXm9DGJLXtQ935hmJbma7gYRNamKy2889s+VjD
                        k823dbDJuZ6yZQPOLHdATbL5tg42oYXJKtuLsgMO87Z2mzQZ8nEs2wvnCf2CaU5y3qvdJrQvK1ND
                        0RzaDTDB5r2abXLuxhtZGioU58Ywwea9Wm2q9YvB706NpeqEw7yr1Sa0La8AyJLcmZjzfGOYdzXa
                        pAkAAWFLbmlizrOSa76r0Sa0LC9B2OJ5apkjanLJdAWbTc69BIDx5QVFR9ScpkxXsNmEdiWxak+K
                        jjgUm8p0BZNNmu1BgHy5xndEMedZOM75phabvH+fegCfUMK4HdvqwQbHmm9qsQmtSmbTrmiOLXFG
                        Taz5pgabfDuJwa1pX3yH9EqlOdB5sQab0KasDw3Hd0ivVMNc7LpNmr1hiG6mLHy7Q6SaF7tuE1oU
                        w9BwNOf2GkSqebHLNvkWEoWoZkrDtzyvITWp5nuu2uTbRxheRXtTckjNmc73XLUJrUly0d6UHHKY
                        91y0SbMxkgfUmaT+xBxHH2q+56JNaEvugnXG5+Be4vUFf00oma6wZpNrGZGgrckpEBBKpius2YSW
                        JLtnfypOORRbynSFJZve0ZJk9+xPxSmHYkuZrrBik2ZXMGhpnlJxSs25ynSFFZvQiuT37I/m5BaP
                        NjTTfMsFm1yLCAYtTU6JYo6jzjTfcsEmtCEa0NLktCjmNF8Y5i31Nmn2hIN25jmeU4o5jfpk51vq
                        bUILogLtTE6NYk7zhWHeUm3TR7QgKtDO+BzdK/7KjyTTFbQ2eZaQANqZpCLzI8l0Ba1NaD0gNUeg
                        ObqkMTWRZLqC0ibXDhJAO3NBvTE1hyvTFZQ2oe3A1BxCvTGHYkeZrqCzSbNfCdDKXFBvTM3pynQF
                        nU1oOUA1h6A5u7WzjUw031FlE9oNPWhlnM5u7WwjE8131NjkOX8SaGWS2hRzGm2i+Y4am9BqLIBW
                        5gLP3xgq5jR/M8w7KmzSbFYFtDJXOI4p5jDaA57vqLAJbcYKaGOS+hRzmL8Z5h3v26TZqwxoY65w
                        HFPMYbQnPN/xtk2areqANiar0fRAMl3htk1oL4AtB6E5vJQ5NYFkusJdmzxHTwRtTFal6YFkusJd
                        m9BaIFuOotqcQ7GhTFe4aZNmo0qghbmk2pyaQ5bpCjdtQlsBbTmKanMOxYYyXeGeTZp9SoEWxu30
                        MubU5JHpCrds2uAXg0e2HIXm9F7wyM4j0xVu2YR2Yh20MG6n9wIxh1HmmW94xybHqbNBC+N2ei8Q
                        cxhlnvmGd2xCK2EALcw1fnOKOctbkk2aTaqB9uUavznFnEV50PMNb9iENsIC2pdr/OYUc5a3HJve
                        0UZYQPvid3zXiDmLMs58w5c2+U2MAO2L3/FdI+YsyjjzDV/ahPbBBtoXv+O7RsxZlHHmG76yyW9g
                        CGhf/I7vGjFnUcaZb/jKJrQORtC+vMBtTjFHeUuwSbNBRdC6vKDWoEOxn0xXeGET2oYKJQdSa9Ch
                        2E+mK1zbhJbBjLyVxm9QjzTDXOylTZrlayJvpfErODvNvNhLm9Au2JG30mjO75rsNPNir2zymxWG
                        vJXGr+HsNPNir2xCq+CAvJVGc37XZKeZF3thk9+oOOStNm6DeoQZ5mIvbEKb4IG81cZtUI8ww1zs
                        c5vQIrggrxoE4zaoR5hhLvapTZql60KbatiE9sCH6jZpDvCS2ja5jYmFNpWwCa2BE7Spgk1uU6JB
                        60KbfH/DJxa0Lq+oNOdQ7KexCe2AH2hbaNM57znaVMAmtAKOoG2hTZpVq4O2hTahDfAEbYvnCUbP
                        qcly2yavAUuAtqW7TV7z1QBtS3eb0Ofvi9ytkjZF2OQ1XhFoE9Qm9PE7U90mr75r2qRZcQdoE9Im
                        9Ol7Q5uANmkW3ALahLNJs94e0CacTeiz96e8TZojvKCgTU6TlQJtS1+b0CcfAdqWtjY5DVYLtC1t
                        bUIffAhoW7ra9D/ogw8BbctL6ow5FPu9tOm/6F5DekYPkTMlbfIcTjt2IWhTCrSJNvlBm2iTH7SJ
                        NvnRxKZ32pRBE5t8xsxOMq/1eJvKf4mANm1Ucw+bPmUnkekKtAmNy5iSnWS+IW1CQ5v2qZk2xSSZ
                        b0ib4NCmDJxscik6kjJD0ibaRJvch6NNyYXPN6RNcMoMSZtoE21yH+4K9ByvoE0Z0KbkGWnTATZ5
                        zJkeRKYr0CY4tGmXlp8PXgfatEvLtCkoyLxU2gSHNu3SMm0KCjIvlTbBoU27tOxXdek5JT3IfEfa
                        BIc2bdLyFjY5fDFc0guf70ib8NCmBNxs8uk6jioT0ibaRJvch2tu0yO98HmntAmPfcL8wueddrCp
                        +qfhVQakTbSJNrkPR5uSC5fpCrQJT5UBaZNh9DJUmY820SbalNTyJja9F5mPNp1gk+YUadMqbjYV
                        /zScNmVAm3LHo020iTbdw8+mD+hRLqFNGfjZJOYskdCmDGhT7nS0iTbRpnv42VT703DalAFtok11
                        Wu5iEyKHTFdoYpOYwxSeE5FjXihtwkObdmiZNsXlmBfaxCaXf7+t6JyCyDHftIlNpT8Np00btEyb
                        AnPMN6VNeGhTCo42uVUegNEmSI55n7QJD21KgTbRJj8cbar8iZPNJoHkmO9Km/DQphRoE23y493R
                        Jr/S3bHZhMkxr7O0TbaaaVNgjnmdtAkPbdqg5rDWS40pmBzzbWkTHtpUv+YmNn3A5JDpCqVtcv0S
                        gZjTRGGyCZRj3iZtwkObcvC0qe6rzmKTgHLM96VNeGhTDrSJNtXoObT4MlOicszLpE14aFP9nlvY
                        5DoTbdKAniZgSkHlmG9Mm/DQpiRcbXKt3hGDTbAc8y5pEx7DSK45aFNvm3wnok0q0NO4DymuOY63
                        STNgQ5twZct0hVY2iTlPCLQpCdpEm/z409Wmoq+6Kk/H8Ta1+DScNpVvesoDPY7vjM45aJMOMecJ
                        QHOItAlU9fk2eU9Dm5Sgx3EdUYBB5nvTJjjLIyKDyHSF6jb94WuTmAP5Q5vyoE1ps9AmLehxJrzT
                        pjTOt6nMKA1s0oy43AIU2pQHbUqbhDapQc/zO7SpftnH2+QfhDapEXMgZzRnSJus0KasOTrYtNj2
                        U9DzOM33AZtEpivQJjSL84GTyHSF+jad/qp7LzMFbapxDvnjRUxBmxZAz+MyXkSSFjZphqRNSUXL
                        dIWGNok5kSt1ZqBNC3xCD+Qw3Qd0FJmusIFNZ3/itGYTPIpMV+hok5gTObJkU8wEPWxaKpw2hUaZ
                        J+hoU6lXXaEBaFOhw1hjJf9f+J5lusIONh39iVOh/LRpiUJfI9Cc4L8UyCLTFbawaalywHFkjVYg
                        i0xX6GmTmCMhR4tK38Smgz9xWrGpQpZ5gz1tqvOqqxS+i03v3jY90BN9YyG7RGXpYpNmTuyJaFnI
                        XqLleYF72OT8q3kjj0THymNSIoxMV9jDpmM/cVqwSUqEmafoapOYI7mwYFONMPP+NrFpoXXYoWjQ
                        5w78Oj5tameT1Ch5HmMTm0591ZV6CmjTOuiJ/kZzfvEPQR+b9L2faVOVNDJdoa9NYs5kp9Yz0Mem
                        M191tR6BRjZpRj3XpjIVy3SFxjaJOVP6TLGRG9l04qtObVOdODJdobNNj+1Gio3TySbNrJZGEikW
                        mDaZ2G2iQnlkusI+NgW86sScyYTWpui4rWx6P80mbdzoPK1s0j7KBc7nmmrut7LptFed9ukoFWje
                        XG+boJeT0iYpFWieZiebtA9zcZuUUaVUv/M0O9l02KuunPi0yQpuGM3Z5XjfzCblARQ5JJ9hiiWa
                        97aVTf4/pBn1a9puUM/6Zjad9KrTHF1SzG42KY9gvZZqo6SkpE12QKMUDNnNpohXnZhDxU+Sk7Gd
                        TZqB77LBIPUyyXSFzWwK+Fsd5lswVQklJ1M7m4551akSJmXqZ5Nm4mKHtTyGFAw1z7SbTYdcTu8V
                        badNLtSeQrJCNbRJM3K581oaomSqeWXb2XTE5VRT9Y42fQyw6ZE8Q03TO9qkmdnWTYkREqN1tOmA
                        V13RZC1t0gxtKyeKosFa2vRHgE2pl5Pm1KrmkukKG9oU8qoTc6qQ/Jmxmtqkmfo2NeOX7VWmK+xo
                        0+aXk+LQ8kIpg51kk2bs26Slr5hJXatMV9jSpq0vJ8WZZUXSJ6NNr6iXPbnVrjZp5jYW5I3i6xuP
                        wq3Oy9rTpo0vp/tHJtmltrVJM3it4ysm92qp8642tWnby+n+iUl6p31t0kxe6QBLqW3odF7VrjZt
                        ejndPzDJr7SxTe8RNok51gsKif07jW3SjF7mDO+HluKVzvNta1PMq07MsZwyIxrtbJNm9iKneD+y
                        VG90HnBfm2Iup9DfNVdE6me0tkkzvLWm5MCBIZwKnSfc2KaYyynwWiguU3ObNNNbe0qNu0Gf85Z2
                        tmmzywnv8wua26QZH64Ten/fOmW6wtY2BV1OYs414f5RhWzvG/FMmzTzK4iIit3dvU2ZrrC3TUGX
                        U8CB3j8pgZXZ3iZNAeauDNz/7a+f9ihz3tDmNu1yOeF2VkCbNA3gdLqfUjbpcp5zd5uiLicxB/sB
                        xTEhq6RNYZeTmJN9ByRxZJXzoNvbFHU5OR6sYlNok7Qp7nJyO1lFQNmmyXnS/W2K+Q5xP500Z4Qt
                        kjb9TZRNLoerOaIHtkfapG0hWyfNP1olG/U4z3qCTXGXk/kL06rf0YmukTapa8jVSbOX7FTjPOwR
                        NsVdTjaddL89GF0ibfqHkF/6bNZJ9w99CrpE2rRShJakTOgKadN3Am1aPGelTIJukDatNZGikzYQ
                        ukBlZJmucIpNcV8Rf97dFfE7+EObvhNpk/bq0JzLyvox0Ka1LhaQ+0l0f5fTrl6jwXngc2wK+Uc1
                        V058ZW10d1+gTT8SbNO9Mw8VNRbatNpGjE+rCdDN6dPLdIWTbIr9e91ljV+IWDMT2vQzCTZ9nv/H
                        Fs1J/Aa6toUZZLrCWTaZznRRAfueYpgY1d4881k2perkBrq0lfJkusJhNiW961wR89BO0KbfQLtB
                        m06ySVNJDdCNLVUn0xWOs2k7ncQ8MaK5eerzbNrtXYeu6zu0aQbaDxViHtcN2mRtBQ66rMXeZLrC
                        iTbtpJOYh8XUNs99pE0bvevQTf0IbXoCWpK7hP4jQVpo0zPQmpgOBQRt8mgGCLqm5c5kusKpNu2h
                        k5jHRFU2T36sTVvohO5ovTGZrnCuTRvoBPxN89bCZLrCwTbV10nMI8L6mkc/2abyOqH7MdQl0xWO
                        tqm4TmKeD9fWY7rC2TbV1gldjqWs+QqH21RaJ3Q3v0GbXlFXJ0FX8xu06SVldUIX8zu0ybekRIp9
                        sUlZ1HyBDjbV1EnQrfzOsIZvYVNJndCdTKBN3j1lIeaZkC09Sd/Epno6iXmkAG6nf/LxXWwq97ZD
                        12Hr6MnH97GpmE7oNkwVPfv7aCObSr3tBF2GqaFn6TvZVOl6Qjcx565NH558fC+b6lxP6CKeYEzf
                        zKb43wN9D0HX8ARj+nY21XjdiXmKGAZtiqksFHQFT7Gl72hTAZ/QBZiakacf3dMmtE+CHt/Uy+Pp
                        R3e1aenf1mlg051X3fMP7mvTG/DzcfTgFwzLo9DaJtgLDz32FZbwzW16gwgl6JktfVyFp01/c9uD
                        Ty6vR0HPaynj6kNp0zdeOvD1j/1xvE3jMvvj6kNp00+8Pv3rru+BnvIFVyPK5UfSJiUNbLq4pl/8
                        oA1tUuIgU3mb3laT0yYlDjIJeoblKV99GG3SMXrYNNfp5UfRJh1dbJoMeiM2bdLhYRN6hqVR5c6H
                        0CYdDjLtYtMCtEkHbbqCNqnweNHRJvIVD5sEPUQctEkFbbqENqnweNEJeog4aJMK2nQJbVJBmy6h
                        TRoGbbqENmlwsQk9RCC0SQNtuoY2afCQiTaRr9Cma2iTBtp0DW1SMGjTNbRJAW16AW1SQJteQJsU
                        0KYX0CYFLjLRJvIF2vQC2qSANv3nNv9FRy0PbaJNbgzaRJvcoE20yQ8nmwQ9hwHa5AZtok1+0Cba
                        5IePTLSJ/A1tok1+0Cba5IeTTTt/iYA2uUGbaJMftIk2uTG8bHqgJ1mHNnnhZpOgJ1mHNnlBm2iT
                        H7SJNvnhZtPGn4bTJi9oE23yw88mQY+yDG3ygjbRJj/cZKJNxPNfKEePsgxt8oI20SY/HG0S9Cyr
                        0CYvaBNt8sPRpm1fdbTJC9pEm/zwtEnQwyxCm7zwtOmTPQ4E2uSFp027vupokxeuNgl6mjVokxe0
                        iTb54WrTpq862uSFr02CHmcJ2uQFbaJNfvjatOerjjZ54WyToOdZgTZ5QZtokx/ONm35qqNNXnjb
                        JOiBFqBNXnjbtOPlRJu8ePe26YGeSA9t8mLwVUeb3HC3acNXHW3ywt8mQY+khjZ54W/TfpcTbfIi
                        wCZBz6SFNnkRYNN2lxNt8iLCpg/ooZTQJjcCbBL0TEpokxsBNu32qqNNbkTYJOihdNAmNyJs2uxy
                        ok1uhNgk6KlU0CY3Qmza63KiTW4MXk60yY0Ym7a6nGiTG0E2CXouBbTJjSCbdrqcaJMfQTYJeq77
                        0CY/gmza6HKiTX5E2STowW5Dm/yIsmmfy4k2+THaX060yY8wm7a5nGiTH3E2CXq0m9AmP+Js2uVy
                        ok2OxNkk6NHuQZscibNpk8uJNjkSaNMev4+eNjkyAnUS9HB3oE2ORNq0xbuONjkSapOgp7sBbfIk
                        0qYdLifa5EmoTYKe7jW0yZP35pcTbfJkNL+caJMnsTbV14k2uRJrU/l3HW1yJdgmQc/3Atrkysfe
                        lxNtcmX0vpxokyvRNhX/lfS0yZdom2q/62iTL+E2CXrCK2iTL6P15USbfIm3SdAjXkCbnAm3qbJO
                        tMmZeJsKv+tokzPvnS8n2uTMSLicHughn0GbnMmwqey7jjZ5k2GToId8Am3yJsOmqpcTbfJmNNaJ
                        NnnzR4pNgh5zCm1yJ8WmmpcTbXJn9NWJNrmTZJOg55xAm/zJsani5USb/EmyqaBOtMmfkWSToAf9
                        DdrkT5ZN9S4n2hRAlk3ldKJNAXzMsknQk/4CbQpgdL2caFMEaTYV04k2RZBnk6BH/QnaFMFoejnR
                        pggSbRL0rD9Cm0LIs6mUTrQphMTLqdK7jjaFkGmToIf9Dm2KIdGmQj8QRZtiyLyc6rzraFMMqTYJ
                        etpv0KYgMm0qcznRpiBSL6cqOtGmIHJtEvS4X6FNUaTaVORyok1RdLycaFMUuTbV+KITbQoj16YS
                        7zraFEby5SToed9oUyDJNlW4nGhTHMk2CXpe2hRJ9uUk6IFpUyTJNuHfdbQpkGybBD0wbQpkdLuc
                        aFMk3S4n2hRJ+uX0ATsvbYok3Sbwu442hZJuk0DHpU2hNLucaFMsvS4n2hTLe6vLiTaFkfOPGpTS
                        iTYF8CfIo68IbnDa5AvUI/jlRJu8GGiJ/kVgHdAmB+qI9BVYEbTJRjWRviCoNmjTOiVN+sID1Aht
                        WqOuSV8AtUKbFkC78hrBFEOblAy0KPfAlEObNGyi0mfU5USbbvMRbYgKSEW06R5oOdQIoiXadAO0
                        GUsgiqJNr0BbsYoAuqJNlwy0EwYe+XXRpudgv7HETn5jtOkZaBfsSHpntGnKQJvgQnpttGkC2gIv
                        JLs42vQrqG/njiC7O9r0MwMtgCuS3B5t+pGzXPqcfjnRpu8c51L65USbvnGgS5+zLyfa9JUzXcq+
                        nGjT35zq0ufky4k2He1S8uVEm452iTblgj7tcDLLbG4T+qgTkMQ6W9s00CedQmKhjW3q4VLq5dTX
                        JvQh55HXaVebBvqIE5G0VpvahD7gXNJqbWkT+nSzeWQV29Cm3X94QI9kVdvPJvTRIsjqtptNJ32f
                        7n0kqd1mNg30uYJIqreXTehDhfHI6beTTQN9pjgkp+FGNjWWKetV18em7PP79DTJANgkKR23sSnv
                        4B638iQr9elWKCtNbEo6u4cmU65OKTX3sClBpoWHP9Umyei5hU1FT2qk6pRRdAebyp5Sqk4ZTTew
                        KfCEpG4096x3ON6muO8Y8PhrUqZOCWWfbtOofTZh8WhTAEGnJW4BE23yC/2Us22Kkck1YqJO8X0f
                        bVOETN5fVI7I+IRHeOEn2/TufyDinzJPp4Dwv3CwTbscR5pN8a+6c2366H0Wj6CgI82mqAn+5Vib
                        vGWSuKhpOgXO8JVTbdrqHLJsCn/VHWrT+0YuJf6EX3TtZ9o0tjqDvHedBM9xpE2uhyMZiZNsin4w
                        TrTJU6a/ciJnveuCxzjQJk+ZHjuGvkBipzjPJsfHPOdb87+SY1PwVXueTX7VPzJjjxydYoc4zia3
                        3jMvpr/J0UlCZzjNpk1qD41Om5wYXq0jwqfoFDrBWTZ5ySRbp8eNdpZNOzy/8fFpU6XT2H4A2HQn
                        2TTqP7wpE9CmMkch0BkSbIoc8BybfH4/KnoK2lSDI2TKeNcFpj/GJo9jEPQQbyE/aEObtJwiU8K7
                        LnDMU2yq3bIGj+fimrjsh9jk0PEDPcM3wnWKi36GTQ4HgB7hB6JtkrDkR9h0lkzhl5OEJT/CprNk
                        itcpLPgJNtnLR0/wK7QJxnkyReskUbEPsOlAmYLfdRIVe3+bzMWjB5gSalPYyNvbZJbpgZ5gDm3a
                        sXVBD/AE81OCGHp3m6ylR/VqhzalY/2mpqhaPaBNmzWe/ROYKkagTkGR97bJWjg6/zW0aau+0fFf
                        YH1WLpCYxFvbZKw7qNIy89GmxLKDGvUkzKaga3lnm0oW6orxeaFNaVWj49/iPcomCYm7sU0V6yw2
                        JG26yyjYZrUpadNdbG2i0yeNmVzAtjbZHlpBx0+akzbdo2CXMQTpJBFZd7XJ1jE6vQraFI3tewdC
                        mgzD9uDQpte8m5pEp1cSYlNICXva1OlqegvSKSLonjbV6zGUEWGTBATd0iZbu+j0C9CmQN6rtRiN
                        7fGhTVfYPmtCp18iQqeAmDva9F7tkUyANpVsFh1+kUGbChYr6PSr+NsUUMWGNlV7IHMwPUO0KaTW
                        gAazeKdNAZgaRIeHDZ5TxnY2jWKP4yaT06YpxfrbZnTaNMH0gAo6PXD2lDp2s6nYw7jR8LTpN0yP
                        p397O01Pm37D1B46PHj8hEL2ssn0cAo6PXh+2uTZJjq8B7SpSJmCDu+B6XGiTX5dosP74GqTeKfb
                        yiZLc6V/xeV9TA8UbfJq0r05ELSpQpHo8F6YHina9J1SxW3ZQvQjtpFNpqcSHb5IDbTpG5baBB2+
                        SA+06R9Mz6SAw3vyTpvslKoNiemxin3Ietjk3dq+TdCmL5ieSGz0UlXQpr8xtYaNXqsL2sTPwf3K
                        oE180f2Ml03ezexiU6XO8NAmE8NSmSCT16uDNlWqrAK0CdYeMngQgzaByhNg8DCcbHLuZg+bKj1/
                        NTA9X7SJNv2E7Xd/trbJ9CA6F1YF2gRp7oHLHYnpCaNNq+BiFy6lsU2mx9C5rzr4XE6+mXawqdLT
                        VwjalF8bLHU4LpeTb6QNbLK1hkpdvZeuNpnaElTq6sXQJtr0Ex6Xk2+i+jbZOgOFzoE2qTHZJKDQ
                        G1QTUVB9mwqVVQ7apMT2/GEyp0GblNCmsHIa2mTq6pBfKBfUDm1CdlUQ8+Xk21B1m2x1+XZVENqU
                        WBckciq0Ka8tSORUrJeTuKYpbpOtLN+qamK9nFzD0KbNoU1ZXSESZ2N73mgTbXKsqJNNxgcPkDgf
                        2nQXm00CSLxbR51sshUlgMTbleQahTZtD226xyhUVF1sLblGoU3bQ5vuYZPpr/zAGGhTfE1dPm2i
                        TfcYtCm+J9cktOkAaFNwSd49laZMS7TpAEaVlmjTAdCm2I4+d/q0yfQrVV2D0KYToE2RFdEm2uRX
                        UTebBm16gfX3qyfHhUKbAhtqZ5PhHneNQZuOoEhNdW0yykSbaJNLQV84/tej/MSgTdcYbZLkuFho
                        U1Q/tIk2+fXT0ab1m9w1RVmbjDLRJtrkUU9ES/Wp0RNtOoNRoqeqNv1Jm1TQppB2mtq0/F81XVPQ
                        pkMo0VNVm95pk44SPVW1ySqTpKYtwOrj5xqCNh3CoE3PoU1KaJN/N7SJNvl109em1dvcNQNtOgXa
                        9JSPtEkLbfKuprNNgzY9w2xTZtga0Kan0CY1tMm5mdY2LT6BrhFo0zEs9SSuEWjTMdCmJ9CmBd5p
                        0xyzTB1tWnoExTUCbToG2vQE2rQAbXoCbcpqTVwT0KZzoE1TBm1agTZNoU1L4HuiTefwEd4TbTqH
                        ldp8E9Cmc6BNUz7SphVo0xS7TLSJNn2DNi1Bm6bQpqzenH9zMW06CH1N4huANh0EbfJphTat9Sa+
                        ASraNGjTGrRpAm1ahDZNoE2L6Gt6+AagTQehL845AG06CNrkUgptWizOOQBtOgja5FIKbVoszjlA
                        RZscZKJNtxDnALTpIGjTBNq0CG2aQJsWoU0TPGzy7mkL1DY9nAPQpoNQ2+QdgDYdBG2aQJsWoU0T
                        aNMitGkCbVpEa5N7SbTpIGjTBNq0CG2a4GFTyy9f0qYJtGkRrU3uAWjTQdCmCbRpEdo0gTYtQpsm
                        0KZFlDaJe4BjbfKvqj60aQJtWoQ2TaBNiyhtergHoE0HobTJPwBtOgjaNMHFpo5/qaNNE2jTIjqb
                        xD8AbToI2jSBNi1Cmyb42PRIy1uGj+jH7VybJC1vGXQFBQSgTQdBm8yl0Ka14iL6Odemhp+G0yZr
                        KbRpsTgJCECbDgJeD206CHg9B9skaYGrQJuspdCmfxnwdmjTOdCmGU42/ZUWuAgqm0ISVLRJ1Up2
                        YYWhTeZWaNNabyEJTrZJ0hLXQNNbTDe06Rzw3dCmc9B0E5PgZJu6feKEr4Y2nQO+Gtp0DopmJCZB
                        RZv+9LIpqLOiaB7CoGYq2uT1xXDa9JSgCEfb1OtVR5vm0KYVFDZJUATadAy0aY6bTVGtlaRAL7Tp
                        GBS9REUoadNw0ykvM54CtdCmY7jfikRFONymsN7qoSgtrBXadAqK0sIyHG5To1cdbbIXQ5u+cb8T
                        CctQ0ia/LxE0etVV6IQ2ncL9TuIynG5Tn1ddhUpo0yGM241IXIiaNt2vBtldKWiTQzW0SV1ZYIjj
                        beryqrvdx6fAELTpEG73IYEhatrk9nMGwe3V4f7zF5mipk2ef6nrcTnRpgtok5LbNklkigY2hfZX
                        hRptFLXpnTbpuN1GaIqiNg3PyykzOIj7f20JjdHBJslMjuF2X7Fd0KYjuN1XbIyiNrl+Gt7gVVek
                        ihY2SWp0BEWaoE0nMIo0UdWm2/3cIjU6gNttBefoYZOkZs+nSg+06QSq9FDVJt9PnA5/1d1+9KKD
                        NLFJcsMnc9emyG+U+0ITm86+nMo8U2Vtuvu80ab7NoUH6WKT5KavWVV4krI2eX4z7+GX012bJDxJ
                        WZu8P3GKrxJGnQeKNu0PbXrNcNYpOX69oiQ+Sh+bEsrEUOhxqmuT96fhx15ON8cP/9LlW2WbvD9x
                        OvVyGoXGb2TToZfTe6HpC9t096G7zYfsCVIodDW1siml0KotpQxf2Ca+6u7wsdLsrWyS9BHKlJQz
                        emWbBi8nt45y0vSySdJniKbWc1TZJv9X3XmXU63HqJlNSa2mMWo9RaVteufl9IJiD1Fpm+4+eW0v
                        p7sFZU1d2qY//G0663KqNnRpmwI+cTrrcqo2c22bBi8nj3rSAvWzSQBzBFFu4to2Rbzqzrmcyl1N
                        HW0SxCDIcvISFbfp7uOn4oGYBNeN5EXqaNMh77qC0xa3KeRVd8a7ruDV1NOmIy6nirNWt+nuE9ju
                        crr73wlSR61uU9Dl9MAM48h7waupq03bv+tGyUHL23S7Nh2CmcaNmnOWt8n9B8iPuJxqXk31bYp6
                        1e2tU82raQObbj+GSpKLxnSSnKuvTTvrVHXE+jaFver2fddVvZp2sCnsctpWp6pXU2+b0tv2oe7T
                        soFNca+6PXW6/XTlT7eDTXGX05bvusLDNbdpQ51ujyb52XawKfBVt59O9x8tQLgtbLrfoB7BjbVE
                        6cG2sCn0ckK0ntEEIh1t2kqnUXuqPWy6X+IKD+BkYT1A8u1hU+zltM9n4vdHEki+TWxSPJQH61R+
                        Itq0j06KEgSTcBObgl91W+ikeaJAEXexSVPloTophhFQxF1sCr+cyuu0wyzb2DSa66SZRFAht7Ep
                        6mdXNtFpj0G2sSn+VVdZp6EZQ2Ax97FJVegiD/CMPrPjcu5jU8blVPS/2e0i00426To9SCfd4MgJ
                        NrIp5XIqqJPyKUJG3ckmZa2roMe0TS3IrLSpuE7aoaFhd7Ip51WHPpGf2UqmvWzSVruMoCddnRgc
                        fCub0i4n9Kl8Q/34gPPuZZO63XXQoy6N+wAH3sumvMupgk4ftZEFnXgzm9RPqwEBz7rhA7CZTZmX
                        E/h09HEf6MPZzqbRRKeFOQV9NvvZFPHvkBc8oQWZ8O+5DW3KfdeBzmiboL+wn00rj60FyR9xk5i/
                        s59N2ZfT588fcucbKxk/oU/lCxvatNS2jczx6id8zoY25V9Oie+RsZbvA/pMvrKjTYuN7+BT6XCv
                        2dGm5K8S5B3ZcjT0gXxjS5sQ77r4QxtFcynY06b14sv6dPdfVp0g6OP4lz1tQl1OcT4ZEgn6ML6z
                        qU0JP0ee6ZMljqDP4gc2tQn3rgs4wHJyL7OrTcB3ne8ZGj5fKifTvjYNsE4+52gOIehz+IltbSqg
                        k1UohwkEfQo/s69N6HfdPzwW0797bC7oM/iFjW1C/r3uJ/T//d5rZ/QR/MrGNpV4131Dbqd23BR9
                        AL+xs01F3nX3jzd3NwBb21RPp3/466eUI2aTB7r939nbpqBz2gJBlz9hb5sa6yTo6mdsblPZd11L
                        mba3qalOgq59zvY2DfTBUqbvbG9TS53QnT9jf5savuvQjT/lAJva6YTu+zkn2NRMJ3TbFxxh00Af
                        MGX6yhE2ddIJXfUlZ9jURyd00dccYhPox38p08+cYlOLz8T/stcUyzE2NdCpxu9ouuIcm47XSdAF
                        v+Ygmw7XSdD13uAkm6w/6FgaQbd7h5NsqvNTLE1lOsumc7/sJOhm73GWTafqhK71LofZdKZO6FJv
                        c5pNJ+qErvQ+x9l0nk7oQhWcZ9NhOgm6Tg0H2nTUlzEF3aWKI206R6cHukkdZ9p0ik7oGrUcatMZ
                        OqFLVHOqTQd8Li7oCvUca9P2Ogm6wAXOtWlzndDtLXGwTTt/8iTo6tY42qZtdRJ0cYucbdOmbzt0
                        a8scbtOOOgm6s3VOt2m/tx26Lwvn27SXToJuy0QDm3Z626GrMtLBpm2uJ0H3ZKWHTXtcT+iS7DSx
                        aQOdPqArcqCLTdXfdoKux4U+NpX+UWB0N040sqnu607QxXjRyqaarztBl+JHM5sKXk/oRjzpZlO1
                        6wndhi/9bKrkE7oJbzraVOV19wHdgzstbSrhk6A7CKCpTfDXnaDnD6GtTVCfHujZg2hsE8wn9Nhx
                        tLYJ8fmToEeOpLlN2b95FT1tMO1test74Ql60HBo098kfHuBoGfMgDb9w6BKdmjTd4KEEvRcedCm
                        n3AX6gN6olRo02/4qYSeJB3aNIXvtyVo03N4J2mhTS/gjaSANt2DHt3hvk2EEEIIIYQQQgghhBBC
                        CCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCH/8P/T2g3wTNSy
                        bgAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMC0wNy0wNFQwMzo1MDozOSswMzowMFesjGwAAAAldEVY
                        dGRhdGU6bW9kaWZ5ADIwMjAtMDctMDRUMDM6NTA6MzkrMDM6MDAm8TTQAAAAAElFTkSuQmCC"></image>
                  </svg>
               </a>
               | 
               
               <span class="icon twitter">
                  <a href="https://twitter.com/i_amanchadha">
                     <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                        <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                           c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                           c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                           c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                           C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                           c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                           c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"></path>
                     </svg>
                  </a>
               </span>
               <!-- <span class="username">i_amanchadha</span> -->
                | 
               <a href="mailto:hi@aman.ai">
                  <svg version="1.1" class="mail-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                     <image id="image0" width="16" height="16" x="0" y="0" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAW4AAAFuBAMAAABTjO+8AAAABGdBTUEAALGPC/xhBQAAACBjSFJN
                        AAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAALVBMVEWxsLDGxcW4t7esq6u+
                        vr7Z2NiqqamxsLCvrq7Ozc2ysrK1tbWenZ2dnZ3////zevNgAAAAAXRSTlMAQObYZgAAAAFiS0dE
                        Dm+9ME8AAAAJcEhZcwAACxMAAAsTAQCanBgAAAAHdElNRQfkBwQDLRvUSpUpAAALt0lEQVR42u2d
                        PW8jyRGGR7Lk3XXEyNqQwAVKBewtiHMkwAfQoQ4L3B02ImCs98KVuFZzFfECm3Am4A7YDXmR/sQF
                        /gHO7+94R6Somarq7qr+mGra/YZifzzsfmc4XdNdappcOvjixZcX2VrPpj+az1r8QxtDqp/MRmfa
                        IDI93WKbxUgbRaS3D9zmUhtFolfmUUttGL6OOtjm+kIbh61Jl3t/nPLK9LXUBuLpAGDvi1NWkHs/
                        nPKtwVprQ/l1QGDvg1NWFLf5URvLp28NrbUCy+sfzJB6MUqD/SoeRagkk/M0nkOqFA+Rx2+H5zY3
                        8dzfK2CncIrGcBtztYfuvtdtJPdHJe7ZXtrEmPdx2MdK2OZ6P+1tzEUU9+/VuMdR3E/UuM/+L7lP
                        9pR7um3lry+G0iQp93lUKxL9rnJX7spduSt35a7clbtyV+7KXbkrd+Wu3JW7clfuyl25K3flrtyV
                        u3JX7spduSt35a7c+809Men0rnJX7spduSt35a7clVuiOzXuZQz2QyMK3POLcOzjHd/w3DEnBaa7
                        xgH3z1+nE2h6xx3u8McmFNYN4U55dIkOd6hTpkaZO8wp3QaUuEOO93ZdosUdchC86xI1bvmvT7+6
                        GrfUKX2X6HFLndJ3iSK3zCnoWJoet8Qp+EyxHrfEKSemIG6+U4jDi5rcXKdQJ881ublOwS5R5uad
                        SiePuOpyc5xC5yfQ5eakIaFcos7td4rlILQ2t88ptiwW2tw+p9AuKYDb7RTrcXl9bpdT7LlO9Lld
                        TrG5pAhuu1McSRVK4LY5xZURpwRu8y+6ht0lhXDTOSOcqTfK4KaSi7jzJpXBTTnF5RLE/eeEiRXO
                        BNzYKX8wEu6JSad3NPeC5RSLS+ZTNe6XNBFwynPLMOtxnx3SxXtOsbjkjer7tE9k8a5TLC5ZKL8H
                        pHvpOMWSg22kzH1EV9g55XhFfv6m0X7vSieP3CXL+97+sS63JVnn2jXcm9yFytxkctSHAadza82a
                        ArgtTtnQ3FEfbRMAanPTcB/aT55Rn8xvC+E+WFF03YI9bWvpc9MuXjb4lUir3Ztafe7mlKjzgWZ4
                        XMkVwA1fkd0D0j9Ky8bDnVF4vw9l5FvKP51IRQnclJPPmu8cLimEm3jse0fYft1ppQhuYsl+iROW
                        9lYUZXDjZc0NujX0V3CFcCOnzBv4TcYlcjeHPu6/91sphRvmDUbcoHgx3E8qd+Wu3JW7cv9Pcpf6
                        ezn1cLdBwQK54ZoHcy9K5EZrTMxtXhbIPTV+7h5jGdx4DUxxz0vjfrZicZuvCuM+NTzuzpqnBG4q
                        JktzP64xC+C2RDYp7sc1fQHcd4bPvYuh6HPTkXsb90PMSp2bflNi5X6IEapzr4TcW6dYuH/9Tzr9
                        28Vt+zdydu6NUyzcv5l0eufgPrBVsnNvdl0rc08CuHsvUXS47f8pz8XdOkWV+8heycXdvp1S5Z4E
                        cn+uq8n9yVHJzT2/UOQ+dFVyc5srRe63Edxmosa9cFZC3H+iyw3P3dfio4f7jN7Zps09e+LjZp2D
                        GZr7hhFn45w7Gph7MeLEB0+K437DimsyztUN8BzbUbufisFNVQXcGUV0PmJyExsQNLnbfYw8brxV
                        RZF7E2hlceOAnCL3uYAbhbb0uLfhYSY3DCW+DOaQ6hQCiriRU4YacNjvWMgNw1uR/9+WKzjPu4Af
                        m/vA1kJWWUeLzY1CLmM5hViwz3UANwxxhSR/EQrOcWdDoIAbBosYh6oj5RgpAbdj1vII9rfsfCbh
                        hgGMzE6B89tLryDiPnK1lFzO60nEjQJ0Sz6FWK+cJDJuuJszo1Pg3IJkYULuQ3drCQWuJZicTciN
                        gnRnPAqxfgL9zMDnUm7olJh0hg7Beb2CBcTc8KhgHqeA0VncRnOjPcwzP4VYn7x9yLlhWAKPRbTg
                        nN7gInJu1OqVl0MoNDKjJNwogPUmMfdzRvsh3JzxiBAMSC6oQiHcqOWbJqFQWI8clSBuFMBK6RSe
                        C8O4YQAroVPgXM7pYmHcKBqzaBIJueQ8KTcKYDGc8jNMxUsJOtAWYArlRnvhRh6g1+1AXvtKoSyJ
                        toKh3CiQNG+c2q4C5u4hR4HfcXJutD/LGTLcrRXdKw3oPntwKZwb7YdzDeUdAwXPoeNLhnOjMIHD
                        KV3bjqyl0DWztrcYwY2cYh3Knm3tt0zoEldgKYYb7XYaWwqe9ErZbplw/pyXQgw37okuBn8CR/Qo
                        QJcsXV1HcaPdfOTMop9A+jEMus4dVIrjRjue1kShE1iIdAq6yi8ycqOgEuFJIucO8RiGrhVPx5Hc
                        aK8Wcgq5nwIv7aDjfGGCWG6062kJCtD7V2agFHTJ4sLTbyw3ChkAp1gyM4EgALpOZr5uo7nRwfVL
                        56e0UybOT/NwoxHtVrHv+euWglc3IyQTz40c3LmDOfb8uUoxFiEJuNEd4/FeYHOJuxQnPJCA2+4U
                        +/7hVkuLl1iL7BTc6Bdxmw3IsX+41fbOE+KSRNzIKZv7wcTNvbnzoLq80EASbrxXb9bYzyL0nYJ+
                        lzguScWNwgef72ToieP6G8Ip6Npg7mxJxI0W4jf4xMoaz8CPREKQQbnxNqi/wT+0q7g7+Ef4ddn7
                        cVJxk2mlep5oC5Fn4uCXG5b7mQdpfF/Kc63ydxEl47ak0YMD6Z6WsQK3E2l3uTmnRbCjJSG3y7zn
                        nGmRvO1PyO0wb/embJ+WtaCvlNz0UVQDbspUXrh7iXazJOW2Hdcb9UpZMjXL9oQk5bY4BT7gTclS
                        S1FPabnJ46joAY8MTQj3PCXmJpxCLAOIox7S/SCJuYklDrUMOEGlpP2k5j6GQORiETlFvE04NTcc
                        SctiET12S984J+ZGPDNLQbjMkb5xTsttWWhGlRyCG43irbUoWsbP2L0k50YsrtoobHLL7CU9N5z7
                        9wlLZ+SGI+j5LRHNTkZuMQf8jZL8ZibknojnXV4jAzfjFRUUCiAuh+cOYgj4rqm5V6Ai77k0rFZC
                        btHL9Ueh5971sNzB/Qd+31TccL75kZDAmmm4Q0etIaIu6+G4Ud9jNjZ7M0gO7jtQSXZWMKh2Cm60
                        nUuEjUOG42G4Ub/nMu6g752A+xRUkZ89Dmghnlu4cZPSs4l4xqK5j+V9YuG0qtm5p6BC2BZ2cSux
                        3Ik2gqNZG+XlFvdnE+swRjrukyQuCWgpjjvhwRLh4Zoo7qQHeWRjEMXNOdjEl6i1GO7EB9VEB/Yi
                        uJMfDJSMQwR3+oOYghbDub1HaQPEn8FwbtBHkoPG/OPiwdx5DnazWw3l9hzLD9aEOYuh3KD9ZIkL
                        uCkoArnzJYpgthzGnTMxB28mw7hXmVzSypn2JI47b+IZVush3LkT/XBmM4T7LqNL7scFgFPjEsCd
                        Pz0Rowc59xCJw+CMpuD2txkv/9iIuW0J6tLKm1RNyg2DmF+xMOQ6hVyR3L72UsmXqFHIPVz6RE9P
                        Mm4YnsqZrnLqnFkZN2grWVYISnCM+mEJETcMYo5ycrt7k3DDwEPq/DhQrtmVcJ8M6BLfOAm4QQAv
                        cVYfSo4e+dxDu6QVmOFOqJPP/dzaRj7Zx4rNDYJ3GbKEUbL2yuWG33w2CDaa5V0wj8v9yVI/t2zj
                        xeQGgbuBXEL1fCHifkv+dRCBmX4v4abrDiRyzFjcIDyVKTelTYdU7yzuiZ5LWoGQ4SWXm6o3qMC4
                        LXncIDw1QP5sqCNMwOBe4W87tMDy/pLDDerkz/pNCYzd2s+t75JWiMLLfQe/qY7grPu4/1mCS1qB
                        8Tv1cIP5UcP2HGH3cI/1uN1H2N3cw/yvCZtOQ7mzBQN5ch1hd3Kf63K7jrC7uIf73zU2nYZwK7uk
                        lfUIu4v7XJu6sR5hd3FffV2CJmLuslW5K3flLk+Vu3JX7vJUuSt35S5P+8p9vafcc2/y1DJ1RWb8
                        Kl8fmo/aCEE6sy/1i9bal9S4UDXu3Nelqn2B/Z02RIBmjT1pY8HahC5PtDHE2mxf8mXeLU4PkeKn
                        8U0Nir2LFL9eabMIdN0JcB//5cW+6JcN8X8B85vetwnigQ8AAAAldEVYdGRhdGU6Y3JlYXRlADIw
                        MjAtMDctMDRUMDM6NDU6MjcrMDM6MDDsnuMrAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDIwLTA3LTA0
                        VDAzOjQ1OjI3KzAzOjAwncNblwAAAABJRU5ErkJggg=="></image>
                  </svg>
               </a>
               | 
               <a id="theme-toggle" onclick="modeSwitcher()" style="cursor: pointer;">
                  <svg version="1.1" class="mail-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                     <image id="image0" width="16" height="16" x="0" y="0" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAMAAAAM7l6QAAAABGdBTUEAALGPC/xhBQAAACBjSFJN
                        AAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAACYVBMVEU/PzpEREBBQT1CQj4/
                        PztAQDtHR0NJSUU+PjpISERDQz9AQDw5OTRFRUE8PDhCQj1CQj89PTlKSkY+PjlNTUlLS0hEREBD
                        Qz9aWleHh4WtrazBwcHCwsLCwsLCwsLAwMCurq2IiIZgYFxXV1Sbm5rFxcXCwsKgoKBkZGFERECX
                        l5bExMSPj45LS0empqWpqahUVFCnp6axsbFTU09CQj6lpaSpqahISESRkZCNjYtUVFG/v7/FxcW7
                        u7vExMVhYV6ampmTk5FXV1S3t7eenp1VVVHCwsOYmJd3d3XIyMjCwsJdXVqEhIKrq6uGhoSnp6aX
                        l5aAgH6srKzAwMBdXVq8vLzCwsOZmZhNTUm3t7bDw8PCwsKYmJexsbCYmJawsK/CwsJOTkq2trXD
                        w8K9vb1bW1jBwcK9vb2pqaiXl5aCgoCvr66AgH6jo6OGhoNYWFXAwMB9fXvIyMjGxsZeXluamplM
                        TEi5ubmcnJteXlrCwsLGxsaTk5FDQz+dnZzJycljY2CJiYe+vr5bW1hUVFCcnJuVlZRGRkKmpqW4
                        uLd8fHl/f33AwMCioqFFRUFQUEyurq6wsLCFhYNkZGBSUk9SUk9hYV6JiYenp6bHx8inp6ZKSkZP
                        T0unp6bExMS6urm0tLSzs7O4uLjExMSioqGMjIrExMTKysuVlZRFRUFiYl6hoaDExMTIyMicnJtr
                        a2hhYV6Li4qxsbDDw8O+vr2zs7KHh4VlZWPHx8fGxsbCwsLJycnIyMjDw8PKysvExMTKysrMzMzL
                        y8vFxcXJycrFxcbGxsfHx8jIyMnExMX///9/oPL/AAAAuHRSTlMAAAAAAAAAAAAAAAAAAAAAAAAA
                        AAAAAQEYUJzK4+3kzJxYGSKE5+qSIgJe7GoGlqYMprcLAZapAl1uH/H70vMkhWYP1ZoW7G5G/fMb
                        UbpinWtbrMsd1OVuBtfn7m3IbMnlBNTozhzz1Z5sVq5Yt2YW7zf48iCTD9CiH/DzZwWv9Ctp0QsQ
                        rnABqNFKO82sAg22uF0fBwUfV7T7uw0Lp/PYycnV8qtu7/JxASeZ7vGgLh5hqebTrWUhilEqqgAA
                        AAFiS0dEyvO0NuYAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAHdElNRQfkCBYKLR1KuANWAAACD0lE
                        QVQoz23TZXvUQBAA4CG7R09K4ZANFtwKFHcvTrHi0BZ3d5dCKe4uxd1d7jbZJCQFwr9ik1wud83N
                        hyRP3uzOk5lZIE6IUK95i5atWktSm7bt2ncQQHTfg3MVUMdOnRNJ6kRS7tK1GxZSXEhIqH53SWE0
                        HUzp0TMPe6txUS9Vo1nB1N59wi6HivrqNBByv/7Y5gGRgTmU+6DBAufwkF85kCczhoZFwMOGa0Ed
                        MVKjbNRogOgYOahG8dhxJpXHx2DCxOBiY1I0f/IUykqmwjQllwpig+kJWjsDZiYCWop4yQpm6TQ5
                        G+bkVhKaW8LYPJhfR9UFUafcaOEik5ZBebbqFa4SlLf4Ny2vw/oS5CqJRpbavCxr5wpPScPlK0y6
                        ElZlNNJI5bUjtHoNY2th3R9f1/tKCjbINLkRNtWmdy5t5KsY2/yXWltg6zbNqxXylcS376Bs5y7A
                        u+V0JX2N7dlrUmUfArz/gL384KFMDR8+olBWeTQOJH7M4N2vOp6PPIzi6hN8gIyTSASCTp3mz9qZ
                        s43jYQEhAZoI587zPqkXLtrDRPClyzy9aV25eu1602Y3bt66fYen0+/WhNw5x/fuq8we/wcPHz1+
                        8tSyW2w8q8HeKcGR5y8s/gHTTPOffVdevnodyzhE+M3bd7Lp1JeZ1vsPH53/KEwx/xX06fOXqq+S
                        VPbt+4+fQjx1BP8DniGUSqIRNGsAAAAldEVYdGRhdGU6Y3JlYXRlADIwMjAtMDgtMjJUMTA6NDU6
                        MjkrMDM6MDBYVnojAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDIwLTA4LTIyVDEwOjQ1OjI5KzAzOjAw
                        KQvCnwAAAABJRU5ErkJggg=="></image>
                  </svg>
               </a>
            </li>
         </ul>
      </div>
      <div align="center" class="footer-col-1 column">
         <a href="https://www.amanchadha.com/">www.amanchadha.com</a>
      </div>
      <!-- <div class="footer-col-2 column">
         </div>
         
         <div class="footer-col-3 column">
         
         </div> -->
   </div>
   <!-- add permalinks to headers in kramdown -->
   <!-- <script>
      var headings = document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]");
      
      for (var i = 0; i < headings.length; i++) {
          headings[i].innerHTML =
              '<a href="#' + headings[i].id + '">' +
                  headings[i].innerText +
              '</a>';
      }
   </script>   -->

   <!-- add title case to section headings -->
   <script src="https://aman.ai/js/ap-style-title-case.js" type="text/javascript"></script>   
   <script>
      var headings = document.querySelectorAll("h1, h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]");
      
      for (var i = 0; i < headings.length; i++) {
          headings[i].innerHTML = titleCase(headings[i].innerHTML);
      }
      
      var toc = document.querySelectorAll("a[id^='markdown-toc-']");
      
      for (var i = 0; i < toc.length; i++) {
          toc[i].innerHTML = titleCase(toc[i].innerHTML);
      }      
   </script>        
</footer>

    <script src="https://aman.ai/js/nanobar.min.js"></script>
    <script>
    var options = {
      classname: 'my-class',
        id: 'my-id'
    };
    var nanobar = new Nanobar( options );
    nanobar.go(100);
    </script><div class="nanobar my-class" id="my-id" style="position: fixed;"><div class="bar"></div></div>     

    <!-- Scroll bar -->
    <div class="progress-bar"></div>
    <!-- Script used to generate --scroll variable with current scroll percentage value -->
    <script>
    var element = document.documentElement,
      body = document.body,
      scrollTop = 'scrollTop',
      scrollHeight = 'scrollHeight',
      progress = document.querySelector('.progress-bar'),
      scroll;

    document.addEventListener('scroll', function() {
      scroll = (element[scrollTop]||body[scrollTop]) / ((element[scrollHeight]||body[scrollHeight]) - element.clientHeight) * 100;
      progress.style.setProperty('--scroll', scroll + '%');
    });
    </script>    
    <!-- theme switcher -->
    <script src="https://aman.ai/js/mode-switcher.js"></script>
    <!-- mathjax -->
<!--     <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" id=""></script>
    <!-- make mathjax responsive -->
    <script type="text/x-mathjax-config;executed=true">
      MathJax.Hub.Config({
       "HTML-CSS": { linebreaks: { automatic: true } },
       "SVG": { linebreaks: { automatic: true } },
      });
    </script>
    <!-- Copy button -->
    <script src="https://aman.ai/js/clipboard.min.js"></script>
    <script src="https://aman.ai/js/copy.js"></script>      
    

<div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-size-adjust: none; font-family: STIXSizeOneSym, sans-serif;"></div></div><iframe name="googlefcPresent" style="display: none; width: 0px; height: 0px; border: none; z-index: -1000; left: -1000px; top: -1000px;"></iframe><iframe name="__tcfapiLocator" src="about:blank" style="display: none; width: 0px; height: 0px; border: none; z-index: -1000; left: -1000px; top: -1000px;"></iframe><iframe name="googlefcInactive" src="about:blank" style="display: none; width: 0px; height: 0px; border: none; z-index: -1000; left: -1000px; top: -1000px;"></iframe><iframe name="googlefcLoaded" src="about:blank" style="display: none; width: 0px; height: 0px; border: none; z-index: -1000; left: -1000px; top: -1000px;"></iframe><iframe src="https://www.google.com/recaptcha/api2/aframe" width="0" height="0" style="display: none;"></iframe></body><iframe id="google_esf" name="google_esf" src="https://googleads.g.doubleclick.net/pagead/html/r20251211/r20190131/zrt_lookup.html" style="display: none;"></iframe></html>