[
  {
    "id": "ai-transferability-estimation-log-expected-empirical-prediction-leep-1",
    "domain": "ai_primers",
    "category": "Miscellaneous",
    "article": "Transferability Estimation",
    "articleSlug": "transferability-estimation",
    "chapter": "Overview",
    "title": "Log Expected Empirical Prediction (LEEP)",
    "subtitle": "Overview",
    "contentHtml": "<ul>\n  <li><a href=\"https://arxiv.org/abs/2002.12462\">LEEP</a> by Nguyen et al. from Amazon Web Services and Facebook AI in ICML 2020 proposes to measure the transferability from the source dataset to the target dataset by evaluating the log likelihood of the correct prediction on the target dataset. The individual probability of the correct prediction on the target dataset is calculated through a predictive distribution based on two conditional probabilities:\n    <ol>\n      <li>The probability of the dummy label based on the categorical distribution of the trained model (trained on the source dataset) evaluated on the input of the target dataset.</li>\n      <li>The conditional density of the target dataset’s label given the dummy label from the previous step. The predictive distribution is then evaluated through integrating over all possible dummy labels.</li>\n    </ol>\n  </li>\n</ul>\n<ol>\n      <li>The probability of the dummy label based on the categorical distribution of the trained model (trained on the source dataset) evaluated on the input of the target dataset.</li>\n      <li>The conditional density of the target dataset’s label given the dummy label from the previous step. The predictive distribution is then evaluated through integrating over all possible dummy labels.</li>\n    </ol>",
    "contentMarkdown": "*   [LEEP](https://arxiv.org/abs/2002.12462) by Nguyen et al. from Amazon Web Services and Facebook AI in ICML 2020 proposes to measure the transferability from the source dataset to the target dataset by evaluating the log likelihood of the correct prediction on the target dataset. The individual probability of the correct prediction on the target dataset is calculated through a predictive distribution based on two conditional probabilities:\n    1.  The probability of the dummy label based on the categorical distribution of the trained model (trained on the source dataset) evaluated on the input of the target dataset.\n    2.  The conditional density of the target dataset’s label given the dummy label from the previous step. The predictive distribution is then evaluated through integrating over all possible dummy labels.\n\n1.  The probability of the dummy label based on the categorical distribution of the trained model (trained on the source dataset) evaluated on the input of the target dataset.\n2.  The conditional density of the target dataset’s label given the dummy label from the previous step. The predictive distribution is then evaluated through integrating over all possible dummy labels.",
    "order": 1,
    "orderInChapter": 1,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "miscellaneous"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 182,
      "contentLength": 1312
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/transferability-estimation/#log-expected-empirical-prediction-(leep)",
    "scrapedAt": "2025-12-28T11:57:31.937Z"
  },
  {
    "id": "ai-transferability-estimation-optimal-transport-dataset-distance-otdd-2",
    "domain": "ai_primers",
    "category": "Miscellaneous",
    "article": "Transferability Estimation",
    "articleSlug": "transferability-estimation",
    "chapter": "Overview",
    "title": "Optimal Transport Dataset Distance (OTDD)",
    "subtitle": "Overview",
    "contentHtml": "<ul>\n  <li><a href=\"https://proceedings.neurips.cc/paper/2020/file/f52a7b2610fb4d3f74b4106fb80b233d-Paper.pdf\">OTDD</a> by Alvarez-Melis et al. from Microsoft Research in NeurIPS 2020 proposes to measure distances between datasets through optimal transport as an estimation for transferability. Ideally, smaller distance indicates better transferability.</li>\n</ul>",
    "contentMarkdown": "*   [OTDD](https://proceedings.neurips.cc/paper/2020/file/f52a7b2610fb4d3f74b4106fb80b233d-Paper.pdf) by Alvarez-Melis et al. from Microsoft Research in NeurIPS 2020 proposes to measure distances between datasets through optimal transport as an estimation for transferability. Ideally, smaller distance indicates better transferability.",
    "order": 2,
    "orderInChapter": 2,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "miscellaneous"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 32,
      "contentLength": 365
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/transferability-estimation/#optimal-transport-dataset-distance-(otdd)",
    "scrapedAt": "2025-12-28T11:57:31.937Z"
  },
  {
    "id": "ai-transferability-estimation-leep-vs-otdd-3",
    "domain": "ai_primers",
    "category": "Miscellaneous",
    "article": "Transferability Estimation",
    "articleSlug": "transferability-estimation",
    "chapter": "Overview",
    "title": "LEEP vs. OTDD",
    "subtitle": "Overview",
    "contentHtml": "<ul>\n  <li>Compared to LEEP, OTDD does not require training a model on the source dataset. It only needs the feature-label pairs of the two datasets. Specifically, the distance measure is composed of two parts:\n    <ol>\n      <li>The distance between feature vectors of the two datasets.</li>\n      <li>The distance between the labels of the two datasets, where each label is represented by the distribution of the associated feature vectors.</li>\n    </ol>\n  </li>\n  <li>However, the drawback of the OTDD approach is obvious. Wasserstein distance is known to be computationally expensive. Therefore, OTDD needs to rely on approximation algorithms. Although the authors propose that it is possible to use Gaussian distribution as the modeling choice for the feature vector distribution under each label so that the 2-Wasserstein distance can be calculated through an analytic form, the approximation of this approach is too coarse. In comparison, the LEEP approach only involves one iteration of trained model inference on the target dataset to acquire the dummy label distribution.</li>\n  <li>In terms of experiments, both papers validated the statistical correlation between their proposed transferability estimation approaches and the model performance on the target dataset on several transfer learning tasks. Specifically, the LEEP approach witnessed larger than 0.94 correlation coefficients between the LEEP score and the test accuracy (closer to 1 correlation coefficient indicates better transferability measurement) when transferring from the ImageNet dataset to the CIFAR-100 dataset and from the CIFAR-10 dataset to the CIFAR-100 dataset. The OTDD approach witnessed -0.85 correlation between the dataset distance and the relative drop in test error (closer to -1 correlation coefficient indicates better distance measure) when transferring from the MNIST dataset (with augmentations) to the USPS dataset. However, when not performing augmentations, the correlation when transferring among the MNIST dataset, its variations and the USPS dataset is only -0.59 for OTDD.</li>\n  <li>Overall, neither of the two approaches require re-training a model on the target dataset.</li>\n  <li>The following illustration compares the major differences between OTDD and LEEP.</li>\n</ul>\n<ol>\n      <li>The distance between feature vectors of the two datasets.</li>\n      <li>The distance between the labels of the two datasets, where each label is represented by the distribution of the associated feature vectors.</li>\n    </ol>\n<p><img src=\"/primers/ai/assets/transferability-estimation/OTDD_LEEP_Visualization.png\" alt=\"\"></p>",
    "contentMarkdown": "*   Compared to LEEP, OTDD does not require training a model on the source dataset. It only needs the feature-label pairs of the two datasets. Specifically, the distance measure is composed of two parts:\n    1.  The distance between feature vectors of the two datasets.\n    2.  The distance between the labels of the two datasets, where each label is represented by the distribution of the associated feature vectors.\n*   However, the drawback of the OTDD approach is obvious. Wasserstein distance is known to be computationally expensive. Therefore, OTDD needs to rely on approximation algorithms. Although the authors propose that it is possible to use Gaussian distribution as the modeling choice for the feature vector distribution under each label so that the 2-Wasserstein distance can be calculated through an analytic form, the approximation of this approach is too coarse. In comparison, the LEEP approach only involves one iteration of trained model inference on the target dataset to acquire the dummy label distribution.\n*   In terms of experiments, both papers validated the statistical correlation between their proposed transferability estimation approaches and the model performance on the target dataset on several transfer learning tasks. Specifically, the LEEP approach witnessed larger than 0.94 correlation coefficients between the LEEP score and the test accuracy (closer to 1 correlation coefficient indicates better transferability measurement) when transferring from the ImageNet dataset to the CIFAR-100 dataset and from the CIFAR-10 dataset to the CIFAR-100 dataset. The OTDD approach witnessed -0.85 correlation between the dataset distance and the relative drop in test error (closer to -1 correlation coefficient indicates better distance measure) when transferring from the MNIST dataset (with augmentations) to the USPS dataset. However, when not performing augmentations, the correlation when transferring among the MNIST dataset, its variations and the USPS dataset is only -0.59 for OTDD.\n*   Overall, neither of the two approaches require re-training a model on the target dataset.\n*   The following illustration compares the major differences between OTDD and LEEP.\n\n1.  The distance between feature vectors of the two datasets.\n2.  The distance between the labels of the two datasets, where each label is represented by the distribution of the associated feature vectors.\n\n![](/primers/ai/assets/transferability-estimation/OTDD_LEEP_Visualization.png)",
    "order": 3,
    "orderInChapter": 3,
    "difficulty": 2,
    "estimatedMinutes": 2,
    "tags": [
      "miscellaneous",
      "transfer learning"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 359,
      "contentLength": 2627
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/transferability-estimation/#leep-vs.-otdd",
    "scrapedAt": "2025-12-28T11:57:31.937Z"
  }
]