[
  {
    "id": "ai-model-acceleration-overview-1",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Training Optimizations",
    "title": "Overview",
    "order": 1,
    "orderInChapter": 1,
    "contentHtml": "<ul>\n  <li>\n    <p>Training optimizations for large language models (LLMs) focus on reducing computational and memory overhead during the training phase while preserving model quality. As LLMs scale in size and sequence length, traditional attention mechanisms and dense architectures become bottlenecks due to their high compute and memory requirements—most notably the quadratic complexity of self-attention.</p>\n  </li>\n  <li>\n    <p>This section explores innovations aimed at accelerating training through both algorithmic and systems-level enhancements. These include:</p>\n\n    <ul>\n      <li>\n        <p><strong>Memory-aware attention algorithms</strong> like FlashAttention and FlashAttention-2 that optimize data movement between GPU memory hierarchies (e.g., from HBM to SRAM), significantly reducing memory bandwidth usage and computation time. These approaches prioritize hardware efficiency through techniques such as tiling, recomputation, and parallelization of attention blocks.</p>\n      </li>\n      <li>\n        <p><strong>Multi-query and grouped-query attention methods</strong>, such as those proposed in the Fast Transformer Decoding and GQA papers, which reduce redundancy in attention heads by sharing key/value projections. These techniques are especially valuable for speeding up decoding and inference but also reduce the number of parameters and computational cost during training.</p>\n      </li>\n      <li>\n        <p><strong>Sparse and localized attention schemes</strong> like those introduced in Longformer, which replace global self-attention with a combination of local windowed and task-specific global attention. This approach reduces memory consumption and compute time from quadratic to linear with respect to sequence length, enabling efficient training on longer sequences.</p>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p>Together, these methods represent a growing body of work that rethinks the Transformer architecture and its memory-compute tradeoffs. They aim to make LLM training more scalable, efficient, and accessible—paving the way for faster iterations and the deployment of increasingly capable models on constrained hardware. Subsequent sections provide a closer look at specific techniques and their empirical results.</p>\n  </li>\n</ul>\n<p>Training optimizations for large language models (LLMs) focus on reducing computational and memory overhead during the training phase while preserving model quality. As LLMs scale in size and sequence length, traditional attention mechanisms and dense architectures become bottlenecks due to their high compute and memory requirements—most notably the quadratic complexity of self-attention.</p>\n<p>This section explores innovations aimed at accelerating training through both algorithmic and systems-level enhancements. These include:</p>\n<ul>\n      <li>\n        <p><strong>Memory-aware attention algorithms</strong> like FlashAttention and FlashAttention-2 that optimize data movement between GPU memory hierarchies (e.g., from HBM to SRAM), significantly reducing memory bandwidth usage and computation time. These approaches prioritize hardware efficiency through techniques such as tiling, recomputation, and parallelization of attention blocks.</p>\n      </li>\n      <li>\n        <p><strong>Multi-query and grouped-query attention methods</strong>, such as those proposed in the Fast Transformer Decoding and GQA papers, which reduce redundancy in attention heads by sharing key/value projections. These techniques are especially valuable for speeding up decoding and inference but also reduce the number of parameters and computational cost during training.</p>\n      </li>\n      <li>\n        <p><strong>Sparse and localized attention schemes</strong> like those introduced in Longformer, which replace global self-attention with a combination of local windowed and task-specific global attention. This approach reduces memory consumption and compute time from quadratic to linear with respect to sequence length, enabling efficient training on longer sequences.</p>\n      </li>\n    </ul>\n<p><strong>Memory-aware attention algorithms</strong> like FlashAttention and FlashAttention-2 that optimize data movement between GPU memory hierarchies (e.g., from HBM to SRAM), significantly reducing memory bandwidth usage and computation time. These approaches prioritize hardware efficiency through techniques such as tiling, recomputation, and parallelization of attention blocks.</p>\n<p><strong>Multi-query and grouped-query attention methods</strong>, such as those proposed in the Fast Transformer Decoding and GQA papers, which reduce redundancy in attention heads by sharing key/value projections. These techniques are especially valuable for speeding up decoding and inference but also reduce the number of parameters and computational cost during training.</p>\n<p><strong>Sparse and localized attention schemes</strong> like those introduced in Longformer, which replace global self-attention with a combination of local windowed and task-specific global attention. This approach reduces memory consumption and compute time from quadratic to linear with respect to sequence length, enabling efficient training on longer sequences.</p>\n<p>Together, these methods represent a growing body of work that rethinks the Transformer architecture and its memory-compute tradeoffs. They aim to make LLM training more scalable, efficient, and accessible—paving the way for faster iterations and the deployment of increasingly capable models on constrained hardware. Subsequent sections provide a closer look at specific techniques and their empirical results.</p>",
    "contentMarkdown": "*   Training optimizations for large language models (LLMs) focus on reducing computational and memory overhead during the training phase while preserving model quality. As LLMs scale in size and sequence length, traditional attention mechanisms and dense architectures become bottlenecks due to their high compute and memory requirements—most notably the quadratic complexity of self-attention.\n    \n*   This section explores innovations aimed at accelerating training through both algorithmic and systems-level enhancements. These include:\n    \n    *   **Memory-aware attention algorithms** like FlashAttention and FlashAttention-2 that optimize data movement between GPU memory hierarchies (e.g., from HBM to SRAM), significantly reducing memory bandwidth usage and computation time. These approaches prioritize hardware efficiency through techniques such as tiling, recomputation, and parallelization of attention blocks.\n        \n    *   **Multi-query and grouped-query attention methods**, such as those proposed in the Fast Transformer Decoding and GQA papers, which reduce redundancy in attention heads by sharing key/value projections. These techniques are especially valuable for speeding up decoding and inference but also reduce the number of parameters and computational cost during training.\n        \n    *   **Sparse and localized attention schemes** like those introduced in Longformer, which replace global self-attention with a combination of local windowed and task-specific global attention. This approach reduces memory consumption and compute time from quadratic to linear with respect to sequence length, enabling efficient training on longer sequences.\n        \n*   Together, these methods represent a growing body of work that rethinks the Transformer architecture and its memory-compute tradeoffs. They aim to make LLM training more scalable, efficient, and accessible—paving the way for faster iterations and the deployment of increasingly capable models on constrained hardware. Subsequent sections provide a closer look at specific techniques and their empirical results.\n    \n\nTraining optimizations for large language models (LLMs) focus on reducing computational and memory overhead during the training phase while preserving model quality. As LLMs scale in size and sequence length, traditional attention mechanisms and dense architectures become bottlenecks due to their high compute and memory requirements—most notably the quadratic complexity of self-attention.\n\nThis section explores innovations aimed at accelerating training through both algorithmic and systems-level enhancements. These include:\n\n*   **Memory-aware attention algorithms** like FlashAttention and FlashAttention-2 that optimize data movement between GPU memory hierarchies (e.g., from HBM to SRAM), significantly reducing memory bandwidth usage and computation time. These approaches prioritize hardware efficiency through techniques such as tiling, recomputation, and parallelization of attention blocks.\n    \n*   **Multi-query and grouped-query attention methods**, such as those proposed in the Fast Transformer Decoding and GQA papers, which reduce redundancy in attention heads by sharing key/value projections. These techniques are especially valuable for speeding up decoding and inference but also reduce the number of parameters and computational cost during training.\n    \n*   **Sparse and localized attention schemes** like those introduced in Longformer, which replace global self-attention with a combination of local windowed and task-specific global attention. This approach reduces memory consumption and compute time from quadratic to linear with respect to sequence length, enabling efficient training on longer sequences.\n    \n\n**Memory-aware attention algorithms** like FlashAttention and FlashAttention-2 that optimize data movement between GPU memory hierarchies (e.g., from HBM to SRAM), significantly reducing memory bandwidth usage and computation time. These approaches prioritize hardware efficiency through techniques such as tiling, recomputation, and parallelization of attention blocks.\n\n**Multi-query and grouped-query attention methods**, such as those proposed in the Fast Transformer Decoding and GQA papers, which reduce redundancy in attention heads by sharing key/value projections. These techniques are especially valuable for speeding up decoding and inference but also reduce the number of parameters and computational cost during training.\n\n**Sparse and localized attention schemes** like those introduced in Longformer, which replace global self-attention with a combination of local windowed and task-specific global attention. This approach reduces memory consumption and compute time from quadratic to linear with respect to sequence length, enabling efficient training on longer sequences.\n\nTogether, these methods represent a growing body of work that rethinks the Transformer architecture and its memory-compute tradeoffs. They aim to make LLM training more scalable, efficient, and accessible—paving the way for faster iterations and the deployment of increasingly capable models on constrained hardware. Subsequent sections provide a closer look at specific techniques and their empirical results.",
    "contentLength": 5654,
    "wordCount": 682,
    "hasCode": false,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/model-acceleration/#overview"
  },
  {
    "id": "ai-model-acceleration-flashattention-2",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Training Optimizations",
    "title": "FlashAttention",
    "order": 2,
    "orderInChapter": 2,
    "contentHtml": "<ul>\n  <li>Proposed in <a href=\"https://arxiv.org/abs/2205.14135\">FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a> by Dao et al. from Stanford.</li>\n  <li>Transformers are slow and memory-hungry on long sequences, since the time and memory complexity of self-attention are quadratic in sequence length. Approximate attention methods have attempted to address this problem by trading off model quality to reduce the compute complexity, but often do not achieve wall-clock speedup. They argue that a missing principle is making attention algorithms IO-aware – accounting for reads and writes between levels of GPU memory.</li>\n  <li>This paper by Dao et al. from Stanford in 2022 proposes FlashAttention, an IO-aware exact attention algorithm that uses tiling to reduce the number of memory reads/writes between GPU high bandwidth memory (HBM) and GPU on-chip SRAM. Specifically, FlashAttention reorders the attention computation and leverages classical techniques (tiling, recomputation) to significantly speed it up and reduce memory usage from quadratic to linear in sequence length.</li>\n  <li>They analyze the IO complexity of FlashAttention, showing that it requires fewer HBM accesses than standard attention, and is optimal for a range of SRAM sizes. They also extend FlashAttention to block-sparse attention, yielding an approximate attention algorithm that is faster than any existing approximate attention method.</li>\n  <li>FlashAttention trains Transformers faster than existing baselines: 15% end-to-end wall-clock speedup on BERT-large (seq. length 512) compared to the MLPerf 1.1 training speed record, 3x speedup on GPT-2 (seq. length 1K), and 2.4x speedup on long-range arena (seq. length 1K-4K).</li>\n  <li>FlashAttention and block-sparse FlashAttention enable longer context in Transformers, yielding higher quality models (0.7 better perplexity on GPT-2 and 6.4 points of lift on long-document classification) and entirely new capabilities: the first Transformers to achieve better-than-chance performance on the Path-X challenge (seq. length 16K, 61.4% accuracy) and Path-256 (seq. length 64K, 63.1% accuracy).</li>\n  <li>The figure below from the paper shows: (Left) FlashAttention uses tiling to prevent materialization of the large <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-1-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>N</mi><mo>&amp;#x00D7;</mo><mi>N</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.66em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2\"><span class=\"mi\" id=\"MathJax-Span-3\" style=\"font-family: STIXGeneral-Italic;\">N<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-4\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-5\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">N<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>N</mi><mo>×</mo><mi>N</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-1\">N \\times N</script> attention matrix (dotted box) on (relatively) slow GPU HBM. In the outer loop (red arrows), FlashAttention loops through blocks of the <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-2-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-6\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-7\"><span class=\"mi\" id=\"MathJax-Span-8\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-2\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-3-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-9\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-10\"><span class=\"mi\" id=\"MathJax-Span-11\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-3\">V</script> matrices and loads them to fast on-chip SRAM. In each block, FlashAttention loops over blocks of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-4-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>Q</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-12\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-13\"><span class=\"mi\" id=\"MathJax-Span-14\" style=\"font-family: STIXGeneral-Italic;\">Q</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Q</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-4\">Q</script> matrix (blue arrows), loading them to SRAM, and writing the output of the attention computation back to HBM. Right: Speedup over the PyTorch implementation of attention on GPT-2. FlashAttention does not read and write the large <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-5-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>N</mi><mo>&amp;#x00D7;</mo><mi>N</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-15\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.66em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-16\"><span class=\"mi\" id=\"MathJax-Span-17\" style=\"font-family: STIXGeneral-Italic;\">N<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-18\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-19\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">N<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>N</mi><mo>×</mo><mi>N</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-5\">N \\times N</script> attention matrix to HBM, resulting in an 7.6x speedup on the attention computation.</li>\n</ul>\n<p><img src=\"../../../images/papers/FlashAttention.jpg\" alt=\"\"></p>\n<ul>\n  <li><a href=\"https://github.com/Dao-AILab/flash-attention\">Code</a></li>\n  <li>A detailed discourse on this topic is available in our <a href=\"../flashattention\">FlashAttention</a> primer.</li>\n</ul>",
    "contentMarkdown": "*   Proposed in [FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/abs/2205.14135) by Dao et al. from Stanford.\n*   Transformers are slow and memory-hungry on long sequences, since the time and memory complexity of self-attention are quadratic in sequence length. Approximate attention methods have attempted to address this problem by trading off model quality to reduce the compute complexity, but often do not achieve wall-clock speedup. They argue that a missing principle is making attention algorithms IO-aware – accounting for reads and writes between levels of GPU memory.\n*   This paper by Dao et al. from Stanford in 2022 proposes FlashAttention, an IO-aware exact attention algorithm that uses tiling to reduce the number of memory reads/writes between GPU high bandwidth memory (HBM) and GPU on-chip SRAM. Specifically, FlashAttention reorders the attention computation and leverages classical techniques (tiling, recomputation) to significantly speed it up and reduce memory usage from quadratic to linear in sequence length.\n*   They analyze the IO complexity of FlashAttention, showing that it requires fewer HBM accesses than standard attention, and is optimal for a range of SRAM sizes. They also extend FlashAttention to block-sparse attention, yielding an approximate attention algorithm that is faster than any existing approximate attention method.\n*   FlashAttention trains Transformers faster than existing baselines: 15% end-to-end wall-clock speedup on BERT-large (seq. length 512) compared to the MLPerf 1.1 training speed record, 3x speedup on GPT-2 (seq. length 1K), and 2.4x speedup on long-range arena (seq. length 1K-4K).\n*   FlashAttention and block-sparse FlashAttention enable longer context in Transformers, yielding higher quality models (0.7 better perplexity on GPT-2 and 6.4 points of lift on long-document classification) and entirely new capabilities: the first Transformers to achieve better-than-chance performance on the Path-X challenge (seq. length 16K, 61.4% accuracy) and Path-256 (seq. length 64K, 63.1% accuracy).\n*   The figure below from the paper shows: (Left) FlashAttention uses tiling to prevent materialization of the large N×NN×NN \\\\times N attention matrix (dotted box) on (relatively) slow GPU HBM. In the outer loop (red arrows), FlashAttention loops through blocks of the KKK and VVV matrices and loads them to fast on-chip SRAM. In each block, FlashAttention loops over blocks of QQQ matrix (blue arrows), loading them to SRAM, and writing the output of the attention computation back to HBM. Right: Speedup over the PyTorch implementation of attention on GPT-2. FlashAttention does not read and write the large N×NN×NN \\\\times N attention matrix to HBM, resulting in an 7.6x speedup on the attention computation.\n\n![](../../../images/papers/FlashAttention.jpg)\n\n*   [Code](https://github.com/Dao-AILab/flash-attention)\n*   A detailed discourse on this topic is available in our [FlashAttention](../flashattention) primer.",
    "contentLength": 10091,
    "wordCount": 426,
    "hasCode": false,
    "hasMath": true,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/model-acceleration/#flashattention"
  },
  {
    "id": "ai-model-acceleration-flashattention-2-3",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Training Optimizations",
    "title": "FlashAttention-2",
    "order": 3,
    "orderInChapter": 3,
    "contentHtml": "<ul>\n  <li>Proposed in <a href=\"https://tridao.me/publications/flash2/flash2.pdf\">FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning</a> by Dao from Princeton and Stanford.</li>\n  <li>Scaling Transformers to longer sequence lengths has been a major problem in the last several years, promising to improve performance in language modeling and high-resolution image understanding, as well as to unlock new applications in code, audio, and video generation. The attention layer is the main bottleneck in scaling to longer sequences, as its runtime and memory increase quadratically in the sequence length.</li>\n  <li><a href=\"#flashattention-fast-and-memory-efficient-exact-attention-with-io-awareness\">FlashAttention</a> exploits the asymmetric GPU memory hierarchy to bring significant memory saving (linear instead of quadratic) and runtime speedup (2-4x compared to optimized baselines), with no approximation. However, FlashAttention is still not nearly as fast as optimized matrix-multiply (GEMM) operations, reaching only 25-40% of the theoretical maximum FLOPs/s.</li>\n  <li>They observe that the inefficiency is due to suboptimal work partitioning between different thread blocks and warps on the GPU, causing either low-occupancy or unnecessary shared memory reads/writes.</li>\n  <li>This paper by Dao from Princeton and Stanford proposes FlashAttention-2, with better work partitioning to address these issues. In particular, they (1) tweak the algorithm to reduce the number of non-matmul FLOPs, (2) parallelize the attention computation, even for a single head, across different thread blocks to increase occupancy, and (3) within each thread block, distribute the work between warps to reduce communication through shared memory. These yield around 2x speedup compared to FlashAttention, reaching 50-73% of the theoretical maximum FLOPs/s on A100 and getting close to the efficiency of GEMM operations.</li>\n  <li>They empirically validate that when used end-to-end to train GPT-style models, FlashAttention-2 reaches training speed of up to 225 TFLOPs/s per A100 GPU (72% model FLOPs utilization).</li>\n  <li>The following figure from <a href=\"https://www.linkedin.com/in/sebastianraschka/\">Sebastian Raschka</a> summarizes FlashAttention-2:</li>\n</ul>\n<p><img src=\"../../../images/papers/FlashAttention-2.webp\" alt=\"\"></p>",
    "contentMarkdown": "*   Proposed in [FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning](https://tridao.me/publications/flash2/flash2.pdf) by Dao from Princeton and Stanford.\n*   Scaling Transformers to longer sequence lengths has been a major problem in the last several years, promising to improve performance in language modeling and high-resolution image understanding, as well as to unlock new applications in code, audio, and video generation. The attention layer is the main bottleneck in scaling to longer sequences, as its runtime and memory increase quadratically in the sequence length.\n*   [FlashAttention](#flashattention-fast-and-memory-efficient-exact-attention-with-io-awareness) exploits the asymmetric GPU memory hierarchy to bring significant memory saving (linear instead of quadratic) and runtime speedup (2-4x compared to optimized baselines), with no approximation. However, FlashAttention is still not nearly as fast as optimized matrix-multiply (GEMM) operations, reaching only 25-40% of the theoretical maximum FLOPs/s.\n*   They observe that the inefficiency is due to suboptimal work partitioning between different thread blocks and warps on the GPU, causing either low-occupancy or unnecessary shared memory reads/writes.\n*   This paper by Dao from Princeton and Stanford proposes FlashAttention-2, with better work partitioning to address these issues. In particular, they (1) tweak the algorithm to reduce the number of non-matmul FLOPs, (2) parallelize the attention computation, even for a single head, across different thread blocks to increase occupancy, and (3) within each thread block, distribute the work between warps to reduce communication through shared memory. These yield around 2x speedup compared to FlashAttention, reaching 50-73% of the theoretical maximum FLOPs/s on A100 and getting close to the efficiency of GEMM operations.\n*   They empirically validate that when used end-to-end to train GPT-style models, FlashAttention-2 reaches training speed of up to 225 TFLOPs/s per A100 GPU (72% model FLOPs utilization).\n*   The following figure from [Sebastian Raschka](https://www.linkedin.com/in/sebastianraschka/) summarizes FlashAttention-2:\n\n![](../../../images/papers/FlashAttention-2.webp)",
    "contentLength": 2365,
    "wordCount": 291,
    "hasCode": false,
    "hasMath": false,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/model-acceleration/#flashattention-2"
  },
  {
    "id": "ai-model-acceleration-flashattention-3-fast-and-accurate-attention-with--4",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Training Optimizations",
    "title": "FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision",
    "order": 4,
    "orderInChapter": 4,
    "contentHtml": "<ul>\n  <li>Proposed in <a href=\"https://arxiv.org/abs/2407.08608\">FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision</a> by Shah et al. from Colfax Research, Meta, NVIDIA, Georgia Tech, Princeton University, and Together AI.</li>\n  <li>\n    <p>FlashAttention-3 is an optimized attention mechanism for NVIDIA Hopper GPUs (H100), achieving significant speedups and accuracy improvements by exploiting hardware asynchrony and FP8 low-precision capabilities.</p>\n  </li>\n  <li>\n    <p><strong>Key Contributions</strong>:</p>\n\n    <ul>\n      <li><strong>Producer–Consumer Asynchrony</strong>: Implements warp-specialized software pipelining with a circular shared-memory buffer, separating producer warps (data movement via TMA) and consumer warps (Tensor Core GEMMs), hiding memory and instruction latencies.</li>\n      <li><strong>GEMM–Softmax Overlap</strong>: Breaks sequential dependencies to pipeline block-wise <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-6-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>Q</mi><msup><mi>K</mi><mi mathvariant=&quot;normal&quot;>&amp;#x22A4;</mi></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-20\" style=\"width: 2.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1002.09em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-21\"><span class=\"mi\" id=\"MathJax-Span-22\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span class=\"msubsup\" id=\"MathJax-Span-23\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-24\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.784em;\"><span class=\"mi\" id=\"MathJax-Span-25\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⊤</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Q</mi><msup><mi>K</mi><mi mathvariant=\"normal\">⊤</mi></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-6\">QK^\\top</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-7-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-26\" style=\"width: 1.669em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.36em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-27\"><span class=\"mi\" id=\"MathJax-Span-28\" style=\"font-family: STIXGeneral-Italic;\">P</span><span class=\"mi\" id=\"MathJax-Span-29\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-7\">PV</script> GEMMs with softmax, using “pingpong” scheduling across warpgroups and intra-warpgroup 2-stage pipelining to keep Tensor Cores and special function units active simultaneously.</li>\n      <li><strong>FP8 Low-precision Support</strong>: Adapts FlashAttention to FP8 WGMMA layout constraints via in-kernel transpose (using LDSM/STSM) and register permutations, and improves FP8 accuracy with block quantization and incoherent processing using random orthogonal transformations.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Architecture and Implementation</strong>:</p>\n\n    <ul>\n      <li><strong>Input</strong>: Query (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-8-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>Q</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-30\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-31\"><span class=\"mi\" id=\"MathJax-Span-32\" style=\"font-family: STIXGeneral-Italic;\">Q</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Q</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-8\">Q</script>), Key (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-33\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-34\"><span class=\"mi\" id=\"MathJax-Span-35\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-9\">K</script>), Value (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-36\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-37\"><span class=\"mi\" id=\"MathJax-Span-38\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-10\">V</script>) matrices partitioned into tiles; head dimension <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-39\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-40\"><span class=\"mi\" id=\"MathJax-Span-41\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-11\">d</script>, sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>N</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-42\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-43\"><span class=\"mi\" id=\"MathJax-Span-44\" style=\"font-family: STIXGeneral-Italic;\">N<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>N</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">N</script>, query block size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>B</mi><mi>r</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-45\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-46\"><span class=\"msubsup\" id=\"MathJax-Span-47\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-48\" style=\"font-family: STIXGeneral-Italic;\">B</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-49\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>B</mi><mi>r</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">B_r</script>, key block size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-14-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>B</mi><mi>c</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-50\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-51\"><span class=\"msubsup\" id=\"MathJax-Span-52\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-53\" style=\"font-family: STIXGeneral-Italic;\">B</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-54\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>B</mi><mi>c</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-14\">B_c</script>.</li>\n      <li>\n        <p><strong>Forward Pass (FP16)</strong>:</p>\n\n        <ul>\n          <li><strong>Producer warps</strong>: Load <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-15-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>Q</mi><mi>i</mi></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>$</mo></mrow><mo>,</mo><mi>t</mi><mi>h</mi><mi>e</mi><mi>n</mi><mi>s</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>y</mi><mi>l</mi><mi>o</mi><mi>a</mi><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-55\" style=\"width: 12.398em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.315em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1010.32em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-56\"><span class=\"msubsup\" id=\"MathJax-Span-57\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-58\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-59\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"texatom\" id=\"MathJax-Span-60\"><span class=\"mrow\" id=\"MathJax-Span-61\"><span class=\"mo\" id=\"MathJax-Span-62\" style=\"font-family: STIXGeneral-Regular;\">$</span></span></span><span class=\"mo\" id=\"MathJax-Span-63\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-64\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-65\" style=\"font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-66\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-67\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-68\" style=\"font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-69\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-70\" style=\"font-family: STIXGeneral-Italic;\">q</span><span class=\"mi\" id=\"MathJax-Span-71\" style=\"font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-72\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-73\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-74\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-75\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-76\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-77\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-78\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-79\" style=\"font-family: STIXGeneral-Italic;\">y</span><span class=\"mi\" id=\"MathJax-Span-80\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-81\" style=\"font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-82\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-83\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>Q</mi><mi>i</mi></msub><mrow class=\"MJX-TeXAtom-ORD\"><mo>$</mo></mrow><mo>,</mo><mi>t</mi><mi>h</mi><mi>e</mi><mi>n</mi><mi>s</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>y</mi><mi>l</mi><mi>o</mi><mi>a</mi><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-15\">Q_i$, then sequentially load</script>K_j<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-16-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>,</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-84\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.93em, 1000.21em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-85\"><span class=\"mo\" id=\"MathJax-Span-86\" style=\"font-family: STIXGeneral-Regular;\">,</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>,</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-16\">,</script>V_j$$ tiles from HBM to SMEM using TMA, notifying consumers via barriers.</li>\n          <li><strong>Consumer warps</strong>: Perform SS-GEMM (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi mathvariant=&quot;normal&quot;>&amp;#x22A4;</mi></msubsup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-87\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1002.35em, 2.763em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-88\"><span class=\"msubsup\" id=\"MathJax-Span-89\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-90\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-91\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-92\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-93\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -4.372em; left: 0.784em;\"><span class=\"mi\" id=\"MathJax-Span-94\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⊤</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.326em, -999.997em); top: -3.695em; left: 0.68em;\"><span class=\"mi\" id=\"MathJax-Span-95\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.622em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi mathvariant=\"normal\">⊤</mi></msubsup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-17\">Q_iK_j^\\top</script>), row-wise max tracking, local softmax, RS-GEMM ($\\tilde{P}_{ij}V_j$), with scaling for stability, writing <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>O</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-96\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-97\"><span class=\"msubsup\" id=\"MathJax-Span-98\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-99\" style=\"font-family: STIXGeneral-Italic;\">O</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-100\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>O</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-18\">O_i</script> and log-sum-exp values <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>L</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-101\" style=\"width: 1.044em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.84em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-102\"><span class=\"msubsup\" id=\"MathJax-Span-103\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-104\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-105\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>L</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-19\">L_i</script> to HBM.</li>\n          <li><strong>Pipelined version</strong>: Overlaps GEMM from iteration <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-20-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>j</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-106\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-107\"><span class=\"mi\" id=\"MathJax-Span-108\" style=\"font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>j</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-20\">j</script> with softmax from iteration <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>j</mi><mo>+</mo><mn>1</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>$</mo></mrow><mo>,</mo><mi>r</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>i</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>g</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>b</mi><mi>u</mi><mi>f</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo stretchy=&quot;false&quot;>(</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>$</mo></mrow><msub><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>next</mtext></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-109\" style=\"width: 20.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1017.29em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-110\"><span class=\"mi\" id=\"MathJax-Span-111\" style=\"font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-112\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-113\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"texatom\" id=\"MathJax-Span-114\"><span class=\"mrow\" id=\"MathJax-Span-115\"><span class=\"mo\" id=\"MathJax-Span-116\" style=\"font-family: STIXGeneral-Regular;\">$</span></span></span><span class=\"mo\" id=\"MathJax-Span-117\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-118\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-119\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-120\" style=\"font-family: STIXGeneral-Italic;\">q</span><span class=\"mi\" id=\"MathJax-Span-121\" style=\"font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-122\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-123\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-124\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-125\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-126\" style=\"font-family: STIXGeneral-Italic;\">g</span><span class=\"mi\" id=\"MathJax-Span-127\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-128\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-129\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-130\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-131\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-132\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-133\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-134\" style=\"font-family: STIXGeneral-Italic;\">g</span><span class=\"mi\" id=\"MathJax-Span-135\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-136\" style=\"font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-137\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-138\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-139\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-140\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mi\" id=\"MathJax-Span-141\" style=\"font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-142\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-143\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-144\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-145\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-146\" style=\"font-family: STIXGeneral-Italic;\">s</span><span class=\"mo\" id=\"MathJax-Span-147\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"texatom\" id=\"MathJax-Span-148\"><span class=\"mrow\" id=\"MathJax-Span-149\"><span class=\"mo\" id=\"MathJax-Span-150\" style=\"font-family: STIXGeneral-Regular;\">$</span></span></span><span class=\"msubsup\" id=\"MathJax-Span-151\"><span style=\"display: inline-block; position: relative; width: 1.773em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-152\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-153\"><span class=\"mrow\" id=\"MathJax-Span-154\"><span class=\"mtext\" id=\"MathJax-Span-155\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">next</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>j</mi><mo>+</mo><mn>1</mn><mrow class=\"MJX-TeXAtom-ORD\"><mo>$</mo></mrow><mo>,</mo><mi>r</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>i</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>g</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>b</mi><mi>u</mi><mi>f</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mrow class=\"MJX-TeXAtom-ORD\"><mo>$</mo></mrow><msub><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>next</mtext></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">j+1$, requiring extra register buffers ($S_{\\text{next}}</script>).</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>FP8 Mode</strong>:</p>\n\n        <ul>\n          <li><strong>Layout handling</strong>: Ensures k-major operand layout for <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-156\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-157\"><span class=\"mi\" id=\"MathJax-Span-158\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-22\">V</script> in second GEMM by in-kernel transpose; register permutation aligns FP32 accumulators with FP8 operand layout.</li>\n          <li><strong>Quantization</strong>: Block-level scaling (per <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>B</mi><mi>r</mi></msub><mo>&amp;#x00D7;</mo><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-159\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.66em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-160\"><span class=\"msubsup\" id=\"MathJax-Span-161\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-162\" style=\"font-family: STIXGeneral-Italic;\">B</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-163\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-164\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-165\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>B</mi><mi>r</mi></msub><mo>×</mo><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-23\">B_r\\times d</script> or <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>B</mi><mi>c</mi></msub><mo>&amp;#x00D7;</mo><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-166\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.66em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-167\"><span class=\"msubsup\" id=\"MathJax-Span-168\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-169\" style=\"font-family: STIXGeneral-Italic;\">B</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-170\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-171\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-172\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>B</mi><mi>c</mi></msub><mo>×</mo><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">B_c\\times d</script> tile) and incoherent processing (Hadamard + random <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00B1;</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-173\" style=\"width: 1.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.94em, 2.451em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-174\"><span class=\"mo\" id=\"MathJax-Span-175\" style=\"font-family: STIXGeneral-Regular;\">±</span><span class=\"mn\" id=\"MathJax-Span-176\" style=\"font-family: STIXGeneral-Regular;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>±</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">\\pm1</script> diagonal matrices) reduce RMSE for outlier-heavy tensors.</li>\n        </ul>\n      </li>\n      <li>The following figure from the paper shows ping‑pong scheduling for 2 warpgroups to overlap softmax and GEMMs: the softmax of one warpgroup should be scheduled when the GEMMs of another warpgroup are running. The same color denotes the same iteration.</li>\n    </ul>\n\n    <p><img src=\"../../../images/papers/FlashAttention‑3_1.jpg\" alt=\"\"></p>\n\n    <ul>\n      <li>The following figure from the paper shows 2-stage WGMMA-softmax pipelining.</li>\n    </ul>\n\n    <p><img src=\"../../../images/papers/FlashAttention‑3_2.jpg\" alt=\"\"></p>\n  </li>\n  <li>\n    <p><strong>Benchmarks</strong>:</p>\n\n    <ul>\n      <li>On H100 SXM5, <strong>FP16</strong> forward pass reaches up to 740 TFLOPs/s (75% utilization), 1.5–2.0× faster than FlashAttention-2, and 3–16× faster than standard attention; backward pass sees 1.5–1.75× speedup.</li>\n      <li><strong>FP8</strong> forward pass approaches 1.2 PFLOPs/s, outperforming cuDNN for some head dimensions and sequence lengths.</li>\n      <li><strong>Accuracy</strong>: FP16 matches FlashAttention-2 error (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-26-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x2248;</mo><mn>1.9</mn><mo>&amp;#x00D7;</mo><msup><mn>10</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2212;</mo><mn>4</mn></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-177\" style=\"width: 6.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.159em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1005.16em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-178\"><span class=\"mo\" id=\"MathJax-Span-179\" style=\"font-family: STIXGeneral-Regular;\">≈</span><span class=\"mn\" id=\"MathJax-Span-180\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1.9</span><span class=\"mo\" id=\"MathJax-Span-181\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-182\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.93em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.99em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-183\" style=\"font-family: STIXGeneral-Regular;\">10</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.992em;\"><span class=\"texatom\" id=\"MathJax-Span-184\"><span class=\"mrow\" id=\"MathJax-Span-185\"><span class=\"mo\" id=\"MathJax-Span-186\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-187\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">4</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>≈</mo><mn>1.9</mn><mo>×</mo><msup><mn>10</mn><mrow class=\"MJX-TeXAtom-ORD\"><mo>−</mo><mn>4</mn></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-26\">\\approx 1.9\\times 10^{-4}</script> RMSE), both outperforming standard FP16 attention; FP8 with both block quantization and incoherent processing achieves 2.6× lower RMSE than baseline FP8 per-tensor scaling.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Ablation Studies</strong>:</p>\n\n    <ul>\n      <li>Removing GEMM–softmax pipelining or warp specialization reduces throughput from 661 TFLOPs/s to ~570–582 TFLOPs/s.</li>\n      <li>Both optimizations contribute substantially to the performance gains.</li>\n    </ul>\n  </li>\n  <li><a href=\"https://github.com/Dao-AILab/flash-attention\">Code</a></li>\n</ul>\n<p>FlashAttention-3 is an optimized attention mechanism for NVIDIA Hopper GPUs (H100), achieving significant speedups and accuracy improvements by exploiting hardware asynchrony and FP8 low-precision capabilities.</p>\n<p><strong>Key Contributions</strong>:</p>\n<ul>\n      <li><strong>Producer–Consumer Asynchrony</strong>: Implements warp-specialized software pipelining with a circular shared-memory buffer, separating producer warps (data movement via TMA) and consumer warps (Tensor Core GEMMs), hiding memory and instruction latencies.</li>\n      <li><strong>GEMM–Softmax Overlap</strong>: Breaks sequential dependencies to pipeline block-wise <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-6-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>Q</mi><msup><mi>K</mi><mi mathvariant=&quot;normal&quot;>&amp;#x22A4;</mi></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-20\" style=\"width: 2.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1002.09em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-21\"><span class=\"mi\" id=\"MathJax-Span-22\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span class=\"msubsup\" id=\"MathJax-Span-23\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-24\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.784em;\"><span class=\"mi\" id=\"MathJax-Span-25\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⊤</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Q</mi><msup><mi>K</mi><mi mathvariant=\"normal\">⊤</mi></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-6\">QK^\\top</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-7-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-26\" style=\"width: 1.669em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.36em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-27\"><span class=\"mi\" id=\"MathJax-Span-28\" style=\"font-family: STIXGeneral-Italic;\">P</span><span class=\"mi\" id=\"MathJax-Span-29\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-7\">PV</script> GEMMs with softmax, using “pingpong” scheduling across warpgroups and intra-warpgroup 2-stage pipelining to keep Tensor Cores and special function units active simultaneously.</li>\n      <li><strong>FP8 Low-precision Support</strong>: Adapts FlashAttention to FP8 WGMMA layout constraints via in-kernel transpose (using LDSM/STSM) and register permutations, and improves FP8 accuracy with block quantization and incoherent processing using random orthogonal transformations.</li>\n    </ul>\n<p><strong>Architecture and Implementation</strong>:</p>\n<ul>\n      <li><strong>Input</strong>: Query (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-8-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>Q</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-30\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-31\"><span class=\"mi\" id=\"MathJax-Span-32\" style=\"font-family: STIXGeneral-Italic;\">Q</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Q</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-8\">Q</script>), Key (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-33\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-34\"><span class=\"mi\" id=\"MathJax-Span-35\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-9\">K</script>), Value (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-36\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-37\"><span class=\"mi\" id=\"MathJax-Span-38\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-10\">V</script>) matrices partitioned into tiles; head dimension <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-39\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-40\"><span class=\"mi\" id=\"MathJax-Span-41\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-11\">d</script>, sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>N</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-42\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-43\"><span class=\"mi\" id=\"MathJax-Span-44\" style=\"font-family: STIXGeneral-Italic;\">N<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>N</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">N</script>, query block size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>B</mi><mi>r</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-45\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-46\"><span class=\"msubsup\" id=\"MathJax-Span-47\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-48\" style=\"font-family: STIXGeneral-Italic;\">B</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-49\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>B</mi><mi>r</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">B_r</script>, key block size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-14-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>B</mi><mi>c</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-50\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-51\"><span class=\"msubsup\" id=\"MathJax-Span-52\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-53\" style=\"font-family: STIXGeneral-Italic;\">B</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-54\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>B</mi><mi>c</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-14\">B_c</script>.</li>\n      <li>\n        <p><strong>Forward Pass (FP16)</strong>:</p>\n\n        <ul>\n          <li><strong>Producer warps</strong>: Load <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-15-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>Q</mi><mi>i</mi></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>$</mo></mrow><mo>,</mo><mi>t</mi><mi>h</mi><mi>e</mi><mi>n</mi><mi>s</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>y</mi><mi>l</mi><mi>o</mi><mi>a</mi><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-55\" style=\"width: 12.398em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.315em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1010.32em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-56\"><span class=\"msubsup\" id=\"MathJax-Span-57\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-58\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-59\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"texatom\" id=\"MathJax-Span-60\"><span class=\"mrow\" id=\"MathJax-Span-61\"><span class=\"mo\" id=\"MathJax-Span-62\" style=\"font-family: STIXGeneral-Regular;\">$</span></span></span><span class=\"mo\" id=\"MathJax-Span-63\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-64\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-65\" style=\"font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-66\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-67\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-68\" style=\"font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-69\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-70\" style=\"font-family: STIXGeneral-Italic;\">q</span><span class=\"mi\" id=\"MathJax-Span-71\" style=\"font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-72\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-73\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-74\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-75\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-76\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-77\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-78\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-79\" style=\"font-family: STIXGeneral-Italic;\">y</span><span class=\"mi\" id=\"MathJax-Span-80\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-81\" style=\"font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-82\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-83\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>Q</mi><mi>i</mi></msub><mrow class=\"MJX-TeXAtom-ORD\"><mo>$</mo></mrow><mo>,</mo><mi>t</mi><mi>h</mi><mi>e</mi><mi>n</mi><mi>s</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>y</mi><mi>l</mi><mi>o</mi><mi>a</mi><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-15\">Q_i$, then sequentially load</script>K_j<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-16-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>,</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-84\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.93em, 1000.21em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-85\"><span class=\"mo\" id=\"MathJax-Span-86\" style=\"font-family: STIXGeneral-Regular;\">,</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>,</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-16\">,</script>V_j$$ tiles from HBM to SMEM using TMA, notifying consumers via barriers.</li>\n          <li><strong>Consumer warps</strong>: Perform SS-GEMM (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi mathvariant=&quot;normal&quot;>&amp;#x22A4;</mi></msubsup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-87\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1002.35em, 2.763em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-88\"><span class=\"msubsup\" id=\"MathJax-Span-89\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-90\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-91\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-92\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-93\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -4.372em; left: 0.784em;\"><span class=\"mi\" id=\"MathJax-Span-94\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⊤</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.326em, -999.997em); top: -3.695em; left: 0.68em;\"><span class=\"mi\" id=\"MathJax-Span-95\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.622em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi mathvariant=\"normal\">⊤</mi></msubsup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-17\">Q_iK_j^\\top</script>), row-wise max tracking, local softmax, RS-GEMM ($\\tilde{P}_{ij}V_j$), with scaling for stability, writing <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>O</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-96\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-97\"><span class=\"msubsup\" id=\"MathJax-Span-98\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-99\" style=\"font-family: STIXGeneral-Italic;\">O</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-100\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>O</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-18\">O_i</script> and log-sum-exp values <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>L</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-101\" style=\"width: 1.044em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.84em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-102\"><span class=\"msubsup\" id=\"MathJax-Span-103\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-104\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-105\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>L</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-19\">L_i</script> to HBM.</li>\n          <li><strong>Pipelined version</strong>: Overlaps GEMM from iteration <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-20-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>j</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-106\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-107\"><span class=\"mi\" id=\"MathJax-Span-108\" style=\"font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>j</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-20\">j</script> with softmax from iteration <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>j</mi><mo>+</mo><mn>1</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>$</mo></mrow><mo>,</mo><mi>r</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>i</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>g</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>b</mi><mi>u</mi><mi>f</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo stretchy=&quot;false&quot;>(</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>$</mo></mrow><msub><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>next</mtext></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-109\" style=\"width: 20.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1017.29em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-110\"><span class=\"mi\" id=\"MathJax-Span-111\" style=\"font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-112\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-113\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"texatom\" id=\"MathJax-Span-114\"><span class=\"mrow\" id=\"MathJax-Span-115\"><span class=\"mo\" id=\"MathJax-Span-116\" style=\"font-family: STIXGeneral-Regular;\">$</span></span></span><span class=\"mo\" id=\"MathJax-Span-117\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-118\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-119\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-120\" style=\"font-family: STIXGeneral-Italic;\">q</span><span class=\"mi\" id=\"MathJax-Span-121\" style=\"font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-122\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-123\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-124\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-125\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-126\" style=\"font-family: STIXGeneral-Italic;\">g</span><span class=\"mi\" id=\"MathJax-Span-127\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-128\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-129\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-130\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-131\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-132\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-133\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-134\" style=\"font-family: STIXGeneral-Italic;\">g</span><span class=\"mi\" id=\"MathJax-Span-135\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-136\" style=\"font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-137\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-138\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-139\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-140\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mi\" id=\"MathJax-Span-141\" style=\"font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-142\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-143\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-144\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-145\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-146\" style=\"font-family: STIXGeneral-Italic;\">s</span><span class=\"mo\" id=\"MathJax-Span-147\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"texatom\" id=\"MathJax-Span-148\"><span class=\"mrow\" id=\"MathJax-Span-149\"><span class=\"mo\" id=\"MathJax-Span-150\" style=\"font-family: STIXGeneral-Regular;\">$</span></span></span><span class=\"msubsup\" id=\"MathJax-Span-151\"><span style=\"display: inline-block; position: relative; width: 1.773em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-152\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-153\"><span class=\"mrow\" id=\"MathJax-Span-154\"><span class=\"mtext\" id=\"MathJax-Span-155\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">next</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>j</mi><mo>+</mo><mn>1</mn><mrow class=\"MJX-TeXAtom-ORD\"><mo>$</mo></mrow><mo>,</mo><mi>r</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>i</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>g</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>b</mi><mi>u</mi><mi>f</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mrow class=\"MJX-TeXAtom-ORD\"><mo>$</mo></mrow><msub><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>next</mtext></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">j+1$, requiring extra register buffers ($S_{\\text{next}}</script>).</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>FP8 Mode</strong>:</p>\n\n        <ul>\n          <li><strong>Layout handling</strong>: Ensures k-major operand layout for <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-156\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-157\"><span class=\"mi\" id=\"MathJax-Span-158\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-22\">V</script> in second GEMM by in-kernel transpose; register permutation aligns FP32 accumulators with FP8 operand layout.</li>\n          <li><strong>Quantization</strong>: Block-level scaling (per <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>B</mi><mi>r</mi></msub><mo>&amp;#x00D7;</mo><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-159\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.66em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-160\"><span class=\"msubsup\" id=\"MathJax-Span-161\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-162\" style=\"font-family: STIXGeneral-Italic;\">B</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-163\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-164\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-165\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>B</mi><mi>r</mi></msub><mo>×</mo><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-23\">B_r\\times d</script> or <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>B</mi><mi>c</mi></msub><mo>&amp;#x00D7;</mo><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-166\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.66em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-167\"><span class=\"msubsup\" id=\"MathJax-Span-168\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-169\" style=\"font-family: STIXGeneral-Italic;\">B</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-170\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-171\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-172\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>B</mi><mi>c</mi></msub><mo>×</mo><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">B_c\\times d</script> tile) and incoherent processing (Hadamard + random <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00B1;</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-173\" style=\"width: 1.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.94em, 2.451em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-174\"><span class=\"mo\" id=\"MathJax-Span-175\" style=\"font-family: STIXGeneral-Regular;\">±</span><span class=\"mn\" id=\"MathJax-Span-176\" style=\"font-family: STIXGeneral-Regular;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>±</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">\\pm1</script> diagonal matrices) reduce RMSE for outlier-heavy tensors.</li>\n        </ul>\n      </li>\n      <li>The following figure from the paper shows ping‑pong scheduling for 2 warpgroups to overlap softmax and GEMMs: the softmax of one warpgroup should be scheduled when the GEMMs of another warpgroup are running. The same color denotes the same iteration.</li>\n    </ul>\n<p><strong>Forward Pass (FP16)</strong>:</p>\n<ul>\n          <li><strong>Producer warps</strong>: Load <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-15-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>Q</mi><mi>i</mi></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>$</mo></mrow><mo>,</mo><mi>t</mi><mi>h</mi><mi>e</mi><mi>n</mi><mi>s</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>y</mi><mi>l</mi><mi>o</mi><mi>a</mi><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-55\" style=\"width: 12.398em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.315em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1010.32em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-56\"><span class=\"msubsup\" id=\"MathJax-Span-57\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-58\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-59\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"texatom\" id=\"MathJax-Span-60\"><span class=\"mrow\" id=\"MathJax-Span-61\"><span class=\"mo\" id=\"MathJax-Span-62\" style=\"font-family: STIXGeneral-Regular;\">$</span></span></span><span class=\"mo\" id=\"MathJax-Span-63\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-64\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-65\" style=\"font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-66\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-67\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-68\" style=\"font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-69\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-70\" style=\"font-family: STIXGeneral-Italic;\">q</span><span class=\"mi\" id=\"MathJax-Span-71\" style=\"font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-72\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-73\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-74\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-75\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-76\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-77\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-78\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-79\" style=\"font-family: STIXGeneral-Italic;\">y</span><span class=\"mi\" id=\"MathJax-Span-80\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-81\" style=\"font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-82\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-83\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>Q</mi><mi>i</mi></msub><mrow class=\"MJX-TeXAtom-ORD\"><mo>$</mo></mrow><mo>,</mo><mi>t</mi><mi>h</mi><mi>e</mi><mi>n</mi><mi>s</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>a</mi><mi>l</mi><mi>l</mi><mi>y</mi><mi>l</mi><mi>o</mi><mi>a</mi><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-15\">Q_i$, then sequentially load</script>K_j<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-16-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>,</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-84\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.93em, 1000.21em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-85\"><span class=\"mo\" id=\"MathJax-Span-86\" style=\"font-family: STIXGeneral-Regular;\">,</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>,</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-16\">,</script>V_j$$ tiles from HBM to SMEM using TMA, notifying consumers via barriers.</li>\n          <li><strong>Consumer warps</strong>: Perform SS-GEMM (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi mathvariant=&quot;normal&quot;>&amp;#x22A4;</mi></msubsup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-87\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1002.35em, 2.763em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-88\"><span class=\"msubsup\" id=\"MathJax-Span-89\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-90\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-91\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-92\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-93\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -4.372em; left: 0.784em;\"><span class=\"mi\" id=\"MathJax-Span-94\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⊤</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.326em, -999.997em); top: -3.695em; left: 0.68em;\"><span class=\"mi\" id=\"MathJax-Span-95\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.622em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi mathvariant=\"normal\">⊤</mi></msubsup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-17\">Q_iK_j^\\top</script>), row-wise max tracking, local softmax, RS-GEMM ($\\tilde{P}_{ij}V_j$), with scaling for stability, writing <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>O</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-96\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-97\"><span class=\"msubsup\" id=\"MathJax-Span-98\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-99\" style=\"font-family: STIXGeneral-Italic;\">O</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-100\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>O</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-18\">O_i</script> and log-sum-exp values <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>L</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-101\" style=\"width: 1.044em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.84em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-102\"><span class=\"msubsup\" id=\"MathJax-Span-103\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-104\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-105\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>L</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-19\">L_i</script> to HBM.</li>\n          <li><strong>Pipelined version</strong>: Overlaps GEMM from iteration <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-20-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>j</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-106\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-107\"><span class=\"mi\" id=\"MathJax-Span-108\" style=\"font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>j</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-20\">j</script> with softmax from iteration <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>j</mi><mo>+</mo><mn>1</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>$</mo></mrow><mo>,</mo><mi>r</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>i</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>g</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>b</mi><mi>u</mi><mi>f</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo stretchy=&quot;false&quot;>(</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>$</mo></mrow><msub><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>next</mtext></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-109\" style=\"width: 20.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1017.29em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-110\"><span class=\"mi\" id=\"MathJax-Span-111\" style=\"font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-112\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-113\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"texatom\" id=\"MathJax-Span-114\"><span class=\"mrow\" id=\"MathJax-Span-115\"><span class=\"mo\" id=\"MathJax-Span-116\" style=\"font-family: STIXGeneral-Regular;\">$</span></span></span><span class=\"mo\" id=\"MathJax-Span-117\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-118\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-119\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-120\" style=\"font-family: STIXGeneral-Italic;\">q</span><span class=\"mi\" id=\"MathJax-Span-121\" style=\"font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-122\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-123\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-124\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-125\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-126\" style=\"font-family: STIXGeneral-Italic;\">g</span><span class=\"mi\" id=\"MathJax-Span-127\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-128\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-129\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-130\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-131\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-132\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-133\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-134\" style=\"font-family: STIXGeneral-Italic;\">g</span><span class=\"mi\" id=\"MathJax-Span-135\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-136\" style=\"font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-137\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-138\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-139\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-140\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mi\" id=\"MathJax-Span-141\" style=\"font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-142\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-143\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-144\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-145\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-146\" style=\"font-family: STIXGeneral-Italic;\">s</span><span class=\"mo\" id=\"MathJax-Span-147\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"texatom\" id=\"MathJax-Span-148\"><span class=\"mrow\" id=\"MathJax-Span-149\"><span class=\"mo\" id=\"MathJax-Span-150\" style=\"font-family: STIXGeneral-Regular;\">$</span></span></span><span class=\"msubsup\" id=\"MathJax-Span-151\"><span style=\"display: inline-block; position: relative; width: 1.773em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-152\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-153\"><span class=\"mrow\" id=\"MathJax-Span-154\"><span class=\"mtext\" id=\"MathJax-Span-155\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">next</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>j</mi><mo>+</mo><mn>1</mn><mrow class=\"MJX-TeXAtom-ORD\"><mo>$</mo></mrow><mo>,</mo><mi>r</mi><mi>e</mi><mi>q</mi><mi>u</mi><mi>i</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>e</mi><mi>x</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>g</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>b</mi><mi>u</mi><mi>f</mi><mi>f</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mrow class=\"MJX-TeXAtom-ORD\"><mo>$</mo></mrow><msub><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>next</mtext></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">j+1$, requiring extra register buffers ($S_{\\text{next}}</script>).</li>\n        </ul>\n<p><strong>FP8 Mode</strong>:</p>\n<ul>\n          <li><strong>Layout handling</strong>: Ensures k-major operand layout for <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-156\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-157\"><span class=\"mi\" id=\"MathJax-Span-158\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-22\">V</script> in second GEMM by in-kernel transpose; register permutation aligns FP32 accumulators with FP8 operand layout.</li>\n          <li><strong>Quantization</strong>: Block-level scaling (per <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>B</mi><mi>r</mi></msub><mo>&amp;#x00D7;</mo><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-159\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.66em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-160\"><span class=\"msubsup\" id=\"MathJax-Span-161\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-162\" style=\"font-family: STIXGeneral-Italic;\">B</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-163\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-164\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-165\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>B</mi><mi>r</mi></msub><mo>×</mo><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-23\">B_r\\times d</script> or <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>B</mi><mi>c</mi></msub><mo>&amp;#x00D7;</mo><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-166\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.66em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-167\"><span class=\"msubsup\" id=\"MathJax-Span-168\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-169\" style=\"font-family: STIXGeneral-Italic;\">B</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-170\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-171\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-172\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>B</mi><mi>c</mi></msub><mo>×</mo><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">B_c\\times d</script> tile) and incoherent processing (Hadamard + random <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00B1;</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-173\" style=\"width: 1.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.94em, 2.451em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-174\"><span class=\"mo\" id=\"MathJax-Span-175\" style=\"font-family: STIXGeneral-Regular;\">±</span><span class=\"mn\" id=\"MathJax-Span-176\" style=\"font-family: STIXGeneral-Regular;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>±</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">\\pm1</script> diagonal matrices) reduce RMSE for outlier-heavy tensors.</li>\n        </ul>\n<p><img src=\"../../../images/papers/FlashAttention‑3_1.jpg\" alt=\"\"></p>\n<ul>\n      <li>The following figure from the paper shows 2-stage WGMMA-softmax pipelining.</li>\n    </ul>\n<p><img src=\"../../../images/papers/FlashAttention‑3_2.jpg\" alt=\"\"></p>\n<p><strong>Benchmarks</strong>:</p>\n<ul>\n      <li>On H100 SXM5, <strong>FP16</strong> forward pass reaches up to 740 TFLOPs/s (75% utilization), 1.5–2.0× faster than FlashAttention-2, and 3–16× faster than standard attention; backward pass sees 1.5–1.75× speedup.</li>\n      <li><strong>FP8</strong> forward pass approaches 1.2 PFLOPs/s, outperforming cuDNN for some head dimensions and sequence lengths.</li>\n      <li><strong>Accuracy</strong>: FP16 matches FlashAttention-2 error (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-26-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x2248;</mo><mn>1.9</mn><mo>&amp;#x00D7;</mo><msup><mn>10</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2212;</mo><mn>4</mn></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-177\" style=\"width: 6.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.159em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1005.16em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-178\"><span class=\"mo\" id=\"MathJax-Span-179\" style=\"font-family: STIXGeneral-Regular;\">≈</span><span class=\"mn\" id=\"MathJax-Span-180\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1.9</span><span class=\"mo\" id=\"MathJax-Span-181\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-182\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.93em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.99em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-183\" style=\"font-family: STIXGeneral-Regular;\">10</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.992em;\"><span class=\"texatom\" id=\"MathJax-Span-184\"><span class=\"mrow\" id=\"MathJax-Span-185\"><span class=\"mo\" id=\"MathJax-Span-186\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-187\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">4</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>≈</mo><mn>1.9</mn><mo>×</mo><msup><mn>10</mn><mrow class=\"MJX-TeXAtom-ORD\"><mo>−</mo><mn>4</mn></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-26\">\\approx 1.9\\times 10^{-4}</script> RMSE), both outperforming standard FP16 attention; FP8 with both block quantization and incoherent processing achieves 2.6× lower RMSE than baseline FP8 per-tensor scaling.</li>\n    </ul>\n<p><strong>Ablation Studies</strong>:</p>\n<ul>\n      <li>Removing GEMM–softmax pipelining or warp specialization reduces throughput from 661 TFLOPs/s to ~570–582 TFLOPs/s.</li>\n      <li>Both optimizations contribute substantially to the performance gains.</li>\n    </ul>",
    "contentMarkdown": "*   Proposed in [FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision](https://arxiv.org/abs/2407.08608) by Shah et al. from Colfax Research, Meta, NVIDIA, Georgia Tech, Princeton University, and Together AI.\n*   FlashAttention-3 is an optimized attention mechanism for NVIDIA Hopper GPUs (H100), achieving significant speedups and accuracy improvements by exploiting hardware asynchrony and FP8 low-precision capabilities.\n    \n*   **Key Contributions**:\n    \n    *   **Producer–Consumer Asynchrony**: Implements warp-specialized software pipelining with a circular shared-memory buffer, separating producer warps (data movement via TMA) and consumer warps (Tensor Core GEMMs), hiding memory and instruction latencies.\n    *   **GEMM–Softmax Overlap**: Breaks sequential dependencies to pipeline block-wise QK⊤QK⊤QK^\\\\top and PVPVPV GEMMs with softmax, using “pingpong” scheduling across warpgroups and intra-warpgroup 2-stage pipelining to keep Tensor Cores and special function units active simultaneously.\n    *   **FP8 Low-precision Support**: Adapts FlashAttention to FP8 WGMMA layout constraints via in-kernel transpose (using LDSM/STSM) and register permutations, and improves FP8 accuracy with block quantization and incoherent processing using random orthogonal transformations.\n*   **Architecture and Implementation**:\n    \n    *   **Input**: Query (QQQ), Key (KKK), Value (VVV) matrices partitioned into tiles; head dimension ddd, sequence length NNN, query block size BrBrB\\_r, key block size BcBcB\\_c.\n    *   **Forward Pass (FP16)**:\n        \n        *   **Producer warps**: Load Qi$,thensequentiallyloadQi$,thensequentiallyloadQ\\_i$, then sequentially loadK\\_j,,,V\\_j$$ tiles from HBM to SMEM using TMA, notifying consumers via barriers.\n        *   **Consumer warps**: Perform SS-GEMM (QiK⊤jQiKj⊤Q\\_iK\\_j^\\\\top), row-wise max tracking, local softmax, RS-GEMM ($\\\\tilde{P}\\_{ij}V\\_j$), with scaling for stability, writing OiOiO\\_i and log-sum-exp values LiLiL\\_i to HBM.\n        *   **Pipelined version**: Overlaps GEMM from iteration jjj with softmax from iteration j+1$,requiringextraregisterbuffers($Snextj+1$,requiringextraregisterbuffers($Snextj+1$, requiring extra register buffers ($S\\_{\\\\text{next}}).\n    *   **FP8 Mode**:\n        \n        *   **Layout handling**: Ensures k-major operand layout for VVV in second GEMM by in-kernel transpose; register permutation aligns FP32 accumulators with FP8 operand layout.\n        *   **Quantization**: Block-level scaling (per Br×dBr×dB\\_r\\\\times d or Bc×dBc×dB\\_c\\\\times d tile) and incoherent processing (Hadamard + random ±1±1\\\\pm1 diagonal matrices) reduce RMSE for outlier-heavy tensors.\n    *   The following figure from the paper shows ping‑pong scheduling for 2 warpgroups to overlap softmax and GEMMs: the softmax of one warpgroup should be scheduled when the GEMMs of another warpgroup are running. The same color denotes the same iteration.\n    \n    ![](../../../images/papers/FlashAttention‑3_1.jpg)\n    \n    *   The following figure from the paper shows 2-stage WGMMA-softmax pipelining.\n    \n    ![](../../../images/papers/FlashAttention‑3_2.jpg)\n    \n*   **Benchmarks**:\n    \n    *   On H100 SXM5, **FP16** forward pass reaches up to 740 TFLOPs/s (75% utilization), 1.5–2.0× faster than FlashAttention-2, and 3–16× faster than standard attention; backward pass sees 1.5–1.75× speedup.\n    *   **FP8** forward pass approaches 1.2 PFLOPs/s, outperforming cuDNN for some head dimensions and sequence lengths.\n    *   **Accuracy**: FP16 matches FlashAttention-2 error (≈1.9×10−4≈1.9×10−4\\\\approx 1.9\\\\times 10^{-4} RMSE), both outperforming standard FP16 attention; FP8 with both block quantization and incoherent processing achieves 2.6× lower RMSE than baseline FP8 per-tensor scaling.\n*   **Ablation Studies**:\n    \n    *   Removing GEMM–softmax pipelining or warp specialization reduces throughput from 661 TFLOPs/s to ~570–582 TFLOPs/s.\n    *   Both optimizations contribute substantially to the performance gains.\n*   [Code](https://github.com/Dao-AILab/flash-attention)\n\nFlashAttention-3 is an optimized attention mechanism for NVIDIA Hopper GPUs (H100), achieving significant speedups and accuracy improvements by exploiting hardware asynchrony and FP8 low-precision capabilities.\n\n**Key Contributions**:\n\n*   **Producer–Consumer Asynchrony**: Implements warp-specialized software pipelining with a circular shared-memory buffer, separating producer warps (data movement via TMA) and consumer warps (Tensor Core GEMMs), hiding memory and instruction latencies.\n*   **GEMM–Softmax Overlap**: Breaks sequential dependencies to pipeline block-wise QK⊤QK⊤QK^\\\\top and PVPVPV GEMMs with softmax, using “pingpong” scheduling across warpgroups and intra-warpgroup 2-stage pipelining to keep Tensor Cores and special function units active simultaneously.\n*   **FP8 Low-precision Support**: Adapts FlashAttention to FP8 WGMMA layout constraints via in-kernel transpose (using LDSM/STSM) and register permutations, and improves FP8 accuracy with block quantization and incoherent processing using random orthogonal transformations.\n\n**Architecture and Implementation**:\n\n*   **Input**: Query (QQQ), Key (KKK), Value (VVV) matrices partitioned into tiles; head dimension ddd, sequence length NNN, query block size BrBrB\\_r, key block size BcBcB\\_c.\n*   **Forward Pass (FP16)**:\n    \n    *   **Producer warps**: Load Qi$,thensequentiallyloadQi$,thensequentiallyloadQ\\_i$, then sequentially loadK\\_j,,,V\\_j$$ tiles from HBM to SMEM using TMA, notifying consumers via barriers.\n    *   **Consumer warps**: Perform SS-GEMM (QiK⊤jQiKj⊤Q\\_iK\\_j^\\\\top), row-wise max tracking, local softmax, RS-GEMM ($\\\\tilde{P}\\_{ij}V\\_j$), with scaling for stability, writing OiOiO\\_i and log-sum-exp values LiLiL\\_i to HBM.\n    *   **Pipelined version**: Overlaps GEMM from iteration jjj with softmax from iteration j+1$,requiringextraregisterbuffers($Snextj+1$,requiringextraregisterbuffers($Snextj+1$, requiring extra register buffers ($S\\_{\\\\text{next}}).\n*   **FP8 Mode**:\n    \n    *   **Layout handling**: Ensures k-major operand layout for VVV in second GEMM by in-kernel transpose; register permutation aligns FP32 accumulators with FP8 operand layout.\n    *   **Quantization**: Block-level scaling (per Br×dBr×dB\\_r\\\\times d or Bc×dBc×dB\\_c\\\\times d tile) and incoherent processing (Hadamard + random ±1±1\\\\pm1 diagonal matrices) reduce RMSE for outlier-heavy tensors.\n*   The following figure from the paper shows ping‑pong scheduling for 2 warpgroups to overlap softmax and GEMMs: the softmax of one warpgroup should be scheduled when the GEMMs of another warpgroup are running. The same color denotes the same iteration.\n\n**Forward Pass (FP16)**:\n\n*   **Producer warps**: Load Qi$,thensequentiallyloadQi$,thensequentiallyloadQ\\_i$, then sequentially loadK\\_j,,,V\\_j$$ tiles from HBM to SMEM using TMA, notifying consumers via barriers.\n*   **Consumer warps**: Perform SS-GEMM (QiK⊤jQiKj⊤Q\\_iK\\_j^\\\\top), row-wise max tracking, local softmax, RS-GEMM ($\\\\tilde{P}\\_{ij}V\\_j$), with scaling for stability, writing OiOiO\\_i and log-sum-exp values LiLiL\\_i to HBM.\n*   **Pipelined version**: Overlaps GEMM from iteration jjj with softmax from iteration j+1$,requiringextraregisterbuffers($Snextj+1$,requiringextraregisterbuffers($Snextj+1$, requiring extra register buffers ($S\\_{\\\\text{next}}).\n\n**FP8 Mode**:\n\n*   **Layout handling**: Ensures k-major operand layout for VVV in second GEMM by in-kernel transpose; register permutation aligns FP32 accumulators with FP8 operand layout.\n*   **Quantization**: Block-level scaling (per Br×dBr×dB\\_r\\\\times d or Bc×dBc×dB\\_c\\\\times d tile) and incoherent processing (Hadamard + random ±1±1\\\\pm1 diagonal matrices) reduce RMSE for outlier-heavy tensors.\n\n![](../../../images/papers/FlashAttention‑3_1.jpg)\n\n*   The following figure from the paper shows 2-stage WGMMA-softmax pipelining.\n\n![](../../../images/papers/FlashAttention‑3_2.jpg)\n\n**Benchmarks**:\n\n*   On H100 SXM5, **FP16** forward pass reaches up to 740 TFLOPs/s (75% utilization), 1.5–2.0× faster than FlashAttention-2, and 3–16× faster than standard attention; backward pass sees 1.5–1.75× speedup.\n*   **FP8** forward pass approaches 1.2 PFLOPs/s, outperforming cuDNN for some head dimensions and sequence lengths.\n*   **Accuracy**: FP16 matches FlashAttention-2 error (≈1.9×10−4≈1.9×10−4\\\\approx 1.9\\\\times 10^{-4} RMSE), both outperforming standard FP16 attention; FP8 with both block quantization and incoherent processing achieves 2.6× lower RMSE than baseline FP8 per-tensor scaling.\n\n**Ablation Studies**:\n\n*   Removing GEMM–softmax pipelining or warp specialization reduces throughput from 661 TFLOPs/s to ~570–582 TFLOPs/s.\n*   Both optimizations contribute substantially to the performance gains.",
    "contentLength": 128054,
    "wordCount": 1009,
    "hasCode": false,
    "hasMath": true,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/model-acceleration/#flashattention-3:-fast-and-accurate-attention-with-asynchrony-and-low-precision"
  },
  {
    "id": "ai-model-acceleration-multi-query-attention-mqa-5",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Training Optimizations",
    "title": "Multi-Query Attention (MQA)",
    "order": 5,
    "orderInChapter": 5,
    "contentHtml": "<ul>\n  <li>Proposed in <a href=\"https://arxiv.org/abs/1911.02150\">Fast Transformer Decoding: One Write-Head is All You Need</a>.</li>\n  <li>Multi-head attention layers, as used in the Transformer neural sequence model, are a powerful alternative to RNNs for moving information across and between sequences. While training these layers is\ngenerally fast and simple, due to parallelizability across the length of the sequence, incremental inference (where such paralleization is impossible) is often slow, due to the memory-bandwidth cost of repeatedly\nloading the large “keys” and “values” tensors.</li>\n  <li>This paper by Shazeer from Google in 2019 proposes a variant called Multi-Query Attention (MQA), where the keys and values are shared across all of the different attention “heads”, greatly reducing the size of these tensors and hence the memory bandwidth requirements of incremental decoding.</li>\n  <li>They verify experimentally that the resulting models can indeed be much faster to decode, and incur only minor quality degradation from the baseline.</li>\n  <li>A detailed discourse on this topic is available in our <a href=\"../attention\">Attention</a> primer.</li>\n</ul>",
    "contentMarkdown": "*   Proposed in [Fast Transformer Decoding: One Write-Head is All You Need](https://arxiv.org/abs/1911.02150).\n*   Multi-head attention layers, as used in the Transformer neural sequence model, are a powerful alternative to RNNs for moving information across and between sequences. While training these layers is generally fast and simple, due to parallelizability across the length of the sequence, incremental inference (where such paralleization is impossible) is often slow, due to the memory-bandwidth cost of repeatedly loading the large “keys” and “values” tensors.\n*   This paper by Shazeer from Google in 2019 proposes a variant called Multi-Query Attention (MQA), where the keys and values are shared across all of the different attention “heads”, greatly reducing the size of these tensors and hence the memory bandwidth requirements of incremental decoding.\n*   They verify experimentally that the resulting models can indeed be much faster to decode, and incur only minor quality degradation from the baseline.\n*   A detailed discourse on this topic is available in our [Attention](../attention) primer.",
    "contentLength": 1184,
    "wordCount": 162,
    "hasCode": false,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/model-acceleration/#multi-query-attention-(mqa)"
  },
  {
    "id": "ai-model-acceleration-grouped-query-attention-gqa-6",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Training Optimizations",
    "title": "Grouped-Query Attention (GQA)",
    "order": 6,
    "orderInChapter": 6,
    "contentHtml": "<ul>\n  <li>Proposed in<a href=\"https://arxiv.org/abs/2305.13245\">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints</a>.</li>\n  <li>MQA, which only uses a single key-value head, drastically speeds up decoder inference. However, MQA can lead to quality degradation, and moreover it may not be desirable to train a separate model just for faster inference.</li>\n  <li>This paper by Ainslie et al. from Google Research (1) proposes a recipe for uptraining existing multi-head language model checkpoints into models with MQA using 5% of original pre-training compute, and (2) introduces grouped-query attention (GQA), a generalization of multi-query attention (MQA) which uses an intermediate (more than one, less than number of query heads) number of key-value heads.</li>\n  <li>The following figure from the paper presents an overview of grouped-query method. Multi-head attention has <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-27-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-188\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-189\"><span class=\"mi\" id=\"MathJax-Span-190\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-27\">H</script> query, key, and value heads. Multi-query attention shares single key and value heads across all query heads. Grouped-query attention instead shares single key and value heads for each group of query heads, interpolating between multi-head and multi-query attention.</li>\n</ul>\n<p><img src=\"../../../images/papers/GQA.jpg\" alt=\"\"></p>\n<ul>\n  <li>MQA uses a single key-value head to speed up decoder inference but can lead to quality degradation. The authors propose a novel method to transform existing multi-head attention (MHA) language model checkpoints into models with MQA, requiring only 5% of the original pre-training compute.</li>\n  <li>The paper presents Grouped-Query Attention (GQA), an intermediate approach between multi-head and multi-query attention. In GQA, query heads are divided into groups, each sharing a single key and value head. This method allows uptrained GQA models to achieve near MHA quality with speeds comparable to MQA.</li>\n  <li>Experiments conducted on the T5.1.1 architecture across various datasets (including CNN/Daily Mail, arXiv, PubMed, MediaSum, Multi-News, WMT, and TriviaQA) show that GQA models offer a balance between inference speed and quality.</li>\n  <li>The study includes ablation experiments to evaluate different modeling choices, such as the number of GQA groups and checkpoint conversion methods. These provide insights into the model’s performance under various configurations.</li>\n  <li>The paper acknowledges limitations, such as evaluation challenges for longer sequences and the absence of comparisons with models trained from scratch. It also notes that the findings are particularly applicable to encoder-decoder models and suggests GQA might have a stronger advantage in decoder-only models.</li>\n  <li>They show that uptrained GQA achieves quality close to multi-head attention with comparable speed to MQA.</li>\n  <li>A detailed discourse on this topic is available in our <a href=\"../attention\">Attention</a> primer.</li>\n</ul>",
    "contentMarkdown": "*   Proposed in[GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints](https://arxiv.org/abs/2305.13245).\n*   MQA, which only uses a single key-value head, drastically speeds up decoder inference. However, MQA can lead to quality degradation, and moreover it may not be desirable to train a separate model just for faster inference.\n*   This paper by Ainslie et al. from Google Research (1) proposes a recipe for uptraining existing multi-head language model checkpoints into models with MQA using 5% of original pre-training compute, and (2) introduces grouped-query attention (GQA), a generalization of multi-query attention (MQA) which uses an intermediate (more than one, less than number of query heads) number of key-value heads.\n*   The following figure from the paper presents an overview of grouped-query method. Multi-head attention has HHH query, key, and value heads. Multi-query attention shares single key and value heads across all query heads. Grouped-query attention instead shares single key and value heads for each group of query heads, interpolating between multi-head and multi-query attention.\n\n![](../../../images/papers/GQA.jpg)\n\n*   MQA uses a single key-value head to speed up decoder inference but can lead to quality degradation. The authors propose a novel method to transform existing multi-head attention (MHA) language model checkpoints into models with MQA, requiring only 5% of the original pre-training compute.\n*   The paper presents Grouped-Query Attention (GQA), an intermediate approach between multi-head and multi-query attention. In GQA, query heads are divided into groups, each sharing a single key and value head. This method allows uptrained GQA models to achieve near MHA quality with speeds comparable to MQA.\n*   Experiments conducted on the T5.1.1 architecture across various datasets (including CNN/Daily Mail, arXiv, PubMed, MediaSum, Multi-News, WMT, and TriviaQA) show that GQA models offer a balance between inference speed and quality.\n*   The study includes ablation experiments to evaluate different modeling choices, such as the number of GQA groups and checkpoint conversion methods. These provide insights into the model’s performance under various configurations.\n*   The paper acknowledges limitations, such as evaluation challenges for longer sequences and the absence of comparisons with models trained from scratch. It also notes that the findings are particularly applicable to encoder-decoder models and suggests GQA might have a stronger advantage in decoder-only models.\n*   They show that uptrained GQA achieves quality close to multi-head attention with comparable speed to MQA.\n*   A detailed discourse on this topic is available in our [Attention](../attention) primer.",
    "contentLength": 4181,
    "wordCount": 395,
    "hasCode": false,
    "hasMath": true,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/model-acceleration/#grouped-query-attention-(gqa)"
  },
  {
    "id": "ai-model-acceleration-linear-attention-7",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Training Optimizations",
    "title": "Linear Attention",
    "order": 7,
    "orderInChapter": 7,
    "contentHtml": "<ul>\n  <li>Proposed in <a href=\"https://arxiv.org/abs/2006.04768\">Linformer: Self-Attention with Linear Complexity</a> by Wang et al. from Facebook AI.</li>\n  <li>The authors proposes a novel approach to optimizing the self-attention mechanism in Transformer models, reducing its complexity from quadratic to linear with respect to sequence length. This method, named Linformer, maintains competitive performance with standard Transformer models while significantly enhancing efficiency in both time and memory usage.</li>\n  <li>Linformer introduces a low-rank approximation of the self-attention mechanism. By empirically and theoretically demonstrating that the self-attention matrix is of low rank, the authors propose a decomposition of the original scaled dot-product attention into multiple smaller attentions via linear projections. This factorization effectively reduces both the space and time complexity of self-attention from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-28-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-191\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1002.29em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-192\"><span class=\"mi\" id=\"MathJax-Span-193\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-194\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-195\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-196\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-197\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-198\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-28\">O(n^2)</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-29-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-199\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.83em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-200\"><span class=\"mi\" id=\"MathJax-Span-201\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-202\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-203\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-204\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-29\">O(n)</script>, addressing the scalability issues of traditional Transformers.</li>\n  <li>The model architecture involves projecting key and value matrices into lower-dimensional spaces before computing the attention, which retains the model’s effectiveness while reducing computational demands. The approach includes options for parameter sharing across projections, which can further reduce the number of trainable parameters without significantly impacting performance.</li>\n  <li>\n    <p>In summary, here’s how Linformer achieves linear-time attention:</p>\n\n    <ol>\n      <li>\n        <p><strong>Low-Rank Approximation</strong>: The core idea behind Linformer is the observation that self-attention can be approximated by a low-rank matrix. This implies that the complex relationships captured by self-attention in Transformers do not necessarily require a full rank matrix, allowing for a more efficient representation.</p>\n      </li>\n      <li>\n        <p><strong>Reduced Complexity</strong>: While standard self-attention mechanisms in Transformers have a time and space complexity of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-205\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1002.29em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-206\"><span class=\"mi\" id=\"MathJax-Span-207\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-208\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-209\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-210\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-211\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-212\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-30\">O(n^2)</script> with respect to the sequence length (n), Linformer reduces this complexity to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-213\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.83em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-214\"><span class=\"mi\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-31\">O(n)</script>. This significant reduction is both in terms of time and space, making it much more efficient for processing longer sequences.</p>\n      </li>\n      <li>\n        <p><strong>Mechanism of Linear Self-Attention</strong>: The Linformer achieves this by decomposing the scaled dot-product attention into multiple smaller attentions through linear projections. Specifically, it introduces two linear projection matrices <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>E</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-219\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-220\"><span class=\"msubsup\" id=\"MathJax-Span-221\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-222\" style=\"font-family: STIXGeneral-Italic;\">E<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-223\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>E</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">E_i</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>F</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-224\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-225\"><span class=\"msubsup\" id=\"MathJax-Span-226\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-227\" style=\"font-family: STIXGeneral-Italic;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-228\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>F</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">F_i</script> which are used when computing the key and value matrices. By first projecting the original high-dimensional key and value matrices into a lower-dimensional space (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x00D7;</mo><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-229\" style=\"width: 2.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.09em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-230\"><span class=\"mi\" id=\"MathJax-Span-231\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-233\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi><mo>×</mo><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">n \\times k</script>), Linformer effectively reduces the complexity of the attention mechanism.</p>\n      </li>\n      <li>\n        <p><strong>Combination of Operations</strong>: The combination of these operations forms a low-rank factorization of the original attention matrix. Essentially, Linformer simplifies the computational process by approximating the full attention mechanism with a series of smaller, more manageable operations that collectively capture the essential characteristics of the original full-rank attention.</p>\n      </li>\n    </ol>\n  </li>\n  <li>The figure below from the paper shows: (left and bottom-right) architecture and example of the proposed multihead linear self-attention; (top right) inference time vs. sequence length the various Linformer models.</li>\n</ul>\n<p>In summary, here’s how Linformer achieves linear-time attention:</p>\n<ol>\n      <li>\n        <p><strong>Low-Rank Approximation</strong>: The core idea behind Linformer is the observation that self-attention can be approximated by a low-rank matrix. This implies that the complex relationships captured by self-attention in Transformers do not necessarily require a full rank matrix, allowing for a more efficient representation.</p>\n      </li>\n      <li>\n        <p><strong>Reduced Complexity</strong>: While standard self-attention mechanisms in Transformers have a time and space complexity of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-205\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1002.29em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-206\"><span class=\"mi\" id=\"MathJax-Span-207\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-208\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-209\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-210\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-211\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-212\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-30\">O(n^2)</script> with respect to the sequence length (n), Linformer reduces this complexity to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-213\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.83em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-214\"><span class=\"mi\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-31\">O(n)</script>. This significant reduction is both in terms of time and space, making it much more efficient for processing longer sequences.</p>\n      </li>\n      <li>\n        <p><strong>Mechanism of Linear Self-Attention</strong>: The Linformer achieves this by decomposing the scaled dot-product attention into multiple smaller attentions through linear projections. Specifically, it introduces two linear projection matrices <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>E</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-219\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-220\"><span class=\"msubsup\" id=\"MathJax-Span-221\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-222\" style=\"font-family: STIXGeneral-Italic;\">E<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-223\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>E</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">E_i</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>F</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-224\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-225\"><span class=\"msubsup\" id=\"MathJax-Span-226\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-227\" style=\"font-family: STIXGeneral-Italic;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-228\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>F</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">F_i</script> which are used when computing the key and value matrices. By first projecting the original high-dimensional key and value matrices into a lower-dimensional space (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x00D7;</mo><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-229\" style=\"width: 2.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.09em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-230\"><span class=\"mi\" id=\"MathJax-Span-231\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-233\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi><mo>×</mo><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">n \\times k</script>), Linformer effectively reduces the complexity of the attention mechanism.</p>\n      </li>\n      <li>\n        <p><strong>Combination of Operations</strong>: The combination of these operations forms a low-rank factorization of the original attention matrix. Essentially, Linformer simplifies the computational process by approximating the full attention mechanism with a series of smaller, more manageable operations that collectively capture the essential characteristics of the original full-rank attention.</p>\n      </li>\n    </ol>\n<p><strong>Low-Rank Approximation</strong>: The core idea behind Linformer is the observation that self-attention can be approximated by a low-rank matrix. This implies that the complex relationships captured by self-attention in Transformers do not necessarily require a full rank matrix, allowing for a more efficient representation.</p>\n<p><strong>Reduced Complexity</strong>: While standard self-attention mechanisms in Transformers have a time and space complexity of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-205\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1002.29em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-206\"><span class=\"mi\" id=\"MathJax-Span-207\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-208\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-209\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-210\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-211\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-212\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-30\">O(n^2)</script> with respect to the sequence length (n), Linformer reduces this complexity to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-213\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.83em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-214\"><span class=\"mi\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-31\">O(n)</script>. This significant reduction is both in terms of time and space, making it much more efficient for processing longer sequences.</p>\n<p><strong>Mechanism of Linear Self-Attention</strong>: The Linformer achieves this by decomposing the scaled dot-product attention into multiple smaller attentions through linear projections. Specifically, it introduces two linear projection matrices <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>E</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-219\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-220\"><span class=\"msubsup\" id=\"MathJax-Span-221\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-222\" style=\"font-family: STIXGeneral-Italic;\">E<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-223\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>E</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">E_i</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>F</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-224\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-225\"><span class=\"msubsup\" id=\"MathJax-Span-226\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-227\" style=\"font-family: STIXGeneral-Italic;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-228\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>F</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">F_i</script> which are used when computing the key and value matrices. By first projecting the original high-dimensional key and value matrices into a lower-dimensional space (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>&amp;#x00D7;</mo><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-229\" style=\"width: 2.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.09em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-230\"><span class=\"mi\" id=\"MathJax-Span-231\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-233\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi><mo>×</mo><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">n \\times k</script>), Linformer effectively reduces the complexity of the attention mechanism.</p>\n<p><strong>Combination of Operations</strong>: The combination of these operations forms a low-rank factorization of the original attention matrix. Essentially, Linformer simplifies the computational process by approximating the full attention mechanism with a series of smaller, more manageable operations that collectively capture the essential characteristics of the original full-rank attention.</p>\n<p><img src=\"../../../images/papers/Linformer.jpg\" alt=\"\"></p>\n<ul>\n  <li>Experimental validation shows that Linformer achieves similar or better performance compared to the original Transformer on standard NLP tasks such as sentiment analysis and question answering, using datasets like GLUE and IMDB reviews. Notably, the model offers considerable improvements in training and inference speeds, especially beneficial for longer sequences.</li>\n  <li>Additionally, various strategies for enhancing the efficiency of Linformer are tested, including different levels of parameter sharing and the use of non-uniform projected dimensions tailored to the specific demands of different layers within the model.</li>\n  <li>The authors suggest that the reduced computational requirements of Linformer not only make high-performance models more accessible and cost-effective but also open the door to environmentally friendlier AI practices due to decreased energy consumption.</li>\n  <li>In summary, Linformer proposes a more efficient self-attention mechanism for Transformers by leveraging the low-rank nature of self-attention matrices. This approach significantly reduces the computational burden, especially for long sequences, by lowering the complexity of attention calculations from quadratic to linear in terms of both time and space. This makes Linformer an attractive choice for tasks involving large datasets or long sequence inputs, where traditional Transformers might be less feasible due to their higher computational demands.</li>\n  <li>A detailed discourse on this topic is available in our <a href=\"../attention\">Attention</a> primer.</li>\n</ul>",
    "contentMarkdown": "*   Proposed in [Linformer: Self-Attention with Linear Complexity](https://arxiv.org/abs/2006.04768) by Wang et al. from Facebook AI.\n*   The authors proposes a novel approach to optimizing the self-attention mechanism in Transformer models, reducing its complexity from quadratic to linear with respect to sequence length. This method, named Linformer, maintains competitive performance with standard Transformer models while significantly enhancing efficiency in both time and memory usage.\n*   Linformer introduces a low-rank approximation of the self-attention mechanism. By empirically and theoretically demonstrating that the self-attention matrix is of low rank, the authors propose a decomposition of the original scaled dot-product attention into multiple smaller attentions via linear projections. This factorization effectively reduces both the space and time complexity of self-attention from O(n2)O(n2)O(n^2) to O(n)O(n)O(n), addressing the scalability issues of traditional Transformers.\n*   The model architecture involves projecting key and value matrices into lower-dimensional spaces before computing the attention, which retains the model’s effectiveness while reducing computational demands. The approach includes options for parameter sharing across projections, which can further reduce the number of trainable parameters without significantly impacting performance.\n*   In summary, here’s how Linformer achieves linear-time attention:\n    \n    1.  **Low-Rank Approximation**: The core idea behind Linformer is the observation that self-attention can be approximated by a low-rank matrix. This implies that the complex relationships captured by self-attention in Transformers do not necessarily require a full rank matrix, allowing for a more efficient representation.\n        \n    2.  **Reduced Complexity**: While standard self-attention mechanisms in Transformers have a time and space complexity of O(n2)O(n2)O(n^2) with respect to the sequence length (n), Linformer reduces this complexity to O(n)O(n)O(n). This significant reduction is both in terms of time and space, making it much more efficient for processing longer sequences.\n        \n    3.  **Mechanism of Linear Self-Attention**: The Linformer achieves this by decomposing the scaled dot-product attention into multiple smaller attentions through linear projections. Specifically, it introduces two linear projection matrices EiEiE\\_i and FiFiF\\_i which are used when computing the key and value matrices. By first projecting the original high-dimensional key and value matrices into a lower-dimensional space (n×kn×kn \\\\times k), Linformer effectively reduces the complexity of the attention mechanism.\n        \n    4.  **Combination of Operations**: The combination of these operations forms a low-rank factorization of the original attention matrix. Essentially, Linformer simplifies the computational process by approximating the full attention mechanism with a series of smaller, more manageable operations that collectively capture the essential characteristics of the original full-rank attention.\n        \n*   The figure below from the paper shows: (left and bottom-right) architecture and example of the proposed multihead linear self-attention; (top right) inference time vs. sequence length the various Linformer models.\n\nIn summary, here’s how Linformer achieves linear-time attention:\n\n1.  **Low-Rank Approximation**: The core idea behind Linformer is the observation that self-attention can be approximated by a low-rank matrix. This implies that the complex relationships captured by self-attention in Transformers do not necessarily require a full rank matrix, allowing for a more efficient representation.\n    \n2.  **Reduced Complexity**: While standard self-attention mechanisms in Transformers have a time and space complexity of O(n2)O(n2)O(n^2) with respect to the sequence length (n), Linformer reduces this complexity to O(n)O(n)O(n). This significant reduction is both in terms of time and space, making it much more efficient for processing longer sequences.\n    \n3.  **Mechanism of Linear Self-Attention**: The Linformer achieves this by decomposing the scaled dot-product attention into multiple smaller attentions through linear projections. Specifically, it introduces two linear projection matrices EiEiE\\_i and FiFiF\\_i which are used when computing the key and value matrices. By first projecting the original high-dimensional key and value matrices into a lower-dimensional space (n×kn×kn \\\\times k), Linformer effectively reduces the complexity of the attention mechanism.\n    \n4.  **Combination of Operations**: The combination of these operations forms a low-rank factorization of the original attention matrix. Essentially, Linformer simplifies the computational process by approximating the full attention mechanism with a series of smaller, more manageable operations that collectively capture the essential characteristics of the original full-rank attention.\n    \n\n**Low-Rank Approximation**: The core idea behind Linformer is the observation that self-attention can be approximated by a low-rank matrix. This implies that the complex relationships captured by self-attention in Transformers do not necessarily require a full rank matrix, allowing for a more efficient representation.\n\n**Reduced Complexity**: While standard self-attention mechanisms in Transformers have a time and space complexity of O(n2)O(n2)O(n^2) with respect to the sequence length (n), Linformer reduces this complexity to O(n)O(n)O(n). This significant reduction is both in terms of time and space, making it much more efficient for processing longer sequences.\n\n**Mechanism of Linear Self-Attention**: The Linformer achieves this by decomposing the scaled dot-product attention into multiple smaller attentions through linear projections. Specifically, it introduces two linear projection matrices EiEiE\\_i and FiFiF\\_i which are used when computing the key and value matrices. By first projecting the original high-dimensional key and value matrices into a lower-dimensional space (n×kn×kn \\\\times k), Linformer effectively reduces the complexity of the attention mechanism.\n\n**Combination of Operations**: The combination of these operations forms a low-rank factorization of the original attention matrix. Essentially, Linformer simplifies the computational process by approximating the full attention mechanism with a series of smaller, more manageable operations that collectively capture the essential characteristics of the original full-rank attention.\n\n![](../../../images/papers/Linformer.jpg)\n\n*   Experimental validation shows that Linformer achieves similar or better performance compared to the original Transformer on standard NLP tasks such as sentiment analysis and question answering, using datasets like GLUE and IMDB reviews. Notably, the model offers considerable improvements in training and inference speeds, especially beneficial for longer sequences.\n*   Additionally, various strategies for enhancing the efficiency of Linformer are tested, including different levels of parameter sharing and the use of non-uniform projected dimensions tailored to the specific demands of different layers within the model.\n*   The authors suggest that the reduced computational requirements of Linformer not only make high-performance models more accessible and cost-effective but also open the door to environmentally friendlier AI practices due to decreased energy consumption.\n*   In summary, Linformer proposes a more efficient self-attention mechanism for Transformers by leveraging the low-rank nature of self-attention matrices. This approach significantly reduces the computational burden, especially for long sequences, by lowering the complexity of attention calculations from quadratic to linear in terms of both time and space. This makes Linformer an attractive choice for tasks involving large datasets or long sequence inputs, where traditional Transformers might be less feasible due to their higher computational demands.\n*   A detailed discourse on this topic is available in our [Attention](../attention) primer.",
    "contentLength": 39899,
    "wordCount": 1067,
    "hasCode": false,
    "hasMath": true,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/model-acceleration/#linear-attention"
  },
  {
    "id": "ai-model-acceleration-longformer-8",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Training Optimizations",
    "title": "Longformer",
    "order": 8,
    "orderInChapter": 8,
    "contentHtml": "<ul>\n  <li>Proposed in <a href=\"https://arxiv.org/abs/2004.05150\">Longformer: The Long-Document Transformer</a>.</li>\n  <li>Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length.</li>\n  <li>This paper by Beltagy et al. from Allen AI in 2020 seeks to address this limitation, by introducing the Longformer with an attention mechanism that scales linearly with sequence length (commonly called Sliding Window Attention in the field), making it easy to process documents of thousands of tokens or longer.</li>\n  <li>Longformer’s attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention.</li>\n  <li>The figure below from the paper compares the full self-attention pattern and the configuration of attention patterns in Longformer.</li>\n</ul>\n<p><img src=\"../../../images/papers/Longformer.jpg\" alt=\"\"></p>\n<ul>\n  <li>Following prior work on long-sequence transformers, they evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8.</li>\n  <li>In contrast to most prior work, they also pretrain Longformer and finetune it on a variety of downstream tasks.</li>\n  <li>Their pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA. They finally introduce the Longformer-Encoder-Decoder (LED), a Longformer variant for supporting long document generative sequence-to-sequence tasks, and demonstrate its effectiveness on the arXiv summarization dataset.</li>\n  <li>The figure below from the paper illustrates the runtime and memory of full self-attention and different implementations of Longformer’s self-attention; <code class=\"language-plaintext highlighter-rouge\">Longformer-loop</code> is nonvectorized, <code class=\"language-plaintext highlighter-rouge\">Longformer</code>-chunk is vectorized, and <code class=\"language-plaintext highlighter-rouge\">Longformer-cuda</code> is a custom cuda kernel implementations. Longformer’s memory usage scales linearly with the sequence length, unlike the full self-attention mechanism that runs out of memory for long sequences on current GPUs. Different implementations vary in speed, with the vectorized Longformer-chunk being the fastest.</li>\n</ul>\n<p><img src=\"../../../images/papers/Longformer2.jpg\" alt=\"\"></p>\n<ul>\n  <li>A detailed discourse on this topic is available in our <a href=\"../attention\">Attention</a> primer.</li>\n</ul>",
    "contentMarkdown": "*   Proposed in [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150).\n*   Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length.\n*   This paper by Beltagy et al. from Allen AI in 2020 seeks to address this limitation, by introducing the Longformer with an attention mechanism that scales linearly with sequence length (commonly called Sliding Window Attention in the field), making it easy to process documents of thousands of tokens or longer.\n*   Longformer’s attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention.\n*   The figure below from the paper compares the full self-attention pattern and the configuration of attention patterns in Longformer.\n\n![](../../../images/papers/Longformer.jpg)\n\n*   Following prior work on long-sequence transformers, they evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8.\n*   In contrast to most prior work, they also pretrain Longformer and finetune it on a variety of downstream tasks.\n*   Their pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA. They finally introduce the Longformer-Encoder-Decoder (LED), a Longformer variant for supporting long document generative sequence-to-sequence tasks, and demonstrate its effectiveness on the arXiv summarization dataset.\n*   The figure below from the paper illustrates the runtime and memory of full self-attention and different implementations of Longformer’s self-attention; `Longformer-loop` is nonvectorized, `Longformer`\\-chunk is vectorized, and `Longformer-cuda` is a custom cuda kernel implementations. Longformer’s memory usage scales linearly with the sequence length, unlike the full self-attention mechanism that runs out of memory for long sequences on current GPUs. Different implementations vary in speed, with the vectorized Longformer-chunk being the fastest.\n\n![](../../../images/papers/Longformer2.jpg)\n\n*   A detailed discourse on this topic is available in our [Attention](../attention) primer.",
    "contentLength": 2611,
    "wordCount": 297,
    "hasCode": true,
    "hasMath": false,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/model-acceleration/#longformer"
  },
  {
    "id": "ai-model-acceleration-overview-9",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Inference Optimizations",
    "title": "Overview",
    "order": 9,
    "orderInChapter": 1,
    "contentHtml": "<ul>\n  <li>\n    <p>Inference optimizations are a crucial area of research and engineering in the deployment of transformer models, particularly for real-time and resource-constrained environments. The goal is to minimize the computational cost and latency of running large language models (LLMs) without compromising their predictive accuracy. Optimizations during inference directly affect the responsiveness, scalability, and feasibility of these models in production systems.</p>\n  </li>\n  <li>\n    <p>One of the central challenges in inference is the autoregressive nature of many LLMs, where each token depends on the previously generated sequence. This leads to sequential dependencies that make naive inference expensive, especially for long sequences. To address this, a suite of optimization techniques has been developed to enhance the performance of transformer-based models during inference:</p>\n\n    <ul>\n      <li>\n        <p><strong>KV Caching</strong>: The KV cache in transformer models is a critical optimization that enhances the efficiency and speed of sequence generation, making it a key component for deploying these models in real-world applications. The use of KV caching in autoregressive decoding processes, along with its role in latency optimization and scalability, makes it indispensable for serving transformer-based models efficiently. It allows previously computed key and value projections from self-attention layers to be stored and reused during subsequent decoding steps, avoiding redundant computations. This dramatically reduces per-token inference time beyond the first token, supports long-sequence generation, and is essential for achieving low-latency, high-throughput serving in applications like chat, streaming, and interactive agents.</p>\n      </li>\n      <li>\n        <p><strong>Model Quantization</strong>: Model quantization reduces the precision of weights and activations from 32-bit floating-point (<code class=\"language-plaintext highlighter-rouge\">float32</code>) to lower-bit formats such as <code class=\"language-plaintext highlighter-rouge\">int8</code>, <code class=\"language-plaintext highlighter-rouge\">float8</code>, or even 4-bit representations like <code class=\"language-plaintext highlighter-rouge\">int4</code>. This significantly cuts memory footprint and bandwidth usage, enabling deployment on smaller hardware and increasing throughput. Post-training quantization (PTQ) and quantization-aware training (QAT) are two common approaches. Quantized models benefit from faster matrix multiplications and lower energy consumption, and modern toolchains (e.g., NVIDIA TensorRT, Intel Neural Compressor) support hardware acceleration for quantized ops with minimal accuracy degradation.</p>\n      </li>\n      <li>\n        <p><strong>Operator Fusion</strong>: Operator fusion consolidates multiple sequential operations—such as linear projections, bias addition, layer normalization, and activation functions—into a single computational kernel. This reduces the number of memory read/write operations and kernel launch overhead on GPUs or TPUs, improving execution efficiency. For example, fusing a dense layer and a ReLU activation into a single fused kernel reduces latency and allows for more effective use of SIMD or CUDA cores, which are otherwise underutilized with fragmented ops.</p>\n      </li>\n      <li>\n        <p><strong>Speculative Decoding</strong>: Speculative decoding accelerates autoregressive generation by using a lightweight draft model to predict multiple future tokens in a single forward pass. These candidate tokens are then validated in parallel by the full, slower model. If validated, they are accepted en masse; otherwise, the generation rolls back. This pipeline reduces the number of expensive full-model invocations while maintaining generation fidelity. Approaches like Draft and Target Models, Medusa, Self-Speculative Decoding, FastRAG, and NVIDIA’s Speculative Decoding with Prefill leverage this technique to boost throughput while preserving model output quality.</p>\n      </li>\n      <li>\n        <p><strong>FlashAttention and Efficient Attention Kernels</strong>: FlashAttention is a memory-efficient attention algorithm that computes attention outputs in a tiled, fused, and GPU-friendly way, avoiding the need to materialize large intermediate attention matrices. It exploits GPU SRAM to keep frequently accessed blocks in high-speed memory and streams partial results to minimize memory bandwidth pressure. This approach scales better with sequence length and batch size than traditional softmax-based attention implementations. FlashAttention-2 and similar kernels (e.g., xFormers, Triton) are now standard in high-performance transformer inference stacks.</p>\n      </li>\n      <li><strong>Batching, Sequence Packing, and Prefilling</strong>:</li>\n      <li><strong>Batching</strong> groups multiple inference requests into a single execution pass, maximizing GPU utilization, amortizing kernel launch overhead, and improving throughput. Dynamic batching adapts to incoming request patterns, while token-level batching (e.g., vLLM) synchronizes decoding steps to serve many requests concurrently without blocking new ones.</li>\n      <li><strong>Sequence Packing</strong> minimizes padding waste by concatenating multiple short sequences into a single sequence tensor within a batch element, using an attention mask to prevent cross-sequence attention. This increases the density of useful tokens processed per batch, reducing memory footprint and improving effective throughput, especially in workloads with highly variable sequence lengths.</li>\n      <li>\n        <p><strong>Prefilling</strong> precomputes the KV cache for all prompt tokens before autoregressive decoding begins, avoiding redundant computation during generation. Optimizations like fused prefill kernels, prompt sharing, and layer-wise streaming further reduce latency in the prompt phase, which is often the most expensive stage for long inputs. Together, these three techniques ensure high hardware utilization, lower padding overhead, and minimized per-token computation cost.</p>\n      </li>\n      <li>\n        <p><strong>Prompt Caching</strong>: Caches the KV states of frequently used or repeated prompts—such as system instructions, few-shot exemplars, or user-defined templates—so they don’t need to be recomputed for each request. Particularly effective in chat or API-driven systems where the same initial context (e.g., “You are a helpful assistant…”) is used across sessions. By reusing prompt KV states, servers can skip prompt processing entirely and begin generation with the cache already initialized, significantly reducing time to first token and overall compute.</p>\n      </li>\n      <li>\n        <p><strong>Early Exit and Token Pruning</strong>: Early exit allows transformer layers to terminate inference for specific tokens when confidence thresholds or entropy-based stopping criteria are met, saving computation on later layers. Token pruning dynamically removes tokens or attention paths deemed irrelevant during inference, based on learned importance scores or gating functions. These techniques reduce compute costs without heavily sacrificing model output quality, and are especially useful for deployment scenarios where speed is prioritized over full precision.</p>\n      </li>\n      <li><strong>Hardware-Aware Scheduling</strong>: This optimization involves aligning inference workloads with the specifics of the underlying hardware—e.g., GPU memory hierarchy, tensor core availability, or pipeline concurrency. Scheduling strategies include operator placement, memory prefetching, stream prioritization, and load balancing across multi-GPU setups. For example, on NVIDIA GPUs, frameworks may utilize CUDA streams, shared memory, and kernel fusion to maximize throughput, while TPU inference may leverage XLA compilation for graph-level optimizations. Fine-tuned scheduling reduces contention, increases parallelism, and maximizes total inference throughput per watt.</li>\n    </ul>\n  </li>\n</ul>\n<p>Inference optimizations are a crucial area of research and engineering in the deployment of transformer models, particularly for real-time and resource-constrained environments. The goal is to minimize the computational cost and latency of running large language models (LLMs) without compromising their predictive accuracy. Optimizations during inference directly affect the responsiveness, scalability, and feasibility of these models in production systems.</p>\n<p>One of the central challenges in inference is the autoregressive nature of many LLMs, where each token depends on the previously generated sequence. This leads to sequential dependencies that make naive inference expensive, especially for long sequences. To address this, a suite of optimization techniques has been developed to enhance the performance of transformer-based models during inference:</p>\n<ul>\n      <li>\n        <p><strong>KV Caching</strong>: The KV cache in transformer models is a critical optimization that enhances the efficiency and speed of sequence generation, making it a key component for deploying these models in real-world applications. The use of KV caching in autoregressive decoding processes, along with its role in latency optimization and scalability, makes it indispensable for serving transformer-based models efficiently. It allows previously computed key and value projections from self-attention layers to be stored and reused during subsequent decoding steps, avoiding redundant computations. This dramatically reduces per-token inference time beyond the first token, supports long-sequence generation, and is essential for achieving low-latency, high-throughput serving in applications like chat, streaming, and interactive agents.</p>\n      </li>\n      <li>\n        <p><strong>Model Quantization</strong>: Model quantization reduces the precision of weights and activations from 32-bit floating-point (<code class=\"language-plaintext highlighter-rouge\">float32</code>) to lower-bit formats such as <code class=\"language-plaintext highlighter-rouge\">int8</code>, <code class=\"language-plaintext highlighter-rouge\">float8</code>, or even 4-bit representations like <code class=\"language-plaintext highlighter-rouge\">int4</code>. This significantly cuts memory footprint and bandwidth usage, enabling deployment on smaller hardware and increasing throughput. Post-training quantization (PTQ) and quantization-aware training (QAT) are two common approaches. Quantized models benefit from faster matrix multiplications and lower energy consumption, and modern toolchains (e.g., NVIDIA TensorRT, Intel Neural Compressor) support hardware acceleration for quantized ops with minimal accuracy degradation.</p>\n      </li>\n      <li>\n        <p><strong>Operator Fusion</strong>: Operator fusion consolidates multiple sequential operations—such as linear projections, bias addition, layer normalization, and activation functions—into a single computational kernel. This reduces the number of memory read/write operations and kernel launch overhead on GPUs or TPUs, improving execution efficiency. For example, fusing a dense layer and a ReLU activation into a single fused kernel reduces latency and allows for more effective use of SIMD or CUDA cores, which are otherwise underutilized with fragmented ops.</p>\n      </li>\n      <li>\n        <p><strong>Speculative Decoding</strong>: Speculative decoding accelerates autoregressive generation by using a lightweight draft model to predict multiple future tokens in a single forward pass. These candidate tokens are then validated in parallel by the full, slower model. If validated, they are accepted en masse; otherwise, the generation rolls back. This pipeline reduces the number of expensive full-model invocations while maintaining generation fidelity. Approaches like Draft and Target Models, Medusa, Self-Speculative Decoding, FastRAG, and NVIDIA’s Speculative Decoding with Prefill leverage this technique to boost throughput while preserving model output quality.</p>\n      </li>\n      <li>\n        <p><strong>FlashAttention and Efficient Attention Kernels</strong>: FlashAttention is a memory-efficient attention algorithm that computes attention outputs in a tiled, fused, and GPU-friendly way, avoiding the need to materialize large intermediate attention matrices. It exploits GPU SRAM to keep frequently accessed blocks in high-speed memory and streams partial results to minimize memory bandwidth pressure. This approach scales better with sequence length and batch size than traditional softmax-based attention implementations. FlashAttention-2 and similar kernels (e.g., xFormers, Triton) are now standard in high-performance transformer inference stacks.</p>\n      </li>\n      <li><strong>Batching, Sequence Packing, and Prefilling</strong>:</li>\n      <li><strong>Batching</strong> groups multiple inference requests into a single execution pass, maximizing GPU utilization, amortizing kernel launch overhead, and improving throughput. Dynamic batching adapts to incoming request patterns, while token-level batching (e.g., vLLM) synchronizes decoding steps to serve many requests concurrently without blocking new ones.</li>\n      <li><strong>Sequence Packing</strong> minimizes padding waste by concatenating multiple short sequences into a single sequence tensor within a batch element, using an attention mask to prevent cross-sequence attention. This increases the density of useful tokens processed per batch, reducing memory footprint and improving effective throughput, especially in workloads with highly variable sequence lengths.</li>\n      <li>\n        <p><strong>Prefilling</strong> precomputes the KV cache for all prompt tokens before autoregressive decoding begins, avoiding redundant computation during generation. Optimizations like fused prefill kernels, prompt sharing, and layer-wise streaming further reduce latency in the prompt phase, which is often the most expensive stage for long inputs. Together, these three techniques ensure high hardware utilization, lower padding overhead, and minimized per-token computation cost.</p>\n      </li>\n      <li>\n        <p><strong>Prompt Caching</strong>: Caches the KV states of frequently used or repeated prompts—such as system instructions, few-shot exemplars, or user-defined templates—so they don’t need to be recomputed for each request. Particularly effective in chat or API-driven systems where the same initial context (e.g., “You are a helpful assistant…”) is used across sessions. By reusing prompt KV states, servers can skip prompt processing entirely and begin generation with the cache already initialized, significantly reducing time to first token and overall compute.</p>\n      </li>\n      <li>\n        <p><strong>Early Exit and Token Pruning</strong>: Early exit allows transformer layers to terminate inference for specific tokens when confidence thresholds or entropy-based stopping criteria are met, saving computation on later layers. Token pruning dynamically removes tokens or attention paths deemed irrelevant during inference, based on learned importance scores or gating functions. These techniques reduce compute costs without heavily sacrificing model output quality, and are especially useful for deployment scenarios where speed is prioritized over full precision.</p>\n      </li>\n      <li><strong>Hardware-Aware Scheduling</strong>: This optimization involves aligning inference workloads with the specifics of the underlying hardware—e.g., GPU memory hierarchy, tensor core availability, or pipeline concurrency. Scheduling strategies include operator placement, memory prefetching, stream prioritization, and load balancing across multi-GPU setups. For example, on NVIDIA GPUs, frameworks may utilize CUDA streams, shared memory, and kernel fusion to maximize throughput, while TPU inference may leverage XLA compilation for graph-level optimizations. Fine-tuned scheduling reduces contention, increases parallelism, and maximizes total inference throughput per watt.</li>\n    </ul>\n<p><strong>KV Caching</strong>: The KV cache in transformer models is a critical optimization that enhances the efficiency and speed of sequence generation, making it a key component for deploying these models in real-world applications. The use of KV caching in autoregressive decoding processes, along with its role in latency optimization and scalability, makes it indispensable for serving transformer-based models efficiently. It allows previously computed key and value projections from self-attention layers to be stored and reused during subsequent decoding steps, avoiding redundant computations. This dramatically reduces per-token inference time beyond the first token, supports long-sequence generation, and is essential for achieving low-latency, high-throughput serving in applications like chat, streaming, and interactive agents.</p>\n<p><strong>Model Quantization</strong>: Model quantization reduces the precision of weights and activations from 32-bit floating-point (<code class=\"language-plaintext highlighter-rouge\">float32</code>) to lower-bit formats such as <code class=\"language-plaintext highlighter-rouge\">int8</code>, <code class=\"language-plaintext highlighter-rouge\">float8</code>, or even 4-bit representations like <code class=\"language-plaintext highlighter-rouge\">int4</code>. This significantly cuts memory footprint and bandwidth usage, enabling deployment on smaller hardware and increasing throughput. Post-training quantization (PTQ) and quantization-aware training (QAT) are two common approaches. Quantized models benefit from faster matrix multiplications and lower energy consumption, and modern toolchains (e.g., NVIDIA TensorRT, Intel Neural Compressor) support hardware acceleration for quantized ops with minimal accuracy degradation.</p>\n<p><strong>Operator Fusion</strong>: Operator fusion consolidates multiple sequential operations—such as linear projections, bias addition, layer normalization, and activation functions—into a single computational kernel. This reduces the number of memory read/write operations and kernel launch overhead on GPUs or TPUs, improving execution efficiency. For example, fusing a dense layer and a ReLU activation into a single fused kernel reduces latency and allows for more effective use of SIMD or CUDA cores, which are otherwise underutilized with fragmented ops.</p>\n<p><strong>Speculative Decoding</strong>: Speculative decoding accelerates autoregressive generation by using a lightweight draft model to predict multiple future tokens in a single forward pass. These candidate tokens are then validated in parallel by the full, slower model. If validated, they are accepted en masse; otherwise, the generation rolls back. This pipeline reduces the number of expensive full-model invocations while maintaining generation fidelity. Approaches like Draft and Target Models, Medusa, Self-Speculative Decoding, FastRAG, and NVIDIA’s Speculative Decoding with Prefill leverage this technique to boost throughput while preserving model output quality.</p>\n<p><strong>FlashAttention and Efficient Attention Kernels</strong>: FlashAttention is a memory-efficient attention algorithm that computes attention outputs in a tiled, fused, and GPU-friendly way, avoiding the need to materialize large intermediate attention matrices. It exploits GPU SRAM to keep frequently accessed blocks in high-speed memory and streams partial results to minimize memory bandwidth pressure. This approach scales better with sequence length and batch size than traditional softmax-based attention implementations. FlashAttention-2 and similar kernels (e.g., xFormers, Triton) are now standard in high-performance transformer inference stacks.</p>\n<p><strong>Prefilling</strong> precomputes the KV cache for all prompt tokens before autoregressive decoding begins, avoiding redundant computation during generation. Optimizations like fused prefill kernels, prompt sharing, and layer-wise streaming further reduce latency in the prompt phase, which is often the most expensive stage for long inputs. Together, these three techniques ensure high hardware utilization, lower padding overhead, and minimized per-token computation cost.</p>\n<p><strong>Prompt Caching</strong>: Caches the KV states of frequently used or repeated prompts—such as system instructions, few-shot exemplars, or user-defined templates—so they don’t need to be recomputed for each request. Particularly effective in chat or API-driven systems where the same initial context (e.g., “You are a helpful assistant…”) is used across sessions. By reusing prompt KV states, servers can skip prompt processing entirely and begin generation with the cache already initialized, significantly reducing time to first token and overall compute.</p>\n<p><strong>Early Exit and Token Pruning</strong>: Early exit allows transformer layers to terminate inference for specific tokens when confidence thresholds or entropy-based stopping criteria are met, saving computation on later layers. Token pruning dynamically removes tokens or attention paths deemed irrelevant during inference, based on learned importance scores or gating functions. These techniques reduce compute costs without heavily sacrificing model output quality, and are especially useful for deployment scenarios where speed is prioritized over full precision.</p>",
    "contentMarkdown": "*   Inference optimizations are a crucial area of research and engineering in the deployment of transformer models, particularly for real-time and resource-constrained environments. The goal is to minimize the computational cost and latency of running large language models (LLMs) without compromising their predictive accuracy. Optimizations during inference directly affect the responsiveness, scalability, and feasibility of these models in production systems.\n    \n*   One of the central challenges in inference is the autoregressive nature of many LLMs, where each token depends on the previously generated sequence. This leads to sequential dependencies that make naive inference expensive, especially for long sequences. To address this, a suite of optimization techniques has been developed to enhance the performance of transformer-based models during inference:\n    \n    *   **KV Caching**: The KV cache in transformer models is a critical optimization that enhances the efficiency and speed of sequence generation, making it a key component for deploying these models in real-world applications. The use of KV caching in autoregressive decoding processes, along with its role in latency optimization and scalability, makes it indispensable for serving transformer-based models efficiently. It allows previously computed key and value projections from self-attention layers to be stored and reused during subsequent decoding steps, avoiding redundant computations. This dramatically reduces per-token inference time beyond the first token, supports long-sequence generation, and is essential for achieving low-latency, high-throughput serving in applications like chat, streaming, and interactive agents.\n        \n    *   **Model Quantization**: Model quantization reduces the precision of weights and activations from 32-bit floating-point (`float32`) to lower-bit formats such as `int8`, `float8`, or even 4-bit representations like `int4`. This significantly cuts memory footprint and bandwidth usage, enabling deployment on smaller hardware and increasing throughput. Post-training quantization (PTQ) and quantization-aware training (QAT) are two common approaches. Quantized models benefit from faster matrix multiplications and lower energy consumption, and modern toolchains (e.g., NVIDIA TensorRT, Intel Neural Compressor) support hardware acceleration for quantized ops with minimal accuracy degradation.\n        \n    *   **Operator Fusion**: Operator fusion consolidates multiple sequential operations—such as linear projections, bias addition, layer normalization, and activation functions—into a single computational kernel. This reduces the number of memory read/write operations and kernel launch overhead on GPUs or TPUs, improving execution efficiency. For example, fusing a dense layer and a ReLU activation into a single fused kernel reduces latency and allows for more effective use of SIMD or CUDA cores, which are otherwise underutilized with fragmented ops.\n        \n    *   **Speculative Decoding**: Speculative decoding accelerates autoregressive generation by using a lightweight draft model to predict multiple future tokens in a single forward pass. These candidate tokens are then validated in parallel by the full, slower model. If validated, they are accepted en masse; otherwise, the generation rolls back. This pipeline reduces the number of expensive full-model invocations while maintaining generation fidelity. Approaches like Draft and Target Models, Medusa, Self-Speculative Decoding, FastRAG, and NVIDIA’s Speculative Decoding with Prefill leverage this technique to boost throughput while preserving model output quality.\n        \n    *   **FlashAttention and Efficient Attention Kernels**: FlashAttention is a memory-efficient attention algorithm that computes attention outputs in a tiled, fused, and GPU-friendly way, avoiding the need to materialize large intermediate attention matrices. It exploits GPU SRAM to keep frequently accessed blocks in high-speed memory and streams partial results to minimize memory bandwidth pressure. This approach scales better with sequence length and batch size than traditional softmax-based attention implementations. FlashAttention-2 and similar kernels (e.g., xFormers, Triton) are now standard in high-performance transformer inference stacks.\n        \n    *   **Batching, Sequence Packing, and Prefilling**:\n    *   **Batching** groups multiple inference requests into a single execution pass, maximizing GPU utilization, amortizing kernel launch overhead, and improving throughput. Dynamic batching adapts to incoming request patterns, while token-level batching (e.g., vLLM) synchronizes decoding steps to serve many requests concurrently without blocking new ones.\n    *   **Sequence Packing** minimizes padding waste by concatenating multiple short sequences into a single sequence tensor within a batch element, using an attention mask to prevent cross-sequence attention. This increases the density of useful tokens processed per batch, reducing memory footprint and improving effective throughput, especially in workloads with highly variable sequence lengths.\n    *   **Prefilling** precomputes the KV cache for all prompt tokens before autoregressive decoding begins, avoiding redundant computation during generation. Optimizations like fused prefill kernels, prompt sharing, and layer-wise streaming further reduce latency in the prompt phase, which is often the most expensive stage for long inputs. Together, these three techniques ensure high hardware utilization, lower padding overhead, and minimized per-token computation cost.\n        \n    *   **Prompt Caching**: Caches the KV states of frequently used or repeated prompts—such as system instructions, few-shot exemplars, or user-defined templates—so they don’t need to be recomputed for each request. Particularly effective in chat or API-driven systems where the same initial context (e.g., “You are a helpful assistant…”) is used across sessions. By reusing prompt KV states, servers can skip prompt processing entirely and begin generation with the cache already initialized, significantly reducing time to first token and overall compute.\n        \n    *   **Early Exit and Token Pruning**: Early exit allows transformer layers to terminate inference for specific tokens when confidence thresholds or entropy-based stopping criteria are met, saving computation on later layers. Token pruning dynamically removes tokens or attention paths deemed irrelevant during inference, based on learned importance scores or gating functions. These techniques reduce compute costs without heavily sacrificing model output quality, and are especially useful for deployment scenarios where speed is prioritized over full precision.\n        \n    *   **Hardware-Aware Scheduling**: This optimization involves aligning inference workloads with the specifics of the underlying hardware—e.g., GPU memory hierarchy, tensor core availability, or pipeline concurrency. Scheduling strategies include operator placement, memory prefetching, stream prioritization, and load balancing across multi-GPU setups. For example, on NVIDIA GPUs, frameworks may utilize CUDA streams, shared memory, and kernel fusion to maximize throughput, while TPU inference may leverage XLA compilation for graph-level optimizations. Fine-tuned scheduling reduces contention, increases parallelism, and maximizes total inference throughput per watt.\n\nInference optimizations are a crucial area of research and engineering in the deployment of transformer models, particularly for real-time and resource-constrained environments. The goal is to minimize the computational cost and latency of running large language models (LLMs) without compromising their predictive accuracy. Optimizations during inference directly affect the responsiveness, scalability, and feasibility of these models in production systems.\n\nOne of the central challenges in inference is the autoregressive nature of many LLMs, where each token depends on the previously generated sequence. This leads to sequential dependencies that make naive inference expensive, especially for long sequences. To address this, a suite of optimization techniques has been developed to enhance the performance of transformer-based models during inference:\n\n*   **KV Caching**: The KV cache in transformer models is a critical optimization that enhances the efficiency and speed of sequence generation, making it a key component for deploying these models in real-world applications. The use of KV caching in autoregressive decoding processes, along with its role in latency optimization and scalability, makes it indispensable for serving transformer-based models efficiently. It allows previously computed key and value projections from self-attention layers to be stored and reused during subsequent decoding steps, avoiding redundant computations. This dramatically reduces per-token inference time beyond the first token, supports long-sequence generation, and is essential for achieving low-latency, high-throughput serving in applications like chat, streaming, and interactive agents.\n    \n*   **Model Quantization**: Model quantization reduces the precision of weights and activations from 32-bit floating-point (`float32`) to lower-bit formats such as `int8`, `float8`, or even 4-bit representations like `int4`. This significantly cuts memory footprint and bandwidth usage, enabling deployment on smaller hardware and increasing throughput. Post-training quantization (PTQ) and quantization-aware training (QAT) are two common approaches. Quantized models benefit from faster matrix multiplications and lower energy consumption, and modern toolchains (e.g., NVIDIA TensorRT, Intel Neural Compressor) support hardware acceleration for quantized ops with minimal accuracy degradation.\n    \n*   **Operator Fusion**: Operator fusion consolidates multiple sequential operations—such as linear projections, bias addition, layer normalization, and activation functions—into a single computational kernel. This reduces the number of memory read/write operations and kernel launch overhead on GPUs or TPUs, improving execution efficiency. For example, fusing a dense layer and a ReLU activation into a single fused kernel reduces latency and allows for more effective use of SIMD or CUDA cores, which are otherwise underutilized with fragmented ops.\n    \n*   **Speculative Decoding**: Speculative decoding accelerates autoregressive generation by using a lightweight draft model to predict multiple future tokens in a single forward pass. These candidate tokens are then validated in parallel by the full, slower model. If validated, they are accepted en masse; otherwise, the generation rolls back. This pipeline reduces the number of expensive full-model invocations while maintaining generation fidelity. Approaches like Draft and Target Models, Medusa, Self-Speculative Decoding, FastRAG, and NVIDIA’s Speculative Decoding with Prefill leverage this technique to boost throughput while preserving model output quality.\n    \n*   **FlashAttention and Efficient Attention Kernels**: FlashAttention is a memory-efficient attention algorithm that computes attention outputs in a tiled, fused, and GPU-friendly way, avoiding the need to materialize large intermediate attention matrices. It exploits GPU SRAM to keep frequently accessed blocks in high-speed memory and streams partial results to minimize memory bandwidth pressure. This approach scales better with sequence length and batch size than traditional softmax-based attention implementations. FlashAttention-2 and similar kernels (e.g., xFormers, Triton) are now standard in high-performance transformer inference stacks.\n    \n*   **Batching, Sequence Packing, and Prefilling**:\n*   **Batching** groups multiple inference requests into a single execution pass, maximizing GPU utilization, amortizing kernel launch overhead, and improving throughput. Dynamic batching adapts to incoming request patterns, while token-level batching (e.g., vLLM) synchronizes decoding steps to serve many requests concurrently without blocking new ones.\n*   **Sequence Packing** minimizes padding waste by concatenating multiple short sequences into a single sequence tensor within a batch element, using an attention mask to prevent cross-sequence attention. This increases the density of useful tokens processed per batch, reducing memory footprint and improving effective throughput, especially in workloads with highly variable sequence lengths.\n*   **Prefilling** precomputes the KV cache for all prompt tokens before autoregressive decoding begins, avoiding redundant computation during generation. Optimizations like fused prefill kernels, prompt sharing, and layer-wise streaming further reduce latency in the prompt phase, which is often the most expensive stage for long inputs. Together, these three techniques ensure high hardware utilization, lower padding overhead, and minimized per-token computation cost.\n    \n*   **Prompt Caching**: Caches the KV states of frequently used or repeated prompts—such as system instructions, few-shot exemplars, or user-defined templates—so they don’t need to be recomputed for each request. Particularly effective in chat or API-driven systems where the same initial context (e.g., “You are a helpful assistant…”) is used across sessions. By reusing prompt KV states, servers can skip prompt processing entirely and begin generation with the cache already initialized, significantly reducing time to first token and overall compute.\n    \n*   **Early Exit and Token Pruning**: Early exit allows transformer layers to terminate inference for specific tokens when confidence thresholds or entropy-based stopping criteria are met, saving computation on later layers. Token pruning dynamically removes tokens or attention paths deemed irrelevant during inference, based on learned importance scores or gating functions. These techniques reduce compute costs without heavily sacrificing model output quality, and are especially useful for deployment scenarios where speed is prioritized over full precision.\n    \n*   **Hardware-Aware Scheduling**: This optimization involves aligning inference workloads with the specifics of the underlying hardware—e.g., GPU memory hierarchy, tensor core availability, or pipeline concurrency. Scheduling strategies include operator placement, memory prefetching, stream prioritization, and load balancing across multi-GPU setups. For example, on NVIDIA GPUs, frameworks may utilize CUDA streams, shared memory, and kernel fusion to maximize throughput, while TPU inference may leverage XLA compilation for graph-level optimizations. Fine-tuned scheduling reduces contention, increases parallelism, and maximizes total inference throughput per watt.\n\n**KV Caching**: The KV cache in transformer models is a critical optimization that enhances the efficiency and speed of sequence generation, making it a key component for deploying these models in real-world applications. The use of KV caching in autoregressive decoding processes, along with its role in latency optimization and scalability, makes it indispensable for serving transformer-based models efficiently. It allows previously computed key and value projections from self-attention layers to be stored and reused during subsequent decoding steps, avoiding redundant computations. This dramatically reduces per-token inference time beyond the first token, supports long-sequence generation, and is essential for achieving low-latency, high-throughput serving in applications like chat, streaming, and interactive agents.\n\n**Model Quantization**: Model quantization reduces the precision of weights and activations from 32-bit floating-point (`float32`) to lower-bit formats such as `int8`, `float8`, or even 4-bit representations like `int4`. This significantly cuts memory footprint and bandwidth usage, enabling deployment on smaller hardware and increasing throughput. Post-training quantization (PTQ) and quantization-aware training (QAT) are two common approaches. Quantized models benefit from faster matrix multiplications and lower energy consumption, and modern toolchains (e.g., NVIDIA TensorRT, Intel Neural Compressor) support hardware acceleration for quantized ops with minimal accuracy degradation.\n\n**Operator Fusion**: Operator fusion consolidates multiple sequential operations—such as linear projections, bias addition, layer normalization, and activation functions—into a single computational kernel. This reduces the number of memory read/write operations and kernel launch overhead on GPUs or TPUs, improving execution efficiency. For example, fusing a dense layer and a ReLU activation into a single fused kernel reduces latency and allows for more effective use of SIMD or CUDA cores, which are otherwise underutilized with fragmented ops.\n\n**Speculative Decoding**: Speculative decoding accelerates autoregressive generation by using a lightweight draft model to predict multiple future tokens in a single forward pass. These candidate tokens are then validated in parallel by the full, slower model. If validated, they are accepted en masse; otherwise, the generation rolls back. This pipeline reduces the number of expensive full-model invocations while maintaining generation fidelity. Approaches like Draft and Target Models, Medusa, Self-Speculative Decoding, FastRAG, and NVIDIA’s Speculative Decoding with Prefill leverage this technique to boost throughput while preserving model output quality.\n\n**FlashAttention and Efficient Attention Kernels**: FlashAttention is a memory-efficient attention algorithm that computes attention outputs in a tiled, fused, and GPU-friendly way, avoiding the need to materialize large intermediate attention matrices. It exploits GPU SRAM to keep frequently accessed blocks in high-speed memory and streams partial results to minimize memory bandwidth pressure. This approach scales better with sequence length and batch size than traditional softmax-based attention implementations. FlashAttention-2 and similar kernels (e.g., xFormers, Triton) are now standard in high-performance transformer inference stacks.\n\n**Prefilling** precomputes the KV cache for all prompt tokens before autoregressive decoding begins, avoiding redundant computation during generation. Optimizations like fused prefill kernels, prompt sharing, and layer-wise streaming further reduce latency in the prompt phase, which is often the most expensive stage for long inputs. Together, these three techniques ensure high hardware utilization, lower padding overhead, and minimized per-token computation cost.\n\n**Prompt Caching**: Caches the KV states of frequently used or repeated prompts—such as system instructions, few-shot exemplars, or user-defined templates—so they don’t need to be recomputed for each request. Particularly effective in chat or API-driven systems where the same initial context (e.g., “You are a helpful assistant…”) is used across sessions. By reusing prompt KV states, servers can skip prompt processing entirely and begin generation with the cache already initialized, significantly reducing time to first token and overall compute.\n\n**Early Exit and Token Pruning**: Early exit allows transformer layers to terminate inference for specific tokens when confidence thresholds or entropy-based stopping criteria are met, saving computation on later layers. Token pruning dynamically removes tokens or attention paths deemed irrelevant during inference, based on learned importance scores or gating functions. These techniques reduce compute costs without heavily sacrificing model output quality, and are especially useful for deployment scenarios where speed is prioritized over full precision.",
    "contentLength": 21510,
    "wordCount": 2591,
    "hasCode": true,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/model-acceleration/#overview"
  },
  {
    "id": "ai-model-acceleration-kv-cache-10",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Inference Optimizations",
    "title": "KV Cache",
    "order": 10,
    "orderInChapter": 2,
    "contentHtml": "<h4 id=\"background-self-attention\">Background: Self-Attention</h4>\n<ul>\n  <li>\n    <p>In transformer models, each token attends to all previous tokens using a self-attention mechanism. For a sequence of input token embeddings <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-35-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>X</mi><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>T</mi><mo>&amp;#x22C5;</mo><mi>d</mi></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-234\" style=\"width: 4.586em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.805em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1003.8em, 2.451em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-235\"><span class=\"mi\" id=\"MathJax-Span-236\" style=\"font-family: STIXGeneral-Italic;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-237\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-238\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-239\"><span class=\"mrow\" id=\"MathJax-Span-240\"><span class=\"mi\" id=\"MathJax-Span-241\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-242\"><span class=\"mrow\" id=\"MathJax-Span-243\"><span class=\"mi\" id=\"MathJax-Span-244\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-245\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-246\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>X</mi><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>T</mi><mo>⋅</mo><mi>d</mi></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-35\">X \\in \\mathbb{R}^{T \\cdot d}</script>, the transformer computes:</p>\n\n    <ul>\n      <li>\n        <p><strong>Queries</strong>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>Q</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>Q</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-247\" style=\"width: 4.951em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.117em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.12em, 2.607em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-248\"><span class=\"mi\" id=\"MathJax-Span-249\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span class=\"mo\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-251\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-252\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-253\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-254\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>Q</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>Q</mi></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-36\">Q = X W_Q</script>\n      </li>\n      <li>\n        <p><strong>Keys</strong>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-37-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>K</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>K</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-255\" style=\"width: 5.003em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.17em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-256\"><span class=\"mi\" id=\"MathJax-Span-257\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-258\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-259\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-260\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-261\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-262\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>K</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>K</mi></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-37\">K = X W_K</script>\n      </li>\n      <li>\n        <p><strong>Values</strong>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>V</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>V</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-263\" style=\"width: 5.003em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.17em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-264\"><span class=\"mi\" id=\"MathJax-Span-265\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-266\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-267\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-268\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-269\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-270\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>V</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>V</mi></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-38\">V = X W_V</script>\n      </li>\n      <li>\n        <p>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>Q</mi></msub><mo>,</mo><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><msub><mi>W</mi><mi>V</mi></msub><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mo>&amp;#x22C5;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-271\" style=\"width: 10.107em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.388em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1008.39em, 2.659em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-272\"><span class=\"msubsup\" id=\"MathJax-Span-273\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-274\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-275\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-276\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-277\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-278\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-279\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-280\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-281\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-282\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-283\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-284\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-285\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.034em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-286\"><span class=\"mrow\" id=\"MathJax-Span-287\"><span class=\"mi\" id=\"MathJax-Span-288\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-289\"><span class=\"mrow\" id=\"MathJax-Span-290\"><span class=\"mi\" id=\"MathJax-Span-291\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-292\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-293\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-294\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-295\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.503em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>Q</mi></msub><mo>,</mo><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><msub><mi>W</mi><mi>V</mi></msub><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>d</mi><mo>⋅</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">W_Q, W_K, W_V \\in \\mathbb{R}^{d \\cdot d_k}</script> are learned projection matrices, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-40-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-296\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-297\"><span class=\"msubsup\" id=\"MathJax-Span-298\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-299\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-300\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-40\">d_k</script> is the head dimension.</p>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p>The attention output is given by:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-41-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>Attention</mtext><mo stretchy=&quot;false&quot;>(</mo><mi>Q</mi><mo>,</mo><mi>K</mi><mo>,</mo><mi>V</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo>(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi mathvariant=&quot;normal&quot;>&amp;#x22A4;</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo>)</mo></mrow><mi>V</mi></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-301\" style=\"width: 20.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(2.19em, 1017.29em, 5.576em, -999.997em); top: -4.112em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-302\"><span class=\"mtext\" id=\"MathJax-Span-303\" style=\"font-family: STIXGeneral-Regular;\">Attention</span><span class=\"mo\" id=\"MathJax-Span-304\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-305\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span class=\"mo\" id=\"MathJax-Span-306\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-307\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-308\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-309\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-310\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-311\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-312\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">softmax</span><span class=\"mrow\" id=\"MathJax-Span-313\" style=\"padding-left: 0.211em;\"><span class=\"mo\" id=\"MathJax-Span-314\" style=\"vertical-align: -0.779em;\"><span style=\"font-family: STIXSizeFourSym;\">(</span></span><span class=\"mfrac\" id=\"MathJax-Span-315\"><span style=\"display: inline-block; position: relative; width: 2.19em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.023em, 1002.09em, 4.326em, -999.997em); top: -4.685em; left: 50%; margin-left: -1.039em;\"><span class=\"mrow\" id=\"MathJax-Span-316\"><span class=\"mi\" id=\"MathJax-Span-317\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span class=\"msubsup\" id=\"MathJax-Span-318\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-319\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.784em;\"><span class=\"mi\" id=\"MathJax-Span-320\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⊤</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(2.971em, 1001.88em, 4.534em, -999.997em); top: -3.122em; left: 50%; margin-left: -0.935em;\"><span class=\"msqrt\" id=\"MathJax-Span-321\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.326em, -999.997em); top: -4.008em; left: 0.94em;\"><span class=\"mrow\" id=\"MathJax-Span-322\"><span class=\"msubsup\" id=\"MathJax-Span-323\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-324\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-325\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.023em, 1000.94em, 3.388em, -999.997em); top: -4.06em; left: 0.94em;\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; font-family: STIXGeneral-Regular; top: -4.008em; left: 0em;\">‾<span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; font-family: STIXGeneral-Regular; top: -4.008em; left: 0.419em;\">‾<span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(2.867em, 1000.94em, 4.43em, -999.997em); top: -3.904em; left: 0em;\"><span style=\"font-family: STIXGeneral-Regular;\">√</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1002.19em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.19em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-326\" style=\"vertical-align: -0.779em;\"><span style=\"font-family: STIXSizeFourSym;\">)</span></span></span><span class=\"mi\" id=\"MathJax-Span-327\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.117em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -1.622em; border-left: 0px solid; width: 0px; height: 3.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><mo>,</mo><mi>K</mi><mo>,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo>(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi mathvariant=\"normal\">⊤</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo>)</mo></mrow><mi>V</mi></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-41\">\\text{Attention}(Q, K, V) = \\text{softmax}\\left( \\frac{Q K^\\top}{\\sqrt{d_k}} \\right) V</script>\n  </li>\n  <li>\n    <p>In a naive implementation, for each decoding step we must compute <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-42-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-328\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-329\"><span class=\"mi\" id=\"MathJax-Span-330\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-42\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-43-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-331\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-332\"><span class=\"mi\" id=\"MathJax-Span-333\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-43\">V</script> for all tokens in the current sequence, across all layers. If <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-44-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-334\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-335\"><span class=\"mi\" id=\"MathJax-Span-336\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-44\">n</script> is the number of tokens so far and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-45-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-337\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-338\"><span class=\"mi\" id=\"MathJax-Span-339\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-45\">l</script> is the number of layers, this requires <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-46-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi><mo>&amp;#x00D7;</mo><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-340\" style=\"width: 4.951em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.117em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.07em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-341\"><span class=\"mi\" id=\"MathJax-Span-342\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-343\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mo\" id=\"MathJax-Span-344\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">(</span><span class=\"mi\" id=\"MathJax-Span-345\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-346\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"mn\" id=\"MathJax-Span-347\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-348\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi><mo>×</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-46\">l \\times (n−1)</script> matrix multiplications per step, each of cost <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-47-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-349\" style=\"width: 2.919em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.398em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1002.35em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-350\"><span class=\"mi\" id=\"MathJax-Span-351\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-352\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-353\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-354\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-355\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-356\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-47\">O(d^2)</script>, leading to:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-48-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>Cost per token</mtext><mo>=</mo><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-357\" style=\"width: 14.586em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 12.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1012.09em, 2.607em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-358\"><span class=\"mtext\" id=\"MathJax-Span-359\" style=\"font-family: STIXGeneral-Regular;\">Cost per token</span><span class=\"mo\" id=\"MathJax-Span-360\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-361\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">O</span><span class=\"mo\" id=\"MathJax-Span-362\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-363\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-364\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-365\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-366\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-367\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-368\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-369\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-370\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>Cost per token</mtext><mo>=</mo><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-48\">\\text{Cost per token} = O(l \\cdot n \\cdot d^2)</script>\n  </li>\n  <li>\n    <p>A detailed discourse on self-attention is available in our <a href=\"../transformers\">Transformers</a> primer.</p>\n  </li>\n</ul>\n<p>In transformer models, each token attends to all previous tokens using a self-attention mechanism. For a sequence of input token embeddings <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-35-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>X</mi><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>T</mi><mo>&amp;#x22C5;</mo><mi>d</mi></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-234\" style=\"width: 4.586em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.805em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1003.8em, 2.451em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-235\"><span class=\"mi\" id=\"MathJax-Span-236\" style=\"font-family: STIXGeneral-Italic;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-237\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-238\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-239\"><span class=\"mrow\" id=\"MathJax-Span-240\"><span class=\"mi\" id=\"MathJax-Span-241\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-242\"><span class=\"mrow\" id=\"MathJax-Span-243\"><span class=\"mi\" id=\"MathJax-Span-244\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-245\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-246\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>X</mi><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>T</mi><mo>⋅</mo><mi>d</mi></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-35\">X \\in \\mathbb{R}^{T \\cdot d}</script>, the transformer computes:</p>\n<ul>\n      <li>\n        <p><strong>Queries</strong>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>Q</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>Q</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-247\" style=\"width: 4.951em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.117em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.12em, 2.607em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-248\"><span class=\"mi\" id=\"MathJax-Span-249\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span class=\"mo\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-251\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-252\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-253\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-254\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>Q</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>Q</mi></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-36\">Q = X W_Q</script>\n      </li>\n      <li>\n        <p><strong>Keys</strong>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-37-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>K</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>K</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-255\" style=\"width: 5.003em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.17em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-256\"><span class=\"mi\" id=\"MathJax-Span-257\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-258\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-259\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-260\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-261\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-262\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>K</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>K</mi></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-37\">K = X W_K</script>\n      </li>\n      <li>\n        <p><strong>Values</strong>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>V</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>V</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-263\" style=\"width: 5.003em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.169em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.17em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-264\"><span class=\"mi\" id=\"MathJax-Span-265\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-266\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-267\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-268\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-269\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-270\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>V</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>V</mi></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-38\">V = X W_V</script>\n      </li>\n      <li>\n        <p>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>Q</mi></msub><mo>,</mo><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><msub><mi>W</mi><mi>V</mi></msub><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mo>&amp;#x22C5;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-271\" style=\"width: 10.107em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.388em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1008.39em, 2.659em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-272\"><span class=\"msubsup\" id=\"MathJax-Span-273\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-274\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-275\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-276\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-277\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-278\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-279\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-280\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-281\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-282\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-283\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-284\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-285\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.034em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-286\"><span class=\"mrow\" id=\"MathJax-Span-287\"><span class=\"mi\" id=\"MathJax-Span-288\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-289\"><span class=\"mrow\" id=\"MathJax-Span-290\"><span class=\"mi\" id=\"MathJax-Span-291\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-292\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-293\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-294\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-295\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.503em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>Q</mi></msub><mo>,</mo><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><msub><mi>W</mi><mi>V</mi></msub><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>d</mi><mo>⋅</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">W_Q, W_K, W_V \\in \\mathbb{R}^{d \\cdot d_k}</script> are learned projection matrices, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-40-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-296\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-297\"><span class=\"msubsup\" id=\"MathJax-Span-298\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-299\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-300\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-40\">d_k</script> is the head dimension.</p>\n      </li>\n    </ul>\n<p><strong>Queries</strong>:</p>\n<p><strong>Keys</strong>:</p>\n<p><strong>Values</strong>:</p>\n<p>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>Q</mi></msub><mo>,</mo><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><msub><mi>W</mi><mi>V</mi></msub><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>d</mi><mo>&amp;#x22C5;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-271\" style=\"width: 10.107em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.388em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1008.39em, 2.659em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-272\"><span class=\"msubsup\" id=\"MathJax-Span-273\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-274\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-275\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-276\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-277\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-278\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-279\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-280\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-281\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-282\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-283\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-284\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-285\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.034em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-286\"><span class=\"mrow\" id=\"MathJax-Span-287\"><span class=\"mi\" id=\"MathJax-Span-288\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-289\"><span class=\"mrow\" id=\"MathJax-Span-290\"><span class=\"mi\" id=\"MathJax-Span-291\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-292\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-293\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-294\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-295\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.503em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>Q</mi></msub><mo>,</mo><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><msub><mi>W</mi><mi>V</mi></msub><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>d</mi><mo>⋅</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">W_Q, W_K, W_V \\in \\mathbb{R}^{d \\cdot d_k}</script> are learned projection matrices, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-40-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-296\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-297\"><span class=\"msubsup\" id=\"MathJax-Span-298\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-299\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-300\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-40\">d_k</script> is the head dimension.</p>\n<p>The attention output is given by:</p>\n<p>In a naive implementation, for each decoding step we must compute <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-42-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-328\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-329\"><span class=\"mi\" id=\"MathJax-Span-330\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-42\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-43-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-331\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-332\"><span class=\"mi\" id=\"MathJax-Span-333\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-43\">V</script> for all tokens in the current sequence, across all layers. If <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-44-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-334\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-335\"><span class=\"mi\" id=\"MathJax-Span-336\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-44\">n</script> is the number of tokens so far and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-45-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-337\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-338\"><span class=\"mi\" id=\"MathJax-Span-339\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-45\">l</script> is the number of layers, this requires <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-46-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi><mo>&amp;#x00D7;</mo><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-340\" style=\"width: 4.951em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.117em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.07em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-341\"><span class=\"mi\" id=\"MathJax-Span-342\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-343\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mo\" id=\"MathJax-Span-344\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">(</span><span class=\"mi\" id=\"MathJax-Span-345\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-346\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"mn\" id=\"MathJax-Span-347\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-348\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi><mo>×</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-46\">l \\times (n−1)</script> matrix multiplications per step, each of cost <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-47-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-349\" style=\"width: 2.919em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.398em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1002.35em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-350\"><span class=\"mi\" id=\"MathJax-Span-351\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-352\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-353\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-354\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-355\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-356\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-47\">O(d^2)</script>, leading to:</p>\n<p>A detailed discourse on self-attention is available in our <a href=\"../transformers\">Transformers</a> primer.</p>\n<h4 id=\"motivation\">Motivation</h4>\n<ul>\n  <li>In the context of serving transformer models, the <strong>Key-Value (KV) cache</strong> is a core optimization technique that dramatically improves the efficiency of autoregressive decoding. It stores intermediate attention computations from previous decoding steps—specifically, the key and value tensors produced within the self-attention mechanism—so they do not need to be recomputed at every new generation step. This reduces both inference time and redundant memory access, making long-form generation feasible for LLMs.</li>\n</ul>\n<h5 id=\"the-problem-quadratic-recomputation-in-naive-generation\">The Problem: Quadratic Recomputation in Naive Generation</h5>\n<ul>\n  <li>\n    <p>During autoregressive generation, each new token depends on all previously generated tokens.\nIn a <strong>naive transformer implementation</strong>, the model recomputes the key <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-49-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-371\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-372\"><span class=\"mi\" id=\"MathJax-Span-373\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-49\">K</script> and value <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-50-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-374\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-375\"><span class=\"mi\" id=\"MathJax-Span-376\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-50\">V</script> representations for <strong>all tokens</strong> in the sequence at every decoding step and across all layers. This quickly becomes computationally expensive, since the total cost per predicted token for a single attention head is:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-51-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-377\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-378\"><span class=\"mi\" id=\"MathJax-Span-379\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-380\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-381\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-382\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-383\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-384\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-385\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-386\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-387\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-388\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-51\">O(l \\cdot n \\cdot d^2)</script>\n\n    <ul>\n      <li>\n        <p>where:</p>\n\n        <ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-52-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-389\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-390\"><span class=\"mi\" id=\"MathJax-Span-391\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-52\">n</script> = number of tokens seen so far (sequence length)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-53-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-392\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-393\"><span class=\"mi\" id=\"MathJax-Span-394\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-53\">l</script> = number of layers (depth)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-54-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-395\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-396\"><span class=\"mi\" id=\"MathJax-Span-397\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-54\">d</script> = model (embedding) dimension</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p>Without caching, predicting each new token involves:</p>\n\n    <ol>\n      <li>Computing the key and value matrices for all past tokens and for every layer.</li>\n      <li>\n        <p>Performing matrix multiplications of the form:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-55-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>K</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><mspace width=&quot;1em&quot; /><mi>V</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>V</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-398\" style=\"width: 11.982em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 9.951em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1009.95em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-399\"><span class=\"mi\" id=\"MathJax-Span-400\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-401\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-402\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-403\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-404\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-405\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-406\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mspace\" id=\"MathJax-Span-407\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"mi\" id=\"MathJax-Span-408\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-409\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-410\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-411\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-412\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-413\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>K</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><mspace width=\"1em\"></mspace><mi>V</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>V</mi></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-55\">K = X W_K, \\quad V = X W_V</script>\n\n        <ul>\n          <li>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-56-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>X</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-414\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-415\"><span class=\"mi\" id=\"MathJax-Span-416\" style=\"font-family: STIXGeneral-Italic;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>X</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-56\">X</script> is the layer input, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-57-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>K</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-417\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-418\"><span class=\"msubsup\" id=\"MathJax-Span-419\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-420\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-421\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>K</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-57\">W_K</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-58-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>V</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-422\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-423\"><span class=\"msubsup\" id=\"MathJax-Span-424\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-425\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-426\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>V</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-58\">W_V</script> are fixed weight matrices.</li>\n        </ul>\n      </li>\n    </ol>\n  </li>\n</ul>\n<p>During autoregressive generation, each new token depends on all previously generated tokens.\nIn a <strong>naive transformer implementation</strong>, the model recomputes the key <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-49-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-371\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-372\"><span class=\"mi\" id=\"MathJax-Span-373\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-49\">K</script> and value <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-50-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-374\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-375\"><span class=\"mi\" id=\"MathJax-Span-376\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-50\">V</script> representations for <strong>all tokens</strong> in the sequence at every decoding step and across all layers. This quickly becomes computationally expensive, since the total cost per predicted token for a single attention head is:</p>\n<ul>\n      <li>\n        <p>where:</p>\n\n        <ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-52-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-389\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-390\"><span class=\"mi\" id=\"MathJax-Span-391\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-52\">n</script> = number of tokens seen so far (sequence length)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-53-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-392\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-393\"><span class=\"mi\" id=\"MathJax-Span-394\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-53\">l</script> = number of layers (depth)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-54-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-395\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-396\"><span class=\"mi\" id=\"MathJax-Span-397\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-54\">d</script> = model (embedding) dimension</li>\n        </ul>\n      </li>\n    </ul>\n<p>where:</p>\n<ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-52-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-389\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-390\"><span class=\"mi\" id=\"MathJax-Span-391\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-52\">n</script> = number of tokens seen so far (sequence length)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-53-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-392\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-393\"><span class=\"mi\" id=\"MathJax-Span-394\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-53\">l</script> = number of layers (depth)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-54-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-395\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-396\"><span class=\"mi\" id=\"MathJax-Span-397\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-54\">d</script> = model (embedding) dimension</li>\n        </ul>\n<p>Without caching, predicting each new token involves:</p>\n<ol>\n      <li>Computing the key and value matrices for all past tokens and for every layer.</li>\n      <li>\n        <p>Performing matrix multiplications of the form:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-55-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>K</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><mspace width=&quot;1em&quot; /><mi>V</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>V</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-398\" style=\"width: 11.982em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 9.951em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1009.95em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-399\"><span class=\"mi\" id=\"MathJax-Span-400\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-401\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-402\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-403\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-404\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-405\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-406\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mspace\" id=\"MathJax-Span-407\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"mi\" id=\"MathJax-Span-408\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-409\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-410\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-411\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-412\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-413\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>K</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><mspace width=\"1em\"></mspace><mi>V</mi><mo>=</mo><mi>X</mi><msub><mi>W</mi><mi>V</mi></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-55\">K = X W_K, \\quad V = X W_V</script>\n\n        <ul>\n          <li>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-56-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>X</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-414\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-415\"><span class=\"mi\" id=\"MathJax-Span-416\" style=\"font-family: STIXGeneral-Italic;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>X</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-56\">X</script> is the layer input, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-57-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>K</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-417\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-418\"><span class=\"msubsup\" id=\"MathJax-Span-419\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-420\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-421\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>K</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-57\">W_K</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-58-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>V</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-422\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-423\"><span class=\"msubsup\" id=\"MathJax-Span-424\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-425\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-426\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>V</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-58\">W_V</script> are fixed weight matrices.</li>\n        </ul>\n      </li>\n    </ol>\n<p>Performing matrix multiplications of the form:</p>\n<ul>\n          <li>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-56-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>X</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-414\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-415\"><span class=\"mi\" id=\"MathJax-Span-416\" style=\"font-family: STIXGeneral-Italic;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>X</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-56\">X</script> is the layer input, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-57-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>K</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-417\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-418\"><span class=\"msubsup\" id=\"MathJax-Span-419\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-420\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-421\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>K</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-57\">W_K</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-58-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>V</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-422\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-423\"><span class=\"msubsup\" id=\"MathJax-Span-424\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-425\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-426\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>V</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-58\">W_V</script> are fixed weight matrices.</li>\n        </ul>\n<h5 id=\"why-naive-generation-fails\">Why Naive Generation Fails</h5>\n<ul>\n  <li>KV caching fundamentally <strong>solves the quadratic recomputation problem</strong> that arises from this naive approach.</li>\n  <li>\n    <p>Without a KV cache, generating even a 100-token response leads to massive redundant computation:</p>\n\n    <ul>\n      <li><strong>Token 1:</strong> compute attention over 1000 context tokens</li>\n      <li><strong>Token 2:</strong> recompute attention over all 1001 tokens</li>\n      <li><strong>Token 100:</strong> recompute attention over all 1099 tokens</li>\n    </ul>\n  </li>\n  <li>The total number of attention computations can be derived from the arithmetic sum of all attention lengths per decoding step:</li>\n</ul>\n<p>Without a KV cache, generating even a 100-token response leads to massive redundant computation:</p>\n<ul>\n      <li><strong>Token 1:</strong> compute attention over 1000 context tokens</li>\n      <li><strong>Token 2:</strong> recompute attention over all 1001 tokens</li>\n      <li><strong>Token 100:</strong> recompute attention over all 1099 tokens</li>\n    </ul>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-59-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><munderover><mo>&amp;#x2211;</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>100</mn></mrow></munderover><mo stretchy=&quot;false&quot;>(</mo><mn>1000</mn><mo>+</mo><mi>t</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mn>1000</mn><mo>&amp;#x00D7;</mo><mn>100</mn><mo>+</mo><mfrac><mrow><mn>100</mn><mo>&amp;#x00D7;</mo><mn>99</mn></mrow><mn>2</mn></mfrac><mo>=</mo><mn>55,000</mn></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-427\" style=\"width: 26.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 21.773em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(0.263em, 1021.77em, 3.596em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-428\"><span class=\"munderover\" id=\"MathJax-Span-429\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(2.867em, 1001.2em, 4.638em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-430\" style=\"font-family: STIXSizeOneSym; vertical-align: -0.518em;\">∑</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.99em, 4.273em, -999.997em); top: -2.862em; left: 0.107em;\"><span class=\"texatom\" id=\"MathJax-Span-431\"><span class=\"mrow\" id=\"MathJax-Span-432\"><span class=\"mi\" id=\"MathJax-Span-433\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-434\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">=</span><span class=\"mn\" id=\"MathJax-Span-435\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.284em, 1001.04em, 4.169em, -999.997em); top: -5.206em; left: 0.107em;\"><span class=\"texatom\" id=\"MathJax-Span-436\"><span class=\"mrow\" id=\"MathJax-Span-437\"><span class=\"mn\" id=\"MathJax-Span-438\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">100</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-439\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mn\" id=\"MathJax-Span-440\" style=\"font-family: STIXGeneral-Regular;\">1000</span><span class=\"mo\" id=\"MathJax-Span-441\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-442\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-443\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"mn\" id=\"MathJax-Span-444\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-445\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-446\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-447\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1000</span><span class=\"mo\" id=\"MathJax-Span-448\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-449\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">100</span><span class=\"mo\" id=\"MathJax-Span-450\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mfrac\" id=\"MathJax-Span-451\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 3.805em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.18em, 1003.65em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -1.82em;\"><span class=\"mrow\" id=\"MathJax-Span-452\"><span class=\"mn\" id=\"MathJax-Span-453\" style=\"font-family: STIXGeneral-Regular;\">100</span><span class=\"mo\" id=\"MathJax-Span-454\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-455\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">99</span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.258em;\"><span class=\"mn\" id=\"MathJax-Span-456\" style=\"font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1003.8em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 3.805em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-457\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-458\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">55,000</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -1.559em; border-left: 0px solid; width: 0px; height: 3.753em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><munderover><mo>∑</mo><mrow class=\"MJX-TeXAtom-ORD\"><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mn>100</mn></mrow></munderover><mo stretchy=\"false\">(</mo><mn>1000</mn><mo>+</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1000</mn><mo>×</mo><mn>100</mn><mo>+</mo><mfrac><mrow><mn>100</mn><mo>×</mo><mn>99</mn></mrow><mn>2</mn></mfrac><mo>=</mo><mn>55,000</mn></math></span></span></div>\n<ul>\n  <li>\n    <p>Here’s what each term means:</p>\n\n    <ul>\n      <li>The <strong>1000</strong> represents the fixed-length context available before generation begins (e.g., the prompt).</li>\n      <li>The <strong>(t − 1)</strong> accounts for the number of <strong>previously generated tokens</strong> already added before generating token <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-60-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-459\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-460\"><span class=\"mi\" id=\"MathJax-Span-461\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-60\">t</script>. At step <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-61-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-462\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-463\"><span class=\"mi\" id=\"MathJax-Span-464\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-61\">t</script>, the model has already generated <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-62-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>&amp;#x2212;</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-465\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.77em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-466\"><span class=\"mi\" id=\"MathJax-Span-467\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-468\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"mn\" id=\"MathJax-Span-469\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>−</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-62\">t - 1</script> new tokens on top of the initial context, so it must now attend to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-63-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>1000</mn><mo>+</mo><mo stretchy=&quot;false&quot;>(</mo><mi>t</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-470\" style=\"width: 6.773em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.58em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-471\"><span class=\"mn\" id=\"MathJax-Span-472\" style=\"font-family: STIXGeneral-Regular;\">1000</span><span class=\"mo\" id=\"MathJax-Span-473\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mo\" id=\"MathJax-Span-474\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">(</span><span class=\"mi\" id=\"MathJax-Span-475\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-476\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"mn\" id=\"MathJax-Span-477\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-478\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>1000</mn><mo>+</mo><mo stretchy=\"false\">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-63\">1000 + (t - 1)</script> total tokens.</li>\n      <li>The summation over all 100 decoding steps gives the total number of attention operations across the full generation.</li>\n    </ul>\n  </li>\n  <li>\n    <p>Thus, to generate 100 tokens, the model performs approximately <strong>55,000 redundant attention computations</strong> — most of which are recomputations of previously calculated keys and values.</p>\n  </li>\n  <li>\n    <p>The inefficiency is striking:</p>\n\n    <blockquote>\n      <p>Without KV cache: 100 output tokens = ~55,000 attention operations\nWith KV cache: 100 output tokens = 100 attention operations (≈550× reduction)</p>\n    </blockquote>\n  </li>\n  <li>\n    <p>This highlights the key trade-off: <strong>KV caching exchanges memory usage for compute savings</strong>. By storing previously computed keys and values, the model avoids redoing work it has already completed—unlocking massive gains in speed and scalability.</p>\n  </li>\n</ul>\n<p>Here’s what each term means:</p>\n<ul>\n      <li>The <strong>1000</strong> represents the fixed-length context available before generation begins (e.g., the prompt).</li>\n      <li>The <strong>(t − 1)</strong> accounts for the number of <strong>previously generated tokens</strong> already added before generating token <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-60-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-459\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-460\"><span class=\"mi\" id=\"MathJax-Span-461\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-60\">t</script>. At step <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-61-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-462\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-463\"><span class=\"mi\" id=\"MathJax-Span-464\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-61\">t</script>, the model has already generated <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-62-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>&amp;#x2212;</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-465\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.77em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-466\"><span class=\"mi\" id=\"MathJax-Span-467\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-468\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"mn\" id=\"MathJax-Span-469\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>−</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-62\">t - 1</script> new tokens on top of the initial context, so it must now attend to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-63-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>1000</mn><mo>+</mo><mo stretchy=&quot;false&quot;>(</mo><mi>t</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-470\" style=\"width: 6.773em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.58em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-471\"><span class=\"mn\" id=\"MathJax-Span-472\" style=\"font-family: STIXGeneral-Regular;\">1000</span><span class=\"mo\" id=\"MathJax-Span-473\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mo\" id=\"MathJax-Span-474\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">(</span><span class=\"mi\" id=\"MathJax-Span-475\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-476\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"mn\" id=\"MathJax-Span-477\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-478\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>1000</mn><mo>+</mo><mo stretchy=\"false\">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-63\">1000 + (t - 1)</script> total tokens.</li>\n      <li>The summation over all 100 decoding steps gives the total number of attention operations across the full generation.</li>\n    </ul>\n<p>Thus, to generate 100 tokens, the model performs approximately <strong>55,000 redundant attention computations</strong> — most of which are recomputations of previously calculated keys and values.</p>\n<p>The inefficiency is striking:</p>\n<blockquote>\n      <p>Without KV cache: 100 output tokens = ~55,000 attention operations\nWith KV cache: 100 output tokens = 100 attention operations (≈550× reduction)</p>\n    </blockquote>\n<p>Without KV cache: 100 output tokens = ~55,000 attention operations\nWith KV cache: 100 output tokens = 100 attention operations (≈550× reduction)</p>\n<p>This highlights the key trade-off: <strong>KV caching exchanges memory usage for compute savings</strong>. By storing previously computed keys and values, the model avoids redoing work it has already completed—unlocking massive gains in speed and scalability.</p>\n<h5 id=\"the-solution-reusing-cached-representations\">The Solution: Reusing Cached Representations</h5>\n<ul>\n  <li>\n    <p>The KV cache optimization addresses this problem by <strong>reusing previously computed <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-64-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-479\" style=\"width: 0.932em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.777em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.78em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-480\"><span class=\"mi\" id=\"MathJax-Span-481\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.054em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-64\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-65-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-482\" style=\"width: 0.932em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.777em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.78em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-483\"><span class=\"mi\" id=\"MathJax-Span-484\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.054em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-65\">V</script></strong> representations for all past tokens. Instead of recalculating them every time a new token is generated, the model simply:</p>\n\n    <ul>\n      <li>Reuses cached <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-66-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-485\" style=\"width: 3.596em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.971em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.97em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-486\"><span class=\"msubsup\" id=\"MathJax-Span-487\"><span style=\"display: inline-block; position: relative; width: 2.971em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-488\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-489\"><span class=\"mrow\" id=\"MathJax-Span-490\"><span class=\"mn\" id=\"MathJax-Span-491\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-492\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mo\" id=\"MathJax-Span-493\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-494\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-495\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-496\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-497\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-66\">K_{1:(n-1)}</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-67-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-498\" style=\"width: 3.544em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.919em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.92em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-499\"><span class=\"msubsup\" id=\"MathJax-Span-500\"><span style=\"display: inline-block; position: relative; width: 2.919em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-501\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-502\"><span class=\"mrow\" id=\"MathJax-Span-503\"><span class=\"mn\" id=\"MathJax-Span-504\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-505\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mo\" id=\"MathJax-Span-506\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-507\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-508\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-509\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-510\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-67\">V_{1:(n-1)}</script>,</li>\n      <li>Computes only the new <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-68-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>k</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-511\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-512\"><span class=\"msubsup\" id=\"MathJax-Span-513\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-514\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-515\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>k</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-68\">k_t</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-69-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>v</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-516\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-517\"><span class=\"msubsup\" id=\"MathJax-Span-518\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-519\" style=\"font-family: STIXGeneral-Italic;\">v</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-520\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>v</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-69\">v_t</script> for the current token,</li>\n      <li>And appends them to the cache.</li>\n    </ul>\n  </li>\n  <li>\n    <p>This approach effectively removes redundant computation, changing the per-step cost from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-70-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo><mspace width=&quot;1em&quot; /><mtext>to</mtext><mspace width=&quot;1em&quot; /><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-521\" style=\"width: 13.753em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 11.461em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1011.46em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-522\"><span class=\"mi\" id=\"MathJax-Span-523\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-524\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-525\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-526\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-527\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-528\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-529\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-530\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-531\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-532\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mspace\" id=\"MathJax-Span-533\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"mtext\" id=\"MathJax-Span-534\" style=\"font-family: STIXGeneral-Regular;\">to</span><span class=\"mspace\" id=\"MathJax-Span-535\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"mi\" id=\"MathJax-Span-536\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-537\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-538\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-539\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-540\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-541\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-542\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo><mspace width=\"1em\"></mspace><mtext>to</mtext><mspace width=\"1em\"></mspace><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-70\">O(l \\cdot n \\cdot d^2) \\quad \\text{to} \\quad O(l \\cdot d^2</script>—an <strong><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-71-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-543\" style=\"width: 0.622em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.519em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.552em, 1000.47em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-544\"><span class=\"mi\" id=\"MathJax-Span-545\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-71\">n</script>-times speedup</strong> in the sequence dimension.</p>\n  </li>\n  <li>\n    <p>The following figure (<a href=\"https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html\">source</a>) illustrates a typical self-attentioblock in transformers:</p>\n  </li>\n</ul>\n<p>The KV cache optimization addresses this problem by <strong>reusing previously computed <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-64-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-479\" style=\"width: 0.932em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.777em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.78em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-480\"><span class=\"mi\" id=\"MathJax-Span-481\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.054em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-64\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-65-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-482\" style=\"width: 0.932em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.777em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.78em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-483\"><span class=\"mi\" id=\"MathJax-Span-484\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.054em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-65\">V</script></strong> representations for all past tokens. Instead of recalculating them every time a new token is generated, the model simply:</p>\n<ul>\n      <li>Reuses cached <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-66-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-485\" style=\"width: 3.596em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.971em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.97em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-486\"><span class=\"msubsup\" id=\"MathJax-Span-487\"><span style=\"display: inline-block; position: relative; width: 2.971em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-488\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-489\"><span class=\"mrow\" id=\"MathJax-Span-490\"><span class=\"mn\" id=\"MathJax-Span-491\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-492\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mo\" id=\"MathJax-Span-493\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-494\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-495\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-496\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-497\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-66\">K_{1:(n-1)}</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-67-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-498\" style=\"width: 3.544em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.919em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.92em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-499\"><span class=\"msubsup\" id=\"MathJax-Span-500\"><span style=\"display: inline-block; position: relative; width: 2.919em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-501\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-502\"><span class=\"mrow\" id=\"MathJax-Span-503\"><span class=\"mn\" id=\"MathJax-Span-504\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-505\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mo\" id=\"MathJax-Span-506\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-507\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-508\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-509\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-510\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-67\">V_{1:(n-1)}</script>,</li>\n      <li>Computes only the new <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-68-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>k</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-511\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-512\"><span class=\"msubsup\" id=\"MathJax-Span-513\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-514\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-515\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>k</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-68\">k_t</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-69-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>v</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-516\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-517\"><span class=\"msubsup\" id=\"MathJax-Span-518\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-519\" style=\"font-family: STIXGeneral-Italic;\">v</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-520\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>v</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-69\">v_t</script> for the current token,</li>\n      <li>And appends them to the cache.</li>\n    </ul>\n<p>This approach effectively removes redundant computation, changing the per-step cost from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-70-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo><mspace width=&quot;1em&quot; /><mtext>to</mtext><mspace width=&quot;1em&quot; /><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-521\" style=\"width: 13.753em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 11.461em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1011.46em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-522\"><span class=\"mi\" id=\"MathJax-Span-523\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-524\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-525\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-526\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-527\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-528\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-529\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-530\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-531\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-532\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mspace\" id=\"MathJax-Span-533\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"mtext\" id=\"MathJax-Span-534\" style=\"font-family: STIXGeneral-Regular;\">to</span><span class=\"mspace\" id=\"MathJax-Span-535\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"mi\" id=\"MathJax-Span-536\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-537\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-538\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-539\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-540\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-541\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-542\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo><mspace width=\"1em\"></mspace><mtext>to</mtext><mspace width=\"1em\"></mspace><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-70\">O(l \\cdot n \\cdot d^2) \\quad \\text{to} \\quad O(l \\cdot d^2</script>—an <strong><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-71-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-543\" style=\"width: 0.622em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.519em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.552em, 1000.47em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-544\"><span class=\"mi\" id=\"MathJax-Span-545\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-71\">n</script>-times speedup</strong> in the sequence dimension.</p>\n<p>The following figure (<a href=\"https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html\">source</a>) illustrates a typical self-attentioblock in transformers:</p>\n<p><img src=\"/primers/ai/assets/model-acceleration/SA.jpg\" alt=\"Self-Attention Block\"></p>\n<h5 id=\"why-this-matters\">Why This Matters</h5>\n<ul>\n  <li>This improvement is especially critical for long sequences, where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-72-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-546\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-547\"><span class=\"mi\" id=\"MathJax-Span-548\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-72\">n</script> can reach thousands or even millions of tokens. Without caching, latency would scale quadratically with sequence length, quickly becoming impractical.\nWith KV caching, inference scales linearly, enabling efficient streaming and low-latency text generation for modern LLMs.</li>\n</ul>\n<h4 id=\"structure-and-size-of-the-kv-cache\">Structure and Size of the KV Cache</h4>\n<ul>\n  <li>The KV cache stores the key and value tensors for each transformer layer, attention head, the sample indices within each batch, and the token prefix length (i.e., the number of tokens already processed, including the prompt and any previously generated tokens, not just the immediate past token).</li>\n  <li>\n    <p>Assuming a transformer with:</p>\n\n    <ul>\n      <li>Sequence length so far: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-73-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-549\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-550\"><span class=\"mi\" id=\"MathJax-Span-551\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-73\">n</script></li>\n      <li>Number of layers: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-74-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-552\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-553\"><span class=\"mi\" id=\"MathJax-Span-554\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-74\">l</script></li>\n      <li>Number of attention heads per layer: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-75-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>h</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-555\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-556\"><span class=\"mi\" id=\"MathJax-Span-557\" style=\"font-family: STIXGeneral-Italic;\">h</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>h</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-75\">h</script></li>\n      <li>Head dimension: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-76-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-558\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-559\"><span class=\"msubsup\" id=\"MathJax-Span-560\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-561\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-562\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-76\">d_k</script></li>\n      <li>Batch size: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-77-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>b</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-563\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-564\"><span class=\"mi\" id=\"MathJax-Span-565\" style=\"font-family: STIXGeneral-Italic;\">b</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>b</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-77\">b</script></li>\n    </ul>\n  </li>\n  <li>\n    <p>The KV cache for the above setup would consist of two main tensors per layer:</p>\n\n    <ol>\n      <li>\n        <p>A <strong>key tensor</strong> of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-78-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-566\" style=\"width: 5.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.43em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.38em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-567\"><span class=\"mo\" id=\"MathJax-Span-568\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-569\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mo\" id=\"MathJax-Span-570\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-571\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">h</span><span class=\"mo\" id=\"MathJax-Span-572\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-573\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">n</span><span class=\"mo\" id=\"MathJax-Span-574\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-575\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-576\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-577\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-578\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-78\">(b, h, n, d_k)</script>, which stores the projected keys <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-79-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-579\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-580\"><span class=\"mi\" id=\"MathJax-Span-581\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-79\">K</script> for all past tokens.</p>\n      </li>\n      <li>\n        <p>A <strong>value tensor</strong> of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-80-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-582\" style=\"width: 5.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.43em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.38em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-583\"><span class=\"mo\" id=\"MathJax-Span-584\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-585\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mo\" id=\"MathJax-Span-586\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-587\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">h</span><span class=\"mo\" id=\"MathJax-Span-588\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-589\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">n</span><span class=\"mo\" id=\"MathJax-Span-590\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-591\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-592\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-593\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-594\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-80\">(b, h, n, d_k)</script> which stores the projected values <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-81-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-595\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-596\"><span class=\"mi\" id=\"MathJax-Span-597\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-81\">V</script> for all past tokens.</p>\n      </li>\n    </ol>\n  </li>\n  <li>Since each layer requires its own copy of both (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-82-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-598\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-599\"><span class=\"mi\" id=\"MathJax-Span-600\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-82\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-83-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-601\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-602\"><span class=\"mi\" id=\"MathJax-Span-603\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-83\">V</script>) tensors, the total number of stored elements is:</li>\n</ul>\n<p>Assuming a transformer with:</p>\n<ul>\n      <li>Sequence length so far: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-73-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-549\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-550\"><span class=\"mi\" id=\"MathJax-Span-551\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-73\">n</script></li>\n      <li>Number of layers: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-74-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-552\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-553\"><span class=\"mi\" id=\"MathJax-Span-554\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-74\">l</script></li>\n      <li>Number of attention heads per layer: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-75-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>h</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-555\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-556\"><span class=\"mi\" id=\"MathJax-Span-557\" style=\"font-family: STIXGeneral-Italic;\">h</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>h</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-75\">h</script></li>\n      <li>Head dimension: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-76-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-558\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-559\"><span class=\"msubsup\" id=\"MathJax-Span-560\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-561\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-562\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-76\">d_k</script></li>\n      <li>Batch size: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-77-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>b</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-563\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-564\"><span class=\"mi\" id=\"MathJax-Span-565\" style=\"font-family: STIXGeneral-Italic;\">b</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>b</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-77\">b</script></li>\n    </ul>\n<p>The KV cache for the above setup would consist of two main tensors per layer:</p>\n<ol>\n      <li>\n        <p>A <strong>key tensor</strong> of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-78-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-566\" style=\"width: 5.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.43em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.38em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-567\"><span class=\"mo\" id=\"MathJax-Span-568\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-569\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mo\" id=\"MathJax-Span-570\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-571\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">h</span><span class=\"mo\" id=\"MathJax-Span-572\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-573\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">n</span><span class=\"mo\" id=\"MathJax-Span-574\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-575\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-576\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-577\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-578\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-78\">(b, h, n, d_k)</script>, which stores the projected keys <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-79-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-579\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-580\"><span class=\"mi\" id=\"MathJax-Span-581\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-79\">K</script> for all past tokens.</p>\n      </li>\n      <li>\n        <p>A <strong>value tensor</strong> of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-80-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-582\" style=\"width: 5.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.43em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.38em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-583\"><span class=\"mo\" id=\"MathJax-Span-584\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-585\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mo\" id=\"MathJax-Span-586\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-587\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">h</span><span class=\"mo\" id=\"MathJax-Span-588\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-589\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">n</span><span class=\"mo\" id=\"MathJax-Span-590\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-591\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-592\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-593\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-594\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-80\">(b, h, n, d_k)</script> which stores the projected values <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-81-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-595\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-596\"><span class=\"mi\" id=\"MathJax-Span-597\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-81\">V</script> for all past tokens.</p>\n      </li>\n    </ol>\n<p>A <strong>key tensor</strong> of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-78-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-566\" style=\"width: 5.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.43em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.38em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-567\"><span class=\"mo\" id=\"MathJax-Span-568\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-569\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mo\" id=\"MathJax-Span-570\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-571\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">h</span><span class=\"mo\" id=\"MathJax-Span-572\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-573\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">n</span><span class=\"mo\" id=\"MathJax-Span-574\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-575\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-576\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-577\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-578\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-78\">(b, h, n, d_k)</script>, which stores the projected keys <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-79-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-579\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-580\"><span class=\"mi\" id=\"MathJax-Span-581\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-79\">K</script> for all past tokens.</p>\n<p>A <strong>value tensor</strong> of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-80-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-582\" style=\"width: 5.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.43em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.38em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-583\"><span class=\"mo\" id=\"MathJax-Span-584\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-585\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mo\" id=\"MathJax-Span-586\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-587\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">h</span><span class=\"mo\" id=\"MathJax-Span-588\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-589\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">n</span><span class=\"mo\" id=\"MathJax-Span-590\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-591\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-592\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-593\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-594\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>b</mi><mo>,</mo><mi>h</mi><mo>,</mo><mi>n</mi><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-80\">(b, h, n, d_k)</script> which stores the projected values <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-81-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-595\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-596\"><span class=\"mi\" id=\"MathJax-Span-597\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-81\">V</script> for all past tokens.</p>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-84-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>Total elements</mtext><mo>=</mo><mn>2</mn><mo>&amp;#x22C5;</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>b</mi><mo>&amp;#x22C5;</mo><mi>h</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-604\" style=\"width: 18.076em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 15.055em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1015.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-605\"><span class=\"mtext\" id=\"MathJax-Span-606\" style=\"font-family: STIXGeneral-Regular;\">Total elements</span><span class=\"mo\" id=\"MathJax-Span-607\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-608\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span><span class=\"mo\" id=\"MathJax-Span-609\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-610\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-611\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-612\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">b</span><span class=\"mo\" id=\"MathJax-Span-613\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-614\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">h</span><span class=\"mo\" id=\"MathJax-Span-615\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-616\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-617\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-618\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-619\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-620\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>Total elements</mtext><mo>=</mo><mn>2</mn><mo>⋅</mo><mi>l</mi><mo>⋅</mo><mi>b</mi><mo>⋅</mo><mi>h</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msub><mi>d</mi><mi>k</mi></msub></math></span></span></div>\n<ul>\n  <li>\n    <p>If we assume each element is stored in 16-bit floating point precision (<code class=\"language-plaintext highlighter-rouge\">float16</code>), then the total KV cache size in bytes is:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-85-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>Size (bytes)</mtext><mo>=</mo><mn>2</mn><mo>&amp;#x22C5;</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>b</mi><mo>&amp;#x22C5;</mo><mi>h</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x22C5;</mo><mn>2</mn></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-621\" style=\"width: 18.544em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 15.419em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1015.42em, 2.607em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-622\"><span class=\"mtext\" id=\"MathJax-Span-623\" style=\"font-family: STIXGeneral-Regular;\">Size (bytes)</span><span class=\"mo\" id=\"MathJax-Span-624\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-625\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span><span class=\"mo\" id=\"MathJax-Span-626\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-627\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-628\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-629\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">b</span><span class=\"mo\" id=\"MathJax-Span-630\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-631\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">h</span><span class=\"mo\" id=\"MathJax-Span-632\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-633\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-634\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-635\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-636\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-637\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-638\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mn\" id=\"MathJax-Span-639\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">2</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>Size (bytes)</mtext><mo>=</mo><mn>2</mn><mo>⋅</mo><mi>l</mi><mo>⋅</mo><mi>b</mi><mo>⋅</mo><mi>h</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msub><mi>d</mi><mi>k</mi></msub><mo>⋅</mo><mn>2</mn></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-85\">\\text{Size (bytes)} = 2 \\cdot l \\cdot b \\cdot h \\cdot n \\cdot d_k \\cdot 2</script>\n\n    <ul>\n      <li>where the final factor of 2 accounts for the 2 bytes per <code class=\"language-plaintext highlighter-rouge\">float16</code> element.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Example:</strong></p>\n\n    <ul>\n      <li>For a model with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-86-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi><mo>=</mo><mn>32</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-640\" style=\"width: 3.023em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.503em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.5em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-641\"><span class=\"mi\" id=\"MathJax-Span-642\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-643\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-644\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">32</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi><mo>=</mo><mn>32</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-86\">l = 32</script> layers, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-87-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>h</mi><mo>=</mo><mn>32</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-645\" style=\"width: 3.284em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.711em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.71em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-646\"><span class=\"mi\" id=\"MathJax-Span-647\" style=\"font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-648\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-649\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">32</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>h</mi><mo>=</mo><mn>32</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-87\">h = 32</script> heads, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-88-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mn>128</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-650\" style=\"width: 4.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.596em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.54em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-651\"><span class=\"msubsup\" id=\"MathJax-Span-652\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-653\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-654\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-655\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-656\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">128</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mn>128</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-88\">d_k = 128</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-89-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>b</mi><mo>=</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-657\" style=\"width: 2.659em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.19em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.09em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-658\"><span class=\"mi\" id=\"MathJax-Span-659\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mo\" id=\"MathJax-Span-660\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-661\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>b</mi><mo>=</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-89\">b = 1</script>, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-90-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>=</mo><mn>1000</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-662\" style=\"width: 3.44em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.867em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.87em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-663\"><span class=\"mo\" id=\"MathJax-Span-664\" style=\"font-family: STIXGeneral-Regular;\">=</span><span class=\"mn\" id=\"MathJax-Span-665\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1000</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>=</mo><mn>1000</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-90\">= 1000</script>:</li>\n    </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-91-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>Size</mtext><mo>=</mo><mn>2</mn><mo>&amp;#x22C5;</mo><mn>32</mn><mo>&amp;#x22C5;</mo><mn>1</mn><mo>&amp;#x22C5;</mo><mn>32</mn><mo>&amp;#x22C5;</mo><mn>1000</mn><mo>&amp;#x22C5;</mo><mn>128</mn><mo>&amp;#x22C5;</mo><mn>2</mn><mo>=</mo><mn>524,288,000</mn><mtext>&amp;#xA0;</mtext><mtext>bytes</mtext><mtext>&amp;#xA0;</mtext><mo stretchy=&quot;false&quot;>(</mo><mo>&amp;#x2248;</mo><mn>500</mn><mtext>&amp;#xA0;</mtext><mtext>MB</mtext><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-666\" style=\"width: 35.263em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 29.378em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1029.33em, 2.607em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-667\"><span class=\"mtext\" id=\"MathJax-Span-668\" style=\"font-family: STIXGeneral-Regular;\">Size</span><span class=\"mo\" id=\"MathJax-Span-669\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-670\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span><span class=\"mo\" id=\"MathJax-Span-671\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mn\" id=\"MathJax-Span-672\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">32</span><span class=\"mo\" id=\"MathJax-Span-673\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mn\" id=\"MathJax-Span-674\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-675\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mn\" id=\"MathJax-Span-676\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">32</span><span class=\"mo\" id=\"MathJax-Span-677\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mn\" id=\"MathJax-Span-678\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1000</span><span class=\"mo\" id=\"MathJax-Span-679\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mn\" id=\"MathJax-Span-680\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">128</span><span class=\"mo\" id=\"MathJax-Span-681\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mn\" id=\"MathJax-Span-682\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">2</span><span class=\"mo\" id=\"MathJax-Span-683\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-684\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">524,288,000</span><span class=\"mtext\" id=\"MathJax-Span-685\" style=\"font-family: STIXGeneral-Regular;\">&nbsp;</span><span class=\"mtext\" id=\"MathJax-Span-686\" style=\"font-family: STIXGeneral-Regular;\">bytes</span><span class=\"mtext\" id=\"MathJax-Span-687\" style=\"font-family: STIXGeneral-Regular;\">&nbsp;</span><span class=\"mo\" id=\"MathJax-Span-688\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mo\" id=\"MathJax-Span-689\" style=\"font-family: STIXGeneral-Regular;\">≈</span><span class=\"mn\" id=\"MathJax-Span-690\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">500</span><span class=\"mtext\" id=\"MathJax-Span-691\" style=\"font-family: STIXGeneral-Regular;\">&nbsp;</span><span class=\"mtext\" id=\"MathJax-Span-692\" style=\"font-family: STIXGeneral-Regular;\">MB</span><span class=\"mo\" id=\"MathJax-Span-693\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>Size</mtext><mo>=</mo><mn>2</mn><mo>⋅</mo><mn>32</mn><mo>⋅</mo><mn>1</mn><mo>⋅</mo><mn>32</mn><mo>⋅</mo><mn>1000</mn><mo>⋅</mo><mn>128</mn><mo>⋅</mo><mn>2</mn><mo>=</mo><mn>524,288,000</mn><mtext>&nbsp;</mtext><mtext>bytes</mtext><mtext>&nbsp;</mtext><mo stretchy=\"false\">(</mo><mo>≈</mo><mn>500</mn><mtext>&nbsp;</mtext><mtext>MB</mtext><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-91\">\\text{Size} = 2 \\cdot 32 \\cdot 1 \\cdot 32 \\cdot 1000 \\cdot 128 \\cdot 2 = 524{,}288{,}000 \\ \\text{bytes} \\ (\\approx 500 \\ \\text{MB})</script>\n  </li>\n  <li>\n    <p>This shows that the KV cache can become a significant memory consumer for long sequences, which is why optimizations such as quantization or chunked attention are often used in large language model inference.</p>\n  </li>\n</ul>\n<p>If we assume each element is stored in 16-bit floating point precision (<code class=\"language-plaintext highlighter-rouge\">float16</code>), then the total KV cache size in bytes is:</p>\n<ul>\n      <li>where the final factor of 2 accounts for the 2 bytes per <code class=\"language-plaintext highlighter-rouge\">float16</code> element.</li>\n    </ul>\n<p><strong>Example:</strong></p>\n<ul>\n      <li>For a model with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-86-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi><mo>=</mo><mn>32</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-640\" style=\"width: 3.023em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.503em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.5em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-641\"><span class=\"mi\" id=\"MathJax-Span-642\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-643\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-644\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">32</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi><mo>=</mo><mn>32</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-86\">l = 32</script> layers, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-87-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>h</mi><mo>=</mo><mn>32</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-645\" style=\"width: 3.284em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.711em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.71em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-646\"><span class=\"mi\" id=\"MathJax-Span-647\" style=\"font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-648\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-649\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">32</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>h</mi><mo>=</mo><mn>32</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-87\">h = 32</script> heads, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-88-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mn>128</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-650\" style=\"width: 4.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.596em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.54em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-651\"><span class=\"msubsup\" id=\"MathJax-Span-652\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-653\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-654\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-655\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-656\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">128</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mn>128</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-88\">d_k = 128</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-89-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>b</mi><mo>=</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-657\" style=\"width: 2.659em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.19em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.09em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-658\"><span class=\"mi\" id=\"MathJax-Span-659\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mo\" id=\"MathJax-Span-660\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-661\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>b</mi><mo>=</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-89\">b = 1</script>, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-90-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>=</mo><mn>1000</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-662\" style=\"width: 3.44em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.867em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.87em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-663\"><span class=\"mo\" id=\"MathJax-Span-664\" style=\"font-family: STIXGeneral-Regular;\">=</span><span class=\"mn\" id=\"MathJax-Span-665\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1000</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>=</mo><mn>1000</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-90\">= 1000</script>:</li>\n    </ul>\n<p>This shows that the KV cache can become a significant memory consumer for long sequences, which is why optimizations such as quantization or chunked attention are often used in large language model inference.</p>\n<h4 id=\"caching-self-attention-values\">Caching Self-Attention Values</h4>\n<ul>\n  <li>\n    <p>KV caching exploits two key properties:</p>\n\n    <ol>\n      <li>The model weights (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-92-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>K</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-694\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-695\"><span class=\"msubsup\" id=\"MathJax-Span-696\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-697\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-698\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>K</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-92\">W_K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-93-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>V</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-699\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-700\"><span class=\"msubsup\" id=\"MathJax-Span-701\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-702\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-703\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>V</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-93\">W_V</script>) are fixed during inference.</li>\n      <li>The <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-94-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-704\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-705\"><span class=\"mi\" id=\"MathJax-Span-706\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-94\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-95-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-707\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-708\"><span class=\"mi\" id=\"MathJax-Span-709\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-95\">V</script> representations for a given token depend on that token and all prior tokens (via its hidden state), but they do not depend on or change with any future tokens (i.e., they are <strong>immutable</strong> for for all subsequent decoding steps).</li>\n    </ol>\n  </li>\n  <li>\n    <p>Therefore, once we compute the <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-96-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-710\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-711\"><span class=\"mi\" id=\"MathJax-Span-712\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-96\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-97-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-713\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-714\"><span class=\"mi\" id=\"MathJax-Span-715\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-97\">V</script> representations for a given (token, layer, head) tuple, we can store them and reuse them in all subsequent decoding steps.</p>\n  </li>\n  <li>\n    <p>At decoding step <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-98-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-716\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-717\"><span class=\"mi\" id=\"MathJax-Span-718\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-98\">t</script>:</p>\n\n    <ul>\n      <li><strong>Without caching</strong>: recompute <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-99-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-719\" style=\"width: 2.034em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.67em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-720\"><span class=\"msubsup\" id=\"MathJax-Span-721\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-722\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-723\"><span class=\"mrow\" id=\"MathJax-Span-724\"><span class=\"mn\" id=\"MathJax-Span-725\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-726\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-727\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-99\">K_{1:n}</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-100-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-728\" style=\"width: 1.982em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.62em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-729\"><span class=\"msubsup\" id=\"MathJax-Span-730\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-731\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-732\"><span class=\"mrow\" id=\"MathJax-Span-733\"><span class=\"mn\" id=\"MathJax-Span-734\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-735\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-736\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-100\">V_{1:n}</script> from scratch for all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-101-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-737\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-738\"><span class=\"mi\" id=\"MathJax-Span-739\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-101\">t</script> tokens.</li>\n      <li><strong>With caching</strong>: reuse <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-102-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-740\" style=\"width: 3.596em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.971em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.97em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-741\"><span class=\"msubsup\" id=\"MathJax-Span-742\"><span style=\"display: inline-block; position: relative; width: 2.971em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-743\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-744\"><span class=\"mrow\" id=\"MathJax-Span-745\"><span class=\"mn\" id=\"MathJax-Span-746\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-747\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mo\" id=\"MathJax-Span-748\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-749\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-750\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-751\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-752\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-102\">K_{1:(n-1)}</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-103-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-753\" style=\"width: 3.544em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.919em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.92em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-754\"><span class=\"msubsup\" id=\"MathJax-Span-755\"><span style=\"display: inline-block; position: relative; width: 2.919em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-756\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-757\"><span class=\"mrow\" id=\"MathJax-Span-758\"><span class=\"mn\" id=\"MathJax-Span-759\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-760\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mo\" id=\"MathJax-Span-761\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-762\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-763\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-764\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-765\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-103\">V_{1:(n-1)}</script> compute only the new <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-104-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>k</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-766\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-767\"><span class=\"msubsup\" id=\"MathJax-Span-768\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-769\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-770\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>k</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-104\">k_t</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-105-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>v</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-771\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-772\"><span class=\"msubsup\" id=\"MathJax-Span-773\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-774\" style=\"font-family: STIXGeneral-Italic;\">v</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-775\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>v</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-105\">v_t</script> and append them to the cache.</li>\n    </ul>\n  </li>\n  <li>\n    <p>The following figure (<a href=\"https://huggingface.co/blog/not-lain/kv-caching\">source</a>) illustrates the KV caching process, showing how only the new token’s <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-106-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-776\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-777\"><span class=\"mi\" id=\"MathJax-Span-778\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-106\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-107-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-779\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-780\"><span class=\"mi\" id=\"MathJax-Span-781\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-107\">V</script> are computed while the rest are reused:</p>\n  </li>\n</ul>\n<p>KV caching exploits two key properties:</p>\n<ol>\n      <li>The model weights (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-92-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>K</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-694\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-695\"><span class=\"msubsup\" id=\"MathJax-Span-696\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-697\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-698\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>K</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-92\">W_K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-93-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>V</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-699\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-700\"><span class=\"msubsup\" id=\"MathJax-Span-701\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-702\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-703\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>V</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-93\">W_V</script>) are fixed during inference.</li>\n      <li>The <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-94-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-704\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-705\"><span class=\"mi\" id=\"MathJax-Span-706\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-94\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-95-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-707\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-708\"><span class=\"mi\" id=\"MathJax-Span-709\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-95\">V</script> representations for a given token depend on that token and all prior tokens (via its hidden state), but they do not depend on or change with any future tokens (i.e., they are <strong>immutable</strong> for for all subsequent decoding steps).</li>\n    </ol>\n<p>Therefore, once we compute the <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-96-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-710\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-711\"><span class=\"mi\" id=\"MathJax-Span-712\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-96\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-97-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-713\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-714\"><span class=\"mi\" id=\"MathJax-Span-715\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-97\">V</script> representations for a given (token, layer, head) tuple, we can store them and reuse them in all subsequent decoding steps.</p>\n<p>At decoding step <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-98-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-716\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-717\"><span class=\"mi\" id=\"MathJax-Span-718\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-98\">t</script>:</p>\n<ul>\n      <li><strong>Without caching</strong>: recompute <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-99-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-719\" style=\"width: 2.034em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.67em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-720\"><span class=\"msubsup\" id=\"MathJax-Span-721\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-722\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-723\"><span class=\"mrow\" id=\"MathJax-Span-724\"><span class=\"mn\" id=\"MathJax-Span-725\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-726\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-727\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-99\">K_{1:n}</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-100-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-728\" style=\"width: 1.982em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.62em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-729\"><span class=\"msubsup\" id=\"MathJax-Span-730\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-731\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-732\"><span class=\"mrow\" id=\"MathJax-Span-733\"><span class=\"mn\" id=\"MathJax-Span-734\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-735\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-736\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-100\">V_{1:n}</script> from scratch for all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-101-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-737\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-738\"><span class=\"mi\" id=\"MathJax-Span-739\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-101\">t</script> tokens.</li>\n      <li><strong>With caching</strong>: reuse <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-102-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-740\" style=\"width: 3.596em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.971em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.97em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-741\"><span class=\"msubsup\" id=\"MathJax-Span-742\"><span style=\"display: inline-block; position: relative; width: 2.971em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-743\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-744\"><span class=\"mrow\" id=\"MathJax-Span-745\"><span class=\"mn\" id=\"MathJax-Span-746\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-747\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mo\" id=\"MathJax-Span-748\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-749\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-750\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-751\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-752\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-102\">K_{1:(n-1)}</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-103-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-753\" style=\"width: 3.544em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.919em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.92em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-754\"><span class=\"msubsup\" id=\"MathJax-Span-755\"><span style=\"display: inline-block; position: relative; width: 2.919em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-756\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-757\"><span class=\"mrow\" id=\"MathJax-Span-758\"><span class=\"mn\" id=\"MathJax-Span-759\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-760\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mo\" id=\"MathJax-Span-761\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-762\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-763\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-764\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-765\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-103\">V_{1:(n-1)}</script> compute only the new <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-104-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>k</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-766\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-767\"><span class=\"msubsup\" id=\"MathJax-Span-768\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-769\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-770\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>k</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-104\">k_t</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-105-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>v</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-771\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-772\"><span class=\"msubsup\" id=\"MathJax-Span-773\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-774\" style=\"font-family: STIXGeneral-Italic;\">v</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-775\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>v</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-105\">v_t</script> and append them to the cache.</li>\n    </ul>\n<p>The following figure (<a href=\"https://huggingface.co/blog/not-lain/kv-caching\">source</a>) illustrates the KV caching process, showing how only the new token’s <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-106-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-776\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-777\"><span class=\"mi\" id=\"MathJax-Span-778\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-106\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-107-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-779\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-780\"><span class=\"mi\" id=\"MathJax-Span-781\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-107\">V</script> are computed while the rest are reused:</p>\n<p><img src=\"/primers/ai/assets/model-acceleration/KV.png\" alt=\"KV Caching Illustration\"></p>\n<ul>\n  <li>\n    <p>This optimization changes the cost from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-108-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-782\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-783\"><span class=\"mi\" id=\"MathJax-Span-784\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-785\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-786\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-787\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-788\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-789\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-790\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-791\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-792\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-793\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-108\">O(l \\cdot n \\cdot d^2)</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-109-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-794\" style=\"width: 4.378em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.648em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1003.6em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-795\"><span class=\"mi\" id=\"MathJax-Span-796\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-797\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-798\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-799\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-800\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-801\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-802\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-803\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-109\">O(l \\cdot d^2)</script> per decoding step — an <strong><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-110-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-804\" style=\"width: 0.622em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.519em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.552em, 1000.47em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-805\"><span class=\"mi\" id=\"MathJax-Span-806\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-110\">n</script>-times speedup</strong> in the sequence dimension.</p>\n  </li>\n  <li>\n    <p>The improvement is especially significant for long sequences, where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-111-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-807\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-808\"><span class=\"mi\" id=\"MathJax-Span-809\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-111\">n</script> can reach thousands or even millions of tokens. By eliminating redundant attention computations, KV caching enables efficient, low-latency generation at scale.</p>\n  </li>\n</ul>\n<p>This optimization changes the cost from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-108-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-782\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-783\"><span class=\"mi\" id=\"MathJax-Span-784\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-785\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-786\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-787\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-788\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-789\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-790\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-791\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-792\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-793\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-108\">O(l \\cdot n \\cdot d^2)</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-109-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-794\" style=\"width: 4.378em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.648em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1003.6em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-795\"><span class=\"mi\" id=\"MathJax-Span-796\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-797\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-798\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-799\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-800\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-801\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-802\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-803\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-109\">O(l \\cdot d^2)</script> per decoding step — an <strong><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-110-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-804\" style=\"width: 0.622em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.519em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.552em, 1000.47em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-805\"><span class=\"mi\" id=\"MathJax-Span-806\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-110\">n</script>-times speedup</strong> in the sequence dimension.</p>\n<p>The improvement is especially significant for long sequences, where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-111-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-807\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-808\"><span class=\"mi\" id=\"MathJax-Span-809\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-111\">n</script> can reach thousands or even millions of tokens. By eliminating redundant attention computations, KV caching enables efficient, low-latency generation at scale.</p>\n<h6 id=\"why-not-cache-prior-queries\">Why Not Cache Prior Queries?</h6>\n<ul>\n  <li>Only the most recent query <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-112-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>q</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-810\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.78em, 2.503em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-811\"><span class=\"msubsup\" id=\"MathJax-Span-812\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-813\" style=\"font-family: STIXGeneral-Italic;\">q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-814\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>q</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-112\">q_t</script> is used in the self-attention operation (which is recomputed at every step because it depends on the most recent token’s embedding), so caching prior queries (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-113-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-815\" style=\"width: 3.388em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.815em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1002.82em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-816\"><span class=\"msubsup\" id=\"MathJax-Span-817\"><span style=\"display: inline-block; position: relative; width: 2.815em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-818\" style=\"font-family: STIXGeneral-Italic;\">q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-819\"><span class=\"mrow\" id=\"MathJax-Span-820\"><span class=\"mn\" id=\"MathJax-Span-821\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-822\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mo\" id=\"MathJax-Span-823\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-824\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-825\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-826\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-827\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mo stretchy=\"false\">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-113\">q_{1:(n-1)}</script>) offers no benefit. Put simply, only the query corresponding to the latest token in the sequence is needed for decoding.</li>\n</ul>\n<h4 id=\"autoregressive-decoding-process-with-caching\">Autoregressive Decoding Process with Caching</h4>\n<ol>\n  <li>\n    <p><strong>Initial Sequence (Prefill Phase)</strong>:</p>\n\n    <ul>\n      <li>\n        <p>Given a prompt sequence <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-114-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>S</mi><mo>=</mo><mo stretchy=&quot;false&quot;>[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-828\" style=\"width: 9.221em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.55em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-829\"><span class=\"mi\" id=\"MathJax-Span-830\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-831\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mo\" id=\"MathJax-Span-832\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">[</span><span class=\"msubsup\" id=\"MathJax-Span-833\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-834\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-835\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-836\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-837\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-838\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-839\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-840\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-841\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-842\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-843\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-844\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-845\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-846\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>S</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=\"false\">]</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-114\">S = [x_1, x_2, \\dots, x_n]</script> the model computes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-115-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-847\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-848\"><span class=\"mi\" id=\"MathJax-Span-849\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-115\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-116-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-850\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-851\"><span class=\"mi\" id=\"MathJax-Span-852\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-116\">V</script> tensors for all prompt tokens in all layers and stores them in the KV cache.</p>\n      </li>\n      <li>\n        <p>This step still incurs the full cost <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-117-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-853\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-854\"><span class=\"mi\" id=\"MathJax-Span-855\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-856\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-857\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-858\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-859\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-860\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-861\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-862\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-863\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-864\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-117\">O(l \\cdot n \\cdot d^2)</script> because we have no cached values yet.</p>\n      </li>\n      <li>\n        <p>After this prefill step, the model transitions to the <em>decode phase</em>, where we process one token per step.</p>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Predict Next Token (Decode Phase)</strong>:</p>\n\n    <ul>\n      <li>\n        <p>At decoding step <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-118-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>+</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-865\" style=\"width: 2.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.98em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-866\"><span class=\"mi\" id=\"MathJax-Span-867\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-868\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-869\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi><mo>+</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-118\">n+1</script>:</p>\n\n        <ul>\n          <li>\n            <p>Compute the query vector <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-119-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>Q</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-870\" style=\"width: 7.346em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.096em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.1em, 2.607em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-871\"><span class=\"msubsup\" id=\"MathJax-Span-872\"><span style=\"display: inline-block; position: relative; width: 1.773em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-873\" style=\"font-family: STIXGeneral-Italic;\">q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-874\"><span class=\"mrow\" id=\"MathJax-Span-875\"><span class=\"mi\" id=\"MathJax-Span-876\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-877\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-878\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-879\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-880\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-881\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-882\"><span class=\"mrow\" id=\"MathJax-Span-883\"><span class=\"mi\" id=\"MathJax-Span-884\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-885\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-886\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-887\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-888\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-889\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>Q</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-119\">q_{n+1} = x_{n+1} W_Q</script> for the new token.</p>\n          </li>\n          <li>\n            <p>Retrieve all previous keys and values from the cache:</p>\n          </li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-120-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><mspace width=&quot;thickmathspace&quot; /><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-890\" style=\"width: 4.898em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.065em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.07em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-891\"><span class=\"msubsup\" id=\"MathJax-Span-892\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-893\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-894\"><span class=\"mrow\" id=\"MathJax-Span-895\"><span class=\"mn\" id=\"MathJax-Span-896\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-897\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-898\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-899\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mspace\" id=\"MathJax-Span-900\" style=\"height: 0em; vertical-align: 0em; width: 0.315em; display: inline-block; overflow: hidden;\"></span><span class=\"msubsup\" id=\"MathJax-Span-901\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-902\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-903\"><span class=\"mrow\" id=\"MathJax-Span-904\"><span class=\"mn\" id=\"MathJax-Span-905\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-906\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-907\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><mspace width=\"thickmathspace\"></mspace><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-120\">K_{1:n}, \\; V_{1:n}</script>\n\n        <ul>\n          <li>Compute the attention output for the new token using:</li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-121-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>Attention</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-908\" style=\"width: 12.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.419em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1010.37em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-909\"><span class=\"mtext\" id=\"MathJax-Span-910\" style=\"font-family: STIXGeneral-Regular;\">Attention</span><span class=\"mo\" id=\"MathJax-Span-911\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-912\"><span style=\"display: inline-block; position: relative; width: 1.773em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-913\" style=\"font-family: STIXGeneral-Italic;\">q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-914\"><span class=\"mrow\" id=\"MathJax-Span-915\"><span class=\"mi\" id=\"MathJax-Span-916\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-917\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-918\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-919\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-920\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-921\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-922\"><span class=\"mrow\" id=\"MathJax-Span-923\"><span class=\"mn\" id=\"MathJax-Span-924\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-925\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-926\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-927\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-928\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-929\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-930\"><span class=\"mrow\" id=\"MathJax-Span-931\"><span class=\"mn\" id=\"MathJax-Span-932\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-933\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-934\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-935\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><msub><mi>q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-121\">\\text{Attention}(q_{n+1}, K_{1:n}, V_{1:n})</script>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Update Cache</strong>:</p>\n\n    <ul>\n      <li>\n        <p>Compute the new key and value vectors for the current token:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-122-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>k</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><mspace width=&quot;1em&quot; /><msub><mi>v</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>V</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-936\" style=\"width: 16.461em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 13.701em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1013.7em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-937\"><span class=\"msubsup\" id=\"MathJax-Span-938\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-939\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-940\"><span class=\"mrow\" id=\"MathJax-Span-941\"><span class=\"mi\" id=\"MathJax-Span-942\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-943\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-944\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-945\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-946\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-947\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-948\"><span class=\"mrow\" id=\"MathJax-Span-949\"><span class=\"mi\" id=\"MathJax-Span-950\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-951\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-952\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-953\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-954\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-955\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-956\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mspace\" id=\"MathJax-Span-957\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"msubsup\" id=\"MathJax-Span-958\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-959\" style=\"font-family: STIXGeneral-Italic;\">v</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-960\"><span class=\"mrow\" id=\"MathJax-Span-961\"><span class=\"mi\" id=\"MathJax-Span-962\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-963\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-964\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-965\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-966\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-967\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-968\"><span class=\"mrow\" id=\"MathJax-Span-969\"><span class=\"mi\" id=\"MathJax-Span-970\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-971\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-972\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-973\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-974\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-975\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>k</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><mspace width=\"1em\"></mspace><msub><mi>v</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>V</mi></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-122\">k_{n+1} = x_{n+1} W_K, \\quad v_{n+1} = x_{n+1} W_V</script>\n      </li>\n      <li>\n        <p>Append these to the KV cache so they can be reused in future decoding steps:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-123-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow></msub><mo stretchy=&quot;false&quot;>&amp;#x2190;</mo><mo stretchy=&quot;false&quot;>[</mo><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>k</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-976\" style=\"width: 10.211em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.492em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1008.39em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-977\"><span class=\"msubsup\" id=\"MathJax-Span-978\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-979\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-980\"><span class=\"mrow\" id=\"MathJax-Span-981\"><span class=\"mtext\" id=\"MathJax-Span-982\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-983\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">←</span><span class=\"mo\" id=\"MathJax-Span-984\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">[</span><span class=\"msubsup\" id=\"MathJax-Span-985\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-986\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-987\"><span class=\"mrow\" id=\"MathJax-Span-988\"><span class=\"mn\" id=\"MathJax-Span-989\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-990\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-991\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-992\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-993\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-994\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-995\"><span class=\"mrow\" id=\"MathJax-Span-996\"><span class=\"mi\" id=\"MathJax-Span-997\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-998\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-999\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1000\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow></msub><mo stretchy=\"false\">←</mo><mo stretchy=\"false\">[</mo><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>k</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">]</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-123\">K_{\\text{cache}} \\leftarrow [K_{1:n}, k_{n+1}]</script>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-124-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow></msub><mo stretchy=&quot;false&quot;>&amp;#x2190;</mo><mo stretchy=&quot;false&quot;>[</mo><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>v</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1001\" style=\"width: 10.107em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.388em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1008.28em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1002\"><span class=\"msubsup\" id=\"MathJax-Span-1003\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1004\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1005\"><span class=\"mrow\" id=\"MathJax-Span-1006\"><span class=\"mtext\" id=\"MathJax-Span-1007\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1008\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">←</span><span class=\"mo\" id=\"MathJax-Span-1009\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">[</span><span class=\"msubsup\" id=\"MathJax-Span-1010\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1011\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1012\"><span class=\"mrow\" id=\"MathJax-Span-1013\"><span class=\"mn\" id=\"MathJax-Span-1014\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-1015\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-1016\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1017\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-1018\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1019\" style=\"font-family: STIXGeneral-Italic;\">v</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-1020\"><span class=\"mrow\" id=\"MathJax-Span-1021\"><span class=\"mi\" id=\"MathJax-Span-1022\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1023\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-1024\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1025\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow></msub><mo stretchy=\"false\">←</mo><mo stretchy=\"false\">[</mo><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>v</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">]</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-124\">V_{\\text{cache}} \\leftarrow [V_{1:n}, v_{n+1}]</script>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Repeat</strong>:</p>\n\n    <ul>\n      <li>Continue until the end-of-sequence (EOS) token is generated or the maximum token limit is reached.</li>\n    </ul>\n  </li>\n</ol>\n<p><strong>Initial Sequence (Prefill Phase)</strong>:</p>\n<ul>\n      <li>\n        <p>Given a prompt sequence <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-114-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>S</mi><mo>=</mo><mo stretchy=&quot;false&quot;>[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-828\" style=\"width: 9.221em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.55em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-829\"><span class=\"mi\" id=\"MathJax-Span-830\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-831\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mo\" id=\"MathJax-Span-832\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">[</span><span class=\"msubsup\" id=\"MathJax-Span-833\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-834\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-835\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-836\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-837\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-838\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-839\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-840\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-841\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-842\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-843\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-844\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-845\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-846\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>S</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=\"false\">]</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-114\">S = [x_1, x_2, \\dots, x_n]</script> the model computes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-115-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-847\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-848\"><span class=\"mi\" id=\"MathJax-Span-849\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-115\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-116-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-850\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-851\"><span class=\"mi\" id=\"MathJax-Span-852\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-116\">V</script> tensors for all prompt tokens in all layers and stores them in the KV cache.</p>\n      </li>\n      <li>\n        <p>This step still incurs the full cost <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-117-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-853\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-854\"><span class=\"mi\" id=\"MathJax-Span-855\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-856\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-857\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-858\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-859\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-860\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-861\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-862\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-863\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-864\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-117\">O(l \\cdot n \\cdot d^2)</script> because we have no cached values yet.</p>\n      </li>\n      <li>\n        <p>After this prefill step, the model transitions to the <em>decode phase</em>, where we process one token per step.</p>\n      </li>\n    </ul>\n<p>Given a prompt sequence <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-114-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>S</mi><mo>=</mo><mo stretchy=&quot;false&quot;>[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-828\" style=\"width: 9.221em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.55em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-829\"><span class=\"mi\" id=\"MathJax-Span-830\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-831\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mo\" id=\"MathJax-Span-832\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">[</span><span class=\"msubsup\" id=\"MathJax-Span-833\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-834\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-835\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-836\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-837\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-838\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-839\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-840\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-841\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-842\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-843\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-844\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-845\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-846\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>S</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy=\"false\">]</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-114\">S = [x_1, x_2, \\dots, x_n]</script> the model computes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-115-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-847\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-848\"><span class=\"mi\" id=\"MathJax-Span-849\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-115\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-116-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-850\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-851\"><span class=\"mi\" id=\"MathJax-Span-852\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-116\">V</script> tensors for all prompt tokens in all layers and stores them in the KV cache.</p>\n<p>This step still incurs the full cost <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-117-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-853\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-854\"><span class=\"mi\" id=\"MathJax-Span-855\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-856\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-857\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-858\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-859\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-860\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-861\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-862\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-863\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-864\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-117\">O(l \\cdot n \\cdot d^2)</script> because we have no cached values yet.</p>\n<p>After this prefill step, the model transitions to the <em>decode phase</em>, where we process one token per step.</p>\n<p><strong>Predict Next Token (Decode Phase)</strong>:</p>\n<ul>\n      <li>\n        <p>At decoding step <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-118-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>+</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-865\" style=\"width: 2.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.98em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-866\"><span class=\"mi\" id=\"MathJax-Span-867\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-868\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-869\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi><mo>+</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-118\">n+1</script>:</p>\n\n        <ul>\n          <li>\n            <p>Compute the query vector <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-119-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>Q</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-870\" style=\"width: 7.346em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.096em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.1em, 2.607em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-871\"><span class=\"msubsup\" id=\"MathJax-Span-872\"><span style=\"display: inline-block; position: relative; width: 1.773em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-873\" style=\"font-family: STIXGeneral-Italic;\">q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-874\"><span class=\"mrow\" id=\"MathJax-Span-875\"><span class=\"mi\" id=\"MathJax-Span-876\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-877\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-878\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-879\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-880\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-881\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-882\"><span class=\"mrow\" id=\"MathJax-Span-883\"><span class=\"mi\" id=\"MathJax-Span-884\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-885\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-886\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-887\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-888\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-889\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>Q</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-119\">q_{n+1} = x_{n+1} W_Q</script> for the new token.</p>\n          </li>\n          <li>\n            <p>Retrieve all previous keys and values from the cache:</p>\n          </li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-120-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><mspace width=&quot;thickmathspace&quot; /><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-890\" style=\"width: 4.898em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.065em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.07em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-891\"><span class=\"msubsup\" id=\"MathJax-Span-892\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-893\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-894\"><span class=\"mrow\" id=\"MathJax-Span-895\"><span class=\"mn\" id=\"MathJax-Span-896\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-897\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-898\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-899\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mspace\" id=\"MathJax-Span-900\" style=\"height: 0em; vertical-align: 0em; width: 0.315em; display: inline-block; overflow: hidden;\"></span><span class=\"msubsup\" id=\"MathJax-Span-901\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-902\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-903\"><span class=\"mrow\" id=\"MathJax-Span-904\"><span class=\"mn\" id=\"MathJax-Span-905\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-906\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-907\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><mspace width=\"thickmathspace\"></mspace><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-120\">K_{1:n}, \\; V_{1:n}</script>\n\n        <ul>\n          <li>Compute the attention output for the new token using:</li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-121-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>Attention</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-908\" style=\"width: 12.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.419em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1010.37em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-909\"><span class=\"mtext\" id=\"MathJax-Span-910\" style=\"font-family: STIXGeneral-Regular;\">Attention</span><span class=\"mo\" id=\"MathJax-Span-911\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-912\"><span style=\"display: inline-block; position: relative; width: 1.773em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-913\" style=\"font-family: STIXGeneral-Italic;\">q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-914\"><span class=\"mrow\" id=\"MathJax-Span-915\"><span class=\"mi\" id=\"MathJax-Span-916\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-917\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-918\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-919\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-920\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-921\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-922\"><span class=\"mrow\" id=\"MathJax-Span-923\"><span class=\"mn\" id=\"MathJax-Span-924\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-925\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-926\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-927\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-928\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-929\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-930\"><span class=\"mrow\" id=\"MathJax-Span-931\"><span class=\"mn\" id=\"MathJax-Span-932\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-933\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-934\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-935\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><msub><mi>q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-121\">\\text{Attention}(q_{n+1}, K_{1:n}, V_{1:n})</script>\n      </li>\n    </ul>\n<p>At decoding step <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-118-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>+</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-865\" style=\"width: 2.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.98em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-866\"><span class=\"mi\" id=\"MathJax-Span-867\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-868\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-869\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi><mo>+</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-118\">n+1</script>:</p>\n<ul>\n          <li>\n            <p>Compute the query vector <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-119-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>Q</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-870\" style=\"width: 7.346em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.096em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.1em, 2.607em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-871\"><span class=\"msubsup\" id=\"MathJax-Span-872\"><span style=\"display: inline-block; position: relative; width: 1.773em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-873\" style=\"font-family: STIXGeneral-Italic;\">q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-874\"><span class=\"mrow\" id=\"MathJax-Span-875\"><span class=\"mi\" id=\"MathJax-Span-876\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-877\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-878\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-879\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-880\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-881\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-882\"><span class=\"mrow\" id=\"MathJax-Span-883\"><span class=\"mi\" id=\"MathJax-Span-884\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-885\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-886\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-887\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-888\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-889\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>Q</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-119\">q_{n+1} = x_{n+1} W_Q</script> for the new token.</p>\n          </li>\n          <li>\n            <p>Retrieve all previous keys and values from the cache:</p>\n          </li>\n        </ul>\n<p>Compute the query vector <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-119-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>Q</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-870\" style=\"width: 7.346em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.096em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.1em, 2.607em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-871\"><span class=\"msubsup\" id=\"MathJax-Span-872\"><span style=\"display: inline-block; position: relative; width: 1.773em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-873\" style=\"font-family: STIXGeneral-Italic;\">q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-874\"><span class=\"mrow\" id=\"MathJax-Span-875\"><span class=\"mi\" id=\"MathJax-Span-876\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-877\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-878\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-879\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-880\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-881\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-882\"><span class=\"mrow\" id=\"MathJax-Span-883\"><span class=\"mi\" id=\"MathJax-Span-884\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-885\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-886\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-887\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-888\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-889\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>Q</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-119\">q_{n+1} = x_{n+1} W_Q</script> for the new token.</p>\n<p>Retrieve all previous keys and values from the cache:</p>\n<ul>\n          <li>Compute the attention output for the new token using:</li>\n        </ul>\n<p><strong>Update Cache</strong>:</p>\n<ul>\n      <li>\n        <p>Compute the new key and value vectors for the current token:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-122-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>k</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><mspace width=&quot;1em&quot; /><msub><mi>v</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>V</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-936\" style=\"width: 16.461em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 13.701em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1013.7em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-937\"><span class=\"msubsup\" id=\"MathJax-Span-938\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-939\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-940\"><span class=\"mrow\" id=\"MathJax-Span-941\"><span class=\"mi\" id=\"MathJax-Span-942\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-943\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-944\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-945\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-946\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-947\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-948\"><span class=\"mrow\" id=\"MathJax-Span-949\"><span class=\"mi\" id=\"MathJax-Span-950\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-951\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-952\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-953\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-954\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-955\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-956\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mspace\" id=\"MathJax-Span-957\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"msubsup\" id=\"MathJax-Span-958\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-959\" style=\"font-family: STIXGeneral-Italic;\">v</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-960\"><span class=\"mrow\" id=\"MathJax-Span-961\"><span class=\"mi\" id=\"MathJax-Span-962\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-963\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-964\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-965\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-966\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-967\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-968\"><span class=\"mrow\" id=\"MathJax-Span-969\"><span class=\"mi\" id=\"MathJax-Span-970\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-971\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-972\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-973\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-974\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-975\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>k</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>K</mi></msub><mo>,</mo><mspace width=\"1em\"></mspace><msub><mi>v</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><msub><mi>W</mi><mi>V</mi></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-122\">k_{n+1} = x_{n+1} W_K, \\quad v_{n+1} = x_{n+1} W_V</script>\n      </li>\n      <li>\n        <p>Append these to the KV cache so they can be reused in future decoding steps:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-123-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow></msub><mo stretchy=&quot;false&quot;>&amp;#x2190;</mo><mo stretchy=&quot;false&quot;>[</mo><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>k</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-976\" style=\"width: 10.211em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.492em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1008.39em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-977\"><span class=\"msubsup\" id=\"MathJax-Span-978\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-979\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-980\"><span class=\"mrow\" id=\"MathJax-Span-981\"><span class=\"mtext\" id=\"MathJax-Span-982\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-983\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">←</span><span class=\"mo\" id=\"MathJax-Span-984\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">[</span><span class=\"msubsup\" id=\"MathJax-Span-985\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-986\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-987\"><span class=\"mrow\" id=\"MathJax-Span-988\"><span class=\"mn\" id=\"MathJax-Span-989\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-990\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-991\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-992\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-993\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-994\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-995\"><span class=\"mrow\" id=\"MathJax-Span-996\"><span class=\"mi\" id=\"MathJax-Span-997\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-998\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-999\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1000\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow></msub><mo stretchy=\"false\">←</mo><mo stretchy=\"false\">[</mo><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>k</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">]</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-123\">K_{\\text{cache}} \\leftarrow [K_{1:n}, k_{n+1}]</script>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-124-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow></msub><mo stretchy=&quot;false&quot;>&amp;#x2190;</mo><mo stretchy=&quot;false&quot;>[</mo><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>v</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1001\" style=\"width: 10.107em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.388em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1008.28em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1002\"><span class=\"msubsup\" id=\"MathJax-Span-1003\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1004\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1005\"><span class=\"mrow\" id=\"MathJax-Span-1006\"><span class=\"mtext\" id=\"MathJax-Span-1007\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1008\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">←</span><span class=\"mo\" id=\"MathJax-Span-1009\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">[</span><span class=\"msubsup\" id=\"MathJax-Span-1010\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1011\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1012\"><span class=\"mrow\" id=\"MathJax-Span-1013\"><span class=\"mn\" id=\"MathJax-Span-1014\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-1015\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-1016\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1017\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-1018\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1019\" style=\"font-family: STIXGeneral-Italic;\">v</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-1020\"><span class=\"mrow\" id=\"MathJax-Span-1021\"><span class=\"mi\" id=\"MathJax-Span-1022\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1023\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-1024\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1025\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow></msub><mo stretchy=\"false\">←</mo><mo stretchy=\"false\">[</mo><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>v</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">]</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-124\">V_{\\text{cache}} \\leftarrow [V_{1:n}, v_{n+1}]</script>\n      </li>\n    </ul>\n<p>Compute the new key and value vectors for the current token:</p>\n<p>Append these to the KV cache so they can be reused in future decoding steps:</p>\n<p><strong>Repeat</strong>:</p>\n<ul>\n      <li>Continue until the end-of-sequence (EOS) token is generated or the maximum token limit is reached.</li>\n    </ul>\n<h4 id=\"implementation-details\">Implementation Details</h4>\n<h5 id=\"cache-tensor-shape\">Cache Tensor Shape</h5>\n<ul>\n  <li>\n    <p>Assuming:</p>\n\n    <ul>\n      <li>Batch size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-125-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1026\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1027\"><span class=\"mi\" id=\"MathJax-Span-1028\" style=\"font-family: STIXGeneral-Italic;\">B</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-125\">B</script></li>\n      <li>Max sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-126-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1029\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1030\"><span class=\"mi\" id=\"MathJax-Span-1031\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-126\">n</script></li>\n      <li>Number of heads <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-127-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1032\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1033\"><span class=\"mi\" id=\"MathJax-Span-1034\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-127\">H</script></li>\n      <li>Head dimension <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-128-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1035\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1036\"><span class=\"msubsup\" id=\"MathJax-Span-1037\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1038\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1039\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-128\">d_k</script></li>\n      <li>Number of layers <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-129-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1040\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1041\"><span class=\"mi\" id=\"MathJax-Span-1042\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-129\">l</script></li>\n    </ul>\n  </li>\n  <li>\n    <p>The KV cache is structured to store <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-130-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1043\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1044\"><span class=\"mi\" id=\"MathJax-Span-1045\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-130\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-131-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1046\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1047\"><span class=\"mi\" id=\"MathJax-Span-1048\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-131\">V</script> for each <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-132-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi><mo>,</mo><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo>,</mo><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1049\" style=\"width: 9.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.763em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.71em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1050\"><span class=\"mo\" id=\"MathJax-Span-1051\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1052\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-1053\" style=\"font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-1054\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-1055\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-1056\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1057\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1058\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-1059\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-1060\" style=\"font-family: STIXGeneral-Italic;\">y</span><span class=\"mi\" id=\"MathJax-Span-1061\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-1062\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1063\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1064\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">h</span><span class=\"mi\" id=\"MathJax-Span-1065\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-1066\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-1067\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1068\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi><mo>,</mo><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo>,</mo><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-132\">(token, layer, head)</script> tuple. For a <strong>given layer</strong> and <strong>head</strong>, the cache tensor shapes and sizes are:</p>\n\n    <ul>\n      <li>\n        <p><strong>Key cache (per layer, per head):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-133-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1069\" style=\"width: 8.023em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.669em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1006.67em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1070\"><span class=\"msubsup\" id=\"MathJax-Span-1071\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1072\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.25em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1073\"><span class=\"mrow\" id=\"MathJax-Span-1074\"><span class=\"mo\" id=\"MathJax-Span-1075\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1076\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1077\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1078\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1079\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.67em, 4.169em, -999.997em); top: -3.695em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-1080\"><span class=\"mrow\" id=\"MathJax-Span-1081\"><span class=\"mtext\" id=\"MathJax-Span-1082\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1083\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1084\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.128em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1085\"><span class=\"mrow\" id=\"MathJax-Span-1086\"><span class=\"mi\" id=\"MathJax-Span-1087\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1088\"><span class=\"mrow\" id=\"MathJax-Span-1089\"><span class=\"mi\" id=\"MathJax-Span-1090\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1091\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1092\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1093\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1094\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1095\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1096\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-133\">K_{\\text{cache}}^{(l,h)} \\in \\mathbb{R}^{B \\times n \\times d_k}</script>\n\n        <ul>\n          <li><strong>Key cache size (in bytes):</strong></li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-134-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>K</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1097\" style=\"width: 16.409em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 13.648em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1013.6em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1098\"><span class=\"msubsup\" id=\"MathJax-Span-1099\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1100\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.25em, 4.273em, -999.997em); top: -4.477em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-1101\"><span class=\"mrow\" id=\"MathJax-Span-1102\"><span class=\"mo\" id=\"MathJax-Span-1103\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1104\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1105\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1106\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1107\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1108\"><span class=\"mrow\" id=\"MathJax-Span-1109\"><span class=\"mi\" id=\"MathJax-Span-1110\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1111\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-1112\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1113\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1114\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1115\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1116\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1117\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1118\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1119\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1120\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>K</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-134\">S_{K}^{(l,h)} = B \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n      </li>\n      <li>\n        <p><strong>Value cache (per layer, per head):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-135-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1121\" style=\"width: 7.971em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.617em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1006.62em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1122\"><span class=\"msubsup\" id=\"MathJax-Span-1123\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1124\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.25em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1125\"><span class=\"mrow\" id=\"MathJax-Span-1126\"><span class=\"mo\" id=\"MathJax-Span-1127\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1128\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1129\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1130\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1131\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.67em, 4.169em, -999.997em); top: -3.695em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1132\"><span class=\"mrow\" id=\"MathJax-Span-1133\"><span class=\"mtext\" id=\"MathJax-Span-1134\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1135\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1136\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.128em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1137\"><span class=\"mrow\" id=\"MathJax-Span-1138\"><span class=\"mi\" id=\"MathJax-Span-1139\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1140\"><span class=\"mrow\" id=\"MathJax-Span-1141\"><span class=\"mi\" id=\"MathJax-Span-1142\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1143\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1144\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1145\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1146\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1147\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1148\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-135\">V_{\\text{cache}}^{(l,h)} \\in \\mathbb{R}^{B \\times n \\times d_k}</script>\n\n        <ul>\n          <li><strong>Value cache size (in bytes):</strong></li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-136-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>V</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1149\" style=\"width: 16.409em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 13.648em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1013.6em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1150\"><span class=\"msubsup\" id=\"MathJax-Span-1151\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1152\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.25em, 4.273em, -999.997em); top: -4.477em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-1153\"><span class=\"mrow\" id=\"MathJax-Span-1154\"><span class=\"mo\" id=\"MathJax-Span-1155\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1156\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1157\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1158\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1159\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1160\"><span class=\"mrow\" id=\"MathJax-Span-1161\"><span class=\"mi\" id=\"MathJax-Span-1162\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1163\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-1164\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1165\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1166\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1167\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1168\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1169\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1170\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1171\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1172\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>V</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-136\">S_{V}^{(l,h)} = B \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n      </li>\n      <li>\n        <p><strong>Total memory size per layer and head (in bytes):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-137-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>layer, head</mtext></mrow></msub><mo>=</mo><mn>2</mn><mo>&amp;#x00D7;</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1173\" style=\"width: 20.523em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1017.03em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1174\"><span class=\"msubsup\" id=\"MathJax-Span-1175\"><span style=\"display: inline-block; position: relative; width: 3.701em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1176\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1177\"><span class=\"mrow\" id=\"MathJax-Span-1178\"><span class=\"mtext\" id=\"MathJax-Span-1179\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">layer, head</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1180\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1181\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span><span class=\"mo\" id=\"MathJax-Span-1182\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1183\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1184\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1185\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1186\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1187\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1188\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1189\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1190\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1191\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>layer, head</mtext></mrow></msub><mo>=</mo><mn>2</mn><mo>×</mo><mi>B</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-137\">S_{\\text{layer, head}} = 2 \\times B \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n\n        <ul>\n          <li>The factor of 2 accounts for both the key and value tensors.</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p>When combining all layers and attention heads, the total KV cache represents the complete memory footprint required to store all key and value tensors across the entire model. The following equations describe the full model-wide KV Cache cache dimensions and their corresponding memory requirements:</p>\n\n    <ul>\n      <li>\n        <p><strong>Key cache (all layers, all attention heads):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-138-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mtext>total</mtext><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1192\" style=\"width: 10.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.596em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1008.6em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1193\"><span class=\"msubsup\" id=\"MathJax-Span-1194\"><span style=\"display: inline-block; position: relative; width: 2.607em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1195\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.83em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1196\"><span class=\"mrow\" id=\"MathJax-Span-1197\"><span class=\"mo\" id=\"MathJax-Span-1198\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-1199\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">total</span><span class=\"mo\" id=\"MathJax-Span-1200\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.67em, 4.169em, -999.997em); top: -3.695em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-1201\"><span class=\"mrow\" id=\"MathJax-Span-1202\"><span class=\"mtext\" id=\"MathJax-Span-1203\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1204\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1205\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 4.794em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1206\"><span class=\"mrow\" id=\"MathJax-Span-1207\"><span class=\"mi\" id=\"MathJax-Span-1208\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1209\"><span class=\"mrow\" id=\"MathJax-Span-1210\"><span class=\"mi\" id=\"MathJax-Span-1211\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1212\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1213\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1214\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1215\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1216\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1217\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1218\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1219\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1220\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1221\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mtext>total</mtext><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>l</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-138\">K_{\\text{cache}}^{(\\text{total})} \\in \\mathbb{R}^{B \\times l \\times H \\times n \\times d_k}</script>\n\n        <ul>\n          <li><strong>Key cache size (in bytes):</strong></li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-139-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>K</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mtext>total</mtext><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1222\" style=\"width: 20.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.398em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1017.35em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1223\"><span class=\"msubsup\" id=\"MathJax-Span-1224\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1225\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.83em, 4.273em, -999.997em); top: -4.477em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-1226\"><span class=\"mrow\" id=\"MathJax-Span-1227\"><span class=\"mo\" id=\"MathJax-Span-1228\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-1229\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">total</span><span class=\"mo\" id=\"MathJax-Span-1230\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1231\"><span class=\"mrow\" id=\"MathJax-Span-1232\"><span class=\"mi\" id=\"MathJax-Span-1233\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1234\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-1235\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1236\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1237\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1238\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1239\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1240\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1241\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1242\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1243\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1244\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1245\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1246\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1247\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>K</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mtext>total</mtext><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>×</mo><mi>l</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-139\">S_{K}^{(\\text{total})} = B \\times l \\times H \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n      </li>\n      <li>\n        <p><strong>Value cache (all layers, all attention heads):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-140-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mtext>total</mtext><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1248\" style=\"width: 10.263em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.544em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1008.54em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1249\"><span class=\"msubsup\" id=\"MathJax-Span-1250\"><span style=\"display: inline-block; position: relative; width: 2.555em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1251\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.83em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1252\"><span class=\"mrow\" id=\"MathJax-Span-1253\"><span class=\"mo\" id=\"MathJax-Span-1254\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-1255\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">total</span><span class=\"mo\" id=\"MathJax-Span-1256\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.67em, 4.169em, -999.997em); top: -3.695em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1257\"><span class=\"mrow\" id=\"MathJax-Span-1258\"><span class=\"mtext\" id=\"MathJax-Span-1259\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1260\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1261\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 4.794em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1262\"><span class=\"mrow\" id=\"MathJax-Span-1263\"><span class=\"mi\" id=\"MathJax-Span-1264\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1265\"><span class=\"mrow\" id=\"MathJax-Span-1266\"><span class=\"mi\" id=\"MathJax-Span-1267\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1268\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1269\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1270\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1271\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1272\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1273\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1274\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1275\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1276\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1277\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mtext>total</mtext><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>l</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-140\">V_{\\text{cache}}^{(\\text{total})} \\in \\mathbb{R}^{B \\times l \\times H \\times n \\times d_k}</script>\n\n        <ul>\n          <li><strong>Value cache size (in bytes):</strong></li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-141-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>V</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mtext>total</mtext><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1278\" style=\"width: 20.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.398em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1017.35em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1279\"><span class=\"msubsup\" id=\"MathJax-Span-1280\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1281\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.83em, 4.273em, -999.997em); top: -4.477em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-1282\"><span class=\"mrow\" id=\"MathJax-Span-1283\"><span class=\"mo\" id=\"MathJax-Span-1284\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-1285\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">total</span><span class=\"mo\" id=\"MathJax-Span-1286\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1287\"><span class=\"mrow\" id=\"MathJax-Span-1288\"><span class=\"mi\" id=\"MathJax-Span-1289\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1290\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-1291\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1292\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1293\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1294\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1295\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1296\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1297\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1298\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1299\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1300\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1301\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1302\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1303\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>V</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mtext>total</mtext><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>×</mo><mi>l</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-141\">S_{V}^{(\\text{total})} = B \\times l \\times H \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n      </li>\n      <li>\n        <p><strong>Total memory size across the entire model (in bytes):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-142-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>total</mtext></mrow></msub><mo>=</mo><mn>2</mn><mo>&amp;#x00D7;</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1304\" style=\"width: 22.138em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 18.44em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1018.39em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1305\"><span class=\"msubsup\" id=\"MathJax-Span-1306\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1307\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1308\"><span class=\"mrow\" id=\"MathJax-Span-1309\"><span class=\"mtext\" id=\"MathJax-Span-1310\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">total</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1311\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1312\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span><span class=\"mo\" id=\"MathJax-Span-1313\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1314\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1315\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1316\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1317\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1318\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1319\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1320\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1321\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1322\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1323\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1324\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1325\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1326\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>total</mtext></mrow></msub><mo>=</mo><mn>2</mn><mo>×</mo><mi>B</mi><mo>×</mo><mi>l</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-142\">S_{\\text{total}} = 2 \\times B \\times l \\times H \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Notes:</strong></p>\n    <ul>\n      <li>The cache size scales linearly with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-143-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1327\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1328\"><span class=\"mi\" id=\"MathJax-Span-1329\" style=\"font-family: STIXGeneral-Italic;\">B</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-143\">B</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-144-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1330\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1331\"><span class=\"mi\" id=\"MathJax-Span-1332\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-144\">l</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-145-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1333\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1334\"><span class=\"mi\" id=\"MathJax-Span-1335\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-145\">H</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-146-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1336\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1337\"><span class=\"mi\" id=\"MathJax-Span-1338\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-146\">n</script>, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-147-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1339\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1340\"><span class=\"msubsup\" id=\"MathJax-Span-1341\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1342\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1343\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-147\">d_k</script>. During autoregressive generation, the model processes one token per step in the decode phase, only <strong>one</strong> new key and one new value vector are appended at each step for every layer and head. Consequently, as decoding progresses, the total cache grows linearly with the number of generated tokens—reflecting the incremental accumulation of key-value pairs over time.</li>\n      <li>In practice:\n        <ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-148-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>2</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1344\" style=\"width: 8.388em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.982em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.98em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1345\"><span class=\"mtext\" id=\"MathJax-Span-1346\" style=\"font-family: STIXGeneral-Regular;\">sizeof(dtype)</span><span class=\"mo\" id=\"MathJax-Span-1347\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1348\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>2</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-148\">\\text{sizeof(dtype)} = 2</script> bytes for FP16/BF16 caches.</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-149-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1349\" style=\"width: 8.388em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.982em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.88em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1350\"><span class=\"mtext\" id=\"MathJax-Span-1351\" style=\"font-family: STIXGeneral-Regular;\">sizeof(dtype)</span><span class=\"mo\" id=\"MathJax-Span-1352\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1353\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-149\">\\text{sizeof(dtype)} = 1</script> byte for INT8 caches.</li>\n        </ul>\n      </li>\n      <li>Example: For a model with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-150-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi><mo>=</mo><mn>32</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1354\" style=\"width: 3.023em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.503em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.5em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1355\"><span class=\"mi\" id=\"MathJax-Span-1356\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1357\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1358\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">32</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi><mo>=</mo><mn>32</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-150\">l = 32</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-151-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi><mo>=</mo><mn>64</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1359\" style=\"width: 3.596em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.971em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.92em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1360\"><span class=\"mi\" id=\"MathJax-Span-1361\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1362\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1363\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">64</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi><mo>=</mo><mn>64</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-151\">H = 64</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-152-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mn>128</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1364\" style=\"width: 4.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.596em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.54em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1365\"><span class=\"msubsup\" id=\"MathJax-Span-1366\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1367\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1368\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1369\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1370\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">128</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mn>128</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-152\">d_k = 128</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-153-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi><mo>=</mo><mn>8</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1371\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.29em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1372\"><span class=\"mi\" id=\"MathJax-Span-1373\" style=\"font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1374\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1375\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">8</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi><mo>=</mo><mn>8</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-153\">B = 8</script>, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-154-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>=</mo><mn>4096</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1376\" style=\"width: 4.482em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.701em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.65em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1377\"><span class=\"mi\" id=\"MathJax-Span-1378\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1379\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1380\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">4096</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi><mo>=</mo><mn>4096</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-154\">n = 4096</script>, the KV cache can easily consume tens of gigabytes of GPU memory.\nEfficient cache management (e.g., truncation, quantization, or offloading) is thus essential for real-world deployment.</li>\n      <li>Efficient memory layout is crucial — contiguous buffers enable fast appends and reduce memory copy overhead.</li>\n    </ul>\n  </li>\n</ul>\n<p>Assuming:</p>\n<ul>\n      <li>Batch size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-125-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1026\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1027\"><span class=\"mi\" id=\"MathJax-Span-1028\" style=\"font-family: STIXGeneral-Italic;\">B</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-125\">B</script></li>\n      <li>Max sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-126-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1029\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1030\"><span class=\"mi\" id=\"MathJax-Span-1031\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-126\">n</script></li>\n      <li>Number of heads <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-127-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1032\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1033\"><span class=\"mi\" id=\"MathJax-Span-1034\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-127\">H</script></li>\n      <li>Head dimension <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-128-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1035\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1036\"><span class=\"msubsup\" id=\"MathJax-Span-1037\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1038\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1039\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-128\">d_k</script></li>\n      <li>Number of layers <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-129-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1040\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1041\"><span class=\"mi\" id=\"MathJax-Span-1042\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-129\">l</script></li>\n    </ul>\n<p>The KV cache is structured to store <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-130-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1043\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1044\"><span class=\"mi\" id=\"MathJax-Span-1045\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-130\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-131-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1046\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1047\"><span class=\"mi\" id=\"MathJax-Span-1048\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-131\">V</script> for each <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-132-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi><mo>,</mo><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo>,</mo><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1049\" style=\"width: 9.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.763em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.71em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1050\"><span class=\"mo\" id=\"MathJax-Span-1051\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1052\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-1053\" style=\"font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-1054\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-1055\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-1056\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1057\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1058\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-1059\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-1060\" style=\"font-family: STIXGeneral-Italic;\">y</span><span class=\"mi\" id=\"MathJax-Span-1061\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-1062\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1063\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1064\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">h</span><span class=\"mi\" id=\"MathJax-Span-1065\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-1066\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-1067\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1068\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>t</mi><mi>o</mi><mi>k</mi><mi>e</mi><mi>n</mi><mo>,</mo><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo>,</mo><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-132\">(token, layer, head)</script> tuple. For a <strong>given layer</strong> and <strong>head</strong>, the cache tensor shapes and sizes are:</p>\n<ul>\n      <li>\n        <p><strong>Key cache (per layer, per head):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-133-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1069\" style=\"width: 8.023em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.669em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1006.67em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1070\"><span class=\"msubsup\" id=\"MathJax-Span-1071\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1072\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.25em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1073\"><span class=\"mrow\" id=\"MathJax-Span-1074\"><span class=\"mo\" id=\"MathJax-Span-1075\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1076\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1077\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1078\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1079\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.67em, 4.169em, -999.997em); top: -3.695em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-1080\"><span class=\"mrow\" id=\"MathJax-Span-1081\"><span class=\"mtext\" id=\"MathJax-Span-1082\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1083\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1084\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.128em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1085\"><span class=\"mrow\" id=\"MathJax-Span-1086\"><span class=\"mi\" id=\"MathJax-Span-1087\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1088\"><span class=\"mrow\" id=\"MathJax-Span-1089\"><span class=\"mi\" id=\"MathJax-Span-1090\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1091\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1092\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1093\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1094\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1095\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1096\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-133\">K_{\\text{cache}}^{(l,h)} \\in \\mathbb{R}^{B \\times n \\times d_k}</script>\n\n        <ul>\n          <li><strong>Key cache size (in bytes):</strong></li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-134-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>K</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1097\" style=\"width: 16.409em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 13.648em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1013.6em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1098\"><span class=\"msubsup\" id=\"MathJax-Span-1099\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1100\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.25em, 4.273em, -999.997em); top: -4.477em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-1101\"><span class=\"mrow\" id=\"MathJax-Span-1102\"><span class=\"mo\" id=\"MathJax-Span-1103\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1104\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1105\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1106\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1107\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1108\"><span class=\"mrow\" id=\"MathJax-Span-1109\"><span class=\"mi\" id=\"MathJax-Span-1110\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1111\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-1112\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1113\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1114\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1115\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1116\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1117\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1118\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1119\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1120\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>K</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-134\">S_{K}^{(l,h)} = B \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n      </li>\n      <li>\n        <p><strong>Value cache (per layer, per head):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-135-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1121\" style=\"width: 7.971em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.617em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1006.62em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1122\"><span class=\"msubsup\" id=\"MathJax-Span-1123\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1124\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.25em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1125\"><span class=\"mrow\" id=\"MathJax-Span-1126\"><span class=\"mo\" id=\"MathJax-Span-1127\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1128\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1129\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1130\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1131\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.67em, 4.169em, -999.997em); top: -3.695em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1132\"><span class=\"mrow\" id=\"MathJax-Span-1133\"><span class=\"mtext\" id=\"MathJax-Span-1134\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1135\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1136\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.128em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1137\"><span class=\"mrow\" id=\"MathJax-Span-1138\"><span class=\"mi\" id=\"MathJax-Span-1139\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1140\"><span class=\"mrow\" id=\"MathJax-Span-1141\"><span class=\"mi\" id=\"MathJax-Span-1142\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1143\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1144\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1145\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1146\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1147\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1148\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-135\">V_{\\text{cache}}^{(l,h)} \\in \\mathbb{R}^{B \\times n \\times d_k}</script>\n\n        <ul>\n          <li><strong>Value cache size (in bytes):</strong></li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-136-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>V</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1149\" style=\"width: 16.409em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 13.648em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1013.6em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1150\"><span class=\"msubsup\" id=\"MathJax-Span-1151\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1152\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.25em, 4.273em, -999.997em); top: -4.477em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-1153\"><span class=\"mrow\" id=\"MathJax-Span-1154\"><span class=\"mo\" id=\"MathJax-Span-1155\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1156\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1157\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1158\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1159\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1160\"><span class=\"mrow\" id=\"MathJax-Span-1161\"><span class=\"mi\" id=\"MathJax-Span-1162\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1163\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-1164\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1165\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1166\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1167\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1168\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1169\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1170\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1171\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1172\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>V</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-136\">S_{V}^{(l,h)} = B \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n      </li>\n      <li>\n        <p><strong>Total memory size per layer and head (in bytes):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-137-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>layer, head</mtext></mrow></msub><mo>=</mo><mn>2</mn><mo>&amp;#x00D7;</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1173\" style=\"width: 20.523em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1017.03em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1174\"><span class=\"msubsup\" id=\"MathJax-Span-1175\"><span style=\"display: inline-block; position: relative; width: 3.701em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1176\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1177\"><span class=\"mrow\" id=\"MathJax-Span-1178\"><span class=\"mtext\" id=\"MathJax-Span-1179\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">layer, head</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1180\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1181\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span><span class=\"mo\" id=\"MathJax-Span-1182\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1183\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1184\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1185\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1186\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1187\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1188\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1189\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1190\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1191\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>layer, head</mtext></mrow></msub><mo>=</mo><mn>2</mn><mo>×</mo><mi>B</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-137\">S_{\\text{layer, head}} = 2 \\times B \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n\n        <ul>\n          <li>The factor of 2 accounts for both the key and value tensors.</li>\n        </ul>\n      </li>\n    </ul>\n<p><strong>Key cache (per layer, per head):</strong></p>\n<ul>\n          <li><strong>Key cache size (in bytes):</strong></li>\n        </ul>\n<p><strong>Value cache (per layer, per head):</strong></p>\n<ul>\n          <li><strong>Value cache size (in bytes):</strong></li>\n        </ul>\n<p><strong>Total memory size per layer and head (in bytes):</strong></p>\n<ul>\n          <li>The factor of 2 accounts for both the key and value tensors.</li>\n        </ul>\n<p>When combining all layers and attention heads, the total KV cache represents the complete memory footprint required to store all key and value tensors across the entire model. The following equations describe the full model-wide KV Cache cache dimensions and their corresponding memory requirements:</p>\n<ul>\n      <li>\n        <p><strong>Key cache (all layers, all attention heads):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-138-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mtext>total</mtext><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1192\" style=\"width: 10.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.596em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1008.6em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1193\"><span class=\"msubsup\" id=\"MathJax-Span-1194\"><span style=\"display: inline-block; position: relative; width: 2.607em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1195\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.83em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1196\"><span class=\"mrow\" id=\"MathJax-Span-1197\"><span class=\"mo\" id=\"MathJax-Span-1198\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-1199\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">total</span><span class=\"mo\" id=\"MathJax-Span-1200\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.67em, 4.169em, -999.997em); top: -3.695em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-1201\"><span class=\"mrow\" id=\"MathJax-Span-1202\"><span class=\"mtext\" id=\"MathJax-Span-1203\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1204\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1205\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 4.794em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1206\"><span class=\"mrow\" id=\"MathJax-Span-1207\"><span class=\"mi\" id=\"MathJax-Span-1208\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1209\"><span class=\"mrow\" id=\"MathJax-Span-1210\"><span class=\"mi\" id=\"MathJax-Span-1211\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1212\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1213\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1214\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1215\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1216\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1217\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1218\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1219\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1220\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1221\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mtext>total</mtext><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>l</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-138\">K_{\\text{cache}}^{(\\text{total})} \\in \\mathbb{R}^{B \\times l \\times H \\times n \\times d_k}</script>\n\n        <ul>\n          <li><strong>Key cache size (in bytes):</strong></li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-139-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>K</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mtext>total</mtext><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1222\" style=\"width: 20.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.398em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1017.35em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1223\"><span class=\"msubsup\" id=\"MathJax-Span-1224\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1225\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.83em, 4.273em, -999.997em); top: -4.477em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-1226\"><span class=\"mrow\" id=\"MathJax-Span-1227\"><span class=\"mo\" id=\"MathJax-Span-1228\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-1229\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">total</span><span class=\"mo\" id=\"MathJax-Span-1230\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1231\"><span class=\"mrow\" id=\"MathJax-Span-1232\"><span class=\"mi\" id=\"MathJax-Span-1233\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1234\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-1235\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1236\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1237\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1238\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1239\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1240\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1241\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1242\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1243\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1244\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1245\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1246\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1247\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>K</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mtext>total</mtext><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>×</mo><mi>l</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-139\">S_{K}^{(\\text{total})} = B \\times l \\times H \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n      </li>\n      <li>\n        <p><strong>Value cache (all layers, all attention heads):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-140-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mtext>total</mtext><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1248\" style=\"width: 10.263em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.544em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1008.54em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1249\"><span class=\"msubsup\" id=\"MathJax-Span-1250\"><span style=\"display: inline-block; position: relative; width: 2.555em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1251\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.83em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1252\"><span class=\"mrow\" id=\"MathJax-Span-1253\"><span class=\"mo\" id=\"MathJax-Span-1254\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-1255\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">total</span><span class=\"mo\" id=\"MathJax-Span-1256\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.67em, 4.169em, -999.997em); top: -3.695em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1257\"><span class=\"mrow\" id=\"MathJax-Span-1258\"><span class=\"mtext\" id=\"MathJax-Span-1259\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1260\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1261\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 4.794em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1262\"><span class=\"mrow\" id=\"MathJax-Span-1263\"><span class=\"mi\" id=\"MathJax-Span-1264\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1265\"><span class=\"mrow\" id=\"MathJax-Span-1266\"><span class=\"mi\" id=\"MathJax-Span-1267\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1268\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1269\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1270\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1271\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1272\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1273\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1274\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1275\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1276\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1277\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mtext>total</mtext><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>l</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-140\">V_{\\text{cache}}^{(\\text{total})} \\in \\mathbb{R}^{B \\times l \\times H \\times n \\times d_k}</script>\n\n        <ul>\n          <li><strong>Value cache size (in bytes):</strong></li>\n        </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-141-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>V</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mtext>total</mtext><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1278\" style=\"width: 20.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.398em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1017.35em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1279\"><span class=\"msubsup\" id=\"MathJax-Span-1280\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1281\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.83em, 4.273em, -999.997em); top: -4.477em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-1282\"><span class=\"mrow\" id=\"MathJax-Span-1283\"><span class=\"mo\" id=\"MathJax-Span-1284\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-1285\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">total</span><span class=\"mo\" id=\"MathJax-Span-1286\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1287\"><span class=\"mrow\" id=\"MathJax-Span-1288\"><span class=\"mi\" id=\"MathJax-Span-1289\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1290\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-1291\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1292\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1293\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1294\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1295\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1296\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1297\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1298\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1299\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1300\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1301\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1302\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1303\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>V</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mtext>total</mtext><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>=</mo><mi>B</mi><mo>×</mo><mi>l</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-141\">S_{V}^{(\\text{total})} = B \\times l \\times H \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n      </li>\n      <li>\n        <p><strong>Total memory size across the entire model (in bytes):</strong></p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-142-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>S</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>total</mtext></mrow></msub><mo>=</mo><mn>2</mn><mo>&amp;#x00D7;</mo><mi>B</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mtext>sizeof(dtype)</mtext></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1304\" style=\"width: 22.138em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 18.44em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1018.39em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1305\"><span class=\"msubsup\" id=\"MathJax-Span-1306\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1307\" style=\"font-family: STIXGeneral-Italic;\">S<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1308\"><span class=\"mrow\" id=\"MathJax-Span-1309\"><span class=\"mtext\" id=\"MathJax-Span-1310\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">total</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1311\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1312\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span><span class=\"mo\" id=\"MathJax-Span-1313\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1314\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">B</span><span class=\"mo\" id=\"MathJax-Span-1315\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1316\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1317\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1318\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1319\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-1320\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1321\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1322\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1323\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1324\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1325\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-1326\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">sizeof(dtype)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>S</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>total</mtext></mrow></msub><mo>=</mo><mn>2</mn><mo>×</mo><mi>B</mi><mo>×</mo><mi>l</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mtext>sizeof(dtype)</mtext></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-142\">S_{\\text{total}} = 2 \\times B \\times l \\times H \\times n \\times d_k \\times \\text{sizeof(dtype)}</script>\n      </li>\n    </ul>\n<p><strong>Key cache (all layers, all attention heads):</strong></p>\n<ul>\n          <li><strong>Key cache size (in bytes):</strong></li>\n        </ul>\n<p><strong>Value cache (all layers, all attention heads):</strong></p>\n<ul>\n          <li><strong>Value cache size (in bytes):</strong></li>\n        </ul>\n<p><strong>Total memory size across the entire model (in bytes):</strong></p>\n<p><strong>Notes:</strong></p>\n<ul>\n      <li>The cache size scales linearly with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-143-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1327\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1328\"><span class=\"mi\" id=\"MathJax-Span-1329\" style=\"font-family: STIXGeneral-Italic;\">B</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-143\">B</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-144-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1330\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1331\"><span class=\"mi\" id=\"MathJax-Span-1332\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-144\">l</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-145-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1333\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1334\"><span class=\"mi\" id=\"MathJax-Span-1335\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-145\">H</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-146-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1336\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1337\"><span class=\"mi\" id=\"MathJax-Span-1338\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-146\">n</script>, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-147-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1339\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1340\"><span class=\"msubsup\" id=\"MathJax-Span-1341\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1342\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1343\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-147\">d_k</script>. During autoregressive generation, the model processes one token per step in the decode phase, only <strong>one</strong> new key and one new value vector are appended at each step for every layer and head. Consequently, as decoding progresses, the total cache grows linearly with the number of generated tokens—reflecting the incremental accumulation of key-value pairs over time.</li>\n      <li>In practice:\n        <ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-148-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>2</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1344\" style=\"width: 8.388em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.982em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.98em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1345\"><span class=\"mtext\" id=\"MathJax-Span-1346\" style=\"font-family: STIXGeneral-Regular;\">sizeof(dtype)</span><span class=\"mo\" id=\"MathJax-Span-1347\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1348\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>2</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-148\">\\text{sizeof(dtype)} = 2</script> bytes for FP16/BF16 caches.</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-149-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1349\" style=\"width: 8.388em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.982em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.88em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1350\"><span class=\"mtext\" id=\"MathJax-Span-1351\" style=\"font-family: STIXGeneral-Regular;\">sizeof(dtype)</span><span class=\"mo\" id=\"MathJax-Span-1352\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1353\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-149\">\\text{sizeof(dtype)} = 1</script> byte for INT8 caches.</li>\n        </ul>\n      </li>\n      <li>Example: For a model with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-150-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi><mo>=</mo><mn>32</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1354\" style=\"width: 3.023em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.503em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.5em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1355\"><span class=\"mi\" id=\"MathJax-Span-1356\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1357\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1358\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">32</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi><mo>=</mo><mn>32</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-150\">l = 32</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-151-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi><mo>=</mo><mn>64</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1359\" style=\"width: 3.596em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.971em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.92em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1360\"><span class=\"mi\" id=\"MathJax-Span-1361\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1362\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1363\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">64</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi><mo>=</mo><mn>64</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-151\">H = 64</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-152-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mn>128</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1364\" style=\"width: 4.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.596em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.54em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1365\"><span class=\"msubsup\" id=\"MathJax-Span-1366\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1367\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-1368\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1369\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1370\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">128</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mn>128</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-152\">d_k = 128</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-153-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi><mo>=</mo><mn>8</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1371\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.29em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1372\"><span class=\"mi\" id=\"MathJax-Span-1373\" style=\"font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1374\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1375\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">8</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi><mo>=</mo><mn>8</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-153\">B = 8</script>, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-154-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi><mo>=</mo><mn>4096</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1376\" style=\"width: 4.482em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.701em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.65em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1377\"><span class=\"mi\" id=\"MathJax-Span-1378\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1379\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1380\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">4096</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi><mo>=</mo><mn>4096</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-154\">n = 4096</script>, the KV cache can easily consume tens of gigabytes of GPU memory.\nEfficient cache management (e.g., truncation, quantization, or offloading) is thus essential for real-world deployment.</li>\n      <li>Efficient memory layout is crucial — contiguous buffers enable fast appends and reduce memory copy overhead.</li>\n    </ul>\n<ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-148-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>2</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1344\" style=\"width: 8.388em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.982em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.98em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1345\"><span class=\"mtext\" id=\"MathJax-Span-1346\" style=\"font-family: STIXGeneral-Regular;\">sizeof(dtype)</span><span class=\"mo\" id=\"MathJax-Span-1347\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1348\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>2</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-148\">\\text{sizeof(dtype)} = 2</script> bytes for FP16/BF16 caches.</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-149-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1349\" style=\"width: 8.388em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.982em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.88em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1350\"><span class=\"mtext\" id=\"MathJax-Span-1351\" style=\"font-family: STIXGeneral-Regular;\">sizeof(dtype)</span><span class=\"mo\" id=\"MathJax-Span-1352\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-1353\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mtext>sizeof(dtype)</mtext><mo>=</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-149\">\\text{sizeof(dtype)} = 1</script> byte for INT8 caches.</li>\n        </ul>\n<h5 id=\"prefill-phase\">Prefill Phase</h5>\n<ul>\n  <li>\n    <p>When the prompt is first processed:</p>\n\n    <ul>\n      <li>The model computes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-155-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1381\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1382\"><span class=\"mi\" id=\"MathJax-Span-1383\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-155\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-156-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1384\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1385\"><span class=\"mi\" id=\"MathJax-Span-1386\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-156\">V</script> for <strong>all</strong> prompt tokens in every layer, filling the cache.</li>\n      <li>This initial step has the same cost as the naive approach:</li>\n    </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-157-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1387\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1388\"><span class=\"mi\" id=\"MathJax-Span-1389\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1390\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1391\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1392\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1393\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1394\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1395\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1396\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1397\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1398\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-157\">O(l \\cdot n \\cdot d^2)</script>\n  </li>\n  <li>\n    <p>After this, we move into the decode phase, where caching delivers the performance benefits.</p>\n  </li>\n</ul>\n<p>When the prompt is first processed:</p>\n<ul>\n      <li>The model computes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-155-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1381\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1382\"><span class=\"mi\" id=\"MathJax-Span-1383\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-155\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-156-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1384\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1385\"><span class=\"mi\" id=\"MathJax-Span-1386\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-156\">V</script> for <strong>all</strong> prompt tokens in every layer, filling the cache.</li>\n      <li>This initial step has the same cost as the naive approach:</li>\n    </ul>\n<p>After this, we move into the decode phase, where caching delivers the performance benefits.</p>\n<h5 id=\"updates-to-the-kv-cache\">Updates to the KV Cache</h5>\n<ul>\n  <li>During autoregressive decoding, the <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-158-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1399\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1400\"><span class=\"mi\" id=\"MathJax-Span-1401\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-158\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-159-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1402\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1403\"><span class=\"mi\" id=\"MathJax-Span-1404\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-159\">V</script> projections are cached for every processed token, across all layers and heads.</li>\n  <li>\n    <p>Each time a new token is generated:</p>\n\n    <ol>\n      <li>The model computes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-160-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>k</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1405\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1406\"><span class=\"msubsup\" id=\"MathJax-Span-1407\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1408\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-1409\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>k</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-160\">k_t</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-161-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>v</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1410\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1411\"><span class=\"msubsup\" id=\"MathJax-Span-1412\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1413\" style=\"font-family: STIXGeneral-Italic;\">v</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-1414\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>v</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-161\">v_t</script> for that token in each layer.</li>\n      <li>These vectors are appended to the existing <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-162-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1415\" style=\"width: 2.919em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.398em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.4em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1416\"><span class=\"msubsup\" id=\"MathJax-Span-1417\"><span style=\"display: inline-block; position: relative; width: 2.398em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1418\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-1419\"><span class=\"mrow\" id=\"MathJax-Span-1420\"><span class=\"mi\" id=\"MathJax-Span-1421\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-1422\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-1423\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-1424\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-1425\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-162\">K_{cache}</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-163-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1426\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.35em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1427\"><span class=\"msubsup\" id=\"MathJax-Span-1428\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1429\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1430\"><span class=\"mrow\" id=\"MathJax-Span-1431\"><span class=\"mi\" id=\"MathJax-Span-1432\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-1433\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-1434\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-1435\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-1436\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-163\">V_{cache}</script>.</li>\n      <li>The updated cache is then used to compute the attention output for the next token.</li>\n    </ol>\n  </li>\n</ul>\n<p>Each time a new token is generated:</p>\n<ol>\n      <li>The model computes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-160-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>k</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1405\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1406\"><span class=\"msubsup\" id=\"MathJax-Span-1407\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1408\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-1409\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>k</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-160\">k_t</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-161-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>v</mi><mi>t</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1410\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1411\"><span class=\"msubsup\" id=\"MathJax-Span-1412\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1413\" style=\"font-family: STIXGeneral-Italic;\">v</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-1414\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>v</mi><mi>t</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-161\">v_t</script> for that token in each layer.</li>\n      <li>These vectors are appended to the existing <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-162-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1415\" style=\"width: 2.919em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.398em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.4em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1416\"><span class=\"msubsup\" id=\"MathJax-Span-1417\"><span style=\"display: inline-block; position: relative; width: 2.398em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1418\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-1419\"><span class=\"mrow\" id=\"MathJax-Span-1420\"><span class=\"mi\" id=\"MathJax-Span-1421\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-1422\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-1423\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-1424\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-1425\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-162\">K_{cache}</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-163-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1426\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.35em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1427\"><span class=\"msubsup\" id=\"MathJax-Span-1428\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1429\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1430\"><span class=\"mrow\" id=\"MathJax-Span-1431\"><span class=\"mi\" id=\"MathJax-Span-1432\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-1433\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-1434\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-1435\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-1436\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-163\">V_{cache}</script>.</li>\n      <li>The updated cache is then used to compute the attention output for the next token.</li>\n    </ol>\n<h4 id=\"latency-optimizationsavings\">Latency Optimization/Savings</h4>\n<h5 id=\"projection-cost\">Projection Cost</h5>\n<ul>\n  <li>\n    <p><strong>Without caching</strong>:</p>\n\n    <ul>\n      <li>For a single head, at decoding step with sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-164-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1437\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1438\"><span class=\"mi\" id=\"MathJax-Span-1439\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-164\">n</script>, the self-attention module recomputes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-165-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1440\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1441\"><span class=\"mi\" id=\"MathJax-Span-1442\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-165\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-166-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1443\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1444\"><span class=\"mi\" id=\"MathJax-Span-1445\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-166\">V</script> for all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-167-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1446\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1447\"><span class=\"mi\" id=\"MathJax-Span-1448\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-167\">n</script> tokens across all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-168-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1449\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1450\"><span class=\"mi\" id=\"MathJax-Span-1451\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-168\">l</script> layers. Put simply, each new generated token waits for full attention recomputation.</li>\n      <li>\n        <p>Computational cost per predicted token:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-169-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1452\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1453\"><span class=\"mi\" id=\"MathJax-Span-1454\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1455\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1456\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1457\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1458\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1459\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1460\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1461\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1462\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1463\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-169\">O(l \\cdot n \\cdot d^2)</script>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>With caching</strong>:</p>\n\n    <ul>\n      <li>Only the key and value for the <strong>new</strong> token are computed, while the rest are reused from the cache. Put simply, each token only computes new attention scores.</li>\n      <li>\n        <p>Computational cost per predicted token:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-170-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1464\" style=\"width: 4.378em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.648em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1003.6em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1465\"><span class=\"mi\" id=\"MathJax-Span-1466\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1467\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1468\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1469\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1470\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1471\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1472\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1473\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-170\">O(l \\cdot d^2)</script>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p>This represents an <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-171-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1474\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1475\"><span class=\"mi\" id=\"MathJax-Span-1476\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-171\">n</script>-times speedup in the sequence dimension. For large <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-172-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1477\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1478\"><span class=\"mi\" id=\"MathJax-Span-1479\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-172\">n</script> (e.g., thousands or millions of tokens), the cost reduction is dramatic.</p>\n  </li>\n</ul>\n<p><strong>Without caching</strong>:</p>\n<ul>\n      <li>For a single head, at decoding step with sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-164-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1437\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1438\"><span class=\"mi\" id=\"MathJax-Span-1439\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-164\">n</script>, the self-attention module recomputes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-165-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1440\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1441\"><span class=\"mi\" id=\"MathJax-Span-1442\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-165\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-166-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1443\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1444\"><span class=\"mi\" id=\"MathJax-Span-1445\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-166\">V</script> for all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-167-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1446\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1447\"><span class=\"mi\" id=\"MathJax-Span-1448\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-167\">n</script> tokens across all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-168-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1449\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1450\"><span class=\"mi\" id=\"MathJax-Span-1451\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-168\">l</script> layers. Put simply, each new generated token waits for full attention recomputation.</li>\n      <li>\n        <p>Computational cost per predicted token:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-169-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1452\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1453\"><span class=\"mi\" id=\"MathJax-Span-1454\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1455\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1456\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1457\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1458\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1459\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1460\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1461\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1462\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1463\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-169\">O(l \\cdot n \\cdot d^2)</script>\n      </li>\n    </ul>\n<p>Computational cost per predicted token:</p>\n<p><strong>With caching</strong>:</p>\n<ul>\n      <li>Only the key and value for the <strong>new</strong> token are computed, while the rest are reused from the cache. Put simply, each token only computes new attention scores.</li>\n      <li>\n        <p>Computational cost per predicted token:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-170-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1464\" style=\"width: 4.378em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.648em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1003.6em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1465\"><span class=\"mi\" id=\"MathJax-Span-1466\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1467\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1468\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1469\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1470\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1471\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1472\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1473\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-170\">O(l \\cdot d^2)</script>\n      </li>\n    </ul>\n<p>Computational cost per predicted token:</p>\n<p>This represents an <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-171-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1474\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1475\"><span class=\"mi\" id=\"MathJax-Span-1476\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-171\">n</script>-times speedup in the sequence dimension. For large <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-172-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1477\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1478\"><span class=\"mi\" id=\"MathJax-Span-1479\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-172\">n</script> (e.g., thousands or millions of tokens), the cost reduction is dramatic.</p>\n<h5 id=\"attention-score-computation\">Attention Score Computation</h5>\n<ul>\n  <li>\n    <p><strong>Without caching</strong>:</p>\n\n    <ul>\n      <li>\n        <p>At sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-173-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1480\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1481\"><span class=\"mi\" id=\"MathJax-Span-1482\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-173\">n</script>, computing the attention scores requires multiplying the query for the new token with all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-174-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1483\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1484\"><span class=\"mi\" id=\"MathJax-Span-1485\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-174\">n</script> keys. This is done for every layer, so the attention score computation cost per predicted token is:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-175-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1486\" style=\"width: 5.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.638em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1004.59em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1487\"><span class=\"mi\" id=\"MathJax-Span-1488\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1489\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1490\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1491\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1492\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1493\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1494\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1495\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-175\">O(l \\cdot n \\cdot d)</script>\n      </li>\n      <li>\n        <p>Because <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-176-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1496\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1497\"><span class=\"mi\" id=\"MathJax-Span-1498\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-176\">n</script> increases with each generated token, the latency for this step grows linearly in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-177-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1499\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1500\"><span class=\"mi\" id=\"MathJax-Span-1501\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-177\">n</script> per token generation, but overall decoding (projection + attention) without caching still has quadratic growth in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-178-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1502\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1503\"><span class=\"mi\" id=\"MathJax-Span-1504\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-178\">n</script>.</p>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>With caching</strong>:</p>\n\n    <ul>\n      <li>\n        <p>Keys from all previous tokens are already stored. At sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-179-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1505\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1506\"><span class=\"mi\" id=\"MathJax-Span-1507\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-179\">n</script>, we only compute the dot products between the new query and the cached keys:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-180-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1508\" style=\"width: 5.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.638em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1004.59em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1509\"><span class=\"mi\" id=\"MathJax-Span-1510\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1511\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1512\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1513\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1514\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1515\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1516\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1517\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-180\">O(l \\cdot n \\cdot d)</script>\n      </li>\n      <li>\n        <p>The cost per token still grows linearly with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-181-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1518\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1519\"><span class=\"mi\" id=\"MathJax-Span-1520\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-181\">n</script>, but caching removes the quadratic growth that comes from recomputing keys and values for older tokens.</p>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p><strong>Without caching</strong>:</p>\n<ul>\n      <li>\n        <p>At sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-173-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1480\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1481\"><span class=\"mi\" id=\"MathJax-Span-1482\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-173\">n</script>, computing the attention scores requires multiplying the query for the new token with all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-174-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1483\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1484\"><span class=\"mi\" id=\"MathJax-Span-1485\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-174\">n</script> keys. This is done for every layer, so the attention score computation cost per predicted token is:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-175-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1486\" style=\"width: 5.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.638em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1004.59em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1487\"><span class=\"mi\" id=\"MathJax-Span-1488\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1489\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1490\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1491\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1492\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1493\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1494\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1495\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-175\">O(l \\cdot n \\cdot d)</script>\n      </li>\n      <li>\n        <p>Because <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-176-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1496\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1497\"><span class=\"mi\" id=\"MathJax-Span-1498\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-176\">n</script> increases with each generated token, the latency for this step grows linearly in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-177-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1499\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1500\"><span class=\"mi\" id=\"MathJax-Span-1501\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-177\">n</script> per token generation, but overall decoding (projection + attention) without caching still has quadratic growth in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-178-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1502\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1503\"><span class=\"mi\" id=\"MathJax-Span-1504\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-178\">n</script>.</p>\n      </li>\n    </ul>\n<p>At sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-173-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1480\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1481\"><span class=\"mi\" id=\"MathJax-Span-1482\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-173\">n</script>, computing the attention scores requires multiplying the query for the new token with all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-174-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1483\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1484\"><span class=\"mi\" id=\"MathJax-Span-1485\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-174\">n</script> keys. This is done for every layer, so the attention score computation cost per predicted token is:</p>\n<p>Because <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-176-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1496\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1497\"><span class=\"mi\" id=\"MathJax-Span-1498\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-176\">n</script> increases with each generated token, the latency for this step grows linearly in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-177-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1499\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1500\"><span class=\"mi\" id=\"MathJax-Span-1501\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-177\">n</script> per token generation, but overall decoding (projection + attention) without caching still has quadratic growth in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-178-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1502\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1503\"><span class=\"mi\" id=\"MathJax-Span-1504\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-178\">n</script>.</p>\n<p><strong>With caching</strong>:</p>\n<ul>\n      <li>\n        <p>Keys from all previous tokens are already stored. At sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-179-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1505\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1506\"><span class=\"mi\" id=\"MathJax-Span-1507\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-179\">n</script>, we only compute the dot products between the new query and the cached keys:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-180-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1508\" style=\"width: 5.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.638em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1004.59em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1509\"><span class=\"mi\" id=\"MathJax-Span-1510\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1511\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1512\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1513\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1514\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1515\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1516\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1517\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-180\">O(l \\cdot n \\cdot d)</script>\n      </li>\n      <li>\n        <p>The cost per token still grows linearly with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-181-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1518\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1519\"><span class=\"mi\" id=\"MathJax-Span-1520\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-181\">n</script>, but caching removes the quadratic growth that comes from recomputing keys and values for older tokens.</p>\n      </li>\n    </ul>\n<p>Keys from all previous tokens are already stored. At sequence length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-179-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1505\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1506\"><span class=\"mi\" id=\"MathJax-Span-1507\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-179\">n</script>, we only compute the dot products between the new query and the cached keys:</p>\n<p>The cost per token still grows linearly with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-181-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1518\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1519\"><span class=\"mi\" id=\"MathJax-Span-1520\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-181\">n</script>, but caching removes the quadratic growth that comes from recomputing keys and values for older tokens.</p>\n<h5 id=\"total-complexity\">Total Complexity</h5>\n<ul>\n  <li>\n    <p>KV caching transforms overall decoding latency from quadratic in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-182-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1521\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1522\"><span class=\"mi\" id=\"MathJax-Span-1523\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-182\">n</script> to approximately linear in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-183-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1524\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1525\"><span class=\"mi\" id=\"MathJax-Span-1526\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-183\">n</script>, a major improvement for long-sequence generation. Specifically, KV caching changes the dominant scaling term from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-184-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1527\" style=\"width: 5.159em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.273em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1004.22em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1528\"><span class=\"mi\" id=\"MathJax-Span-1529\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1530\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-1531\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1532\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-1533\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1534\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1535\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1536\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1537\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1538\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-184\">O(n^2 \\cdot d^2)</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-185-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1539\" style=\"width: 4.638em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.857em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1003.8em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1540\"><span class=\"mi\" id=\"MathJax-Span-1541\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1542\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-1543\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1544\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-1545\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1546\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1547\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1548\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-185\">O(n^2 \\cdot d)</script> which, for typical transformer sizes, is a substantial improvement in long-sequence latency. This is mathematically represented below.</p>\n  </li>\n  <li>\n    <p><strong>Without caching</strong>:</p>\n\n    <ul>\n      <li>\n        <p>Total cost per predicted token = projection cost + attention score computation:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-186-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2248;</mo><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1549\" style=\"width: 20.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1017.09em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1550\"><span class=\"mi\" id=\"MathJax-Span-1551\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1552\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1553\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1554\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1555\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1556\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1557\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1558\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1559\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1560\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-1561\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-1562\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">O</span><span class=\"mo\" id=\"MathJax-Span-1563\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1564\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1565\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1566\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1567\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1568\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1569\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-1570\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≈</span><span class=\"mi\" id=\"MathJax-Span-1571\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">O</span><span class=\"mo\" id=\"MathJax-Span-1572\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1573\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1574\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1575\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1576\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1577\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1578\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1579\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1580\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo><mo>+</mo><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo><mo>≈</mo><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-186\">O(l \\cdot n \\cdot d^2) + O(l \\cdot n \\cdot d) \\approx O(l \\cdot n \\cdot d^2)</script>\n      </li>\n      <li>\n        <p>Over an entire sequence of length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-187-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1581\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1582\"><span class=\"mi\" id=\"MathJax-Span-1583\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-187\">n</script>, the total decoding cost is:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-188-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>n</mi><mn>2</mn></msup><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1584\" style=\"width: 6.669em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1005.47em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1585\"><span class=\"mi\" id=\"MathJax-Span-1586\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1587\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1588\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1589\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1590\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1591\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-1592\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1593\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1594\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1595\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1596\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1597\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-188\">O(l \\cdot n^2 \\cdot d^2)</script>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>With caching</strong>:</p>\n\n    <ul>\n      <li>\n        <p>Total cost per predicted token = projection cost + attention score computation:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-189-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2248;</mo><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1598\" style=\"width: 18.284em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 15.211em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1015.16em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1599\"><span class=\"mi\" id=\"MathJax-Span-1600\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1601\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1602\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1603\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1604\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1605\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1606\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1607\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-1608\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-1609\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">O</span><span class=\"mo\" id=\"MathJax-Span-1610\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1611\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1612\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1613\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1614\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1615\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1616\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-1617\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≈</span><span class=\"mi\" id=\"MathJax-Span-1618\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">O</span><span class=\"mo\" id=\"MathJax-Span-1619\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1620\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1621\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1622\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1623\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1624\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1625\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo><mo>+</mo><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo><mo>≈</mo><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-189\">O(l \\cdot d^2) + O(l \\cdot n \\cdot d) \\approx O(l \\cdot n \\cdot d)</script>\n      </li>\n      <li>\n        <p>Over an entire sequence of length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-190-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1626\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1627\"><span class=\"mi\" id=\"MathJax-Span-1628\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-190\">n</script>, the total decoding cost is:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-191-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>n</mi><mn>2</mn></msup><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1629\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1630\"><span class=\"mi\" id=\"MathJax-Span-1631\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1632\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1633\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1634\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1635\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1636\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-1637\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1638\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1639\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1640\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-191\">O(l \\cdot n^2 \\cdot d)</script>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>KV caching transforms overall decoding latency from quadratic in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-182-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1521\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1522\"><span class=\"mi\" id=\"MathJax-Span-1523\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-182\">n</script> to approximately linear in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-183-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1524\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1525\"><span class=\"mi\" id=\"MathJax-Span-1526\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-183\">n</script>, a major improvement for long-sequence generation. Specifically, KV caching changes the dominant scaling term from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-184-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1527\" style=\"width: 5.159em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.273em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1004.22em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1528\"><span class=\"mi\" id=\"MathJax-Span-1529\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1530\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-1531\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1532\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-1533\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1534\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1535\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1536\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1537\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1538\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-184\">O(n^2 \\cdot d^2)</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-185-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1539\" style=\"width: 4.638em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.857em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1003.8em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1540\"><span class=\"mi\" id=\"MathJax-Span-1541\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1542\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-1543\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1544\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-1545\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1546\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1547\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1548\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-185\">O(n^2 \\cdot d)</script> which, for typical transformer sizes, is a substantial improvement in long-sequence latency. This is mathematically represented below.</p>\n<p><strong>Without caching</strong>:</p>\n<ul>\n      <li>\n        <p>Total cost per predicted token = projection cost + attention score computation:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-186-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2248;</mo><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1549\" style=\"width: 20.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1017.09em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1550\"><span class=\"mi\" id=\"MathJax-Span-1551\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1552\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1553\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1554\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1555\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1556\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1557\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1558\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1559\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1560\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-1561\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-1562\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">O</span><span class=\"mo\" id=\"MathJax-Span-1563\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1564\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1565\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1566\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1567\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1568\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1569\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-1570\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≈</span><span class=\"mi\" id=\"MathJax-Span-1571\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">O</span><span class=\"mo\" id=\"MathJax-Span-1572\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1573\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1574\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1575\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1576\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1577\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1578\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1579\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1580\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo><mo>+</mo><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo><mo>≈</mo><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-186\">O(l \\cdot n \\cdot d^2) + O(l \\cdot n \\cdot d) \\approx O(l \\cdot n \\cdot d^2)</script>\n      </li>\n      <li>\n        <p>Over an entire sequence of length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-187-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1581\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1582\"><span class=\"mi\" id=\"MathJax-Span-1583\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-187\">n</script>, the total decoding cost is:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-188-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>n</mi><mn>2</mn></msup><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1584\" style=\"width: 6.669em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1005.47em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1585\"><span class=\"mi\" id=\"MathJax-Span-1586\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1587\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1588\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1589\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1590\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1591\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-1592\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1593\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1594\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1595\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1596\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1597\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-188\">O(l \\cdot n^2 \\cdot d^2)</script>\n      </li>\n    </ul>\n<p>Total cost per predicted token = projection cost + attention score computation:</p>\n<p>Over an entire sequence of length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-187-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1581\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1582\"><span class=\"mi\" id=\"MathJax-Span-1583\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-187\">n</script>, the total decoding cost is:</p>\n<p><strong>With caching</strong>:</p>\n<ul>\n      <li>\n        <p>Total cost per predicted token = projection cost + attention score computation:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-189-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2248;</mo><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1598\" style=\"width: 18.284em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 15.211em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1015.16em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1599\"><span class=\"mi\" id=\"MathJax-Span-1600\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1601\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1602\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1603\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1604\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1605\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1606\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1607\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-1608\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-1609\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">O</span><span class=\"mo\" id=\"MathJax-Span-1610\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1611\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1612\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1613\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1614\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1615\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1616\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-1617\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≈</span><span class=\"mi\" id=\"MathJax-Span-1618\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">O</span><span class=\"mo\" id=\"MathJax-Span-1619\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1620\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1621\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1622\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1623\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1624\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1625\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo><mo>+</mo><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo><mo>≈</mo><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-189\">O(l \\cdot d^2) + O(l \\cdot n \\cdot d) \\approx O(l \\cdot n \\cdot d)</script>\n      </li>\n      <li>\n        <p>Over an entire sequence of length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-190-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1626\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1627\"><span class=\"mi\" id=\"MathJax-Span-1628\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-190\">n</script>, the total decoding cost is:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-191-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>n</mi><mn>2</mn></msup><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1629\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1630\"><span class=\"mi\" id=\"MathJax-Span-1631\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1632\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1633\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1634\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1635\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1636\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-1637\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1638\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1639\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1640\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-191\">O(l \\cdot n^2 \\cdot d)</script>\n      </li>\n    </ul>\n<p>Total cost per predicted token = projection cost + attention score computation:</p>\n<p>Over an entire sequence of length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-190-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1626\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1627\"><span class=\"mi\" id=\"MathJax-Span-1628\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-190\">n</script>, the total decoding cost is:</p>\n<h4 id=\"practical-kv-cache-implementation\">Practical KV Cache Implementation</h4>\n<ul>\n  <li>This section connects the abstract cache shapes and complexity analysis to concrete implementation choices made in real Transformer inference engines. The emphasis is on how tensors are allocated, updated, indexed, and consumed during the prefill and decode phases.</li>\n  <li>This tight coupling between tensor layout, cache indexing, and attention computation is what enables modern LLMs to generate long sequences efficiently while maintaining strict correctness guarantees.</li>\n</ul>\n<h5 id=\"cache-allocation-and-memory-layout\">Cache Allocation and Memory Layout</h5>\n<ul>\n  <li>\n    <p>Given the full-model cache shapes:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-192-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow></msub><mo>,</mo><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>cache</mtext></mrow></msub><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>l</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1641\" style=\"width: 13.336em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 11.096em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1011.1em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1642\"><span class=\"msubsup\" id=\"MathJax-Span-1643\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1644\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-1645\"><span class=\"mrow\" id=\"MathJax-Span-1646\"><span class=\"mtext\" id=\"MathJax-Span-1647\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1648\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-1649\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1650\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1651\"><span class=\"mrow\" id=\"MathJax-Span-1652\"><span class=\"mtext\" id=\"MathJax-Span-1653\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">cache</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1654\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1655\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 4.794em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1656\"><span class=\"mrow\" id=\"MathJax-Span-1657\"><span class=\"mi\" id=\"MathJax-Span-1658\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1659\"><span class=\"mrow\" id=\"MathJax-Span-1660\"><span class=\"mi\" id=\"MathJax-Span-1661\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1662\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1663\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1664\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1665\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1666\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1667\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-1668\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1669\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1670\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1671\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow></msub><mo>,</mo><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>cache</mtext></mrow></msub><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>l</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-192\">K_{\\text{cache}}, V_{\\text{cache}} \\in \\mathbb{R}^{B \\times l \\times H \\times n \\times d_k}</script>\n\n    <ul>\n      <li>… most implementations do not dynamically grow tensors with concatenation during decoding. Instead, they preallocate the full cache upfront to avoid repeated memory allocation and costly tensor re-materialization.</li>\n    </ul>\n  </li>\n  <li>\n    <p>In practice, this looks like:</p>\n  </li>\n</ul>\n<p>Given the full-model cache shapes:</p>\n<ul>\n      <li>… most implementations do not dynamically grow tensors with concatenation during decoding. Instead, they preallocate the full cache upfront to avoid repeated memory allocation and costly tensor re-materialization.</li>\n    </ul>\n<p>In practice, this looks like:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code0\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code0\"><span class=\"n\">K_cache</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">empty</span><span class=\"p\">(</span><span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"n\">H</span><span class=\"p\">,</span> <span class=\"n\">n_max</span><span class=\"p\">,</span> <span class=\"n\">d_k</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">device</span><span class=\"p\">)</span>\n<span class=\"n\">V_cache</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">empty</span><span class=\"p\">(</span><span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"n\">H</span><span class=\"p\">,</span> <span class=\"n\">n_max</span><span class=\"p\">,</span> <span class=\"n\">d_k</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">device</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code0\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code0\"><span class=\"n\">K_cache</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">empty</span><span class=\"p\">(</span><span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"n\">H</span><span class=\"p\">,</span> <span class=\"n\">n_max</span><span class=\"p\">,</span> <span class=\"n\">d_k</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">device</span><span class=\"p\">)</span>\n<span class=\"n\">V_cache</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">empty</span><span class=\"p\">(</span><span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"n\">H</span><span class=\"p\">,</span> <span class=\"n\">n_max</span><span class=\"p\">,</span> <span class=\"n\">d_k</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">dtype</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">device</span><span class=\"p\">)</span>\n</code></pre>\n<ul>\n  <li>A separate scalar (or vector, for batched decoding) tracks the current decode position:</li>\n</ul>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code1\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code1\"><span class=\"n\">cache_pos</span> <span class=\"o\">=</span> <span class=\"n\">t</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code1\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code1\"><span class=\"n\">cache_pos</span> <span class=\"o\">=</span> <span class=\"n\">t</span>\n</code></pre>\n<ul>\n  <li>\n    <p>This design choice ensures:</p>\n\n    <ul>\n      <li>Contiguous memory layout.</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-193-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1672\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.83em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1673\"><span class=\"mi\" id=\"MathJax-Span-1674\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1675\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mn\" id=\"MathJax-Span-1676\" style=\"font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-1677\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-193\">O(1)</script> writes per decoding step.</li>\n      <li>Zero tensor copies during cache updates.</li>\n    </ul>\n  </li>\n</ul>\n<p>This design choice ensures:</p>\n<ul>\n      <li>Contiguous memory layout.</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-193-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1672\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.83em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1673\"><span class=\"mi\" id=\"MathJax-Span-1674\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1675\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mn\" id=\"MathJax-Span-1676\" style=\"font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-1677\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-193\">O(1)</script> writes per decoding step.</li>\n      <li>Zero tensor copies during cache updates.</li>\n    </ul>\n<h5 id=\"writing-to-the-cache-during-decoding\">Writing to the Cache During Decoding</h5>\n<ul>\n  <li>At decoding step <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-194-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1678\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1679\"><span class=\"mi\" id=\"MathJax-Span-1680\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-194\">t</script>, for each layer <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-195-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1681\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1682\"><span class=\"mi\" id=\"MathJax-Span-1683\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-195\">l</script> and head <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-196-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>h</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1684\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1685\"><span class=\"mi\" id=\"MathJax-Span-1686\" style=\"font-family: STIXGeneral-Italic;\">h</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>h</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-196\">h</script>, the model computes a single Key and Value vector:</li>\n</ul>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-197-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>k</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>v</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1687\" style=\"width: 9.013em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.503em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1007.5em, 2.607em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1688\"><span class=\"msubsup\" id=\"MathJax-Span-1689\"><span style=\"display: inline-block; position: relative; width: 1.773em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1690\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.25em, 4.273em, -999.997em); top: -4.477em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1691\"><span class=\"mrow\" id=\"MathJax-Span-1692\"><span class=\"mo\" id=\"MathJax-Span-1693\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1694\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1695\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1696\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1697\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.492em, 1000.26em, 4.169em, -999.997em); top: -3.799em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-1698\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1699\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-1700\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1701\" style=\"font-family: STIXGeneral-Italic;\">v</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.25em, 4.273em, -999.997em); top: -4.477em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-1702\"><span class=\"mrow\" id=\"MathJax-Span-1703\"><span class=\"mo\" id=\"MathJax-Span-1704\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1705\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1706\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1707\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1708\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.492em, 1000.26em, 4.169em, -999.997em); top: -3.799em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-1709\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1710\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1711\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1712\"><span class=\"mrow\" id=\"MathJax-Span-1713\"><span class=\"mi\" id=\"MathJax-Span-1714\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1715\"><span class=\"mrow\" id=\"MathJax-Span-1716\"><span class=\"mi\" id=\"MathJax-Span-1717\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1718\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1719\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1720\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1721\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.566em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>k</mi><mi>t</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>v</mi><mi>t</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo>,</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div>\n<ul>\n  <li>These vectors are written directly into the preallocated cache:</li>\n</ul>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code2\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code2\"><span class=\"n\">K_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"n\">cache_pos</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">=</span> <span class=\"n\">K_new</span>\n<span class=\"n\">V_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"n\">cache_pos</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">=</span> <span class=\"n\">V_new</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code2\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code2\"><span class=\"n\">K_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"n\">cache_pos</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">=</span> <span class=\"n\">K_new</span>\n<span class=\"n\">V_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"n\">cache_pos</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">=</span> <span class=\"n\">V_new</span>\n</code></pre>\n<ul>\n  <li>Conceptually, this operation corresponds exactly to appending along the sequence dimension, but avoids reallocation. Over time, the cache fills along the <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-198-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1722\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1723\"><span class=\"mi\" id=\"MathJax-Span-1724\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-198\">n</script> dimension until generation ends or a maximum context length is reached.</li>\n</ul>\n<h5 id=\"reading-from-the-cache-for-attention\">Reading from the Cache for Attention</h5>\n<ul>\n  <li>When computing attention at decoding step <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-199-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1725\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1726\"><span class=\"mi\" id=\"MathJax-Span-1727\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-199\">t</script>, each layer reads all cached Keys and Values up to the current position:</li>\n</ul>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-200-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2264;</mo><mi>t</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>t</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup><mo>,</mo><mspace width=&quot;1em&quot; /><msubsup><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2264;</mo><mi>t</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>t</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1728\" style=\"width: 18.076em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 15.055em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1015.05em, 2.763em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1729\"><span class=\"msubsup\" id=\"MathJax-Span-1730\"><span style=\"display: inline-block; position: relative; width: 1.513em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1731\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.73em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1732\"><span class=\"mrow\" id=\"MathJax-Span-1733\"><span class=\"mo\" id=\"MathJax-Span-1734\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1735\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1736\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.44em, 1000.78em, 4.221em, -999.997em); top: -3.747em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-1737\"><span class=\"mrow\" id=\"MathJax-Span-1738\"><span class=\"mo\" id=\"MathJax-Span-1739\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">≤</span><span class=\"mi\" id=\"MathJax-Span-1740\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1741\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1742\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 4.013em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1743\"><span class=\"mrow\" id=\"MathJax-Span-1744\"><span class=\"mi\" id=\"MathJax-Span-1745\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1746\"><span class=\"mrow\" id=\"MathJax-Span-1747\"><span class=\"mi\" id=\"MathJax-Span-1748\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1749\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1750\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1751\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1752\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1753\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1754\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1755\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1756\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1757\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mspace\" id=\"MathJax-Span-1758\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"msubsup\" id=\"MathJax-Span-1759\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.513em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1760\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.73em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1761\"><span class=\"mrow\" id=\"MathJax-Span-1762\"><span class=\"mo\" id=\"MathJax-Span-1763\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1764\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1765\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.44em, 1000.78em, 4.221em, -999.997em); top: -3.747em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-1766\"><span class=\"mrow\" id=\"MathJax-Span-1767\"><span class=\"mo\" id=\"MathJax-Span-1768\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">≤</span><span class=\"mi\" id=\"MathJax-Span-1769\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1770\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1771\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 4.013em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1772\"><span class=\"mrow\" id=\"MathJax-Span-1773\"><span class=\"mi\" id=\"MathJax-Span-1774\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1775\"><span class=\"mrow\" id=\"MathJax-Span-1776\"><span class=\"mi\" id=\"MathJax-Span-1777\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1778\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1779\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1780\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1781\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1782\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1783\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1784\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1785\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo>≤</mo><mi>t</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>t</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup><mo>,</mo><mspace width=\"1em\"></mspace><msubsup><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo>≤</mo><mi>t</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>t</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div>\n<ul>\n  <li>This is typically implemented via slicing:</li>\n</ul>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code3\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code3\"><span class=\"n\">K_used</span> <span class=\"o\">=</span> <span class=\"n\">K_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"p\">:</span><span class=\"n\">cache_pos</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"p\">:]</span>\n<span class=\"n\">V_used</span> <span class=\"o\">=</span> <span class=\"n\">V_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"p\">:</span><span class=\"n\">cache_pos</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"p\">:]</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code3\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code3\"><span class=\"n\">K_used</span> <span class=\"o\">=</span> <span class=\"n\">K_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"p\">:</span><span class=\"n\">cache_pos</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"p\">:]</span>\n<span class=\"n\">V_used</span> <span class=\"o\">=</span> <span class=\"n\">V_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"p\">:</span><span class=\"n\">cache_pos</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"p\">:]</span>\n</code></pre>\n<ul>\n  <li>No copying occurs here; these are lightweight views into the underlying buffer.</li>\n</ul>\n<h5 id=\"query-computation-and-shape-alignment\">Query Computation and Shape Alignment</h5>\n<ul>\n  <li>The Query is computed only for the current token:</li>\n</ul>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-201-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>Q</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mn>1</mn><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1786\" style=\"width: 8.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.826em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1006.83em, 2.607em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1787\"><span class=\"msubsup\" id=\"MathJax-Span-1788\"><span style=\"display: inline-block; position: relative; width: 1.461em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1789\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.73em, 4.273em, -999.997em); top: -4.477em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1790\"><span class=\"mrow\" id=\"MathJax-Span-1791\"><span class=\"mo\" id=\"MathJax-Span-1792\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1793\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1794\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.492em, 1000.26em, 4.169em, -999.997em); top: -3.799em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-1795\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1796\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-1797\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 4.169em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1798\"><span class=\"mrow\" id=\"MathJax-Span-1799\"><span class=\"mi\" id=\"MathJax-Span-1800\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1801\"><span class=\"mrow\" id=\"MathJax-Span-1802\"><span class=\"mi\" id=\"MathJax-Span-1803\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1804\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1805\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1806\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mn\" id=\"MathJax-Span-1807\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-1808\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-1809\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1810\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-1811\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.566em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>Q</mi><mi>t</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>H</mi><mo>×</mo><mn>1</mn><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div>\n<ul>\n  <li>This shape aligns naturally with cached Keys during attention score computation:</li>\n</ul>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-202-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>Q</mi><mi>t</mi></msub><msubsup><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2264;</mo><mi>t</mi></mrow><mi mathvariant=&quot;normal&quot;>&amp;#x22A4;</mi></msubsup><mo stretchy=&quot;false&quot;>&amp;#x2192;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mn>1</mn><mo>&amp;#x00D7;</mo><mi>t</mi></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1812\" style=\"width: 9.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.763em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1007.76em, 2.711em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1813\"><span class=\"msubsup\" id=\"MathJax-Span-1814\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1815\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-1816\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-1817\"><span style=\"display: inline-block; position: relative; width: 1.461em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1818\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.58em, 4.169em, -999.997em); top: -4.372em; left: 0.784em;\"><span class=\"mi\" id=\"MathJax-Span-1819\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⊤</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.44em, 1000.78em, 4.221em, -999.997em); top: -3.747em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-1820\"><span class=\"mrow\" id=\"MathJax-Span-1821\"><span class=\"mo\" id=\"MathJax-Span-1822\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">≤</span><span class=\"mi\" id=\"MathJax-Span-1823\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1824\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">→</span><span class=\"msubsup\" id=\"MathJax-Span-1825\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.701em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-1826\"><span class=\"mrow\" id=\"MathJax-Span-1827\"><span class=\"mi\" id=\"MathJax-Span-1828\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1829\"><span class=\"mrow\" id=\"MathJax-Span-1830\"><span class=\"mi\" id=\"MathJax-Span-1831\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-1832\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1833\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1834\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mn\" id=\"MathJax-Span-1835\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-1836\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-1837\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>Q</mi><mi>t</mi></msub><msubsup><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo>≤</mo><mi>t</mi></mrow><mi mathvariant=\"normal\">⊤</mi></msubsup><mo stretchy=\"false\">→</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>H</mi><mo>×</mo><mn>1</mn><mo>×</mo><mi>t</mi></mrow></msup></math></span></span></div>\n<ul>\n  <li>The resulting attention weights are then applied to the cached Values to produce the output representation for the current token only.</li>\n</ul>\n<h5 id=\"positional-encoding-consistency-at-scale\">Positional Encoding Consistency at Scale</h5>\n<ul>\n  <li>\n    <p>Because the cache persists across decoding steps, positional encodings must be applied exactly once per token and never retroactively modified.</p>\n  </li>\n  <li><strong>Absolute positional embeddings</strong>:\n    <ul>\n      <li>The embedding for position <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-203-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1838\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1839\"><span class=\"mi\" id=\"MathJax-Span-1840\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-203\">t</script> is added during the forward pass for token <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-204-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1841\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1842\"><span class=\"mi\" id=\"MathJax-Span-1843\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-204\">t</script>. Since cached Keys and Values already contain this information, slicing older entries from the cache remains valid without adjustment.</li>\n    </ul>\n  </li>\n  <li><strong>Relative / implicit schemes (RoPE, ALiBi)</strong>:\n    <ul>\n      <li>Positional transformations are applied at Key/Query creation time. Each cached Key is permanently associated with its position index at creation:</li>\n    </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-205-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>K</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>&amp;#x2190;</mo><mtext>RoPE</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>K</mi><mi>t</mi></msub><mo>,</mo><mi>t</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1844\" style=\"width: 8.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.242em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.19em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1845\"><span class=\"msubsup\" id=\"MathJax-Span-1846\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1847\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"mi\" id=\"MathJax-Span-1848\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1849\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">←</span><span class=\"mtext\" id=\"MathJax-Span-1850\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">RoPE</span><span class=\"mo\" id=\"MathJax-Span-1851\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-1852\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1853\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"mi\" id=\"MathJax-Span-1854\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1855\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-1856\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1857\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>K</mi><mi>t</mi></msub><mo stretchy=\"false\">←</mo><mtext>RoPE</mtext><mo stretchy=\"false\">(</mo><msub><mi>K</mi><mi>t</mi></msub><mo>,</mo><mi>t</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-205\">K_t \\leftarrow \\text{RoPE}(K_t, t)</script>\n\n    <ul>\n      <li>Because relative attention depends on position differences, cached Keys remain correct when reused for future tokens without modification.</li>\n    </ul>\n  </li>\n</ul>\n<p>Because the cache persists across decoding steps, positional encodings must be applied exactly once per token and never retroactively modified.</p>\n<ul>\n      <li>The embedding for position <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-203-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1838\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1839\"><span class=\"mi\" id=\"MathJax-Span-1840\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-203\">t</script> is added during the forward pass for token <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-204-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1841\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1842\"><span class=\"mi\" id=\"MathJax-Span-1843\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-204\">t</script>. Since cached Keys and Values already contain this information, slicing older entries from the cache remains valid without adjustment.</li>\n    </ul>\n<ul>\n      <li>Positional transformations are applied at Key/Query creation time. Each cached Key is permanently associated with its position index at creation:</li>\n    </ul>\n<ul>\n      <li>Because relative attention depends on position differences, cached Keys remain correct when reused for future tokens without modification.</li>\n    </ul>\n<h5 id=\"layerwise-cache-propagation\">Layerwise Cache Propagation</h5>\n<ul>\n  <li>Each Transformer layer maintains an independent KV cache. During decoding, the cache position is shared globally, but writes occur independently per layer:</li>\n</ul>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code4\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code4\"><span class=\"k\">for</span> <span class=\"n\">l</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">num_layers</span><span class=\"p\">):</span>\n    <span class=\"n\">K_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"n\">cache_pos</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">=</span> <span class=\"n\">K_new_l</span>\n    <span class=\"n\">V_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"n\">cache_pos</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">=</span> <span class=\"n\">V_new_l</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code4\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code4\"><span class=\"k\">for</span> <span class=\"n\">l</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">num_layers</span><span class=\"p\">):</span>\n    <span class=\"n\">K_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"n\">cache_pos</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">=</span> <span class=\"n\">K_new_l</span>\n    <span class=\"n\">V_cache</span><span class=\"p\">[:,</span> <span class=\"n\">l</span><span class=\"p\">,</span> <span class=\"p\">:,</span> <span class=\"n\">cache_pos</span><span class=\"p\">,</span> <span class=\"p\">:]</span> <span class=\"o\">=</span> <span class=\"n\">V_new_l</span>\n</code></pre>\n<ul>\n  <li>This mirrors the mathematical definition where each layer has its own attention space and associated memory footprint.</li>\n</ul>\n<h5 id=\"interaction-with-prefill-and-decode-phases\">Interaction with Prefill and Decode Phases</h5>\n<ul>\n  <li>\n    <p>During the prefill phase:</p>\n\n    <ul>\n      <li>The model processes the full prompt of length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-206-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>n</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>prompt</mtext></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1858\" style=\"width: 3.128em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.607em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1002.61em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1859\"><span class=\"msubsup\" id=\"MathJax-Span-1860\"><span style=\"display: inline-block; position: relative; width: 2.607em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1861\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1862\"><span class=\"mrow\" id=\"MathJax-Span-1863\"><span class=\"mtext\" id=\"MathJax-Span-1864\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">prompt</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>n</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>prompt</mtext></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-206\">n_{\\text{prompt}}</script>.</li>\n      <li>The cache is filled for all layers, heads, and positions <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-207-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>0</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1865\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1866\"><span class=\"mn\" id=\"MathJax-Span-1867\" style=\"font-family: STIXGeneral-Regular;\">0</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>0</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-207\">0</script> through <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-208-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>n</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>prompt</mtext></mrow></msub><mo>&amp;#x2212;</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1868\" style=\"width: 5.107em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.221em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.12em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1869\"><span class=\"msubsup\" id=\"MathJax-Span-1870\"><span style=\"display: inline-block; position: relative; width: 2.607em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1871\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1872\"><span class=\"mrow\" id=\"MathJax-Span-1873\"><span class=\"mtext\" id=\"MathJax-Span-1874\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">prompt</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1875\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"mn\" id=\"MathJax-Span-1876\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>n</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>prompt</mtext></mrow></msub><mo>−</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-208\">n_{\\text{prompt}} - 1</script>.</li>\n      <li>Computational cost matches the naive Transformer forward pass.</li>\n    </ul>\n  </li>\n  <li>\n    <p>During the decode phase:</p>\n\n    <ul>\n      <li>Exactly one new Key and one new Value are written per layer and head at each step.</li>\n      <li>Projection cost collapses from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-209-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1877\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1878\"><span class=\"mi\" id=\"MathJax-Span-1879\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1880\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1881\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1882\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1883\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1884\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1885\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1886\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1887\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1888\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-209\">O(l \\cdot n \\cdot d^2)</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-210-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1889\" style=\"width: 4.378em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.648em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1003.6em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1890\"><span class=\"mi\" id=\"MathJax-Span-1891\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1892\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1893\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1894\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1895\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1896\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1897\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1898\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-210\">O(l \\cdot d^2)</script>.</li>\n      <li>Cache reads dominate memory bandwidth, while compute is concentrated in attention score evaluation.</li>\n    </ul>\n  </li>\n</ul>\n<p>During the prefill phase:</p>\n<ul>\n      <li>The model processes the full prompt of length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-206-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>n</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>prompt</mtext></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1858\" style=\"width: 3.128em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.607em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1002.61em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1859\"><span class=\"msubsup\" id=\"MathJax-Span-1860\"><span style=\"display: inline-block; position: relative; width: 2.607em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1861\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1862\"><span class=\"mrow\" id=\"MathJax-Span-1863\"><span class=\"mtext\" id=\"MathJax-Span-1864\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">prompt</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>n</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>prompt</mtext></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-206\">n_{\\text{prompt}}</script>.</li>\n      <li>The cache is filled for all layers, heads, and positions <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-207-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>0</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1865\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1866\"><span class=\"mn\" id=\"MathJax-Span-1867\" style=\"font-family: STIXGeneral-Regular;\">0</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>0</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-207\">0</script> through <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-208-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>n</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>prompt</mtext></mrow></msub><mo>&amp;#x2212;</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1868\" style=\"width: 5.107em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.221em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.12em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1869\"><span class=\"msubsup\" id=\"MathJax-Span-1870\"><span style=\"display: inline-block; position: relative; width: 2.607em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1871\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1872\"><span class=\"mrow\" id=\"MathJax-Span-1873\"><span class=\"mtext\" id=\"MathJax-Span-1874\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">prompt</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1875\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"mn\" id=\"MathJax-Span-1876\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>n</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>prompt</mtext></mrow></msub><mo>−</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-208\">n_{\\text{prompt}} - 1</script>.</li>\n      <li>Computational cost matches the naive Transformer forward pass.</li>\n    </ul>\n<p>During the decode phase:</p>\n<ul>\n      <li>Exactly one new Key and one new Value are written per layer and head at each step.</li>\n      <li>Projection cost collapses from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-209-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1877\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1878\"><span class=\"mi\" id=\"MathJax-Span-1879\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1880\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1881\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1882\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1883\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1884\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1885\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1886\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1887\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1888\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-209\">O(l \\cdot n \\cdot d^2)</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-210-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1889\" style=\"width: 4.378em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.648em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1003.6em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1890\"><span class=\"mi\" id=\"MathJax-Span-1891\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1892\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1893\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1894\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-1895\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1896\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-1897\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1898\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-210\">O(l \\cdot d^2)</script>.</li>\n      <li>Cache reads dominate memory bandwidth, while compute is concentrated in attention score evaluation.</li>\n    </ul>\n<h5 id=\"why-cache-growth-is-linear-but-latency-is-not\">Why Cache Growth is Linear but Latency is Not</h5>\n<ul>\n  <li>Although the cache grows linearly with the number of generated tokens, decoding latency per token grows only linearly due to attention score computation:</li>\n</ul>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-211-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1899\" style=\"width: 5.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.638em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1004.59em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1900\"><span class=\"mi\" id=\"MathJax-Span-1901\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-1902\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1903\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1904\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1905\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-1906\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-1907\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1908\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span></div>\n<ul>\n  <li>Crucially, caching removes the repeated projection of historical tokens, eliminating the quadratic projection term and ensuring that long-context generation remains feasible in practice.</li>\n</ul>\n<h5 id=\"takeaways\">Takeaways</h5>\n<ul>\n  <li>\n    <p>At an implementation level, the KV cache:</p>\n\n    <ul>\n      <li>Is a preallocated, layerwise, headwise memory buffer.</li>\n      <li>Is written once per token and never modified afterward.</li>\n      <li>Converts self-attention into a stateful operation during inference.</li>\n      <li>Preserves exact numerical equivalence with the vanilla Transformer.</li>\n      <li>Shifts decoding from projection-dominated to memory- and attention-dominated runtime behavior.</li>\n    </ul>\n  </li>\n</ul>\n<p>At an implementation level, the KV cache:</p>\n<ul>\n      <li>Is a preallocated, layerwise, headwise memory buffer.</li>\n      <li>Is written once per token and never modified afterward.</li>\n      <li>Converts self-attention into a stateful operation during inference.</li>\n      <li>Preserves exact numerical equivalence with the vanilla Transformer.</li>\n      <li>Shifts decoding from projection-dominated to memory- and attention-dominated runtime behavior.</li>\n    </ul>\n<h4 id=\"practical-deployment-considerations\">Practical Deployment Considerations</h4>\n<h5 id=\"memory-management\">Memory Management</h5>\n<ul>\n  <li>\n    <p>Managing KV caches efficiently is one of the main engineering challenges in large-scale transformer deployment. The cache for each sequence grows linearly with the number of processed tokens, since for every new token the model must store its key and value representations for each layer and attention head. Consequently, even moderate increases in context length can result in exponential GPU memory pressure when serving multiple concurrent requests.</p>\n  </li>\n  <li>\n    <p>To mitigate this, systems adopt several strategies:</p>\n\n    <ul>\n      <li>\n        <p><strong>Sliding Window Caching</strong>: Instead of maintaining the entire attention history, servers often retain only the most recent N tokens per request. This sliding window allows for long-running conversations without exceeding memory budgets, at the cost of slightly reduced long-range recall. For instance, if the model supports 32k tokens but memory is constrained, the cache may only keep the last 8k–16k tokens.</p>\n      </li>\n      <li>\n        <p><strong>Cache Truncation and Compression</strong>: For extreme cases, caches can be truncated or quantized. Truncation drops the oldest segments of the context when the memory budget is reached, while compression methods—like storing keys and values in lower precision (e.g., FP16 or INT8)—trade off a small amount of accuracy for substantial memory savings.</p>\n      </li>\n      <li>\n        <p><strong>Layer-Aware Cache Allocation</strong>: Not all layers contribute equally to performance. Some deployment systems dynamically allocate higher precision or longer cache retention to the most attention-sensitive layers while reducing resource usage for others.</p>\n      </li>\n      <li>\n        <p><strong>Offloading to Host Memory</strong>: For very long contexts or multi-turn conversations, GPU memory may not suffice. Systems can offload part of the cache to CPU memory or even NVMe-based memory pools, fetching it back as needed. However, this introduces latency trade-offs and requires careful memory pinning to minimize data transfer overheads.</p>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>Managing KV caches efficiently is one of the main engineering challenges in large-scale transformer deployment. The cache for each sequence grows linearly with the number of processed tokens, since for every new token the model must store its key and value representations for each layer and attention head. Consequently, even moderate increases in context length can result in exponential GPU memory pressure when serving multiple concurrent requests.</p>\n<p>To mitigate this, systems adopt several strategies:</p>\n<ul>\n      <li>\n        <p><strong>Sliding Window Caching</strong>: Instead of maintaining the entire attention history, servers often retain only the most recent N tokens per request. This sliding window allows for long-running conversations without exceeding memory budgets, at the cost of slightly reduced long-range recall. For instance, if the model supports 32k tokens but memory is constrained, the cache may only keep the last 8k–16k tokens.</p>\n      </li>\n      <li>\n        <p><strong>Cache Truncation and Compression</strong>: For extreme cases, caches can be truncated or quantized. Truncation drops the oldest segments of the context when the memory budget is reached, while compression methods—like storing keys and values in lower precision (e.g., FP16 or INT8)—trade off a small amount of accuracy for substantial memory savings.</p>\n      </li>\n      <li>\n        <p><strong>Layer-Aware Cache Allocation</strong>: Not all layers contribute equally to performance. Some deployment systems dynamically allocate higher precision or longer cache retention to the most attention-sensitive layers while reducing resource usage for others.</p>\n      </li>\n      <li>\n        <p><strong>Offloading to Host Memory</strong>: For very long contexts or multi-turn conversations, GPU memory may not suffice. Systems can offload part of the cache to CPU memory or even NVMe-based memory pools, fetching it back as needed. However, this introduces latency trade-offs and requires careful memory pinning to minimize data transfer overheads.</p>\n      </li>\n    </ul>\n<p><strong>Sliding Window Caching</strong>: Instead of maintaining the entire attention history, servers often retain only the most recent N tokens per request. This sliding window allows for long-running conversations without exceeding memory budgets, at the cost of slightly reduced long-range recall. For instance, if the model supports 32k tokens but memory is constrained, the cache may only keep the last 8k–16k tokens.</p>\n<p><strong>Cache Truncation and Compression</strong>: For extreme cases, caches can be truncated or quantized. Truncation drops the oldest segments of the context when the memory budget is reached, while compression methods—like storing keys and values in lower precision (e.g., FP16 or INT8)—trade off a small amount of accuracy for substantial memory savings.</p>\n<p><strong>Layer-Aware Cache Allocation</strong>: Not all layers contribute equally to performance. Some deployment systems dynamically allocate higher precision or longer cache retention to the most attention-sensitive layers while reducing resource usage for others.</p>\n<p><strong>Offloading to Host Memory</strong>: For very long contexts or multi-turn conversations, GPU memory may not suffice. Systems can offload part of the cache to CPU memory or even NVMe-based memory pools, fetching it back as needed. However, this introduces latency trade-offs and requires careful memory pinning to minimize data transfer overheads.</p>\n<h5 id=\"dynamic-batching\">Dynamic Batching</h5>\n<ul>\n  <li>\n    <p>Dynamic batching is essential for maximizing GPU utilization in real-time inference scenarios. Since users issue requests of varying lengths and progress asynchronously through token generation, each request maintains an independent KV cache that grows at its own rate. A well-designed system must:</p>\n\n    <ul>\n      <li>Efficiently <strong>group requests with similar decoding steps</strong> to form micro-batches without breaking sequence dependencies.</li>\n      <li>Maintain <strong>per-request cache isolation</strong>, ensuring that the correct KV history is retrieved during each attention computation.</li>\n      <li>Implement <strong>fast lookup and append mechanisms</strong>, typically backed by memory pools or custom allocators, allowing concurrent cache updates without heavy synchronization locks.</li>\n      <li>Use <strong>streaming attention scheduling</strong>: at each decoding step, the system identifies which requests are ready to decode and merges them temporarily into a batch. Once the next token is produced, each request’s cache is updated independently.</li>\n    </ul>\n  </li>\n  <li>\n    <p>Systems such as vLLM and TensorRT-LLM provide specialized runtime schedulers that dynamically manage per-request caches while achieving near-optimal GPU occupancy. In such architectures, the ability to reuse KV states and batch across requests determines overall throughput.</p>\n  </li>\n</ul>\n<p>Dynamic batching is essential for maximizing GPU utilization in real-time inference scenarios. Since users issue requests of varying lengths and progress asynchronously through token generation, each request maintains an independent KV cache that grows at its own rate. A well-designed system must:</p>\n<ul>\n      <li>Efficiently <strong>group requests with similar decoding steps</strong> to form micro-batches without breaking sequence dependencies.</li>\n      <li>Maintain <strong>per-request cache isolation</strong>, ensuring that the correct KV history is retrieved during each attention computation.</li>\n      <li>Implement <strong>fast lookup and append mechanisms</strong>, typically backed by memory pools or custom allocators, allowing concurrent cache updates without heavy synchronization locks.</li>\n      <li>Use <strong>streaming attention scheduling</strong>: at each decoding step, the system identifies which requests are ready to decode and merges them temporarily into a batch. Once the next token is produced, each request’s cache is updated independently.</li>\n    </ul>\n<p>Systems such as vLLM and TensorRT-LLM provide specialized runtime schedulers that dynamically manage per-request caches while achieving near-optimal GPU occupancy. In such architectures, the ability to reuse KV states and batch across requests determines overall throughput.</p>\n<h5 id=\"cache-parallelism\">Cache Parallelism</h5>\n<ul>\n  <li>\n    <p>In large-scale multi-GPU or distributed serving environments, KV caches themselves become distributed data structures. When the model’s layers or attention heads are sharded across devices, the corresponding keys and values must follow the same partitioning strategy. Typical configurations include:</p>\n\n    <ul>\n      <li>\n        <p><strong>Tensor Parallelism</strong>: Each GPU holds only a subset of the attention heads. During cross-device attention computations, the K and V tensors are exchanged or synchronized across GPUs via collective operations (e.g., all-gather). Efficient implementations overlap communication and computation to minimize latency.</p>\n      </li>\n      <li>\n        <p><strong>Pipeline Parallelism</strong>: Layers are distributed across GPUs. Each GPU must maintain the KV cache for only the layers it owns. However, during forward passes, intermediate activations are streamed between devices. The system must ensure that caches align temporally across pipeline stages to preserve attention correctness.</p>\n      </li>\n      <li>\n        <p><strong>Model Parallel + Data Parallel Hybridization</strong>: In highly scalable deployments, KV caches are both sharded (for model parallelism) and replicated (for data parallelism). Systems must handle synchronization and memory consistency between replicas, often through NCCL-based communication backends.</p>\n      </li>\n      <li>\n        <p><strong>Cross-Node Caching</strong>: When models run across multiple nodes, caches may be stored in distributed shared memory or remote memory access (RDMA)-capable hardware, allowing direct GPU-to-GPU cache retrieval without CPU intervention.</p>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>In large-scale multi-GPU or distributed serving environments, KV caches themselves become distributed data structures. When the model’s layers or attention heads are sharded across devices, the corresponding keys and values must follow the same partitioning strategy. Typical configurations include:</p>\n<ul>\n      <li>\n        <p><strong>Tensor Parallelism</strong>: Each GPU holds only a subset of the attention heads. During cross-device attention computations, the K and V tensors are exchanged or synchronized across GPUs via collective operations (e.g., all-gather). Efficient implementations overlap communication and computation to minimize latency.</p>\n      </li>\n      <li>\n        <p><strong>Pipeline Parallelism</strong>: Layers are distributed across GPUs. Each GPU must maintain the KV cache for only the layers it owns. However, during forward passes, intermediate activations are streamed between devices. The system must ensure that caches align temporally across pipeline stages to preserve attention correctness.</p>\n      </li>\n      <li>\n        <p><strong>Model Parallel + Data Parallel Hybridization</strong>: In highly scalable deployments, KV caches are both sharded (for model parallelism) and replicated (for data parallelism). Systems must handle synchronization and memory consistency between replicas, often through NCCL-based communication backends.</p>\n      </li>\n      <li>\n        <p><strong>Cross-Node Caching</strong>: When models run across multiple nodes, caches may be stored in distributed shared memory or remote memory access (RDMA)-capable hardware, allowing direct GPU-to-GPU cache retrieval without CPU intervention.</p>\n      </li>\n    </ul>\n<p><strong>Tensor Parallelism</strong>: Each GPU holds only a subset of the attention heads. During cross-device attention computations, the K and V tensors are exchanged or synchronized across GPUs via collective operations (e.g., all-gather). Efficient implementations overlap communication and computation to minimize latency.</p>\n<p><strong>Pipeline Parallelism</strong>: Layers are distributed across GPUs. Each GPU must maintain the KV cache for only the layers it owns. However, during forward passes, intermediate activations are streamed between devices. The system must ensure that caches align temporally across pipeline stages to preserve attention correctness.</p>\n<p><strong>Model Parallel + Data Parallel Hybridization</strong>: In highly scalable deployments, KV caches are both sharded (for model parallelism) and replicated (for data parallelism). Systems must handle synchronization and memory consistency between replicas, often through NCCL-based communication backends.</p>\n<p><strong>Cross-Node Caching</strong>: When models run across multiple nodes, caches may be stored in distributed shared memory or remote memory access (RDMA)-capable hardware, allowing direct GPU-to-GPU cache retrieval without CPU intervention.</p>\n<h5 id=\"why-you-cant-always-cache-everything\">Why You Can’t Always Cache Everything</h5>\n<ul>\n  <li>\n    <p>Memory growth in KV caching is linear in sequence length and proportional to the number of layers, heads, and hidden dimensions:</p>\n\n    <ul>\n      <li><strong>Memory scaling:</strong> For large models (tens of billions of parameters), a single sequence of 1000 tokens may consume roughly 1 GB of KV cache.</li>\n      <li><strong>Batch size impact:</strong> The more concurrent sequences are cached, the fewer requests can fit into GPU memory, directly impacting throughput.</li>\n      <li><strong>Context length:</strong> With ultra-long contexts (e.g., 100k tokens), a naive full cache could exceed 100 GB—far beyond the capacity of even high-end GPUs.</li>\n    </ul>\n  </li>\n</ul>\n<p>Memory growth in KV caching is linear in sequence length and proportional to the number of layers, heads, and hidden dimensions:</p>\n<ul>\n      <li><strong>Memory scaling:</strong> For large models (tens of billions of parameters), a single sequence of 1000 tokens may consume roughly 1 GB of KV cache.</li>\n      <li><strong>Batch size impact:</strong> The more concurrent sequences are cached, the fewer requests can fit into GPU memory, directly impacting throughput.</li>\n      <li><strong>Context length:</strong> With ultra-long contexts (e.g., 100k tokens), a naive full cache could exceed 100 GB—far beyond the capacity of even high-end GPUs.</li>\n    </ul>\n<h4 id=\"multi-head-attention-and-kv-cache\">Multi-Head Attention and KV Cache</h4>\n<ul>\n  <li>\n    <p>In practice, self-attention is implemented with multiple attention heads, each operating in a subspace of the embedding dimension. For head <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-212-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>h</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1909\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1910\"><span class=\"mi\" id=\"MathJax-Span-1911\" style=\"font-family: STIXGeneral-Italic;\">h</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>h</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-212\">h</script> in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-213-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>{</mo><mn>1</mn><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><mi>H</mi><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>}</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1912\" style=\"width: 5.263em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.378em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.27em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1913\"><span class=\"mo\" id=\"MathJax-Span-1914\" style=\"font-family: STIXGeneral-Regular;\">{</span><span class=\"mn\" id=\"MathJax-Span-1915\" style=\"font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-1916\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-1917\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-1918\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"mi\" id=\"MathJax-Span-1919\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1920\" style=\"font-family: STIXGeneral-Regular;\">}</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo fence=\"false\" stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>H</mi><mo fence=\"false\" stretchy=\"false\">}</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-213\">\\{1, \\dots, H\\}</script>, we have:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-214-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msup><mi>Q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mo>=</mo><mi>X</mi><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msup><mi>Q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup></mrow></msub><mo>,</mo><mspace width=&quot;1em&quot; /><msup><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mo>=</mo><mi>X</mi><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msup><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup></mrow></msub><mo>,</mo><mspace width=&quot;1em&quot; /><msup><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mo>=</mo><mi>X</mi><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msup><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>h</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup></mrow></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1921\" style=\"width: 24.482em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 20.367em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1020.37em, 2.763em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1922\"><span class=\"msubsup\" id=\"MathJax-Span-1923\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1924\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1925\"><span class=\"mrow\" id=\"MathJax-Span-1926\"><span class=\"mo\" id=\"MathJax-Span-1927\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1928\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1929\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1930\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-1931\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-1932\"><span style=\"display: inline-block; position: relative; width: 2.034em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1933\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.747em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-1934\"><span class=\"mrow\" id=\"MathJax-Span-1935\"><span class=\"msubsup\" id=\"MathJax-Span-1936\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.47em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1937\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.268em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-1938\"><span class=\"mrow\" id=\"MathJax-Span-1939\"><span class=\"mo\" id=\"MathJax-Span-1940\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1941\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1942\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1943\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mspace\" id=\"MathJax-Span-1944\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"msubsup\" id=\"MathJax-Span-1945\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1946\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1947\"><span class=\"mrow\" id=\"MathJax-Span-1948\"><span class=\"mo\" id=\"MathJax-Span-1949\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1950\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1951\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1952\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-1953\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-1954\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1955\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.747em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-1956\"><span class=\"mrow\" id=\"MathJax-Span-1957\"><span class=\"msubsup\" id=\"MathJax-Span-1958\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1959\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.268em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-1960\"><span class=\"mrow\" id=\"MathJax-Span-1961\"><span class=\"mo\" id=\"MathJax-Span-1962\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1963\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1964\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1965\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mspace\" id=\"MathJax-Span-1966\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"msubsup\" id=\"MathJax-Span-1967\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1968\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-1969\"><span class=\"mrow\" id=\"MathJax-Span-1970\"><span class=\"mo\" id=\"MathJax-Span-1971\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1972\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1973\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-1974\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-1975\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-1976\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1977\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.747em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-1978\"><span class=\"mrow\" id=\"MathJax-Span-1979\"><span class=\"msubsup\" id=\"MathJax-Span-1980\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1981\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.268em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-1982\"><span class=\"mrow\" id=\"MathJax-Span-1983\"><span class=\"mo\" id=\"MathJax-Span-1984\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-1985\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-1986\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.559em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msup><mi>Q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mi>X</mi><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msup><mi>Q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></msub><mo>,</mo><mspace width=\"1em\"></mspace><msup><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mi>X</mi><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msup><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></msub><mo>,</mo><mspace width=\"1em\"></mspace><msup><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mi>X</mi><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msup><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>h</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-214\">Q^{(h)} = X W_{Q^{(h)}}, \\quad K^{(h)} = X W_{K^{(h)}}, \\quad V^{(h)} = X W_{V^{(h)}}</script>\n  </li>\n  <li>\n    <p>The attention outputs from each head are concatenated:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-215-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>Q</mi><mo>=</mo><mtext>concat</mtext><mo stretchy=&quot;false&quot;>(</mo><msup><mi>Q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mo>,</mo><msup><mi>Q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mn>2</mn><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><msup><mi>Q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>H</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1987\" style=\"width: 15.471em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 12.867em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1012.82em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1988\"><span class=\"mi\" id=\"MathJax-Span-1989\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span class=\"mo\" id=\"MathJax-Span-1990\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-1991\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">concat</span><span class=\"mo\" id=\"MathJax-Span-1992\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-1993\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-1994\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-1995\"><span class=\"mrow\" id=\"MathJax-Span-1996\"><span class=\"mo\" id=\"MathJax-Span-1997\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mn\" id=\"MathJax-Span-1998\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-1999\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2000\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-2001\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2002\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-2003\"><span class=\"mrow\" id=\"MathJax-Span-2004\"><span class=\"mo\" id=\"MathJax-Span-2005\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mn\" id=\"MathJax-Span-2006\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span class=\"mo\" id=\"MathJax-Span-2007\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2008\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-2009\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-2010\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-2011\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2012\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-2013\"><span class=\"mrow\" id=\"MathJax-Span-2014\"><span class=\"mo\" id=\"MathJax-Span-2015\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2016\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2017\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2018\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>Q</mi><mo>=</mo><mtext>concat</mtext><mo stretchy=\"false\">(</mo><msup><mi>Q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><msup><mi>Q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><mo>…</mo><mo>,</mo><msup><mi>Q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>H</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-215\">Q = \\text{concat}(Q^{(1)}, Q^{(2)}, \\dots, Q^{(H)})</script>\n\n    <ul>\n      <li>and similarly for <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-216-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2019\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2020\"><span class=\"mi\" id=\"MathJax-Span-2021\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-216\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-217-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2022\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2023\"><span class=\"mi\" id=\"MathJax-Span-2024\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-217\">V</script>.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Caching in multi-head attention</strong>:</p>\n\n    <ul>\n      <li>The KV cache stores keys and values for every head and every layer.</li>\n      <li>Shape for the key and value cache:</li>\n    </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-218-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2025\" style=\"width: 9.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.763em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1007.76em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2026\"><span class=\"msubsup\" id=\"MathJax-Span-2027\"><span style=\"display: inline-block; position: relative; width: 2.398em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2028\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-2029\"><span class=\"mrow\" id=\"MathJax-Span-2030\"><span class=\"mi\" id=\"MathJax-Span-2031\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-2032\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-2033\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-2034\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-2035\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2036\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-2037\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 4.169em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-2038\"><span class=\"mrow\" id=\"MathJax-Span-2039\"><span class=\"mi\" id=\"MathJax-Span-2040\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-2041\"><span class=\"mrow\" id=\"MathJax-Span-2042\"><span class=\"mi\" id=\"MathJax-Span-2043\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-2044\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-2045\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2046\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-2047\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-2048\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-2049\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2050\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-2051\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-218\">K_{cache} \\in \\mathbb{R}^{B \\times H \\times n \\times d_k}</script>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-219-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2052\" style=\"width: 9.273em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.711em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1007.71em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2053\"><span class=\"msubsup\" id=\"MathJax-Span-2054\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2055\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-2056\"><span class=\"mrow\" id=\"MathJax-Span-2057\"><span class=\"mi\" id=\"MathJax-Span-2058\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-2059\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-2060\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">c</span><span class=\"mi\" id=\"MathJax-Span-2061\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-2062\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2063\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-2064\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 4.169em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-2065\"><span class=\"mrow\" id=\"MathJax-Span-2066\"><span class=\"mi\" id=\"MathJax-Span-2067\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-2068\"><span class=\"mrow\" id=\"MathJax-Span-2069\"><span class=\"mi\" id=\"MathJax-Span-2070\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-2071\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-2072\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2073\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mi\" id=\"MathJax-Span-2074\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-2075\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-2076\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2077\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-2078\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>c</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>e</mi></mrow></msub><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>B</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-219\">V_{cache} \\in \\mathbb{R}^{B \\times H \\times n \\times d_k}</script>\n\n    <ul>\n      <li>\n        <p><strong>where</strong></p>\n\n        <ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-220-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2079\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2080\"><span class=\"mi\" id=\"MathJax-Span-2081\" style=\"font-family: STIXGeneral-Italic;\">B</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-220\">B</script> = batch size (number of sequences processed in parallel)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-221-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2082\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2083\"><span class=\"mi\" id=\"MathJax-Span-2084\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-221\">H</script> = number of attention heads</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-222-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2085\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2086\"><span class=\"mi\" id=\"MathJax-Span-2087\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-222\">n</script> = sequence length (number of tokens stored in the cache)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-223-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2088\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2089\"><span class=\"msubsup\" id=\"MathJax-Span-2090\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2091\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-2092\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-223\">d_k</script> = dimension of the key (and value) vectors per head</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Performance implications</strong>:</p>\n\n    <ul>\n      <li>Since each head’s KV cache is independent, the caching logic operates head-wise, but the storage is typically implemented as a unified tensor for efficiency.</li>\n      <li>This unified tensor is arranged to be friendly to GPU tensor cores, enabling very fast read and write operations during decoding.</li>\n    </ul>\n  </li>\n  <li>\n    <p>While KV caching greatly reduces the sequence dimension cost, the <strong>depth dimension</strong> (number of layers <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-224-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2093\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2094\"><span class=\"mi\" id=\"MathJax-Span-2095\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-224\">l</script>) is still a significant contributor to compute. This leads to the <em>KV Sharing</em> idea, covered in detail in the section on <a href=\"#kv-sharing\">KV Sharing</a> — reusing <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-225-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2096\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2097\"><span class=\"mi\" id=\"MathJax-Span-2098\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-225\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-226-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2099\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2100\"><span class=\"mi\" id=\"MathJax-Span-2101\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-226\">V</script> representations across the last half (or fraction) of layers to further cut computation. KV sharing builds on KV caching, but attacks the problem from the layer/depth dimension rather than the token dimension.</p>\n  </li>\n</ul>\n<p>In practice, self-attention is implemented with multiple attention heads, each operating in a subspace of the embedding dimension. For head <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-212-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>h</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1909\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1910\"><span class=\"mi\" id=\"MathJax-Span-1911\" style=\"font-family: STIXGeneral-Italic;\">h</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>h</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-212\">h</script> in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-213-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>{</mo><mn>1</mn><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><mi>H</mi><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>}</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1912\" style=\"width: 5.263em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.378em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.27em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-1913\"><span class=\"mo\" id=\"MathJax-Span-1914\" style=\"font-family: STIXGeneral-Regular;\">{</span><span class=\"mn\" id=\"MathJax-Span-1915\" style=\"font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-1916\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-1917\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-1918\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"mi\" id=\"MathJax-Span-1919\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-1920\" style=\"font-family: STIXGeneral-Regular;\">}</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo fence=\"false\" stretchy=\"false\">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>H</mi><mo fence=\"false\" stretchy=\"false\">}</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-213\">\\{1, \\dots, H\\}</script>, we have:</p>\n<p>The attention outputs from each head are concatenated:</p>\n<ul>\n      <li>and similarly for <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-216-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2019\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2020\"><span class=\"mi\" id=\"MathJax-Span-2021\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-216\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-217-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2022\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2023\"><span class=\"mi\" id=\"MathJax-Span-2024\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-217\">V</script>.</li>\n    </ul>\n<p><strong>Caching in multi-head attention</strong>:</p>\n<ul>\n      <li>The KV cache stores keys and values for every head and every layer.</li>\n      <li>Shape for the key and value cache:</li>\n    </ul>\n<ul>\n      <li>\n        <p><strong>where</strong></p>\n\n        <ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-220-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2079\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2080\"><span class=\"mi\" id=\"MathJax-Span-2081\" style=\"font-family: STIXGeneral-Italic;\">B</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-220\">B</script> = batch size (number of sequences processed in parallel)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-221-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2082\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2083\"><span class=\"mi\" id=\"MathJax-Span-2084\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-221\">H</script> = number of attention heads</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-222-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2085\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2086\"><span class=\"mi\" id=\"MathJax-Span-2087\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-222\">n</script> = sequence length (number of tokens stored in the cache)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-223-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2088\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2089\"><span class=\"msubsup\" id=\"MathJax-Span-2090\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2091\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-2092\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-223\">d_k</script> = dimension of the key (and value) vectors per head</li>\n        </ul>\n      </li>\n    </ul>\n<p><strong>where</strong></p>\n<ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-220-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2079\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2080\"><span class=\"mi\" id=\"MathJax-Span-2081\" style=\"font-family: STIXGeneral-Italic;\">B</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-220\">B</script> = batch size (number of sequences processed in parallel)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-221-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2082\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2083\"><span class=\"mi\" id=\"MathJax-Span-2084\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-221\">H</script> = number of attention heads</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-222-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2085\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2086\"><span class=\"mi\" id=\"MathJax-Span-2087\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-222\">n</script> = sequence length (number of tokens stored in the cache)</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-223-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mi>k</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2088\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2089\"><span class=\"msubsup\" id=\"MathJax-Span-2090\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2091\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-2092\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mi>k</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-223\">d_k</script> = dimension of the key (and value) vectors per head</li>\n        </ul>\n<p><strong>Performance implications</strong>:</p>\n<ul>\n      <li>Since each head’s KV cache is independent, the caching logic operates head-wise, but the storage is typically implemented as a unified tensor for efficiency.</li>\n      <li>This unified tensor is arranged to be friendly to GPU tensor cores, enabling very fast read and write operations during decoding.</li>\n    </ul>\n<p>While KV caching greatly reduces the sequence dimension cost, the <strong>depth dimension</strong> (number of layers <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-224-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2093\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2094\"><span class=\"mi\" id=\"MathJax-Span-2095\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-224\">l</script>) is still a significant contributor to compute. This leads to the <em>KV Sharing</em> idea, covered in detail in the section on <a href=\"#kv-sharing\">KV Sharing</a> — reusing <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-225-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2096\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2097\"><span class=\"mi\" id=\"MathJax-Span-2098\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-225\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-226-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2099\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2100\"><span class=\"mi\" id=\"MathJax-Span-2101\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-226\">V</script> representations across the last half (or fraction) of layers to further cut computation. KV sharing builds on KV caching, but attacks the problem from the layer/depth dimension rather than the token dimension.</p>\n<h4 id=\"summary-of-kv-cache-benefits\">Summary of KV Cache Benefits</h4>\n<ul>\n  <li><strong>Reduces repeated computation</strong> by storing and reusing <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-227-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2102\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2103\"><span class=\"mi\" id=\"MathJax-Span-2104\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-227\">K</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-228-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2105\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2106\"><span class=\"mi\" id=\"MathJax-Span-2107\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-228\">V</script> tensors instead of recomputing them at every step.</li>\n  <li><strong>Enables efficient decoding</strong> in autoregressive generation by cutting per-step cost from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-229-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><mi>n</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2108\" style=\"width: 6.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.107em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1005.05em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2109\"><span class=\"mi\" id=\"MathJax-Span-2110\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-2111\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2112\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2113\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-2114\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-2115\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-2116\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2117\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-2118\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2119\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-229\">O(l \\cdot n \\cdot d^2)</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-230-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo>&amp;#x22C5;</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2120\" style=\"width: 4.378em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.648em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1003.6em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2121\"><span class=\"mi\" id=\"MathJax-Span-2122\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-2123\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2124\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2125\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-2126\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2127\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-2128\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2129\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-230\">O(l \\cdot d^2)</script> — an <strong><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-231-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2130\" style=\"width: 0.622em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.519em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.552em, 1000.47em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2131\"><span class=\"mi\" id=\"MathJax-Span-2132\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-231\">n</script>-times speedup</strong> in the sequence dimension.</li>\n  <li><strong>Optimized for hardware acceleration</strong> via unified tensor layouts that are friendly to GPU tensor cores.</li>\n  <li><strong>Scales well</strong> to large models and long contexts, with latency growing linearly rather than quadratically with sequence length.</li>\n  <li><strong>Maintains accuracy</strong> because cached <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-232-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2133\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2134\"><span class=\"mi\" id=\"MathJax-Span-2135\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-232\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-233-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2136\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2137\"><span class=\"mi\" id=\"MathJax-Span-2138\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-233\">V</script> are identical to recomputed values, given fixed weights.</li>\n</ul>\n<h4 id=\"kv-sharing\">KV Sharing</h4>\n<ul>\n  <li>KV caching, introduced in <a href=\"https://arxiv.org/abs/2405.05254\">You Only Cache Once: Decoder-Decoder Architectures for Language Models</a> by Sun et al. (2024), optimizes the <strong>sequence dimension</strong> (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-234-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2139\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2140\"><span class=\"mi\" id=\"MathJax-Span-2141\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-234\">n</script>) cost, but the <strong>depth dimension</strong> (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-235-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2142\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2143\"><span class=\"mi\" id=\"MathJax-Span-2144\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-235\">l</script>) — the number of layers — still incurs full computation for each layer’s <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-236-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2145\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2146\"><span class=\"mi\" id=\"MathJax-Span-2147\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-236\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-237-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2148\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2149\"><span class=\"mi\" id=\"MathJax-Span-2150\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-237\">V</script>.</li>\n  <li><strong>KV Sharing</strong> addresses this by reducing the cost of computing <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-238-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2151\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2152\"><span class=\"mi\" id=\"MathJax-Span-2153\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-238\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-239-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2154\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2155\"><span class=\"mi\" id=\"MathJax-Span-2156\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-239\">V</script> along the depth dimension.</li>\n  <li>The intuition behind why this can work comes from studies such as <a href=\"https://arxiv.org/abs/2505.13898\">Do Language Models Use Their Depth Efficiently?</a> by Csordás et al., which show empirically that in a deep transformer-like model, the last layers are correlated with each other. This means the final few layers are not necessarily adding much new information, but rather tweaking the output produced so far. This redundancy can potentially be exploited to save computation without significantly degrading model quality.</li>\n</ul>\n<h5 id=\"how-kv-sharing-works\">How KV Sharing Works</h5>\n<ul>\n  <li>\n    <p>The core idea: share <strong>actual <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-240-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2157\" style=\"width: 0.932em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.777em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.78em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2158\"><span class=\"mi\" id=\"MathJax-Span-2159\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.054em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-240\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-241-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2160\" style=\"width: 0.932em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.777em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.78em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2161\"><span class=\"mi\" id=\"MathJax-Span-2162\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.054em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-241\">V</script> representations</strong> (not just weight matrices) across the last fraction of layers.</p>\n  </li>\n  <li>\n    <p>For example, if we share across the last half of the layers (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-242-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mfrac><mi>l</mi><mn>2</mn></mfrac></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2163\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1000.68em, 2.659em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2164\"><span class=\"mfrac\" id=\"MathJax-Span-2165\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.21em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -0.102em;\"><span class=\"mi\" id=\"MathJax-Span-2166\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.154em;\"><span class=\"mn\" id=\"MathJax-Span-2167\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.47em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.471em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mfrac><mi>l</mi><mn>2</mn></mfrac></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-242\">\\frac{l}{2}</script> layers):</p>\n\n    <ol>\n      <li>The final layer before the shared region computes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-243-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2168\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2169\"><span class=\"mi\" id=\"MathJax-Span-2170\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-243\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-244-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2171\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2172\"><span class=\"mi\" id=\"MathJax-Span-2173\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-244\">V</script> normally.</li>\n      <li>All subsequent layers in the shared region reuse these <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-245-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2174\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2175\"><span class=\"mi\" id=\"MathJax-Span-2176\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-245\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-246-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2177\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2178\"><span class=\"mi\" id=\"MathJax-Span-2179\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-246\">V</script> without recomputation, regardless of their inputs.</li>\n      <li>Other parameters (e.g., <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-247-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>Q</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2180\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2181\"><span class=\"msubsup\" id=\"MathJax-Span-2182\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2183\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-2184\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>Q</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-247\">W_Q</script>, MLP weights) remain distinct per layer.</li>\n    </ol>\n  </li>\n  <li>\n    <p>Mathematically:</p>\n\n    <ul>\n      <li>Let <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-248-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>L</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2185\" style=\"width: 2.711em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.242em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.24em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2186\"><span class=\"msubsup\" id=\"MathJax-Span-2187\"><span style=\"display: inline-block; position: relative; width: 2.242em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2188\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-2189\"><span class=\"mrow\" id=\"MathJax-Span-2190\"><span class=\"mi\" id=\"MathJax-Span-2191\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-2192\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-2193\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-2194\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2195\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>L</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-248\">L_{share}</script> be the index of the first shared layer.</li>\n      <li>For any layer <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-249-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>j</mi><mo>&amp;#x2265;</mo><msub><mi>L</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2196\" style=\"width: 4.482em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.701em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.7em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2197\"><span class=\"mi\" id=\"MathJax-Span-2198\" style=\"font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2199\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≥</span><span class=\"msubsup\" id=\"MathJax-Span-2200\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.242em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2201\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-2202\"><span class=\"mrow\" id=\"MathJax-Span-2203\"><span class=\"mi\" id=\"MathJax-Span-2204\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-2205\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-2206\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-2207\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2208\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>j</mi><mo>≥</mo><msub><mi>L</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-249\">j \\geq L_{share}</script>:</li>\n    </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-250-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msup><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>j</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mo>=</mo><msup><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>L</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mo>,</mo><mspace width=&quot;1em&quot; /><msup><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>j</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mo>=</mo><msup><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>L</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2209\" style=\"width: 15.419em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 12.815em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1012.82em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2210\"><span class=\"msubsup\" id=\"MathJax-Span-2211\"><span style=\"display: inline-block; position: relative; width: 1.513em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2212\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-2213\"><span class=\"mrow\" id=\"MathJax-Span-2214\"><span class=\"mo\" id=\"MathJax-Span-2215\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2216\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2217\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2218\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-2219\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.919em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2220\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-2221\"><span class=\"mrow\" id=\"MathJax-Span-2222\"><span class=\"mo\" id=\"MathJax-Span-2223\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2224\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2225\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.419em;\"><span class=\"texatom\" id=\"MathJax-Span-2226\"><span class=\"mrow\" id=\"MathJax-Span-2227\"><span class=\"mi\" id=\"MathJax-Span-2228\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-2229\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-2230\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-2231\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2232\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2233\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2234\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mspace\" id=\"MathJax-Span-2235\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"msubsup\" id=\"MathJax-Span-2236\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.513em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2237\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-2238\"><span class=\"mrow\" id=\"MathJax-Span-2239\"><span class=\"mo\" id=\"MathJax-Span-2240\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2241\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2242\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2243\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-2244\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.867em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2245\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-2246\"><span class=\"mrow\" id=\"MathJax-Span-2247\"><span class=\"mo\" id=\"MathJax-Span-2248\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2249\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2250\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.419em;\"><span class=\"texatom\" id=\"MathJax-Span-2251\"><span class=\"mrow\" id=\"MathJax-Span-2252\"><span class=\"mi\" id=\"MathJax-Span-2253\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-2254\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-2255\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-2256\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2257\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2258\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msup><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><msup><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><msub><mi>L</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></msup><mo>,</mo><mspace width=\"1em\"></mspace><msup><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>j</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><msup><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><msub><mi>L</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-250\">K^{(j)} = K^{(L_{share})}, \\quad V^{(j)} = V^{(L_{share})}</script>\n  </li>\n  <li>\n    <p>The following figure (<a href=\"https://arxiv.org/abs/2405.05254\">source</a>) illustrates KV Sharing across the last half of the layers, showing how a single computed <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-251-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2259\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2260\"><span class=\"mi\" id=\"MathJax-Span-2261\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-251\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-252-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2262\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2263\"><span class=\"mi\" id=\"MathJax-Span-2264\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-252\">V</script> set is reused instead of recalculated:</p>\n  </li>\n</ul>\n<p>The core idea: share <strong>actual <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-240-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2157\" style=\"width: 0.932em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.777em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.78em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2158\"><span class=\"mi\" id=\"MathJax-Span-2159\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.054em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-240\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-241-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2160\" style=\"width: 0.932em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.777em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.78em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2161\"><span class=\"mi\" id=\"MathJax-Span-2162\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.054em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-241\">V</script> representations</strong> (not just weight matrices) across the last fraction of layers.</p>\n<p>For example, if we share across the last half of the layers (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-242-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mfrac><mi>l</mi><mn>2</mn></mfrac></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2163\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1000.68em, 2.659em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2164\"><span class=\"mfrac\" id=\"MathJax-Span-2165\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.21em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -0.102em;\"><span class=\"mi\" id=\"MathJax-Span-2166\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.154em;\"><span class=\"mn\" id=\"MathJax-Span-2167\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.47em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.471em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mfrac><mi>l</mi><mn>2</mn></mfrac></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-242\">\\frac{l}{2}</script> layers):</p>\n<ol>\n      <li>The final layer before the shared region computes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-243-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2168\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2169\"><span class=\"mi\" id=\"MathJax-Span-2170\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-243\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-244-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2171\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2172\"><span class=\"mi\" id=\"MathJax-Span-2173\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-244\">V</script> normally.</li>\n      <li>All subsequent layers in the shared region reuse these <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-245-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2174\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2175\"><span class=\"mi\" id=\"MathJax-Span-2176\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-245\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-246-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2177\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2178\"><span class=\"mi\" id=\"MathJax-Span-2179\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-246\">V</script> without recomputation, regardless of their inputs.</li>\n      <li>Other parameters (e.g., <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-247-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mi>Q</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2180\" style=\"width: 1.721em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.41em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2181\"><span class=\"msubsup\" id=\"MathJax-Span-2182\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2183\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-2184\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mi>Q</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-247\">W_Q</script>, MLP weights) remain distinct per layer.</li>\n    </ol>\n<p>Mathematically:</p>\n<ul>\n      <li>Let <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-248-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>L</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2185\" style=\"width: 2.711em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.242em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.24em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2186\"><span class=\"msubsup\" id=\"MathJax-Span-2187\"><span style=\"display: inline-block; position: relative; width: 2.242em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2188\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-2189\"><span class=\"mrow\" id=\"MathJax-Span-2190\"><span class=\"mi\" id=\"MathJax-Span-2191\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-2192\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-2193\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-2194\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2195\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>L</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-248\">L_{share}</script> be the index of the first shared layer.</li>\n      <li>For any layer <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-249-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>j</mi><mo>&amp;#x2265;</mo><msub><mi>L</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2196\" style=\"width: 4.482em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.701em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.7em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2197\"><span class=\"mi\" id=\"MathJax-Span-2198\" style=\"font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2199\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≥</span><span class=\"msubsup\" id=\"MathJax-Span-2200\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.242em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2201\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-2202\"><span class=\"mrow\" id=\"MathJax-Span-2203\"><span class=\"mi\" id=\"MathJax-Span-2204\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">s</span><span class=\"mi\" id=\"MathJax-Span-2205\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span><span class=\"mi\" id=\"MathJax-Span-2206\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-2207\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2208\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">e</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>j</mi><mo>≥</mo><msub><mi>L</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>s</mi><mi>h</mi><mi>a</mi><mi>r</mi><mi>e</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-249\">j \\geq L_{share}</script>:</li>\n    </ul>\n<p>The following figure (<a href=\"https://arxiv.org/abs/2405.05254\">source</a>) illustrates KV Sharing across the last half of the layers, showing how a single computed <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-251-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2259\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2260\"><span class=\"mi\" id=\"MathJax-Span-2261\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-251\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-252-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2262\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2263\"><span class=\"mi\" id=\"MathJax-Span-2264\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-252\">V</script> set is reused instead of recalculated:</p>\n<p><img src=\"/primers/ai/assets/model-acceleration/KVS.jpg\" alt=\"KV Sharing Illustration\"></p>\n<h5 id=\"flop-savings\">FLOP Savings</h5>\n<ul>\n  <li>If the last <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-253-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mfrac><mi>l</mi><mi>k</mi></mfrac></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2265\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1000.68em, 2.711em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2266\"><span class=\"mfrac\" id=\"MathJax-Span-2267\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.21em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -0.102em;\"><span class=\"mi\" id=\"MathJax-Span-2268\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.154em;\"><span class=\"mi\" id=\"MathJax-Span-2269\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.47em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.471em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.559em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mfrac><mi>l</mi><mi>k</mi></mfrac></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-253\">\\frac{l}{k}</script> layers share <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-254-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2270\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2271\"><span class=\"mi\" id=\"MathJax-Span-2272\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-254\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-255-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2273\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2274\"><span class=\"mi\" id=\"MathJax-Span-2275\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-255\">V</script>, we avoid computing them in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-256-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mfrac><mi>l</mi><mi>k</mi></mfrac></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2276\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1000.68em, 2.711em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2277\"><span class=\"mfrac\" id=\"MathJax-Span-2278\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.21em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -0.102em;\"><span class=\"mi\" id=\"MathJax-Span-2279\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.154em;\"><span class=\"mi\" id=\"MathJax-Span-2280\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.47em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.471em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.559em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mfrac><mi>l</mi><mi>k</mi></mfrac></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-256\">\\frac{l}{k}</script> layers entirely.</li>\n  <li>FLOP reduction: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-257-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>Savings</mtext><mo>=</mo><mfrac><mfrac><mi>l</mi><mi>k</mi></mfrac><mi>l</mi></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>k</mi></mfrac></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2281\" style=\"width: 8.648em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.19em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(0.628em, 1007.19em, 2.763em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2282\"><span class=\"mtext\" id=\"MathJax-Span-2283\" style=\"font-family: STIXGeneral-Regular;\">Savings</span><span class=\"mo\" id=\"MathJax-Span-2284\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mfrac\" id=\"MathJax-Span-2285\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.482em, -999.997em); top: -4.737em; left: 50%; margin-left: -0.31em;\"><span class=\"mfrac\" id=\"MathJax-Span-2286\"><span style=\"display: inline-block; position: relative; width: 0.367em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.492em, 1000.16em, 4.169em, -999.997em); top: -4.372em; left: 50%; margin-left: -0.049em;\"><span class=\"mi\" id=\"MathJax-Span-2287\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.492em, 1000.21em, 4.169em, -999.997em); top: -3.695em; left: 50%; margin-left: -0.102em;\"><span class=\"mi\" id=\"MathJax-Span-2288\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.37em, 1.201em, -999.997em); top: -1.195em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.367em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.21em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.102em;\"><span class=\"mi\" id=\"MathJax-Span-2289\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.73em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.732em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2290\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mfrac\" id=\"MathJax-Span-2291\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -0.154em;\"><span class=\"mn\" id=\"MathJax-Span-2292\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.154em;\"><span class=\"mi\" id=\"MathJax-Span-2293\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.47em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.471em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.559em; border-left: 0px solid; width: 0px; height: 2.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mtext>Savings</mtext><mo>=</mo><mfrac><mfrac><mi>l</mi><mi>k</mi></mfrac><mi>l</mi></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>k</mi></mfrac></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-257\">\\text{Savings} = \\frac{\\frac{l}{k}}{l} = \\frac{1}{k}</script> fraction of the total keys and values computation.</li>\n  <li>\n    <p>Combined with KV caching:</p>\n\n    <ul>\n      <li>KV caching cuts cost in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-258-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2294\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2295\"><span class=\"mi\" id=\"MathJax-Span-2296\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-258\">n</script> (sequence) dimension.</li>\n      <li>KV sharing cuts cost in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-259-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2297\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2298\"><span class=\"mi\" id=\"MathJax-Span-2299\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-259\">l</script> (layer) dimension.</li>\n    </ul>\n  </li>\n</ul>\n<p>Combined with KV caching:</p>\n<ul>\n      <li>KV caching cuts cost in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-258-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2294\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2295\"><span class=\"mi\" id=\"MathJax-Span-2296\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-258\">n</script> (sequence) dimension.</li>\n      <li>KV sharing cuts cost in <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-259-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2297\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2298\"><span class=\"mi\" id=\"MathJax-Span-2299\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-259\">l</script> (layer) dimension.</li>\n    </ul>\n<h5 id=\"why-kv-sharing-can-work\">Why KV Sharing Can Work</h5>\n<ul>\n  <li>Empirical studies referenced in the paper show that in deep transformer models, the last few layers often produce correlated outputs.</li>\n  <li>This suggests that later layers are mostly fine-tuning rather than introducing fundamentally new information.</li>\n  <li>Reusing <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-260-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2300\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2301\"><span class=\"mi\" id=\"MathJax-Span-2302\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-260\">K</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-261-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2303\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2304\"><span class=\"mi\" id=\"MathJax-Span-2305\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-261\">V</script> in these layers therefore has minimal impact on output quality while significantly reducing compute and memory usage.</li>\n</ul>\n<h5 id=\"memory-benefits\">Memory Benefits</h5>\n<ul>\n  <li><strong>No need to store keys and values</strong> for the shared layers at all.</li>\n  <li>Reduces memory footprint in both inference and training.</li>\n  <li>Particularly valuable when serving long sequences, where cache size is dominated by <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-262-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi><mo>&amp;#x00D7;</mo><mi>H</mi><mo>&amp;#x00D7;</mo><mi>n</mi><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mi>k</mi></msub><mo>&amp;#x00D7;</mo><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2306\" style=\"width: 8.961em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.451em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.45em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2307\"><span class=\"mi\" id=\"MathJax-Span-2308\" style=\"font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-2309\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-2310\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2311\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-2312\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span><span class=\"mo\" id=\"MathJax-Span-2313\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-2314\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2315\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-2316\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2317\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-2318\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>n</mi><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub><mo>×</mo><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-262\">B \\times H \\times n \\times d_k \\times l</script> scaling.</li>\n</ul>\n<h5 id=\"deployment-notes\">Deployment Notes</h5>\n<ul>\n  <li>KV sharing must be considered at <strong>training time</strong> for best results, since models not trained with this constraint may suffer quality drops if sharing is applied post hoc.</li>\n  <li>Works alongside KV caching since KV sharing tackles <strong>depth</strong>, while KV caching tackles <strong>sequence length</strong>.</li>\n</ul>",
    "contentMarkdown": "#### Background: Self-Attention\n\n*   In transformer models, each token attends to all previous tokens using a self-attention mechanism. For a sequence of input token embeddings X∈ℝT⋅dX∈RT⋅dX \\\\in \\\\mathbb{R}^{T \\\\cdot d}, the transformer computes:\n    \n    *   **Queries**:\n        \n        Q\\=XWQQ\\=XWQ\n        \n        Q = X W\\_Q\n    *   **Keys**:\n        \n        K\\=XWKK\\=XWK\n        \n        K = X W\\_K\n    *   **Values**:\n        \n        V\\=XWVV\\=XWV\n        \n        V = X W\\_V\n    *   where WQ,WK,WV∈ℝd⋅dkWQ,WK,WV∈Rd⋅dkW\\_Q, W\\_K, W\\_V \\\\in \\\\mathbb{R}^{d \\\\cdot d\\_k} are learned projection matrices, and dkdkd\\_k is the head dimension.\n        \n*   The attention output is given by:\n    \n    Attention(Q,K,V)\\=softmax(QK⊤dk‾‾√)VAttention(Q,K,V)\\=softmax(QK⊤dk)V\n    \n    \\\\text{Attention}(Q, K, V) = \\\\text{softmax}\\\\left( \\\\frac{Q K^\\\\top}{\\\\sqrt{d\\_k}} \\\\right) V\n*   In a naive implementation, for each decoding step we must compute KKK and VVV for all tokens in the current sequence, across all layers. If nnn is the number of tokens so far and lll is the number of layers, this requires l×(n−1)l×(n−1)l \\\\times (n−1) matrix multiplications per step, each of cost O(d2)O(d2)O(d^2), leading to:\n    \n    Cost per token\\=O(l⋅n⋅d2)Cost per token\\=O(l⋅n⋅d2)\n    \n    \\\\text{Cost per token} = O(l \\\\cdot n \\\\cdot d^2)\n*   A detailed discourse on self-attention is available in our [Transformers](../transformers) primer.\n    \n\nIn transformer models, each token attends to all previous tokens using a self-attention mechanism. For a sequence of input token embeddings X∈ℝT⋅dX∈RT⋅dX \\\\in \\\\mathbb{R}^{T \\\\cdot d}, the transformer computes:\n\n*   **Queries**:\n    \n    Q\\=XWQQ\\=XWQ\n    \n    Q = X W\\_Q\n*   **Keys**:\n    \n    K\\=XWKK\\=XWK\n    \n    K = X W\\_K\n*   **Values**:\n    \n    V\\=XWVV\\=XWV\n    \n    V = X W\\_V\n*   where WQ,WK,WV∈ℝd⋅dkWQ,WK,WV∈Rd⋅dkW\\_Q, W\\_K, W\\_V \\\\in \\\\mathbb{R}^{d \\\\cdot d\\_k} are learned projection matrices, and dkdkd\\_k is the head dimension.\n    \n\n**Queries**:\n\n**Keys**:\n\n**Values**:\n\nwhere WQ,WK,WV∈ℝd⋅dkWQ,WK,WV∈Rd⋅dkW\\_Q, W\\_K, W\\_V \\\\in \\\\mathbb{R}^{d \\\\cdot d\\_k} are learned projection matrices, and dkdkd\\_k is the head dimension.\n\nThe attention output is given by:\n\nIn a naive implementation, for each decoding step we must compute KKK and VVV for all tokens in the current sequence, across all layers. If nnn is the number of tokens so far and lll is the number of layers, this requires l×(n−1)l×(n−1)l \\\\times (n−1) matrix multiplications per step, each of cost O(d2)O(d2)O(d^2), leading to:\n\nA detailed discourse on self-attention is available in our [Transformers](../transformers) primer.\n\n#### Motivation\n\n*   In the context of serving transformer models, the **Key-Value (KV) cache** is a core optimization technique that dramatically improves the efficiency of autoregressive decoding. It stores intermediate attention computations from previous decoding steps—specifically, the key and value tensors produced within the self-attention mechanism—so they do not need to be recomputed at every new generation step. This reduces both inference time and redundant memory access, making long-form generation feasible for LLMs.\n\n##### The Problem: Quadratic Recomputation in Naive Generation\n\n*   During autoregressive generation, each new token depends on all previously generated tokens. In a **naive transformer implementation**, the model recomputes the key KKK and value VVV representations for **all tokens** in the sequence at every decoding step and across all layers. This quickly becomes computationally expensive, since the total cost per predicted token for a single attention head is:\n    \n    O(l⋅n⋅d2)O(l⋅n⋅d2)\n    \n    O(l \\\\cdot n \\\\cdot d^2)\n    *   where:\n        \n        *   nnn = number of tokens seen so far (sequence length)\n        *   lll = number of layers (depth)\n        *   ddd = model (embedding) dimension\n*   Without caching, predicting each new token involves:\n    \n    1.  Computing the key and value matrices for all past tokens and for every layer.\n    2.  Performing matrix multiplications of the form:\n        \n        K\\=XWK,V\\=XWVK\\=XWK,V\\=XWV\n        \n        K = X W\\_K, \\\\quad V = X W\\_V\n        *   where XXX is the layer input, and WKWKW\\_K, WVWVW\\_V are fixed weight matrices.\n\nDuring autoregressive generation, each new token depends on all previously generated tokens. In a **naive transformer implementation**, the model recomputes the key KKK and value VVV representations for **all tokens** in the sequence at every decoding step and across all layers. This quickly becomes computationally expensive, since the total cost per predicted token for a single attention head is:\n\n*   where:\n    \n    *   nnn = number of tokens seen so far (sequence length)\n    *   lll = number of layers (depth)\n    *   ddd = model (embedding) dimension\n\nwhere:\n\n*   nnn = number of tokens seen so far (sequence length)\n*   lll = number of layers (depth)\n*   ddd = model (embedding) dimension\n\nWithout caching, predicting each new token involves:\n\n1.  Computing the key and value matrices for all past tokens and for every layer.\n2.  Performing matrix multiplications of the form:\n    \n    K\\=XWK,V\\=XWVK\\=XWK,V\\=XWV\n    \n    K = X W\\_K, \\\\quad V = X W\\_V\n    *   where XXX is the layer input, and WKWKW\\_K, WVWVW\\_V are fixed weight matrices.\n\nPerforming matrix multiplications of the form:\n\n*   where XXX is the layer input, and WKWKW\\_K, WVWVW\\_V are fixed weight matrices.\n\n##### Why Naive Generation Fails\n\n*   KV caching fundamentally **solves the quadratic recomputation problem** that arises from this naive approach.\n*   Without a KV cache, generating even a 100-token response leads to massive redundant computation:\n    \n    *   **Token 1:** compute attention over 1000 context tokens\n    *   **Token 2:** recompute attention over all 1001 tokens\n    *   **Token 100:** recompute attention over all 1099 tokens\n*   The total number of attention computations can be derived from the arithmetic sum of all attention lengths per decoding step:\n\nWithout a KV cache, generating even a 100-token response leads to massive redundant computation:\n\n*   **Token 1:** compute attention over 1000 context tokens\n*   **Token 2:** recompute attention over all 1001 tokens\n*   **Token 100:** recompute attention over all 1099 tokens\n\n∑t\\=1100(1000+t−1)\\=1000×100+100×992\\=55,000∑t\\=1100(1000+t−1)\\=1000×100+100×992\\=55,000\n\n*   Here’s what each term means:\n    \n    *   The **1000** represents the fixed-length context available before generation begins (e.g., the prompt).\n    *   The **(t − 1)** accounts for the number of **previously generated tokens** already added before generating token ttt. At step ttt, the model has already generated t−1t−1t - 1 new tokens on top of the initial context, so it must now attend to 1000+(t−1)1000+(t−1)1000 + (t - 1) total tokens.\n    *   The summation over all 100 decoding steps gives the total number of attention operations across the full generation.\n*   Thus, to generate 100 tokens, the model performs approximately **55,000 redundant attention computations** — most of which are recomputations of previously calculated keys and values.\n    \n*   The inefficiency is striking:\n    \n    > Without KV cache: 100 output tokens = ~55,000 attention operations With KV cache: 100 output tokens = 100 attention operations (≈550× reduction)\n    \n*   This highlights the key trade-off: **KV caching exchanges memory usage for compute savings**. By storing previously computed keys and values, the model avoids redoing work it has already completed—unlocking massive gains in speed and scalability.\n    \n\nHere’s what each term means:\n\n*   The **1000** represents the fixed-length context available before generation begins (e.g., the prompt).\n*   The **(t − 1)** accounts for the number of **previously generated tokens** already added before generating token ttt. At step ttt, the model has already generated t−1t−1t - 1 new tokens on top of the initial context, so it must now attend to 1000+(t−1)1000+(t−1)1000 + (t - 1) total tokens.\n*   The summation over all 100 decoding steps gives the total number of attention operations across the full generation.\n\nThus, to generate 100 tokens, the model performs approximately **55,000 redundant attention computations** — most of which are recomputations of previously calculated keys and values.\n\nThe inefficiency is striking:\n\n> Without KV cache: 100 output tokens = ~55,000 attention operations With KV cache: 100 output tokens = 100 attention operations (≈550× reduction)\n\nWithout KV cache: 100 output tokens = ~55,000 attention operations With KV cache: 100 output tokens = 100 attention operations (≈550× reduction)\n\nThis highlights the key trade-off: **KV caching exchanges memory usage for compute savings**. By storing previously computed keys and values, the model avoids redoing work it has already completed—unlocking massive gains in speed and scalability.\n\n##### The Solution: Reusing Cached Representations\n\n*   The KV cache optimization addresses this problem by **reusing previously computed KKK and VVV** representations for all past tokens. Instead of recalculating them every time a new token is generated, the model simply:\n    \n    *   Reuses cached K1:(n−1)K1:(n−1)K\\_{1:(n-1)} and V1:(n−1)V1:(n−1)V\\_{1:(n-1)},\n    *   Computes only the new ktktk\\_t and vtvtv\\_t for the current token,\n    *   And appends them to the cache.\n*   This approach effectively removes redundant computation, changing the per-step cost from O(l⋅n⋅d2)toO(l⋅d2O(l⋅n⋅d2)toO(l⋅d2O(l \\\\cdot n \\\\cdot d^2) \\\\quad \\\\text{to} \\\\quad O(l \\\\cdot d^2—an **nnn\\-times speedup** in the sequence dimension.\n    \n*   The following figure ([source](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html)) illustrates a typical self-attentioblock in transformers:\n    \n\nThe KV cache optimization addresses this problem by **reusing previously computed KKK and VVV** representations for all past tokens. Instead of recalculating them every time a new token is generated, the model simply:\n\n*   Reuses cached K1:(n−1)K1:(n−1)K\\_{1:(n-1)} and V1:(n−1)V1:(n−1)V\\_{1:(n-1)},\n*   Computes only the new ktktk\\_t and vtvtv\\_t for the current token,\n*   And appends them to the cache.\n\nThis approach effectively removes redundant computation, changing the per-step cost from O(l⋅n⋅d2)toO(l⋅d2O(l⋅n⋅d2)toO(l⋅d2O(l \\\\cdot n \\\\cdot d^2) \\\\quad \\\\text{to} \\\\quad O(l \\\\cdot d^2—an **nnn\\-times speedup** in the sequence dimension.\n\nThe following figure ([source](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html)) illustrates a typical self-attentioblock in transformers:\n\n![Self-Attention Block](/primers/ai/assets/model-acceleration/SA.jpg)\n\n##### Why This Matters\n\n*   This improvement is especially critical for long sequences, where nnn can reach thousands or even millions of tokens. Without caching, latency would scale quadratically with sequence length, quickly becoming impractical. With KV caching, inference scales linearly, enabling efficient streaming and low-latency text generation for modern LLMs.\n\n#### Structure and Size of the KV Cache\n\n*   The KV cache stores the key and value tensors for each transformer layer, attention head, the sample indices within each batch, and the token prefix length (i.e., the number of tokens already processed, including the prompt and any previously generated tokens, not just the immediate past token).\n*   Assuming a transformer with:\n    \n    *   Sequence length so far: nnn\n    *   Number of layers: lll\n    *   Number of attention heads per layer: hhh\n    *   Head dimension: dkdkd\\_k\n    *   Batch size: bbb\n*   The KV cache for the above setup would consist of two main tensors per layer:\n    \n    1.  A **key tensor** of shape (b,h,n,dk)(b,h,n,dk)(b, h, n, d\\_k), which stores the projected keys KKK for all past tokens.\n        \n    2.  A **value tensor** of shape (b,h,n,dk)(b,h,n,dk)(b, h, n, d\\_k) which stores the projected values VVV for all past tokens.\n        \n*   Since each layer requires its own copy of both (KKK and VVV) tensors, the total number of stored elements is:\n\nAssuming a transformer with:\n\n*   Sequence length so far: nnn\n*   Number of layers: lll\n*   Number of attention heads per layer: hhh\n*   Head dimension: dkdkd\\_k\n*   Batch size: bbb\n\nThe KV cache for the above setup would consist of two main tensors per layer:\n\n1.  A **key tensor** of shape (b,h,n,dk)(b,h,n,dk)(b, h, n, d\\_k), which stores the projected keys KKK for all past tokens.\n    \n2.  A **value tensor** of shape (b,h,n,dk)(b,h,n,dk)(b, h, n, d\\_k) which stores the projected values VVV for all past tokens.\n    \n\nA **key tensor** of shape (b,h,n,dk)(b,h,n,dk)(b, h, n, d\\_k), which stores the projected keys KKK for all past tokens.\n\nA **value tensor** of shape (b,h,n,dk)(b,h,n,dk)(b, h, n, d\\_k) which stores the projected values VVV for all past tokens.\n\nTotal elements\\=2⋅l⋅b⋅h⋅n⋅dkTotal elements\\=2⋅l⋅b⋅h⋅n⋅dk\n\n*   If we assume each element is stored in 16-bit floating point precision (`float16`), then the total KV cache size in bytes is:\n    \n    Size (bytes)\\=2⋅l⋅b⋅h⋅n⋅dk⋅2Size (bytes)\\=2⋅l⋅b⋅h⋅n⋅dk⋅2\n    \n    \\\\text{Size (bytes)} = 2 \\\\cdot l \\\\cdot b \\\\cdot h \\\\cdot n \\\\cdot d\\_k \\\\cdot 2\n    *   where the final factor of 2 accounts for the 2 bytes per `float16` element.\n*   **Example:**\n    \n    *   For a model with l\\=32l\\=32l = 32 layers, h\\=32h\\=32h = 32 heads, dk\\=128dk\\=128d\\_k = 128, b\\=1b\\=1b = 1, and \\=1000\\=1000\\= 1000:\n    \n    Size\\=2⋅32⋅1⋅32⋅1000⋅128⋅2\\=524,288,000 bytes (≈500 MB)Size\\=2⋅32⋅1⋅32⋅1000⋅128⋅2\\=524,288,000 bytes (≈500 MB)\n    \n    \\\\text{Size} = 2 \\\\cdot 32 \\\\cdot 1 \\\\cdot 32 \\\\cdot 1000 \\\\cdot 128 \\\\cdot 2 = 524{,}288{,}000 \\\\ \\\\text{bytes} \\\\ (\\\\approx 500 \\\\ \\\\text{MB})\n*   This shows that the KV cache can become a significant memory consumer for long sequences, which is why optimizations such as quantization or chunked attention are often used in large language model inference.\n    \n\nIf we assume each element is stored in 16-bit floating point precision (`float16`), then the total KV cache size in bytes is:\n\n*   where the final factor of 2 accounts for the 2 bytes per `float16` element.\n\n**Example:**\n\n*   For a model with l\\=32l\\=32l = 32 layers, h\\=32h\\=32h = 32 heads, dk\\=128dk\\=128d\\_k = 128, b\\=1b\\=1b = 1, and \\=1000\\=1000\\= 1000:\n\nThis shows that the KV cache can become a significant memory consumer for long sequences, which is why optimizations such as quantization or chunked attention are often used in large language model inference.\n\n#### Caching Self-Attention Values\n\n*   KV caching exploits two key properties:\n    \n    1.  The model weights (WKWKW\\_K and WVWVW\\_V) are fixed during inference.\n    2.  The KKK and VVV representations for a given token depend on that token and all prior tokens (via its hidden state), but they do not depend on or change with any future tokens (i.e., they are **immutable** for for all subsequent decoding steps).\n*   Therefore, once we compute the KKK and VVV representations for a given (token, layer, head) tuple, we can store them and reuse them in all subsequent decoding steps.\n    \n*   At decoding step ttt:\n    \n    *   **Without caching**: recompute K1:nK1:nK\\_{1:n} and V1:nV1:nV\\_{1:n} from scratch for all ttt tokens.\n    *   **With caching**: reuse K1:(n−1)K1:(n−1)K\\_{1:(n-1)} and V1:(n−1)V1:(n−1)V\\_{1:(n-1)} compute only the new ktktk\\_t and vtvtv\\_t and append them to the cache.\n*   The following figure ([source](https://huggingface.co/blog/not-lain/kv-caching)) illustrates the KV caching process, showing how only the new token’s KKK and VVV are computed while the rest are reused:\n    \n\nKV caching exploits two key properties:\n\n1.  The model weights (WKWKW\\_K and WVWVW\\_V) are fixed during inference.\n2.  The KKK and VVV representations for a given token depend on that token and all prior tokens (via its hidden state), but they do not depend on or change with any future tokens (i.e., they are **immutable** for for all subsequent decoding steps).\n\nTherefore, once we compute the KKK and VVV representations for a given (token, layer, head) tuple, we can store them and reuse them in all subsequent decoding steps.\n\nAt decoding step ttt:\n\n*   **Without caching**: recompute K1:nK1:nK\\_{1:n} and V1:nV1:nV\\_{1:n} from scratch for all ttt tokens.\n*   **With caching**: reuse K1:(n−1)K1:(n−1)K\\_{1:(n-1)} and V1:(n−1)V1:(n−1)V\\_{1:(n-1)} compute only the new ktktk\\_t and vtvtv\\_t and append them to the cache.\n\nThe following figure ([source](https://huggingface.co/blog/not-lain/kv-caching)) illustrates the KV caching process, showing how only the new token’s KKK and VVV are computed while the rest are reused:\n\n![KV Caching Illustration](/primers/ai/assets/model-acceleration/KV.png)\n\n*   This optimization changes the cost from O(l⋅n⋅d2)O(l⋅n⋅d2)O(l \\\\cdot n \\\\cdot d^2) to O(l⋅d2)O(l⋅d2)O(l \\\\cdot d^2) per decoding step — an **nnn\\-times speedup** in the sequence dimension.\n    \n*   The improvement is especially significant for long sequences, where nnn can reach thousands or even millions of tokens. By eliminating redundant attention computations, KV caching enables efficient, low-latency generation at scale.\n    \n\nThis optimization changes the cost from O(l⋅n⋅d2)O(l⋅n⋅d2)O(l \\\\cdot n \\\\cdot d^2) to O(l⋅d2)O(l⋅d2)O(l \\\\cdot d^2) per decoding step — an **nnn\\-times speedup** in the sequence dimension.\n\nThe improvement is especially significant for long sequences, where nnn can reach thousands or even millions of tokens. By eliminating redundant attention computations, KV caching enables efficient, low-latency generation at scale.\n\n###### Why Not Cache Prior Queries?\n\n*   Only the most recent query qtqtq\\_t is used in the self-attention operation (which is recomputed at every step because it depends on the most recent token’s embedding), so caching prior queries (q1:(n−1)q1:(n−1)q\\_{1:(n-1)}) offers no benefit. Put simply, only the query corresponding to the latest token in the sequence is needed for decoding.\n\n#### Autoregressive Decoding Process with Caching\n\n1.  **Initial Sequence (Prefill Phase)**:\n    \n    *   Given a prompt sequence S\\=\\[x1,x2,…,xn\\]S\\=\\[x1,x2,…,xn\\]S = \\[x\\_1, x\\_2, \\\\dots, x\\_n\\] the model computes KKK and VVV tensors for all prompt tokens in all layers and stores them in the KV cache.\n        \n    *   This step still incurs the full cost O(l⋅n⋅d2)O(l⋅n⋅d2)O(l \\\\cdot n \\\\cdot d^2) because we have no cached values yet.\n        \n    *   After this prefill step, the model transitions to the _decode phase_, where we process one token per step.\n        \n2.  **Predict Next Token (Decode Phase)**:\n    \n    *   At decoding step n+1n+1n+1:\n        \n        *   Compute the query vector qn+1\\=xn+1WQqn+1\\=xn+1WQq\\_{n+1} = x\\_{n+1} W\\_Q for the new token.\n            \n        *   Retrieve all previous keys and values from the cache:\n            \n        \n        K1:n,V1:nK1:n,V1:n\n        \n        K\\_{1:n}, \\\\; V\\_{1:n}\n        \n        *   Compute the attention output for the new token using:\n        \n        Attention(qn+1,K1:n,V1:n)Attention(qn+1,K1:n,V1:n)\n        \n        \\\\text{Attention}(q\\_{n+1}, K\\_{1:n}, V\\_{1:n})\n3.  **Update Cache**:\n    \n    *   Compute the new key and value vectors for the current token:\n        \n        kn+1\\=xn+1WK,vn+1\\=xn+1WVkn+1\\=xn+1WK,vn+1\\=xn+1WV\n        \n        k\\_{n+1} = x\\_{n+1} W\\_K, \\\\quad v\\_{n+1} = x\\_{n+1} W\\_V\n    *   Append these to the KV cache so they can be reused in future decoding steps:\n        \n        Kcache←\\[K1:n,kn+1\\]Kcache←\\[K1:n,kn+1\\]\n        \n        K\\_{\\\\text{cache}} \\\\leftarrow \\[K\\_{1:n}, k\\_{n+1}\\]\n        \n        Vcache←\\[V1:n,vn+1\\]Vcache←\\[V1:n,vn+1\\]\n        \n        V\\_{\\\\text{cache}} \\\\leftarrow \\[V\\_{1:n}, v\\_{n+1}\\]\n4.  **Repeat**:\n    \n    *   Continue until the end-of-sequence (EOS) token is generated or the maximum token limit is reached.\n\n**Initial Sequence (Prefill Phase)**:\n\n*   Given a prompt sequence S\\=\\[x1,x2,…,xn\\]S\\=\\[x1,x2,…,xn\\]S = \\[x\\_1, x\\_2, \\\\dots, x\\_n\\] the model computes KKK and VVV tensors for all prompt tokens in all layers and stores them in the KV cache.\n    \n*   This step still incurs the full cost O(l⋅n⋅d2)O(l⋅n⋅d2)O(l \\\\cdot n \\\\cdot d^2) because we have no cached values yet.\n    \n*   After this prefill step, the model transitions to the _decode phase_, where we process one token per step.\n    \n\nGiven a prompt sequence S\\=\\[x1,x2,…,xn\\]S\\=\\[x1,x2,…,xn\\]S = \\[x\\_1, x\\_2, \\\\dots, x\\_n\\] the model computes KKK and VVV tensors for all prompt tokens in all layers and stores them in the KV cache.\n\nThis step still incurs the full cost O(l⋅n⋅d2)O(l⋅n⋅d2)O(l \\\\cdot n \\\\cdot d^2) because we have no cached values yet.\n\nAfter this prefill step, the model transitions to the _decode phase_, where we process one token per step.\n\n**Predict Next Token (Decode Phase)**:\n\n*   At decoding step n+1n+1n+1:\n    \n    *   Compute the query vector qn+1\\=xn+1WQqn+1\\=xn+1WQq\\_{n+1} = x\\_{n+1} W\\_Q for the new token.\n        \n    *   Retrieve all previous keys and values from the cache:\n        \n    \n    K1:n,V1:nK1:n,V1:n\n    \n    K\\_{1:n}, \\\\; V\\_{1:n}\n    \n    *   Compute the attention output for the new token using:\n    \n    Attention(qn+1,K1:n,V1:n)Attention(qn+1,K1:n,V1:n)\n    \n    \\\\text{Attention}(q\\_{n+1}, K\\_{1:n}, V\\_{1:n})\n\nAt decoding step n+1n+1n+1:\n\n*   Compute the query vector qn+1\\=xn+1WQqn+1\\=xn+1WQq\\_{n+1} = x\\_{n+1} W\\_Q for the new token.\n    \n*   Retrieve all previous keys and values from the cache:\n    \n\nCompute the query vector qn+1\\=xn+1WQqn+1\\=xn+1WQq\\_{n+1} = x\\_{n+1} W\\_Q for the new token.\n\nRetrieve all previous keys and values from the cache:\n\n*   Compute the attention output for the new token using:\n\n**Update Cache**:\n\n*   Compute the new key and value vectors for the current token:\n    \n    kn+1\\=xn+1WK,vn+1\\=xn+1WVkn+1\\=xn+1WK,vn+1\\=xn+1WV\n    \n    k\\_{n+1} = x\\_{n+1} W\\_K, \\\\quad v\\_{n+1} = x\\_{n+1} W\\_V\n*   Append these to the KV cache so they can be reused in future decoding steps:\n    \n    Kcache←\\[K1:n,kn+1\\]Kcache←\\[K1:n,kn+1\\]\n    \n    K\\_{\\\\text{cache}} \\\\leftarrow \\[K\\_{1:n}, k\\_{n+1}\\]\n    \n    Vcache←\\[V1:n,vn+1\\]Vcache←\\[V1:n,vn+1\\]\n    \n    V\\_{\\\\text{cache}} \\\\leftarrow \\[V\\_{1:n}, v\\_{n+1}\\]\n\nCompute the new key and value vectors for the current token:\n\nAppend these to the KV cache so they can be reused in future decoding steps:\n\n**Repeat**:\n\n*   Continue until the end-of-sequence (EOS) token is generated or the maximum token limit is reached.\n\n#### Implementation Details\n\n##### Cache Tensor Shape\n\n*   Assuming:\n    \n    *   Batch size BBB\n    *   Max sequence length nnn\n    *   Number of heads HHH\n    *   Head dimension dkdkd\\_k\n    *   Number of layers lll\n*   The KV cache is structured to store KKK and VVV for each (token,layer,head)(token,layer,head)(token, layer, head) tuple. For a **given layer** and **head**, the cache tensor shapes and sizes are:\n    \n    *   **Key cache (per layer, per head):**\n        \n        K(l,h)cache∈ℝB×n×dkKcache(l,h)∈RB×n×dk\n        \n        K\\_{\\\\text{cache}}^{(l,h)} \\\\in \\\\mathbb{R}^{B \\\\times n \\\\times d\\_k}\n        \n        *   **Key cache size (in bytes):**\n        \n        S(l,h)K\\=B×n×dk×sizeof(dtype)SK(l,h)\\=B×n×dk×sizeof(dtype)\n        \n        S\\_{K}^{(l,h)} = B \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n    *   **Value cache (per layer, per head):**\n        \n        V(l,h)cache∈ℝB×n×dkVcache(l,h)∈RB×n×dk\n        \n        V\\_{\\\\text{cache}}^{(l,h)} \\\\in \\\\mathbb{R}^{B \\\\times n \\\\times d\\_k}\n        \n        *   **Value cache size (in bytes):**\n        \n        S(l,h)V\\=B×n×dk×sizeof(dtype)SV(l,h)\\=B×n×dk×sizeof(dtype)\n        \n        S\\_{V}^{(l,h)} = B \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n    *   **Total memory size per layer and head (in bytes):**\n        \n        Slayer, head\\=2×B×n×dk×sizeof(dtype)Slayer, head\\=2×B×n×dk×sizeof(dtype)\n        \n        S\\_{\\\\text{layer, head}} = 2 \\\\times B \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n        *   The factor of 2 accounts for both the key and value tensors.\n*   When combining all layers and attention heads, the total KV cache represents the complete memory footprint required to store all key and value tensors across the entire model. The following equations describe the full model-wide KV Cache cache dimensions and their corresponding memory requirements:\n    \n    *   **Key cache (all layers, all attention heads):**\n        \n        K(total)cache∈ℝB×l×H×n×dkKcache(total)∈RB×l×H×n×dk\n        \n        K\\_{\\\\text{cache}}^{(\\\\text{total})} \\\\in \\\\mathbb{R}^{B \\\\times l \\\\times H \\\\times n \\\\times d\\_k}\n        \n        *   **Key cache size (in bytes):**\n        \n        S(total)K\\=B×l×H×n×dk×sizeof(dtype)SK(total)\\=B×l×H×n×dk×sizeof(dtype)\n        \n        S\\_{K}^{(\\\\text{total})} = B \\\\times l \\\\times H \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n    *   **Value cache (all layers, all attention heads):**\n        \n        V(total)cache∈ℝB×l×H×n×dkVcache(total)∈RB×l×H×n×dk\n        \n        V\\_{\\\\text{cache}}^{(\\\\text{total})} \\\\in \\\\mathbb{R}^{B \\\\times l \\\\times H \\\\times n \\\\times d\\_k}\n        \n        *   **Value cache size (in bytes):**\n        \n        S(total)V\\=B×l×H×n×dk×sizeof(dtype)SV(total)\\=B×l×H×n×dk×sizeof(dtype)\n        \n        S\\_{V}^{(\\\\text{total})} = B \\\\times l \\\\times H \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n    *   **Total memory size across the entire model (in bytes):**\n        \n        Stotal\\=2×B×l×H×n×dk×sizeof(dtype)Stotal\\=2×B×l×H×n×dk×sizeof(dtype)\n        \n        S\\_{\\\\text{total}} = 2 \\\\times B \\\\times l \\\\times H \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n*   **Notes:**\n    \n    *   The cache size scales linearly with BBB, lll, HHH, nnn, and dkdkd\\_k. During autoregressive generation, the model processes one token per step in the decode phase, only **one** new key and one new value vector are appended at each step for every layer and head. Consequently, as decoding progresses, the total cache grows linearly with the number of generated tokens—reflecting the incremental accumulation of key-value pairs over time.\n    *   In practice:\n        *   sizeof(dtype)\\=2sizeof(dtype)\\=2\\\\text{sizeof(dtype)} = 2 bytes for FP16/BF16 caches.\n        *   sizeof(dtype)\\=1sizeof(dtype)\\=1\\\\text{sizeof(dtype)} = 1 byte for INT8 caches.\n    *   Example: For a model with l\\=32l\\=32l = 32, H\\=64H\\=64H = 64, dk\\=128dk\\=128d\\_k = 128, B\\=8B\\=8B = 8, and n\\=4096n\\=4096n = 4096, the KV cache can easily consume tens of gigabytes of GPU memory. Efficient cache management (e.g., truncation, quantization, or offloading) is thus essential for real-world deployment.\n    *   Efficient memory layout is crucial — contiguous buffers enable fast appends and reduce memory copy overhead.\n\nAssuming:\n\n*   Batch size BBB\n*   Max sequence length nnn\n*   Number of heads HHH\n*   Head dimension dkdkd\\_k\n*   Number of layers lll\n\nThe KV cache is structured to store KKK and VVV for each (token,layer,head)(token,layer,head)(token, layer, head) tuple. For a **given layer** and **head**, the cache tensor shapes and sizes are:\n\n*   **Key cache (per layer, per head):**\n    \n    K(l,h)cache∈ℝB×n×dkKcache(l,h)∈RB×n×dk\n    \n    K\\_{\\\\text{cache}}^{(l,h)} \\\\in \\\\mathbb{R}^{B \\\\times n \\\\times d\\_k}\n    \n    *   **Key cache size (in bytes):**\n    \n    S(l,h)K\\=B×n×dk×sizeof(dtype)SK(l,h)\\=B×n×dk×sizeof(dtype)\n    \n    S\\_{K}^{(l,h)} = B \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n*   **Value cache (per layer, per head):**\n    \n    V(l,h)cache∈ℝB×n×dkVcache(l,h)∈RB×n×dk\n    \n    V\\_{\\\\text{cache}}^{(l,h)} \\\\in \\\\mathbb{R}^{B \\\\times n \\\\times d\\_k}\n    \n    *   **Value cache size (in bytes):**\n    \n    S(l,h)V\\=B×n×dk×sizeof(dtype)SV(l,h)\\=B×n×dk×sizeof(dtype)\n    \n    S\\_{V}^{(l,h)} = B \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n*   **Total memory size per layer and head (in bytes):**\n    \n    Slayer, head\\=2×B×n×dk×sizeof(dtype)Slayer, head\\=2×B×n×dk×sizeof(dtype)\n    \n    S\\_{\\\\text{layer, head}} = 2 \\\\times B \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n    *   The factor of 2 accounts for both the key and value tensors.\n\n**Key cache (per layer, per head):**\n\n*   **Key cache size (in bytes):**\n\n**Value cache (per layer, per head):**\n\n*   **Value cache size (in bytes):**\n\n**Total memory size per layer and head (in bytes):**\n\n*   The factor of 2 accounts for both the key and value tensors.\n\nWhen combining all layers and attention heads, the total KV cache represents the complete memory footprint required to store all key and value tensors across the entire model. The following equations describe the full model-wide KV Cache cache dimensions and their corresponding memory requirements:\n\n*   **Key cache (all layers, all attention heads):**\n    \n    K(total)cache∈ℝB×l×H×n×dkKcache(total)∈RB×l×H×n×dk\n    \n    K\\_{\\\\text{cache}}^{(\\\\text{total})} \\\\in \\\\mathbb{R}^{B \\\\times l \\\\times H \\\\times n \\\\times d\\_k}\n    \n    *   **Key cache size (in bytes):**\n    \n    S(total)K\\=B×l×H×n×dk×sizeof(dtype)SK(total)\\=B×l×H×n×dk×sizeof(dtype)\n    \n    S\\_{K}^{(\\\\text{total})} = B \\\\times l \\\\times H \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n*   **Value cache (all layers, all attention heads):**\n    \n    V(total)cache∈ℝB×l×H×n×dkVcache(total)∈RB×l×H×n×dk\n    \n    V\\_{\\\\text{cache}}^{(\\\\text{total})} \\\\in \\\\mathbb{R}^{B \\\\times l \\\\times H \\\\times n \\\\times d\\_k}\n    \n    *   **Value cache size (in bytes):**\n    \n    S(total)V\\=B×l×H×n×dk×sizeof(dtype)SV(total)\\=B×l×H×n×dk×sizeof(dtype)\n    \n    S\\_{V}^{(\\\\text{total})} = B \\\\times l \\\\times H \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n*   **Total memory size across the entire model (in bytes):**\n    \n    Stotal\\=2×B×l×H×n×dk×sizeof(dtype)Stotal\\=2×B×l×H×n×dk×sizeof(dtype)\n    \n    S\\_{\\\\text{total}} = 2 \\\\times B \\\\times l \\\\times H \\\\times n \\\\times d\\_k \\\\times \\\\text{sizeof(dtype)}\n\n**Key cache (all layers, all attention heads):**\n\n*   **Key cache size (in bytes):**\n\n**Value cache (all layers, all attention heads):**\n\n*   **Value cache size (in bytes):**\n\n**Total memory size across the entire model (in bytes):**\n\n**Notes:**\n\n*   The cache size scales linearly with BBB, lll, HHH, nnn, and dkdkd\\_k. During autoregressive generation, the model processes one token per step in the decode phase, only **one** new key and one new value vector are appended at each step for every layer and head. Consequently, as decoding progresses, the total cache grows linearly with the number of generated tokens—reflecting the incremental accumulation of key-value pairs over time.\n*   In practice:\n    *   sizeof(dtype)\\=2sizeof(dtype)\\=2\\\\text{sizeof(dtype)} = 2 bytes for FP16/BF16 caches.\n    *   sizeof(dtype)\\=1sizeof(dtype)\\=1\\\\text{sizeof(dtype)} = 1 byte for INT8 caches.\n*   Example: For a model with l\\=32l\\=32l = 32, H\\=64H\\=64H = 64, dk\\=128dk\\=128d\\_k = 128, B\\=8B\\=8B = 8, and n\\=4096n\\=4096n = 4096, the KV cache can easily consume tens of gigabytes of GPU memory. Efficient cache management (e.g., truncation, quantization, or offloading) is thus essential for real-world deployment.\n*   Efficient memory layout is crucial — contiguous buffers enable fast appends and reduce memory copy overhead.\n\n*   sizeof(dtype)\\=2sizeof(dtype)\\=2\\\\text{sizeof(dtype)} = 2 bytes for FP16/BF16 caches.\n*   sizeof(dtype)\\=1sizeof(dtype)\\=1\\\\text{sizeof(dtype)} = 1 byte for INT8 caches.\n\n##### Prefill Phase\n\n*   When the prompt is first processed:\n    \n    *   The model computes KKK and VVV for **all** prompt tokens in every layer, filling the cache.\n    *   This initial step has the same cost as the naive approach:\n    \n    O(l⋅n⋅d2)O(l⋅n⋅d2)\n    \n    O(l \\\\cdot n \\\\cdot d^2)\n*   After this, we move into the decode phase, where caching delivers the performance benefits.\n    \n\nWhen the prompt is first processed:\n\n*   The model computes KKK and VVV for **all** prompt tokens in every layer, filling the cache.\n*   This initial step has the same cost as the naive approach:\n\nAfter this, we move into the decode phase, where caching delivers the performance benefits.\n\n##### Updates to the KV Cache\n\n*   During autoregressive decoding, the KKK and VVV projections are cached for every processed token, across all layers and heads.\n*   Each time a new token is generated:\n    \n    1.  The model computes ktktk\\_t and vtvtv\\_t for that token in each layer.\n    2.  These vectors are appended to the existing KcacheKcacheK\\_{cache} and VcacheVcacheV\\_{cache}.\n    3.  The updated cache is then used to compute the attention output for the next token.\n\nEach time a new token is generated:\n\n1.  The model computes ktktk\\_t and vtvtv\\_t for that token in each layer.\n2.  These vectors are appended to the existing KcacheKcacheK\\_{cache} and VcacheVcacheV\\_{cache}.\n3.  The updated cache is then used to compute the attention output for the next token.\n\n#### Latency Optimization/Savings\n\n##### Projection Cost\n\n*   **Without caching**:\n    \n    *   For a single head, at decoding step with sequence length nnn, the self-attention module recomputes KKK and VVV for all nnn tokens across all lll layers. Put simply, each new generated token waits for full attention recomputation.\n    *   Computational cost per predicted token:\n        \n        O(l⋅n⋅d2)O(l⋅n⋅d2)\n        \n        O(l \\\\cdot n \\\\cdot d^2)\n*   **With caching**:\n    \n    *   Only the key and value for the **new** token are computed, while the rest are reused from the cache. Put simply, each token only computes new attention scores.\n    *   Computational cost per predicted token:\n        \n        O(l⋅d2)O(l⋅d2)\n        \n        O(l \\\\cdot d^2)\n*   This represents an nnn\\-times speedup in the sequence dimension. For large nnn (e.g., thousands or millions of tokens), the cost reduction is dramatic.\n    \n\n**Without caching**:\n\n*   For a single head, at decoding step with sequence length nnn, the self-attention module recomputes KKK and VVV for all nnn tokens across all lll layers. Put simply, each new generated token waits for full attention recomputation.\n*   Computational cost per predicted token:\n    \n    O(l⋅n⋅d2)O(l⋅n⋅d2)\n    \n    O(l \\\\cdot n \\\\cdot d^2)\n\nComputational cost per predicted token:\n\n**With caching**:\n\n*   Only the key and value for the **new** token are computed, while the rest are reused from the cache. Put simply, each token only computes new attention scores.\n*   Computational cost per predicted token:\n    \n    O(l⋅d2)O(l⋅d2)\n    \n    O(l \\\\cdot d^2)\n\nComputational cost per predicted token:\n\nThis represents an nnn\\-times speedup in the sequence dimension. For large nnn (e.g., thousands or millions of tokens), the cost reduction is dramatic.\n\n##### Attention Score Computation\n\n*   **Without caching**:\n    \n    *   At sequence length nnn, computing the attention scores requires multiplying the query for the new token with all nnn keys. This is done for every layer, so the attention score computation cost per predicted token is:\n        \n        O(l⋅n⋅d)O(l⋅n⋅d)\n        \n        O(l \\\\cdot n \\\\cdot d)\n    *   Because nnn increases with each generated token, the latency for this step grows linearly in nnn per token generation, but overall decoding (projection + attention) without caching still has quadratic growth in nnn.\n        \n*   **With caching**:\n    \n    *   Keys from all previous tokens are already stored. At sequence length nnn, we only compute the dot products between the new query and the cached keys:\n        \n        O(l⋅n⋅d)O(l⋅n⋅d)\n        \n        O(l \\\\cdot n \\\\cdot d)\n    *   The cost per token still grows linearly with nnn, but caching removes the quadratic growth that comes from recomputing keys and values for older tokens.\n        \n\n**Without caching**:\n\n*   At sequence length nnn, computing the attention scores requires multiplying the query for the new token with all nnn keys. This is done for every layer, so the attention score computation cost per predicted token is:\n    \n    O(l⋅n⋅d)O(l⋅n⋅d)\n    \n    O(l \\\\cdot n \\\\cdot d)\n*   Because nnn increases with each generated token, the latency for this step grows linearly in nnn per token generation, but overall decoding (projection + attention) without caching still has quadratic growth in nnn.\n    \n\nAt sequence length nnn, computing the attention scores requires multiplying the query for the new token with all nnn keys. This is done for every layer, so the attention score computation cost per predicted token is:\n\nBecause nnn increases with each generated token, the latency for this step grows linearly in nnn per token generation, but overall decoding (projection + attention) without caching still has quadratic growth in nnn.\n\n**With caching**:\n\n*   Keys from all previous tokens are already stored. At sequence length nnn, we only compute the dot products between the new query and the cached keys:\n    \n    O(l⋅n⋅d)O(l⋅n⋅d)\n    \n    O(l \\\\cdot n \\\\cdot d)\n*   The cost per token still grows linearly with nnn, but caching removes the quadratic growth that comes from recomputing keys and values for older tokens.\n    \n\nKeys from all previous tokens are already stored. At sequence length nnn, we only compute the dot products between the new query and the cached keys:\n\nThe cost per token still grows linearly with nnn, but caching removes the quadratic growth that comes from recomputing keys and values for older tokens.\n\n##### Total Complexity\n\n*   KV caching transforms overall decoding latency from quadratic in nnn to approximately linear in nnn, a major improvement for long-sequence generation. Specifically, KV caching changes the dominant scaling term from O(n2⋅d2)O(n2⋅d2)O(n^2 \\\\cdot d^2) to O(n2⋅d)O(n2⋅d)O(n^2 \\\\cdot d) which, for typical transformer sizes, is a substantial improvement in long-sequence latency. This is mathematically represented below.\n    \n*   **Without caching**:\n    \n    *   Total cost per predicted token = projection cost + attention score computation:\n        \n        O(l⋅n⋅d2)+O(l⋅n⋅d)≈O(l⋅n⋅d2)O(l⋅n⋅d2)+O(l⋅n⋅d)≈O(l⋅n⋅d2)\n        \n        O(l \\\\cdot n \\\\cdot d^2) + O(l \\\\cdot n \\\\cdot d) \\\\approx O(l \\\\cdot n \\\\cdot d^2)\n    *   Over an entire sequence of length nnn, the total decoding cost is:\n        \n        O(l⋅n2⋅d2)O(l⋅n2⋅d2)\n        \n        O(l \\\\cdot n^2 \\\\cdot d^2)\n*   **With caching**:\n    \n    *   Total cost per predicted token = projection cost + attention score computation:\n        \n        O(l⋅d2)+O(l⋅n⋅d)≈O(l⋅n⋅d)O(l⋅d2)+O(l⋅n⋅d)≈O(l⋅n⋅d)\n        \n        O(l \\\\cdot d^2) + O(l \\\\cdot n \\\\cdot d) \\\\approx O(l \\\\cdot n \\\\cdot d)\n    *   Over an entire sequence of length nnn, the total decoding cost is:\n        \n        O(l⋅n2⋅d)O(l⋅n2⋅d)\n        \n        O(l \\\\cdot n^2 \\\\cdot d)\n\nKV caching transforms overall decoding latency from quadratic in nnn to approximately linear in nnn, a major improvement for long-sequence generation. Specifically, KV caching changes the dominant scaling term from O(n2⋅d2)O(n2⋅d2)O(n^2 \\\\cdot d^2) to O(n2⋅d)O(n2⋅d)O(n^2 \\\\cdot d) which, for typical transformer sizes, is a substantial improvement in long-sequence latency. This is mathematically represented below.\n\n**Without caching**:\n\n*   Total cost per predicted token = projection cost + attention score computation:\n    \n    O(l⋅n⋅d2)+O(l⋅n⋅d)≈O(l⋅n⋅d2)O(l⋅n⋅d2)+O(l⋅n⋅d)≈O(l⋅n⋅d2)\n    \n    O(l \\\\cdot n \\\\cdot d^2) + O(l \\\\cdot n \\\\cdot d) \\\\approx O(l \\\\cdot n \\\\cdot d^2)\n*   Over an entire sequence of length nnn, the total decoding cost is:\n    \n    O(l⋅n2⋅d2)O(l⋅n2⋅d2)\n    \n    O(l \\\\cdot n^2 \\\\cdot d^2)\n\nTotal cost per predicted token = projection cost + attention score computation:\n\nOver an entire sequence of length nnn, the total decoding cost is:\n\n**With caching**:\n\n*   Total cost per predicted token = projection cost + attention score computation:\n    \n    O(l⋅d2)+O(l⋅n⋅d)≈O(l⋅n⋅d)O(l⋅d2)+O(l⋅n⋅d)≈O(l⋅n⋅d)\n    \n    O(l \\\\cdot d^2) + O(l \\\\cdot n \\\\cdot d) \\\\approx O(l \\\\cdot n \\\\cdot d)\n*   Over an entire sequence of length nnn, the total decoding cost is:\n    \n    O(l⋅n2⋅d)O(l⋅n2⋅d)\n    \n    O(l \\\\cdot n^2 \\\\cdot d)\n\nTotal cost per predicted token = projection cost + attention score computation:\n\nOver an entire sequence of length nnn, the total decoding cost is:\n\n#### Practical KV Cache Implementation\n\n*   This section connects the abstract cache shapes and complexity analysis to concrete implementation choices made in real Transformer inference engines. The emphasis is on how tensors are allocated, updated, indexed, and consumed during the prefill and decode phases.\n*   This tight coupling between tensor layout, cache indexing, and attention computation is what enables modern LLMs to generate long sequences efficiently while maintaining strict correctness guarantees.\n\n##### Cache Allocation and Memory Layout\n\n*   Given the full-model cache shapes:\n    \n    Kcache,Vcache∈ℝB×l×H×n×dkKcache,Vcache∈RB×l×H×n×dk\n    \n    K\\_{\\\\text{cache}}, V\\_{\\\\text{cache}} \\\\in \\\\mathbb{R}^{B \\\\times l \\\\times H \\\\times n \\\\times d\\_k}\n    *   … most implementations do not dynamically grow tensors with concatenation during decoding. Instead, they preallocate the full cache upfront to avoid repeated memory allocation and costly tensor re-materialization.\n*   In practice, this looks like:\n    \n\nGiven the full-model cache shapes:\n\n*   … most implementations do not dynamically grow tensors with concatenation during decoding. Instead, they preallocate the full cache upfront to avoid repeated memory allocation and costly tensor re-materialization.\n\nIn practice, this looks like:\n\n![](https://aman.ai/images/copy.png)\n\n`K_cache = torch.empty(B, l, H, n_max, d_k, dtype=dtype, device=device) V_cache = torch.empty(B, l, H, n_max, d_k, dtype=dtype, device=device)`\n\n![](https://aman.ai/images/copy.png)\n\n`K_cache = torch.empty(B, l, H, n_max, d_k, dtype=dtype, device=device) V_cache = torch.empty(B, l, H, n_max, d_k, dtype=dtype, device=device)`\n\n*   A separate scalar (or vector, for batched decoding) tracks the current decode position:\n\n![](https://aman.ai/images/copy.png)\n\n`cache_pos = t`\n\n![](https://aman.ai/images/copy.png)\n\n`cache_pos = t`\n\n*   This design choice ensures:\n    \n    *   Contiguous memory layout.\n    *   O(1)O(1)O(1) writes per decoding step.\n    *   Zero tensor copies during cache updates.\n\nThis design choice ensures:\n\n*   Contiguous memory layout.\n*   O(1)O(1)O(1) writes per decoding step.\n*   Zero tensor copies during cache updates.\n\n##### Writing to the Cache During Decoding\n\n*   At decoding step ttt, for each layer lll and head hhh, the model computes a single Key and Value vector:\n\nk(l,h)t,v(l,h)t∈ℝB×dkkt(l,h),vt(l,h)∈RB×dk\n\n*   These vectors are written directly into the preallocated cache:\n\n![](https://aman.ai/images/copy.png)\n\n`K_cache[:, l, :, cache_pos, :] = K_new V_cache[:, l, :, cache_pos, :] = V_new`\n\n![](https://aman.ai/images/copy.png)\n\n`K_cache[:, l, :, cache_pos, :] = K_new V_cache[:, l, :, cache_pos, :] = V_new`\n\n*   Conceptually, this operation corresponds exactly to appending along the sequence dimension, but avoids reallocation. Over time, the cache fills along the nnn dimension until generation ends or a maximum context length is reached.\n\n##### Reading from the Cache for Attention\n\n*   When computing attention at decoding step ttt, each layer reads all cached Keys and Values up to the current position:\n\nK(l)≤t∈ℝB×H×t×dk,V(l)≤t∈ℝB×H×t×dkK≤t(l)∈RB×H×t×dk,V≤t(l)∈RB×H×t×dk\n\n*   This is typically implemented via slicing:\n\n![](https://aman.ai/images/copy.png)\n\n`K_used = K_cache[:, l, :, :cache_pos + 1, :] V_used = V_cache[:, l, :, :cache_pos + 1, :]`\n\n![](https://aman.ai/images/copy.png)\n\n`K_used = K_cache[:, l, :, :cache_pos + 1, :] V_used = V_cache[:, l, :, :cache_pos + 1, :]`\n\n*   No copying occurs here; these are lightweight views into the underlying buffer.\n\n##### Query Computation and Shape Alignment\n\n*   The Query is computed only for the current token:\n\nQ(l)t∈ℝB×H×1×dkQt(l)∈RB×H×1×dk\n\n*   This shape aligns naturally with cached Keys during attention score computation:\n\nQtK⊤≤t→ℝB×H×1×tQtK≤t⊤→RB×H×1×t\n\n*   The resulting attention weights are then applied to the cached Values to produce the output representation for the current token only.\n\n##### Positional Encoding Consistency at Scale\n\n*   Because the cache persists across decoding steps, positional encodings must be applied exactly once per token and never retroactively modified.\n    \n*   **Absolute positional embeddings**:\n    *   The embedding for position ttt is added during the forward pass for token ttt. Since cached Keys and Values already contain this information, slicing older entries from the cache remains valid without adjustment.\n*   **Relative / implicit schemes (RoPE, ALiBi)**:\n    \n    *   Positional transformations are applied at Key/Query creation time. Each cached Key is permanently associated with its position index at creation:\n    \n    Kt←RoPE(Kt,t)Kt←RoPE(Kt,t)\n    \n    K\\_t \\\\leftarrow \\\\text{RoPE}(K\\_t, t)\n    *   Because relative attention depends on position differences, cached Keys remain correct when reused for future tokens without modification.\n\nBecause the cache persists across decoding steps, positional encodings must be applied exactly once per token and never retroactively modified.\n\n*   The embedding for position ttt is added during the forward pass for token ttt. Since cached Keys and Values already contain this information, slicing older entries from the cache remains valid without adjustment.\n\n*   Positional transformations are applied at Key/Query creation time. Each cached Key is permanently associated with its position index at creation:\n\n*   Because relative attention depends on position differences, cached Keys remain correct when reused for future tokens without modification.\n\n##### Layerwise Cache Propagation\n\n*   Each Transformer layer maintains an independent KV cache. During decoding, the cache position is shared globally, but writes occur independently per layer:\n\n![](https://aman.ai/images/copy.png)\n\n`for l in range(num_layers):     K_cache[:, l, :, cache_pos, :] = K_new_l     V_cache[:, l, :, cache_pos, :] = V_new_l`\n\n![](https://aman.ai/images/copy.png)\n\n`for l in range(num_layers):     K_cache[:, l, :, cache_pos, :] = K_new_l     V_cache[:, l, :, cache_pos, :] = V_new_l`\n\n*   This mirrors the mathematical definition where each layer has its own attention space and associated memory footprint.\n\n##### Interaction with Prefill and Decode Phases\n\n*   During the prefill phase:\n    \n    *   The model processes the full prompt of length npromptnpromptn\\_{\\\\text{prompt}}.\n    *   The cache is filled for all layers, heads, and positions 000 through nprompt−1nprompt−1n\\_{\\\\text{prompt}} - 1.\n    *   Computational cost matches the naive Transformer forward pass.\n*   During the decode phase:\n    \n    *   Exactly one new Key and one new Value are written per layer and head at each step.\n    *   Projection cost collapses from O(l⋅n⋅d2)O(l⋅n⋅d2)O(l \\\\cdot n \\\\cdot d^2) to O(l⋅d2)O(l⋅d2)O(l \\\\cdot d^2).\n    *   Cache reads dominate memory bandwidth, while compute is concentrated in attention score evaluation.\n\nDuring the prefill phase:\n\n*   The model processes the full prompt of length npromptnpromptn\\_{\\\\text{prompt}}.\n*   The cache is filled for all layers, heads, and positions 000 through nprompt−1nprompt−1n\\_{\\\\text{prompt}} - 1.\n*   Computational cost matches the naive Transformer forward pass.\n\nDuring the decode phase:\n\n*   Exactly one new Key and one new Value are written per layer and head at each step.\n*   Projection cost collapses from O(l⋅n⋅d2)O(l⋅n⋅d2)O(l \\\\cdot n \\\\cdot d^2) to O(l⋅d2)O(l⋅d2)O(l \\\\cdot d^2).\n*   Cache reads dominate memory bandwidth, while compute is concentrated in attention score evaluation.\n\n##### Why Cache Growth is Linear but Latency is Not\n\n*   Although the cache grows linearly with the number of generated tokens, decoding latency per token grows only linearly due to attention score computation:\n\nO(l⋅n⋅d)O(l⋅n⋅d)\n\n*   Crucially, caching removes the repeated projection of historical tokens, eliminating the quadratic projection term and ensuring that long-context generation remains feasible in practice.\n\n##### Takeaways\n\n*   At an implementation level, the KV cache:\n    \n    *   Is a preallocated, layerwise, headwise memory buffer.\n    *   Is written once per token and never modified afterward.\n    *   Converts self-attention into a stateful operation during inference.\n    *   Preserves exact numerical equivalence with the vanilla Transformer.\n    *   Shifts decoding from projection-dominated to memory- and attention-dominated runtime behavior.\n\nAt an implementation level, the KV cache:\n\n*   Is a preallocated, layerwise, headwise memory buffer.\n*   Is written once per token and never modified afterward.\n*   Converts self-attention into a stateful operation during inference.\n*   Preserves exact numerical equivalence with the vanilla Transformer.\n*   Shifts decoding from projection-dominated to memory- and attention-dominated runtime behavior.\n\n#### Practical Deployment Considerations\n\n##### Memory Management\n\n*   Managing KV caches efficiently is one of the main engineering challenges in large-scale transformer deployment. The cache for each sequence grows linearly with the number of processed tokens, since for every new token the model must store its key and value representations for each layer and attention head. Consequently, even moderate increases in context length can result in exponential GPU memory pressure when serving multiple concurrent requests.\n    \n*   To mitigate this, systems adopt several strategies:\n    \n    *   **Sliding Window Caching**: Instead of maintaining the entire attention history, servers often retain only the most recent N tokens per request. This sliding window allows for long-running conversations without exceeding memory budgets, at the cost of slightly reduced long-range recall. For instance, if the model supports 32k tokens but memory is constrained, the cache may only keep the last 8k–16k tokens.\n        \n    *   **Cache Truncation and Compression**: For extreme cases, caches can be truncated or quantized. Truncation drops the oldest segments of the context when the memory budget is reached, while compression methods—like storing keys and values in lower precision (e.g., FP16 or INT8)—trade off a small amount of accuracy for substantial memory savings.\n        \n    *   **Layer-Aware Cache Allocation**: Not all layers contribute equally to performance. Some deployment systems dynamically allocate higher precision or longer cache retention to the most attention-sensitive layers while reducing resource usage for others.\n        \n    *   **Offloading to Host Memory**: For very long contexts or multi-turn conversations, GPU memory may not suffice. Systems can offload part of the cache to CPU memory or even NVMe-based memory pools, fetching it back as needed. However, this introduces latency trade-offs and requires careful memory pinning to minimize data transfer overheads.\n        \n\nManaging KV caches efficiently is one of the main engineering challenges in large-scale transformer deployment. The cache for each sequence grows linearly with the number of processed tokens, since for every new token the model must store its key and value representations for each layer and attention head. Consequently, even moderate increases in context length can result in exponential GPU memory pressure when serving multiple concurrent requests.\n\nTo mitigate this, systems adopt several strategies:\n\n*   **Sliding Window Caching**: Instead of maintaining the entire attention history, servers often retain only the most recent N tokens per request. This sliding window allows for long-running conversations without exceeding memory budgets, at the cost of slightly reduced long-range recall. For instance, if the model supports 32k tokens but memory is constrained, the cache may only keep the last 8k–16k tokens.\n    \n*   **Cache Truncation and Compression**: For extreme cases, caches can be truncated or quantized. Truncation drops the oldest segments of the context when the memory budget is reached, while compression methods—like storing keys and values in lower precision (e.g., FP16 or INT8)—trade off a small amount of accuracy for substantial memory savings.\n    \n*   **Layer-Aware Cache Allocation**: Not all layers contribute equally to performance. Some deployment systems dynamically allocate higher precision or longer cache retention to the most attention-sensitive layers while reducing resource usage for others.\n    \n*   **Offloading to Host Memory**: For very long contexts or multi-turn conversations, GPU memory may not suffice. Systems can offload part of the cache to CPU memory or even NVMe-based memory pools, fetching it back as needed. However, this introduces latency trade-offs and requires careful memory pinning to minimize data transfer overheads.\n    \n\n**Sliding Window Caching**: Instead of maintaining the entire attention history, servers often retain only the most recent N tokens per request. This sliding window allows for long-running conversations without exceeding memory budgets, at the cost of slightly reduced long-range recall. For instance, if the model supports 32k tokens but memory is constrained, the cache may only keep the last 8k–16k tokens.\n\n**Cache Truncation and Compression**: For extreme cases, caches can be truncated or quantized. Truncation drops the oldest segments of the context when the memory budget is reached, while compression methods—like storing keys and values in lower precision (e.g., FP16 or INT8)—trade off a small amount of accuracy for substantial memory savings.\n\n**Layer-Aware Cache Allocation**: Not all layers contribute equally to performance. Some deployment systems dynamically allocate higher precision or longer cache retention to the most attention-sensitive layers while reducing resource usage for others.\n\n**Offloading to Host Memory**: For very long contexts or multi-turn conversations, GPU memory may not suffice. Systems can offload part of the cache to CPU memory or even NVMe-based memory pools, fetching it back as needed. However, this introduces latency trade-offs and requires careful memory pinning to minimize data transfer overheads.\n\n##### Dynamic Batching\n\n*   Dynamic batching is essential for maximizing GPU utilization in real-time inference scenarios. Since users issue requests of varying lengths and progress asynchronously through token generation, each request maintains an independent KV cache that grows at its own rate. A well-designed system must:\n    \n    *   Efficiently **group requests with similar decoding steps** to form micro-batches without breaking sequence dependencies.\n    *   Maintain **per-request cache isolation**, ensuring that the correct KV history is retrieved during each attention computation.\n    *   Implement **fast lookup and append mechanisms**, typically backed by memory pools or custom allocators, allowing concurrent cache updates without heavy synchronization locks.\n    *   Use **streaming attention scheduling**: at each decoding step, the system identifies which requests are ready to decode and merges them temporarily into a batch. Once the next token is produced, each request’s cache is updated independently.\n*   Systems such as vLLM and TensorRT-LLM provide specialized runtime schedulers that dynamically manage per-request caches while achieving near-optimal GPU occupancy. In such architectures, the ability to reuse KV states and batch across requests determines overall throughput.\n    \n\nDynamic batching is essential for maximizing GPU utilization in real-time inference scenarios. Since users issue requests of varying lengths and progress asynchronously through token generation, each request maintains an independent KV cache that grows at its own rate. A well-designed system must:\n\n*   Efficiently **group requests with similar decoding steps** to form micro-batches without breaking sequence dependencies.\n*   Maintain **per-request cache isolation**, ensuring that the correct KV history is retrieved during each attention computation.\n*   Implement **fast lookup and append mechanisms**, typically backed by memory pools or custom allocators, allowing concurrent cache updates without heavy synchronization locks.\n*   Use **streaming attention scheduling**: at each decoding step, the system identifies which requests are ready to decode and merges them temporarily into a batch. Once the next token is produced, each request’s cache is updated independently.\n\nSystems such as vLLM and TensorRT-LLM provide specialized runtime schedulers that dynamically manage per-request caches while achieving near-optimal GPU occupancy. In such architectures, the ability to reuse KV states and batch across requests determines overall throughput.\n\n##### Cache Parallelism\n\n*   In large-scale multi-GPU or distributed serving environments, KV caches themselves become distributed data structures. When the model’s layers or attention heads are sharded across devices, the corresponding keys and values must follow the same partitioning strategy. Typical configurations include:\n    \n    *   **Tensor Parallelism**: Each GPU holds only a subset of the attention heads. During cross-device attention computations, the K and V tensors are exchanged or synchronized across GPUs via collective operations (e.g., all-gather). Efficient implementations overlap communication and computation to minimize latency.\n        \n    *   **Pipeline Parallelism**: Layers are distributed across GPUs. Each GPU must maintain the KV cache for only the layers it owns. However, during forward passes, intermediate activations are streamed between devices. The system must ensure that caches align temporally across pipeline stages to preserve attention correctness.\n        \n    *   **Model Parallel + Data Parallel Hybridization**: In highly scalable deployments, KV caches are both sharded (for model parallelism) and replicated (for data parallelism). Systems must handle synchronization and memory consistency between replicas, often through NCCL-based communication backends.\n        \n    *   **Cross-Node Caching**: When models run across multiple nodes, caches may be stored in distributed shared memory or remote memory access (RDMA)-capable hardware, allowing direct GPU-to-GPU cache retrieval without CPU intervention.\n        \n\nIn large-scale multi-GPU or distributed serving environments, KV caches themselves become distributed data structures. When the model’s layers or attention heads are sharded across devices, the corresponding keys and values must follow the same partitioning strategy. Typical configurations include:\n\n*   **Tensor Parallelism**: Each GPU holds only a subset of the attention heads. During cross-device attention computations, the K and V tensors are exchanged or synchronized across GPUs via collective operations (e.g., all-gather). Efficient implementations overlap communication and computation to minimize latency.\n    \n*   **Pipeline Parallelism**: Layers are distributed across GPUs. Each GPU must maintain the KV cache for only the layers it owns. However, during forward passes, intermediate activations are streamed between devices. The system must ensure that caches align temporally across pipeline stages to preserve attention correctness.\n    \n*   **Model Parallel + Data Parallel Hybridization**: In highly scalable deployments, KV caches are both sharded (for model parallelism) and replicated (for data parallelism). Systems must handle synchronization and memory consistency between replicas, often through NCCL-based communication backends.\n    \n*   **Cross-Node Caching**: When models run across multiple nodes, caches may be stored in distributed shared memory or remote memory access (RDMA)-capable hardware, allowing direct GPU-to-GPU cache retrieval without CPU intervention.\n    \n\n**Tensor Parallelism**: Each GPU holds only a subset of the attention heads. During cross-device attention computations, the K and V tensors are exchanged or synchronized across GPUs via collective operations (e.g., all-gather). Efficient implementations overlap communication and computation to minimize latency.\n\n**Pipeline Parallelism**: Layers are distributed across GPUs. Each GPU must maintain the KV cache for only the layers it owns. However, during forward passes, intermediate activations are streamed between devices. The system must ensure that caches align temporally across pipeline stages to preserve attention correctness.\n\n**Model Parallel + Data Parallel Hybridization**: In highly scalable deployments, KV caches are both sharded (for model parallelism) and replicated (for data parallelism). Systems must handle synchronization and memory consistency between replicas, often through NCCL-based communication backends.\n\n**Cross-Node Caching**: When models run across multiple nodes, caches may be stored in distributed shared memory or remote memory access (RDMA)-capable hardware, allowing direct GPU-to-GPU cache retrieval without CPU intervention.\n\n##### Why You Can’t Always Cache Everything\n\n*   Memory growth in KV caching is linear in sequence length and proportional to the number of layers, heads, and hidden dimensions:\n    \n    *   **Memory scaling:** For large models (tens of billions of parameters), a single sequence of 1000 tokens may consume roughly 1 GB of KV cache.\n    *   **Batch size impact:** The more concurrent sequences are cached, the fewer requests can fit into GPU memory, directly impacting throughput.\n    *   **Context length:** With ultra-long contexts (e.g., 100k tokens), a naive full cache could exceed 100 GB—far beyond the capacity of even high-end GPUs.\n\nMemory growth in KV caching is linear in sequence length and proportional to the number of layers, heads, and hidden dimensions:\n\n*   **Memory scaling:** For large models (tens of billions of parameters), a single sequence of 1000 tokens may consume roughly 1 GB of KV cache.\n*   **Batch size impact:** The more concurrent sequences are cached, the fewer requests can fit into GPU memory, directly impacting throughput.\n*   **Context length:** With ultra-long contexts (e.g., 100k tokens), a naive full cache could exceed 100 GB—far beyond the capacity of even high-end GPUs.\n\n#### Multi-Head Attention and KV Cache\n\n*   In practice, self-attention is implemented with multiple attention heads, each operating in a subspace of the embedding dimension. For head hhh in {1,…,H}{1,…,H}\\\\{1, \\\\dots, H\\\\}, we have:\n    \n    Q(h)\\=XWQ(h),K(h)\\=XWK(h),V(h)\\=XWV(h)Q(h)\\=XWQ(h),K(h)\\=XWK(h),V(h)\\=XWV(h)\n    \n    Q^{(h)} = X W\\_{Q^{(h)}}, \\\\quad K^{(h)} = X W\\_{K^{(h)}}, \\\\quad V^{(h)} = X W\\_{V^{(h)}}\n*   The attention outputs from each head are concatenated:\n    \n    Q\\=concat(Q(1),Q(2),…,Q(H))Q\\=concat(Q(1),Q(2),…,Q(H))\n    \n    Q = \\\\text{concat}(Q^{(1)}, Q^{(2)}, \\\\dots, Q^{(H)})\n    *   and similarly for KKK and VVV.\n*   **Caching in multi-head attention**:\n    \n    *   The KV cache stores keys and values for every head and every layer.\n    *   Shape for the key and value cache:\n    \n    Kcache∈ℝB×H×n×dkKcache∈RB×H×n×dk\n    \n    K\\_{cache} \\\\in \\\\mathbb{R}^{B \\\\times H \\\\times n \\\\times d\\_k}\n    \n    Vcache∈ℝB×H×n×dkVcache∈RB×H×n×dk\n    \n    V\\_{cache} \\\\in \\\\mathbb{R}^{B \\\\times H \\\\times n \\\\times d\\_k}\n    *   **where**\n        \n        *   BBB = batch size (number of sequences processed in parallel)\n        *   HHH = number of attention heads\n        *   nnn = sequence length (number of tokens stored in the cache)\n        *   dkdkd\\_k = dimension of the key (and value) vectors per head\n*   **Performance implications**:\n    \n    *   Since each head’s KV cache is independent, the caching logic operates head-wise, but the storage is typically implemented as a unified tensor for efficiency.\n    *   This unified tensor is arranged to be friendly to GPU tensor cores, enabling very fast read and write operations during decoding.\n*   While KV caching greatly reduces the sequence dimension cost, the **depth dimension** (number of layers lll) is still a significant contributor to compute. This leads to the _KV Sharing_ idea, covered in detail in the section on [KV Sharing](#kv-sharing) — reusing KKK and VVV representations across the last half (or fraction) of layers to further cut computation. KV sharing builds on KV caching, but attacks the problem from the layer/depth dimension rather than the token dimension.\n    \n\nIn practice, self-attention is implemented with multiple attention heads, each operating in a subspace of the embedding dimension. For head hhh in {1,…,H}{1,…,H}\\\\{1, \\\\dots, H\\\\}, we have:\n\nThe attention outputs from each head are concatenated:\n\n*   and similarly for KKK and VVV.\n\n**Caching in multi-head attention**:\n\n*   The KV cache stores keys and values for every head and every layer.\n*   Shape for the key and value cache:\n\n*   **where**\n    \n    *   BBB = batch size (number of sequences processed in parallel)\n    *   HHH = number of attention heads\n    *   nnn = sequence length (number of tokens stored in the cache)\n    *   dkdkd\\_k = dimension of the key (and value) vectors per head\n\n**where**\n\n*   BBB = batch size (number of sequences processed in parallel)\n*   HHH = number of attention heads\n*   nnn = sequence length (number of tokens stored in the cache)\n*   dkdkd\\_k = dimension of the key (and value) vectors per head\n\n**Performance implications**:\n\n*   Since each head’s KV cache is independent, the caching logic operates head-wise, but the storage is typically implemented as a unified tensor for efficiency.\n*   This unified tensor is arranged to be friendly to GPU tensor cores, enabling very fast read and write operations during decoding.\n\nWhile KV caching greatly reduces the sequence dimension cost, the **depth dimension** (number of layers lll) is still a significant contributor to compute. This leads to the _KV Sharing_ idea, covered in detail in the section on [KV Sharing](#kv-sharing) — reusing KKK and VVV representations across the last half (or fraction) of layers to further cut computation. KV sharing builds on KV caching, but attacks the problem from the layer/depth dimension rather than the token dimension.\n\n#### Summary of KV Cache Benefits\n\n*   **Reduces repeated computation** by storing and reusing KKK, VVV tensors instead of recomputing them at every step.\n*   **Enables efficient decoding** in autoregressive generation by cutting per-step cost from O(l⋅n⋅d2)O(l⋅n⋅d2)O(l \\\\cdot n \\\\cdot d^2) to O(l⋅d2)O(l⋅d2)O(l \\\\cdot d^2) — an **nnn\\-times speedup** in the sequence dimension.\n*   **Optimized for hardware acceleration** via unified tensor layouts that are friendly to GPU tensor cores.\n*   **Scales well** to large models and long contexts, with latency growing linearly rather than quadratically with sequence length.\n*   **Maintains accuracy** because cached KKK and VVV are identical to recomputed values, given fixed weights.\n\n#### KV Sharing\n\n*   KV caching, introduced in [You Only Cache Once: Decoder-Decoder Architectures for Language Models](https://arxiv.org/abs/2405.05254) by Sun et al. (2024), optimizes the **sequence dimension** (nnn) cost, but the **depth dimension** (lll) — the number of layers — still incurs full computation for each layer’s KKK and VVV.\n*   **KV Sharing** addresses this by reducing the cost of computing KKK and VVV along the depth dimension.\n*   The intuition behind why this can work comes from studies such as [Do Language Models Use Their Depth Efficiently?](https://arxiv.org/abs/2505.13898) by Csordás et al., which show empirically that in a deep transformer-like model, the last layers are correlated with each other. This means the final few layers are not necessarily adding much new information, but rather tweaking the output produced so far. This redundancy can potentially be exploited to save computation without significantly degrading model quality.\n\n##### How KV Sharing Works\n\n*   The core idea: share **actual KKK and VVV representations** (not just weight matrices) across the last fraction of layers.\n    \n*   For example, if we share across the last half of the layers (l2l2\\\\frac{l}{2} layers):\n    \n    1.  The final layer before the shared region computes KKK and VVV normally.\n    2.  All subsequent layers in the shared region reuse these KKK and VVV without recomputation, regardless of their inputs.\n    3.  Other parameters (e.g., WQWQW\\_Q, MLP weights) remain distinct per layer.\n*   Mathematically:\n    \n    *   Let LshareLshareL\\_{share} be the index of the first shared layer.\n    *   For any layer j≥Lsharej≥Lsharej \\\\geq L\\_{share}:\n    \n    K(j)\\=K(Lshare),V(j)\\=V(Lshare)K(j)\\=K(Lshare),V(j)\\=V(Lshare)\n    \n    K^{(j)} = K^{(L\\_{share})}, \\\\quad V^{(j)} = V^{(L\\_{share})}\n*   The following figure ([source](https://arxiv.org/abs/2405.05254)) illustrates KV Sharing across the last half of the layers, showing how a single computed KKK and VVV set is reused instead of recalculated:\n    \n\nThe core idea: share **actual KKK and VVV representations** (not just weight matrices) across the last fraction of layers.\n\nFor example, if we share across the last half of the layers (l2l2\\\\frac{l}{2} layers):\n\n1.  The final layer before the shared region computes KKK and VVV normally.\n2.  All subsequent layers in the shared region reuse these KKK and VVV without recomputation, regardless of their inputs.\n3.  Other parameters (e.g., WQWQW\\_Q, MLP weights) remain distinct per layer.\n\nMathematically:\n\n*   Let LshareLshareL\\_{share} be the index of the first shared layer.\n*   For any layer j≥Lsharej≥Lsharej \\\\geq L\\_{share}:\n\nThe following figure ([source](https://arxiv.org/abs/2405.05254)) illustrates KV Sharing across the last half of the layers, showing how a single computed KKK and VVV set is reused instead of recalculated:\n\n![KV Sharing Illustration](/primers/ai/assets/model-acceleration/KVS.jpg)\n\n##### FLOP Savings\n\n*   If the last lklk\\\\frac{l}{k} layers share KKK and VVV, we avoid computing them in lklk\\\\frac{l}{k} layers entirely.\n*   FLOP reduction: Savings\\=lkl\\=1kSavings\\=lkl\\=1k\\\\text{Savings} = \\\\frac{\\\\frac{l}{k}}{l} = \\\\frac{1}{k} fraction of the total keys and values computation.\n*   Combined with KV caching:\n    \n    *   KV caching cuts cost in nnn (sequence) dimension.\n    *   KV sharing cuts cost in lll (layer) dimension.\n\nCombined with KV caching:\n\n*   KV caching cuts cost in nnn (sequence) dimension.\n*   KV sharing cuts cost in lll (layer) dimension.\n\n##### Why KV Sharing Can Work\n\n*   Empirical studies referenced in the paper show that in deep transformer models, the last few layers often produce correlated outputs.\n*   This suggests that later layers are mostly fine-tuning rather than introducing fundamentally new information.\n*   Reusing KKK and VVV in these layers therefore has minimal impact on output quality while significantly reducing compute and memory usage.\n\n##### Memory Benefits\n\n*   **No need to store keys and values** for the shared layers at all.\n*   Reduces memory footprint in both inference and training.\n*   Particularly valuable when serving long sequences, where cache size is dominated by B×H×n×dk×lB×H×n×dk×lB \\\\times H \\\\times n \\\\times d\\_k \\\\times l scaling.\n\n##### Deployment Notes\n\n*   KV sharing must be considered at **training time** for best results, since models not trained with this constraint may suffer quality drops if sharing is applied post hoc.\n*   Works alongside KV caching since KV sharing tackles **depth**, while KV caching tackles **sequence length**.",
    "contentLength": 1108867,
    "wordCount": 9669,
    "hasCode": true,
    "hasMath": true,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/model-acceleration/#kv-cache"
  },
  {
    "id": "ai-model-acceleration-model-quantization-11",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Inference Optimizations",
    "title": "Model Quantization",
    "order": 11,
    "orderInChapter": 3,
    "contentHtml": "<ul>\n  <li>Model quantization is a technique used to reduce the precision of numerical values (typically weights and activations) in a neural network from high-precision formats like 32-bit floating point (<code class=\"language-plaintext highlighter-rouge\">float32</code>) to lower-precision formats such as <code class=\"language-plaintext highlighter-rouge\">int8</code>, <code class=\"language-plaintext highlighter-rouge\">float8</code>, or even <code class=\"language-plaintext highlighter-rouge\">int4</code>. This allows for faster inference, reduced memory usage, and lower power consumption, particularly on hardware that supports low-precision arithmetic.</li>\n  <li>A detailed discourse on this topic is available in our <a href=\"../model-compression\">Model Compression</a> primer.</li>\n</ul>\n<h4 id=\"why-quantize\">Why Quantize?</h4>\n<ul>\n  <li>\n    <p>Quantization can lead to significant improvements in efficiency:</p>\n\n    <ul>\n      <li><strong>Reduced Memory Footprint</strong>: An <code class=\"language-plaintext highlighter-rouge\">int8</code> model consumes 75% less memory than its <code class=\"language-plaintext highlighter-rouge\">float32</code> counterpart.</li>\n      <li><strong>Faster Arithmetic</strong>: Lower-precision operations (like <code class=\"language-plaintext highlighter-rouge\">int8</code> or <code class=\"language-plaintext highlighter-rouge\">int4</code> matmuls) are natively supported and highly optimized on modern accelerators (e.g., NVIDIA Tensor Cores, Intel AVX-512 VNNI).</li>\n      <li><strong>Lower Latency</strong>: With less data to move and faster compute kernels, quantized models offer reduced end-to-end inference time.</li>\n    </ul>\n  </li>\n</ul>\n<p>Quantization can lead to significant improvements in efficiency:</p>\n<ul>\n      <li><strong>Reduced Memory Footprint</strong>: An <code class=\"language-plaintext highlighter-rouge\">int8</code> model consumes 75% less memory than its <code class=\"language-plaintext highlighter-rouge\">float32</code> counterpart.</li>\n      <li><strong>Faster Arithmetic</strong>: Lower-precision operations (like <code class=\"language-plaintext highlighter-rouge\">int8</code> or <code class=\"language-plaintext highlighter-rouge\">int4</code> matmuls) are natively supported and highly optimized on modern accelerators (e.g., NVIDIA Tensor Cores, Intel AVX-512 VNNI).</li>\n      <li><strong>Lower Latency</strong>: With less data to move and faster compute kernels, quantized models offer reduced end-to-end inference time.</li>\n    </ul>\n<h4 id=\"types-of-quantization\">Types of Quantization</h4>\n<h5 id=\"post-training-quantization-ptq\">Post-Training Quantization (PTQ)</h5>\n<ul>\n  <li>\n    <p>PTQ involves converting a pre-trained <code class=\"language-plaintext highlighter-rouge\">float32</code> model to a lower-precision model without retraining. It works by calibrating the ranges of tensors using a small sample of data.</p>\n  </li>\n  <li>\n    <p><strong>Key steps in PTQ:</strong></p>\n\n    <ul>\n      <li>\n        <p><strong>Range Calibration</strong>: Identify the min/max values of weights and activations from a calibration dataset.</p>\n      </li>\n      <li>\n        <p><strong>Scale and Zero-Point Calculation</strong>: For each quantized tensor, calculate:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-263-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>q</mi><mo>=</mo><mtext>round</mtext><mrow><mo>(</mo><mfrac><mi>r</mi><mi>s</mi></mfrac><mo>)</mo></mrow><mo>+</mo><mi>z</mi></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2319\" style=\"width: 9.273em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.711em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(2.138em, 1007.71em, 4.326em, -999.997em); top: -3.487em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2320\"><span class=\"mi\" id=\"MathJax-Span-2321\" style=\"font-family: STIXGeneral-Italic;\">q</span><span class=\"mo\" id=\"MathJax-Span-2322\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-2323\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">round</span><span class=\"mrow\" id=\"MathJax-Span-2324\" style=\"padding-left: 0.211em;\"><span class=\"mo\" id=\"MathJax-Span-2325\" style=\"vertical-align: -0.414em;\"><span style=\"font-family: STIXSizeTwoSym;\">(</span></span><span class=\"mfrac\" id=\"MathJax-Span-2326\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.206em;\"><span class=\"mi\" id=\"MathJax-Span-2327\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.206em;\"><span class=\"mi\" id=\"MathJax-Span-2328\" style=\"font-family: STIXGeneral-Italic;\">s</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.52em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.523em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2329\" style=\"vertical-align: -0.414em;\"><span style=\"font-family: STIXSizeTwoSym;\">)</span></span></span><span class=\"mo\" id=\"MathJax-Span-2330\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-2331\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">z</span></span><span style=\"display: inline-block; width: 0px; height: 3.492em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.872em; border-left: 0px solid; width: 0px; height: 2.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>q</mi><mo>=</mo><mtext>round</mtext><mrow><mo>(</mo><mfrac><mi>r</mi><mi>s</mi></mfrac><mo>)</mo></mrow><mo>+</mo><mi>z</mi></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-263\">q = \\text{round}\\left(\\frac{r}{s}\\right) + z</script>\n\n        <ul>\n          <li>\n            <p>where:</p>\n\n            <ul>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-264-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>r</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2332\" style=\"width: 0.419em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.315em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.32em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2333\"><span class=\"mi\" id=\"MathJax-Span-2334\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>r</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-264\">r</script> is the real-valued number</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-265-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>s</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2335\" style=\"width: 0.471em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.367em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.37em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2336\"><span class=\"mi\" id=\"MathJax-Span-2337\" style=\"font-family: STIXGeneral-Italic;\">s</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>s</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-265\">s</script> is the scale (i.e., step size)</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-266-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>z</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2338\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.451em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2339\"><span class=\"mi\" id=\"MathJax-Span-2340\" style=\"font-family: STIXGeneral-Italic;\">z</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 0.753em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>z</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-266\">z</script> is the zero-point to preserve zero mapping in the quantized domain</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-267-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>q</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2341\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2342\"><span class=\"mi\" id=\"MathJax-Span-2343\" style=\"font-family: STIXGeneral-Italic;\">q</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>q</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-267\">q</script> is the quantized value (e.g., 8-bit integer)</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Weight and Activation Clipping</strong>: Clip values to fit within the representable range of the target bit-width (e.g., [-128, 127] for signed <code class=\"language-plaintext highlighter-rouge\">int8</code>).</p>\n  </li>\n</ul>\n<p>PTQ involves converting a pre-trained <code class=\"language-plaintext highlighter-rouge\">float32</code> model to a lower-precision model without retraining. It works by calibrating the ranges of tensors using a small sample of data.</p>\n<p><strong>Key steps in PTQ:</strong></p>\n<ul>\n      <li>\n        <p><strong>Range Calibration</strong>: Identify the min/max values of weights and activations from a calibration dataset.</p>\n      </li>\n      <li>\n        <p><strong>Scale and Zero-Point Calculation</strong>: For each quantized tensor, calculate:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-263-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>q</mi><mo>=</mo><mtext>round</mtext><mrow><mo>(</mo><mfrac><mi>r</mi><mi>s</mi></mfrac><mo>)</mo></mrow><mo>+</mo><mi>z</mi></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2319\" style=\"width: 9.273em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.711em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(2.138em, 1007.71em, 4.326em, -999.997em); top: -3.487em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2320\"><span class=\"mi\" id=\"MathJax-Span-2321\" style=\"font-family: STIXGeneral-Italic;\">q</span><span class=\"mo\" id=\"MathJax-Span-2322\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-2323\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">round</span><span class=\"mrow\" id=\"MathJax-Span-2324\" style=\"padding-left: 0.211em;\"><span class=\"mo\" id=\"MathJax-Span-2325\" style=\"vertical-align: -0.414em;\"><span style=\"font-family: STIXSizeTwoSym;\">(</span></span><span class=\"mfrac\" id=\"MathJax-Span-2326\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.206em;\"><span class=\"mi\" id=\"MathJax-Span-2327\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.206em;\"><span class=\"mi\" id=\"MathJax-Span-2328\" style=\"font-family: STIXGeneral-Italic;\">s</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.52em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.523em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2329\" style=\"vertical-align: -0.414em;\"><span style=\"font-family: STIXSizeTwoSym;\">)</span></span></span><span class=\"mo\" id=\"MathJax-Span-2330\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-2331\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">z</span></span><span style=\"display: inline-block; width: 0px; height: 3.492em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.872em; border-left: 0px solid; width: 0px; height: 2.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>q</mi><mo>=</mo><mtext>round</mtext><mrow><mo>(</mo><mfrac><mi>r</mi><mi>s</mi></mfrac><mo>)</mo></mrow><mo>+</mo><mi>z</mi></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-263\">q = \\text{round}\\left(\\frac{r}{s}\\right) + z</script>\n\n        <ul>\n          <li>\n            <p>where:</p>\n\n            <ul>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-264-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>r</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2332\" style=\"width: 0.419em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.315em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.32em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2333\"><span class=\"mi\" id=\"MathJax-Span-2334\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>r</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-264\">r</script> is the real-valued number</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-265-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>s</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2335\" style=\"width: 0.471em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.367em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.37em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2336\"><span class=\"mi\" id=\"MathJax-Span-2337\" style=\"font-family: STIXGeneral-Italic;\">s</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>s</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-265\">s</script> is the scale (i.e., step size)</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-266-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>z</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2338\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.451em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2339\"><span class=\"mi\" id=\"MathJax-Span-2340\" style=\"font-family: STIXGeneral-Italic;\">z</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 0.753em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>z</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-266\">z</script> is the zero-point to preserve zero mapping in the quantized domain</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-267-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>q</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2341\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2342\"><span class=\"mi\" id=\"MathJax-Span-2343\" style=\"font-family: STIXGeneral-Italic;\">q</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>q</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-267\">q</script> is the quantized value (e.g., 8-bit integer)</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n    </ul>\n<p><strong>Range Calibration</strong>: Identify the min/max values of weights and activations from a calibration dataset.</p>\n<p><strong>Scale and Zero-Point Calculation</strong>: For each quantized tensor, calculate:</p>\n<ul>\n          <li>\n            <p>where:</p>\n\n            <ul>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-264-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>r</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2332\" style=\"width: 0.419em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.315em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.32em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2333\"><span class=\"mi\" id=\"MathJax-Span-2334\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>r</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-264\">r</script> is the real-valued number</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-265-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>s</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2335\" style=\"width: 0.471em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.367em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.37em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2336\"><span class=\"mi\" id=\"MathJax-Span-2337\" style=\"font-family: STIXGeneral-Italic;\">s</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>s</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-265\">s</script> is the scale (i.e., step size)</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-266-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>z</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2338\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.451em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2339\"><span class=\"mi\" id=\"MathJax-Span-2340\" style=\"font-family: STIXGeneral-Italic;\">z</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 0.753em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>z</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-266\">z</script> is the zero-point to preserve zero mapping in the quantized domain</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-267-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>q</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2341\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2342\"><span class=\"mi\" id=\"MathJax-Span-2343\" style=\"font-family: STIXGeneral-Italic;\">q</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>q</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-267\">q</script> is the quantized value (e.g., 8-bit integer)</li>\n            </ul>\n          </li>\n        </ul>\n<p>where:</p>\n<ul>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-264-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>r</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2332\" style=\"width: 0.419em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.315em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.32em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2333\"><span class=\"mi\" id=\"MathJax-Span-2334\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>r</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-264\">r</script> is the real-valued number</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-265-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>s</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2335\" style=\"width: 0.471em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.367em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.37em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2336\"><span class=\"mi\" id=\"MathJax-Span-2337\" style=\"font-family: STIXGeneral-Italic;\">s</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>s</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-265\">s</script> is the scale (i.e., step size)</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-266-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>z</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2338\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.451em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2339\"><span class=\"mi\" id=\"MathJax-Span-2340\" style=\"font-family: STIXGeneral-Italic;\">z</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 0.753em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>z</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-266\">z</script> is the zero-point to preserve zero mapping in the quantized domain</li>\n              <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-267-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>q</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2341\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2342\"><span class=\"mi\" id=\"MathJax-Span-2343\" style=\"font-family: STIXGeneral-Italic;\">q</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>q</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-267\">q</script> is the quantized value (e.g., 8-bit integer)</li>\n            </ul>\n<p><strong>Weight and Activation Clipping</strong>: Clip values to fit within the representable range of the target bit-width (e.g., [-128, 127] for signed <code class=\"language-plaintext highlighter-rouge\">int8</code>).</p>\n<h5 id=\"quantization-aware-training-qat\">Quantization-Aware Training (QAT)</h5>\n<ul>\n  <li>\n    <p>QAT simulates quantization during training. Fake quantization layers are added to mimic low-precision computation while maintaining gradients in high precision.</p>\n  </li>\n  <li>\n    <p><strong>Advantages:</strong></p>\n\n    <ul>\n      <li>More accurate than PTQ for sensitive models (e.g., GPT, BERT).</li>\n      <li>Allows the model to adapt to quantization errors during fine-tuning.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Implementation Details:</strong></p>\n\n    <ul>\n      <li>Frameworks like PyTorch and TensorFlow include fake quantization modules (e.g., <code class=\"language-plaintext highlighter-rouge\">torch.quantization.FakeQuantize</code>).</li>\n      <li>Quant-dequant pairs are inserted in the model graph to simulate the behavior of actual quantized operations.</li>\n    </ul>\n  </li>\n</ul>\n<p>QAT simulates quantization during training. Fake quantization layers are added to mimic low-precision computation while maintaining gradients in high precision.</p>\n<p><strong>Advantages:</strong></p>\n<ul>\n      <li>More accurate than PTQ for sensitive models (e.g., GPT, BERT).</li>\n      <li>Allows the model to adapt to quantization errors during fine-tuning.</li>\n    </ul>\n<p><strong>Implementation Details:</strong></p>\n<ul>\n      <li>Frameworks like PyTorch and TensorFlow include fake quantization modules (e.g., <code class=\"language-plaintext highlighter-rouge\">torch.quantization.FakeQuantize</code>).</li>\n      <li>Quant-dequant pairs are inserted in the model graph to simulate the behavior of actual quantized operations.</li>\n    </ul>\n<h4 id=\"static-vs-dynamic-quantization\">Static vs. Dynamic Quantization</h4>\n<ul>\n  <li><strong>Static Quantization</strong>: Activations are quantized ahead of time using calibration. Requires representative input data and is more performant but less flexible.</li>\n  <li><strong>Dynamic Quantization</strong>: Weights are quantized ahead of time, but activations are quantized at runtime based on actual values. More flexible and easier to integrate but slightly slower.</li>\n</ul>\n<h4 id=\"quantization-in-transformers\">Quantization in Transformers</h4>\n<ul>\n  <li>\n    <p>In transformer models like GPT or BERT, quantization is applied to:</p>\n\n    <ul>\n      <li><strong>Linear layers</strong>: Including query, key, value, and output projections in attention layers.</li>\n      <li><strong>GEMM-heavy blocks</strong>: MLP (feed-forward) layers.</li>\n      <li><strong>Embedding layers</strong>: Often quantized with special handling to preserve lookup efficiency.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Special Considerations</strong>:</p>\n\n    <ul>\n      <li>LayerNorm and Softmax are sensitive to quantization and often kept in <code class=\"language-plaintext highlighter-rouge\">float32</code>.</li>\n      <li>Attention scores may require FP16 or <code class=\"language-plaintext highlighter-rouge\">float32</code> to avoid instability.</li>\n      <li>Mixed-precision quantization (e.g., <code class=\"language-plaintext highlighter-rouge\">float8</code> weights with <code class=\"language-plaintext highlighter-rouge\">int8</code> activations) is sometimes used.</li>\n    </ul>\n  </li>\n</ul>\n<p>In transformer models like GPT or BERT, quantization is applied to:</p>\n<ul>\n      <li><strong>Linear layers</strong>: Including query, key, value, and output projections in attention layers.</li>\n      <li><strong>GEMM-heavy blocks</strong>: MLP (feed-forward) layers.</li>\n      <li><strong>Embedding layers</strong>: Often quantized with special handling to preserve lookup efficiency.</li>\n    </ul>\n<p><strong>Special Considerations</strong>:</p>\n<ul>\n      <li>LayerNorm and Softmax are sensitive to quantization and often kept in <code class=\"language-plaintext highlighter-rouge\">float32</code>.</li>\n      <li>Attention scores may require FP16 or <code class=\"language-plaintext highlighter-rouge\">float32</code> to avoid instability.</li>\n      <li>Mixed-precision quantization (e.g., <code class=\"language-plaintext highlighter-rouge\">float8</code> weights with <code class=\"language-plaintext highlighter-rouge\">int8</code> activations) is sometimes used.</li>\n    </ul>\n<h4 id=\"tooling-and-frameworks\">Tooling and Frameworks</h4>\n<ul>\n  <li><strong>NVIDIA TensorRT / FasterTransformer</strong></li>\n  <li><strong>Intel Neural Compressor (INC)</strong></li>\n  <li><strong>PyTorch Quantization Toolkit</strong></li>\n  <li><strong>ONNX Runtime Quantization</strong></li>\n  <li>\n    <p><strong>BitsAndBytes (for 8-bit and 4-bit LLMs)</strong></p>\n  </li>\n  <li>These tools offer end-to-end pipelines for quantizing, validating, and deploying models.</li>\n</ul>\n<p><strong>BitsAndBytes (for 8-bit and 4-bit LLMs)</strong></p>",
    "contentMarkdown": "*   Model quantization is a technique used to reduce the precision of numerical values (typically weights and activations) in a neural network from high-precision formats like 32-bit floating point (`float32`) to lower-precision formats such as `int8`, `float8`, or even `int4`. This allows for faster inference, reduced memory usage, and lower power consumption, particularly on hardware that supports low-precision arithmetic.\n*   A detailed discourse on this topic is available in our [Model Compression](../model-compression) primer.\n\n#### Why Quantize?\n\n*   Quantization can lead to significant improvements in efficiency:\n    \n    *   **Reduced Memory Footprint**: An `int8` model consumes 75% less memory than its `float32` counterpart.\n    *   **Faster Arithmetic**: Lower-precision operations (like `int8` or `int4` matmuls) are natively supported and highly optimized on modern accelerators (e.g., NVIDIA Tensor Cores, Intel AVX-512 VNNI).\n    *   **Lower Latency**: With less data to move and faster compute kernels, quantized models offer reduced end-to-end inference time.\n\nQuantization can lead to significant improvements in efficiency:\n\n*   **Reduced Memory Footprint**: An `int8` model consumes 75% less memory than its `float32` counterpart.\n*   **Faster Arithmetic**: Lower-precision operations (like `int8` or `int4` matmuls) are natively supported and highly optimized on modern accelerators (e.g., NVIDIA Tensor Cores, Intel AVX-512 VNNI).\n*   **Lower Latency**: With less data to move and faster compute kernels, quantized models offer reduced end-to-end inference time.\n\n#### Types of Quantization\n\n##### Post-Training Quantization (PTQ)\n\n*   PTQ involves converting a pre-trained `float32` model to a lower-precision model without retraining. It works by calibrating the ranges of tensors using a small sample of data.\n    \n*   **Key steps in PTQ:**\n    \n    *   **Range Calibration**: Identify the min/max values of weights and activations from a calibration dataset.\n        \n    *   **Scale and Zero-Point Calculation**: For each quantized tensor, calculate:\n        \n        q\\=round(rs)+zq\\=round(rs)+z\n        \n        q = \\\\text{round}\\\\left(\\\\frac{r}{s}\\\\right) + z\n        *   where:\n            \n            *   rrr is the real-valued number\n            *   sss is the scale (i.e., step size)\n            *   zzz is the zero-point to preserve zero mapping in the quantized domain\n            *   qqq is the quantized value (e.g., 8-bit integer)\n*   **Weight and Activation Clipping**: Clip values to fit within the representable range of the target bit-width (e.g., \\[-128, 127\\] for signed `int8`).\n    \n\nPTQ involves converting a pre-trained `float32` model to a lower-precision model without retraining. It works by calibrating the ranges of tensors using a small sample of data.\n\n**Key steps in PTQ:**\n\n*   **Range Calibration**: Identify the min/max values of weights and activations from a calibration dataset.\n    \n*   **Scale and Zero-Point Calculation**: For each quantized tensor, calculate:\n    \n    q\\=round(rs)+zq\\=round(rs)+z\n    \n    q = \\\\text{round}\\\\left(\\\\frac{r}{s}\\\\right) + z\n    *   where:\n        \n        *   rrr is the real-valued number\n        *   sss is the scale (i.e., step size)\n        *   zzz is the zero-point to preserve zero mapping in the quantized domain\n        *   qqq is the quantized value (e.g., 8-bit integer)\n\n**Range Calibration**: Identify the min/max values of weights and activations from a calibration dataset.\n\n**Scale and Zero-Point Calculation**: For each quantized tensor, calculate:\n\n*   where:\n    \n    *   rrr is the real-valued number\n    *   sss is the scale (i.e., step size)\n    *   zzz is the zero-point to preserve zero mapping in the quantized domain\n    *   qqq is the quantized value (e.g., 8-bit integer)\n\nwhere:\n\n*   rrr is the real-valued number\n*   sss is the scale (i.e., step size)\n*   zzz is the zero-point to preserve zero mapping in the quantized domain\n*   qqq is the quantized value (e.g., 8-bit integer)\n\n**Weight and Activation Clipping**: Clip values to fit within the representable range of the target bit-width (e.g., \\[-128, 127\\] for signed `int8`).\n\n##### Quantization-Aware Training (QAT)\n\n*   QAT simulates quantization during training. Fake quantization layers are added to mimic low-precision computation while maintaining gradients in high precision.\n    \n*   **Advantages:**\n    \n    *   More accurate than PTQ for sensitive models (e.g., GPT, BERT).\n    *   Allows the model to adapt to quantization errors during fine-tuning.\n*   **Implementation Details:**\n    \n    *   Frameworks like PyTorch and TensorFlow include fake quantization modules (e.g., `torch.quantization.FakeQuantize`).\n    *   Quant-dequant pairs are inserted in the model graph to simulate the behavior of actual quantized operations.\n\nQAT simulates quantization during training. Fake quantization layers are added to mimic low-precision computation while maintaining gradients in high precision.\n\n**Advantages:**\n\n*   More accurate than PTQ for sensitive models (e.g., GPT, BERT).\n*   Allows the model to adapt to quantization errors during fine-tuning.\n\n**Implementation Details:**\n\n*   Frameworks like PyTorch and TensorFlow include fake quantization modules (e.g., `torch.quantization.FakeQuantize`).\n*   Quant-dequant pairs are inserted in the model graph to simulate the behavior of actual quantized operations.\n\n#### Static vs. Dynamic Quantization\n\n*   **Static Quantization**: Activations are quantized ahead of time using calibration. Requires representative input data and is more performant but less flexible.\n*   **Dynamic Quantization**: Weights are quantized ahead of time, but activations are quantized at runtime based on actual values. More flexible and easier to integrate but slightly slower.\n\n#### Quantization in Transformers\n\n*   In transformer models like GPT or BERT, quantization is applied to:\n    \n    *   **Linear layers**: Including query, key, value, and output projections in attention layers.\n    *   **GEMM-heavy blocks**: MLP (feed-forward) layers.\n    *   **Embedding layers**: Often quantized with special handling to preserve lookup efficiency.\n*   **Special Considerations**:\n    \n    *   LayerNorm and Softmax are sensitive to quantization and often kept in `float32`.\n    *   Attention scores may require FP16 or `float32` to avoid instability.\n    *   Mixed-precision quantization (e.g., `float8` weights with `int8` activations) is sometimes used.\n\nIn transformer models like GPT or BERT, quantization is applied to:\n\n*   **Linear layers**: Including query, key, value, and output projections in attention layers.\n*   **GEMM-heavy blocks**: MLP (feed-forward) layers.\n*   **Embedding layers**: Often quantized with special handling to preserve lookup efficiency.\n\n**Special Considerations**:\n\n*   LayerNorm and Softmax are sensitive to quantization and often kept in `float32`.\n*   Attention scores may require FP16 or `float32` to avoid instability.\n*   Mixed-precision quantization (e.g., `float8` weights with `int8` activations) is sometimes used.\n\n#### Tooling and Frameworks\n\n*   **NVIDIA TensorRT / FasterTransformer**\n*   **Intel Neural Compressor (INC)**\n*   **PyTorch Quantization Toolkit**\n*   **ONNX Runtime Quantization**\n*   **BitsAndBytes (for 8-bit and 4-bit LLMs)**\n    \n*   These tools offer end-to-end pipelines for quantizing, validating, and deploying models.\n\n**BitsAndBytes (for 8-bit and 4-bit LLMs)**",
    "contentLength": 37431,
    "wordCount": 989,
    "hasCode": true,
    "hasMath": true,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/model-acceleration/#model-quantization"
  },
  {
    "id": "ai-model-acceleration-operator-fusion-12",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Inference Optimizations",
    "title": "Operator Fusion",
    "order": 12,
    "orderInChapter": 4,
    "contentHtml": "<ul>\n  <li>\n    <p>Operator fusion is an inference optimization technique that combines multiple adjacent operations in a neural network computation graph into a single composite operation. This is done to reduce overhead from memory reads/writes, kernel launches, and inter-operation communication, especially on GPU- or TPU-based systems.</p>\n  </li>\n  <li>\n    <p>Fusion reduces latency and increases compute efficiency by keeping data in faster registers or shared memory, rather than flushing it out to slower global memory between every small operation.</p>\n  </li>\n</ul>\n<p>Operator fusion is an inference optimization technique that combines multiple adjacent operations in a neural network computation graph into a single composite operation. This is done to reduce overhead from memory reads/writes, kernel launches, and inter-operation communication, especially on GPU- or TPU-based systems.</p>\n<p>Fusion reduces latency and increases compute efficiency by keeping data in faster registers or shared memory, rather than flushing it out to slower global memory between every small operation.</p>\n<h4 id=\"motivation-1\">Motivation</h4>\n<ul>\n  <li>Modern deep learning workloads often involve many small operations executed sequentially—e.g., matrix multiplications followed by bias addition, normalization, and non-linear activations:</li>\n</ul>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-268-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>x</mi><mo stretchy=&quot;false&quot;>&amp;#x2192;</mo><mi>L</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>a</mi><mi>r</mi><mo stretchy=&quot;false&quot;>&amp;#x2192;</mo><mi>A</mi><mi>d</mi><mi>d</mi><mi>B</mi><mi>i</mi><mi>a</mi><mi>s</mi><mo stretchy=&quot;false&quot;>&amp;#x2192;</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy=&quot;false&quot;>&amp;#x2192;</mo><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2344\" style=\"width: 24.586em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 20.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1020.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2345\"><span class=\"mi\" id=\"MathJax-Span-2346\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2347\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">→</span><span class=\"mi\" id=\"MathJax-Span-2348\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2349\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-2350\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-2351\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-2352\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-2353\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2354\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">→</span><span class=\"mi\" id=\"MathJax-Span-2355\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">A</span><span class=\"mi\" id=\"MathJax-Span-2356\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2357\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2358\" style=\"font-family: STIXGeneral-Italic;\">B</span><span class=\"mi\" id=\"MathJax-Span-2359\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-2360\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-2361\" style=\"font-family: STIXGeneral-Italic;\">s</span><span class=\"mo\" id=\"MathJax-Span-2362\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">→</span><span class=\"mi\" id=\"MathJax-Span-2363\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2364\" style=\"font-family: STIXGeneral-Italic;\">a</span><span class=\"mi\" id=\"MathJax-Span-2365\" style=\"font-family: STIXGeneral-Italic;\">y</span><span class=\"mi\" id=\"MathJax-Span-2366\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-2367\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2368\" style=\"font-family: STIXGeneral-Italic;\">N<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2369\" style=\"font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-2370\" style=\"font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2371\" style=\"font-family: STIXGeneral-Italic;\">m</span><span class=\"mo\" id=\"MathJax-Span-2372\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">→</span><span class=\"mi\" id=\"MathJax-Span-2373\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">R</span><span class=\"mi\" id=\"MathJax-Span-2374\" style=\"font-family: STIXGeneral-Italic;\">e</span><span class=\"mi\" id=\"MathJax-Span-2375\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-2376\" style=\"font-family: STIXGeneral-Italic;\">U<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>x</mi><mo stretchy=\"false\">→</mo><mi>L</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">→</mo><mi>A</mi><mi>d</mi><mi>d</mi><mi>B</mi><mi>i</mi><mi>a</mi><mi>s</mi><mo stretchy=\"false\">→</mo><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy=\"false\">→</mo><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi></math></span></span></div>\n<ul>\n  <li>\n    <p>Each of these operations might otherwise be implemented as a separate kernel. This leads to:</p>\n\n    <ul>\n      <li>Increased kernel launch overhead.</li>\n      <li>Inefficient use of GPU parallelism.</li>\n      <li>Repeated memory access and latency.</li>\n      <li>Limited optimization opportunities for compilers.</li>\n    </ul>\n  </li>\n  <li>\n    <p>By fusing them, the computation becomes more compact, minimizing overhead and maximizing performance.</p>\n  </li>\n</ul>\n<p>Each of these operations might otherwise be implemented as a separate kernel. This leads to:</p>\n<ul>\n      <li>Increased kernel launch overhead.</li>\n      <li>Inefficient use of GPU parallelism.</li>\n      <li>Repeated memory access and latency.</li>\n      <li>Limited optimization opportunities for compilers.</li>\n    </ul>\n<p>By fusing them, the computation becomes more compact, minimizing overhead and maximizing performance.</p>\n<h4 id=\"common-fusion-patterns\">Common Fusion Patterns</h4>\n<ul>\n  <li>\n    <p>Some of the most commonly fused sequences in transformer inference include:</p>\n\n    <ul>\n      <li>\n        <p><strong>GEMM + Bias Add + Activation</strong></p>\n\n        <ul>\n          <li>Example: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-269-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>Y</mi><mo>=</mo><mtext>ReLU</mtext><mo stretchy=&quot;false&quot;>(</mo><mi>X</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>@</mo></mrow><mi>W</mi><mo>+</mo><mi>b</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2377\" style=\"width: 11.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 9.378em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1009.33em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2378\"><span class=\"mi\" id=\"MathJax-Span-2379\" style=\"font-family: STIXGeneral-Italic;\">Y<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2380\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-2381\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">ReLU</span><span class=\"mo\" id=\"MathJax-Span-2382\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2383\" style=\"font-family: STIXGeneral-Italic;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"texatom\" id=\"MathJax-Span-2384\"><span class=\"mrow\" id=\"MathJax-Span-2385\"><span class=\"mo\" id=\"MathJax-Span-2386\" style=\"font-family: STIXGeneral-Regular;\">@</span></span></span><span class=\"mi\" id=\"MathJax-Span-2387\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2388\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-2389\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">b</span><span class=\"mo\" id=\"MathJax-Span-2390\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Y</mi><mo>=</mo><mtext>ReLU</mtext><mo stretchy=\"false\">(</mo><mi>X</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo>@</mo></mrow><mi>W</mi><mo>+</mo><mi>b</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-269\">Y = \\text{ReLU}(X @ W + b)</script></li>\n          <li>Typically fused in MLP layers.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Residual Add + LayerNorm + Dropout</strong></p>\n\n        <ul>\n          <li>Used in transformer blocks.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Query/Key/Value Linear Projections</strong></p>\n\n        <ul>\n          <li>Three <code class=\"language-plaintext highlighter-rouge\">Linear</code> ops fused into a single matmul followed by splitting heads.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Softmax + Masking</strong></p>\n\n        <ul>\n          <li>In attention, softmax is often fused with masking logic to avoid branch divergence on GPUs.</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>Some of the most commonly fused sequences in transformer inference include:</p>\n<ul>\n      <li>\n        <p><strong>GEMM + Bias Add + Activation</strong></p>\n\n        <ul>\n          <li>Example: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-269-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>Y</mi><mo>=</mo><mtext>ReLU</mtext><mo stretchy=&quot;false&quot;>(</mo><mi>X</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>@</mo></mrow><mi>W</mi><mo>+</mo><mi>b</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2377\" style=\"width: 11.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 9.378em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1009.33em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2378\"><span class=\"mi\" id=\"MathJax-Span-2379\" style=\"font-family: STIXGeneral-Italic;\">Y<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2380\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-2381\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">ReLU</span><span class=\"mo\" id=\"MathJax-Span-2382\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2383\" style=\"font-family: STIXGeneral-Italic;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"texatom\" id=\"MathJax-Span-2384\"><span class=\"mrow\" id=\"MathJax-Span-2385\"><span class=\"mo\" id=\"MathJax-Span-2386\" style=\"font-family: STIXGeneral-Regular;\">@</span></span></span><span class=\"mi\" id=\"MathJax-Span-2387\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2388\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-2389\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">b</span><span class=\"mo\" id=\"MathJax-Span-2390\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Y</mi><mo>=</mo><mtext>ReLU</mtext><mo stretchy=\"false\">(</mo><mi>X</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo>@</mo></mrow><mi>W</mi><mo>+</mo><mi>b</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-269\">Y = \\text{ReLU}(X @ W + b)</script></li>\n          <li>Typically fused in MLP layers.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Residual Add + LayerNorm + Dropout</strong></p>\n\n        <ul>\n          <li>Used in transformer blocks.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Query/Key/Value Linear Projections</strong></p>\n\n        <ul>\n          <li>Three <code class=\"language-plaintext highlighter-rouge\">Linear</code> ops fused into a single matmul followed by splitting heads.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Softmax + Masking</strong></p>\n\n        <ul>\n          <li>In attention, softmax is often fused with masking logic to avoid branch divergence on GPUs.</li>\n        </ul>\n      </li>\n    </ul>\n<p><strong>GEMM + Bias Add + Activation</strong></p>\n<ul>\n          <li>Example: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-269-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>Y</mi><mo>=</mo><mtext>ReLU</mtext><mo stretchy=&quot;false&quot;>(</mo><mi>X</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>@</mo></mrow><mi>W</mi><mo>+</mo><mi>b</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2377\" style=\"width: 11.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 9.378em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1009.33em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2378\"><span class=\"mi\" id=\"MathJax-Span-2379\" style=\"font-family: STIXGeneral-Italic;\">Y<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2380\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-2381\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">ReLU</span><span class=\"mo\" id=\"MathJax-Span-2382\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2383\" style=\"font-family: STIXGeneral-Italic;\">X<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"texatom\" id=\"MathJax-Span-2384\"><span class=\"mrow\" id=\"MathJax-Span-2385\"><span class=\"mo\" id=\"MathJax-Span-2386\" style=\"font-family: STIXGeneral-Regular;\">@</span></span></span><span class=\"mi\" id=\"MathJax-Span-2387\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2388\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-2389\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">b</span><span class=\"mo\" id=\"MathJax-Span-2390\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Y</mi><mo>=</mo><mtext>ReLU</mtext><mo stretchy=\"false\">(</mo><mi>X</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo>@</mo></mrow><mi>W</mi><mo>+</mo><mi>b</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-269\">Y = \\text{ReLU}(X @ W + b)</script></li>\n          <li>Typically fused in MLP layers.</li>\n        </ul>\n<p><strong>Residual Add + LayerNorm + Dropout</strong></p>\n<ul>\n          <li>Used in transformer blocks.</li>\n        </ul>\n<p><strong>Query/Key/Value Linear Projections</strong></p>\n<ul>\n          <li>Three <code class=\"language-plaintext highlighter-rouge\">Linear</code> ops fused into a single matmul followed by splitting heads.</li>\n        </ul>\n<p><strong>Softmax + Masking</strong></p>\n<ul>\n          <li>In attention, softmax is often fused with masking logic to avoid branch divergence on GPUs.</li>\n        </ul>\n<h4 id=\"fusion-in-transformers\">Fusion in Transformers</h4>\n<ul>\n  <li>\n    <p>In transformer architectures, operator fusion is especially valuable in:</p>\n\n    <ul>\n      <li>\n        <p><strong>Multi-Head Attention Blocks</strong>:</p>\n\n        <ul>\n          <li>Combine Q/K/V projections and reshape + transpose logic into a single kernel.</li>\n          <li>Fuse attention score computation, masking, and softmax into one efficient operation.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Feed-Forward Networks (FFNs)</strong>:</p>\n\n        <ul>\n          <li>Fuse two linear layers with intermediate activation (e.g., GELU or ReLU).</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>In transformer architectures, operator fusion is especially valuable in:</p>\n<ul>\n      <li>\n        <p><strong>Multi-Head Attention Blocks</strong>:</p>\n\n        <ul>\n          <li>Combine Q/K/V projections and reshape + transpose logic into a single kernel.</li>\n          <li>Fuse attention score computation, masking, and softmax into one efficient operation.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Feed-Forward Networks (FFNs)</strong>:</p>\n\n        <ul>\n          <li>Fuse two linear layers with intermediate activation (e.g., GELU or ReLU).</li>\n        </ul>\n      </li>\n    </ul>\n<p><strong>Multi-Head Attention Blocks</strong>:</p>\n<ul>\n          <li>Combine Q/K/V projections and reshape + transpose logic into a single kernel.</li>\n          <li>Fuse attention score computation, masking, and softmax into one efficient operation.</li>\n        </ul>\n<p><strong>Feed-Forward Networks (FFNs)</strong>:</p>\n<ul>\n          <li>Fuse two linear layers with intermediate activation (e.g., GELU or ReLU).</li>\n        </ul>\n<h4 id=\"implementation-details-1\">Implementation Details</h4>\n<ul>\n  <li>Fusion can be implemented in several ways:</li>\n</ul>\n<h5 id=\"graph-level-fusion-ahead-of-time\">Graph-Level Fusion (Ahead-of-Time)</h5>\n<ul>\n  <li>\n    <p>High-level compilers like XLA (for TensorFlow) or TorchScript (for PyTorch) can analyze the computational graph and fuse operations during compilation.</p>\n  </li>\n  <li>\n    <p>Example in PyTorch:</p>\n  </li>\n</ul>\n<p>High-level compilers like XLA (for TensorFlow) or TorchScript (for PyTorch) can analyze the computational graph and fuse operations during compilation.</p>\n<p>Example in PyTorch:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code5\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code5\"><span class=\"o\">@</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">jit</span><span class=\"p\">.</span><span class=\"n\">script</span>\n<span class=\"k\">def</span> <span class=\"nf\">fused_layer</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w1</span><span class=\"p\">,</span> <span class=\"n\">b1</span><span class=\"p\">,</span> <span class=\"n\">w2</span><span class=\"p\">,</span> <span class=\"n\">b2</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">linear</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w1</span><span class=\"p\">,</span> <span class=\"n\">b1</span><span class=\"p\">))</span> <span class=\"o\">@</span> <span class=\"n\">w2</span><span class=\"p\">.</span><span class=\"n\">T</span> <span class=\"o\">+</span> <span class=\"n\">b2</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code5\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code5\"><span class=\"o\">@</span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">jit</span><span class=\"p\">.</span><span class=\"n\">script</span>\n<span class=\"k\">def</span> <span class=\"nf\">fused_layer</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w1</span><span class=\"p\">,</span> <span class=\"n\">b1</span><span class=\"p\">,</span> <span class=\"n\">w2</span><span class=\"p\">,</span> <span class=\"n\">b2</span><span class=\"p\">):</span>\n    <span class=\"k\">return</span> <span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">relu</span><span class=\"p\">(</span><span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">linear</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">w1</span><span class=\"p\">,</span> <span class=\"n\">b1</span><span class=\"p\">))</span> <span class=\"o\">@</span> <span class=\"n\">w2</span><span class=\"p\">.</span><span class=\"n\">T</span> <span class=\"o\">+</span> <span class=\"n\">b2</span>\n</code></pre>\n<ul>\n  <li>TorchScript may fuse <code class=\"language-plaintext highlighter-rouge\">linear + relu</code> into a single kernel.</li>\n</ul>\n<h5 id=\"kernel-level-fusion-runtime\">Kernel-Level Fusion (Runtime)</h5>\n<ul>\n  <li>\n    <p>Frameworks like NVIDIA’s TensorRT and FasterTransformer include hand-written CUDA kernels that combine multiple operations (e.g., QKV projection + transpose + scale + matmul) in one pass.</p>\n  </li>\n  <li>\n    <p>Example: A fused transformer kernel might compute:</p>\n  </li>\n</ul>\n<p>Frameworks like NVIDIA’s TensorRT and FasterTransformer include hand-written CUDA kernels that combine multiple operations (e.g., QKV projection + transpose + scale + matmul) in one pass.</p>\n<p>Example: A fused transformer kernel might compute:</p>\n<div class=\"language-cpp highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code6\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code6\"><span class=\"n\">qkv</span> <span class=\"o\">=</span> <span class=\"n\">fused_linear_bias_act</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">);</span>  <span class=\"c1\">// one call</span>\n<span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">v</span> <span class=\"o\">=</span> <span class=\"n\">split_heads</span><span class=\"p\">(</span><span class=\"n\">qkv</span><span class=\"p\">);</span>      <span class=\"c1\">// internal fused transpose and reshape</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code6\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code6\"><span class=\"n\">qkv</span> <span class=\"o\">=</span> <span class=\"n\">fused_linear_bias_act</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">);</span>  <span class=\"c1\">// one call</span>\n<span class=\"n\">q</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">,</span> <span class=\"n\">v</span> <span class=\"o\">=</span> <span class=\"n\">split_heads</span><span class=\"p\">(</span><span class=\"n\">qkv</span><span class=\"p\">);</span>      <span class=\"c1\">// internal fused transpose and reshape</span>\n</code></pre>\n<ul>\n  <li>This reduces global memory traffic and utilizes registers/shared memory for intermediate results.</li>\n</ul>\n<h5 id=\"3-custom-kernel-generation\">3. Custom Kernel Generation</h5>\n<ul>\n  <li>\n    <p>Libraries like TVM or Triton enable defining custom fused kernels in a hardware-optimized DSL. These can be compiled just-in-time for maximum throughput.</p>\n  </li>\n  <li>\n    <p>Example in Triton:</p>\n  </li>\n</ul>\n<p>Libraries like TVM or Triton enable defining custom fused kernels in a hardware-optimized DSL. These can be compiled just-in-time for maximum throughput.</p>\n<p>Example in Triton:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code7\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code7\"><span class=\"o\">@</span><span class=\"n\">triton</span><span class=\"p\">.</span><span class=\"n\">jit</span>\n<span class=\"k\">def</span> <span class=\"nf\">fused_gemm_relu</span><span class=\"p\">(...):</span>\n    <span class=\"c1\"># Define fused matmul + bias + relu logic using GPU thread blocks\n</span></code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code7\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code7\"><span class=\"o\">@</span><span class=\"n\">triton</span><span class=\"p\">.</span><span class=\"n\">jit</span>\n<span class=\"k\">def</span> <span class=\"nf\">fused_gemm_relu</span><span class=\"p\">(...):</span>\n    <span class=\"c1\"># Define fused matmul + bias + relu logic using GPU thread blocks\n</span></code></pre>\n<h4 id=\"performance-impact\">Performance Impact</h4>\n<p>Operator fusion can lead to:</p>\n<ul>\n  <li><strong>30–50% improvement in latency</strong> for attention blocks.</li>\n  <li><strong>Higher hardware utilization</strong>, especially on GPUs with tensor cores or vectorized ALUs.</li>\n  <li><strong>Reduced memory bandwidth pressure</strong>, which is often the bottleneck in LLM inference.</li>\n</ul>\n<h4 id=\"tooling-and-ecosystem\">Tooling and Ecosystem</h4>\n<ul>\n  <li><strong>TensorRT</strong>: Extensive fusion for transformer blocks.</li>\n  <li><strong>FasterTransformer</strong>: Fused QKV and FFN kernels.</li>\n  <li><strong>ONNX Runtime with Graph Optimizer</strong>: Automatic fusion passes.</li>\n  <li><strong>TorchScript + FBGEMM</strong>: Fusion of linear + activation ops.</li>\n  <li><strong>TVM / Triton</strong>: Customizable and tunable fusion kernels.</li>\n</ul>",
    "contentMarkdown": "*   Operator fusion is an inference optimization technique that combines multiple adjacent operations in a neural network computation graph into a single composite operation. This is done to reduce overhead from memory reads/writes, kernel launches, and inter-operation communication, especially on GPU- or TPU-based systems.\n    \n*   Fusion reduces latency and increases compute efficiency by keeping data in faster registers or shared memory, rather than flushing it out to slower global memory between every small operation.\n    \n\nOperator fusion is an inference optimization technique that combines multiple adjacent operations in a neural network computation graph into a single composite operation. This is done to reduce overhead from memory reads/writes, kernel launches, and inter-operation communication, especially on GPU- or TPU-based systems.\n\nFusion reduces latency and increases compute efficiency by keeping data in faster registers or shared memory, rather than flushing it out to slower global memory between every small operation.\n\n#### Motivation\n\n*   Modern deep learning workloads often involve many small operations executed sequentially—e.g., matrix multiplications followed by bias addition, normalization, and non-linear activations:\n\nx→Linear→AddBias→LayerNorm→ReLUx→Linear→AddBias→LayerNorm→ReLU\n\n*   Each of these operations might otherwise be implemented as a separate kernel. This leads to:\n    \n    *   Increased kernel launch overhead.\n    *   Inefficient use of GPU parallelism.\n    *   Repeated memory access and latency.\n    *   Limited optimization opportunities for compilers.\n*   By fusing them, the computation becomes more compact, minimizing overhead and maximizing performance.\n    \n\nEach of these operations might otherwise be implemented as a separate kernel. This leads to:\n\n*   Increased kernel launch overhead.\n*   Inefficient use of GPU parallelism.\n*   Repeated memory access and latency.\n*   Limited optimization opportunities for compilers.\n\nBy fusing them, the computation becomes more compact, minimizing overhead and maximizing performance.\n\n#### Common Fusion Patterns\n\n*   Some of the most commonly fused sequences in transformer inference include:\n    \n    *   **GEMM + Bias Add + Activation**\n        \n        *   Example: Y\\=ReLU(X@W+b)Y\\=ReLU(X@W+b)Y = \\\\text{ReLU}(X @ W + b)\n        *   Typically fused in MLP layers.\n    *   **Residual Add + LayerNorm + Dropout**\n        \n        *   Used in transformer blocks.\n    *   **Query/Key/Value Linear Projections**\n        \n        *   Three `Linear` ops fused into a single matmul followed by splitting heads.\n    *   **Softmax + Masking**\n        \n        *   In attention, softmax is often fused with masking logic to avoid branch divergence on GPUs.\n\nSome of the most commonly fused sequences in transformer inference include:\n\n*   **GEMM + Bias Add + Activation**\n    \n    *   Example: Y\\=ReLU(X@W+b)Y\\=ReLU(X@W+b)Y = \\\\text{ReLU}(X @ W + b)\n    *   Typically fused in MLP layers.\n*   **Residual Add + LayerNorm + Dropout**\n    \n    *   Used in transformer blocks.\n*   **Query/Key/Value Linear Projections**\n    \n    *   Three `Linear` ops fused into a single matmul followed by splitting heads.\n*   **Softmax + Masking**\n    \n    *   In attention, softmax is often fused with masking logic to avoid branch divergence on GPUs.\n\n**GEMM + Bias Add + Activation**\n\n*   Example: Y\\=ReLU(X@W+b)Y\\=ReLU(X@W+b)Y = \\\\text{ReLU}(X @ W + b)\n*   Typically fused in MLP layers.\n\n**Residual Add + LayerNorm + Dropout**\n\n*   Used in transformer blocks.\n\n**Query/Key/Value Linear Projections**\n\n*   Three `Linear` ops fused into a single matmul followed by splitting heads.\n\n**Softmax + Masking**\n\n*   In attention, softmax is often fused with masking logic to avoid branch divergence on GPUs.\n\n#### Fusion in Transformers\n\n*   In transformer architectures, operator fusion is especially valuable in:\n    \n    *   **Multi-Head Attention Blocks**:\n        \n        *   Combine Q/K/V projections and reshape + transpose logic into a single kernel.\n        *   Fuse attention score computation, masking, and softmax into one efficient operation.\n    *   **Feed-Forward Networks (FFNs)**:\n        \n        *   Fuse two linear layers with intermediate activation (e.g., GELU or ReLU).\n\nIn transformer architectures, operator fusion is especially valuable in:\n\n*   **Multi-Head Attention Blocks**:\n    \n    *   Combine Q/K/V projections and reshape + transpose logic into a single kernel.\n    *   Fuse attention score computation, masking, and softmax into one efficient operation.\n*   **Feed-Forward Networks (FFNs)**:\n    \n    *   Fuse two linear layers with intermediate activation (e.g., GELU or ReLU).\n\n**Multi-Head Attention Blocks**:\n\n*   Combine Q/K/V projections and reshape + transpose logic into a single kernel.\n*   Fuse attention score computation, masking, and softmax into one efficient operation.\n\n**Feed-Forward Networks (FFNs)**:\n\n*   Fuse two linear layers with intermediate activation (e.g., GELU or ReLU).\n\n#### Implementation Details\n\n*   Fusion can be implemented in several ways:\n\n##### Graph-Level Fusion (Ahead-of-Time)\n\n*   High-level compilers like XLA (for TensorFlow) or TorchScript (for PyTorch) can analyze the computational graph and fuse operations during compilation.\n    \n*   Example in PyTorch:\n    \n\nHigh-level compilers like XLA (for TensorFlow) or TorchScript (for PyTorch) can analyze the computational graph and fuse operations during compilation.\n\nExample in PyTorch:\n\n![](https://aman.ai/images/copy.png)\n\n`@torch.jit.script def fused_layer(x, w1, b1, w2, b2):     return F.relu(F.linear(x, w1, b1)) @ w2.T + b2`\n\n![](https://aman.ai/images/copy.png)\n\n`@torch.jit.script def fused_layer(x, w1, b1, w2, b2):     return F.relu(F.linear(x, w1, b1)) @ w2.T + b2`\n\n*   TorchScript may fuse `linear + relu` into a single kernel.\n\n##### Kernel-Level Fusion (Runtime)\n\n*   Frameworks like NVIDIA’s TensorRT and FasterTransformer include hand-written CUDA kernels that combine multiple operations (e.g., QKV projection + transpose + scale + matmul) in one pass.\n    \n*   Example: A fused transformer kernel might compute:\n    \n\nFrameworks like NVIDIA’s TensorRT and FasterTransformer include hand-written CUDA kernels that combine multiple operations (e.g., QKV projection + transpose + scale + matmul) in one pass.\n\nExample: A fused transformer kernel might compute:\n\n![](https://aman.ai/images/copy.png)\n\n`qkv = fused_linear_bias_act(x);  // one call q, k, v = split_heads(qkv);      // internal fused transpose and reshape`\n\n![](https://aman.ai/images/copy.png)\n\n`qkv = fused_linear_bias_act(x);  // one call q, k, v = split_heads(qkv);      // internal fused transpose and reshape`\n\n*   This reduces global memory traffic and utilizes registers/shared memory for intermediate results.\n\n##### 3\\. Custom Kernel Generation\n\n*   Libraries like TVM or Triton enable defining custom fused kernels in a hardware-optimized DSL. These can be compiled just-in-time for maximum throughput.\n    \n*   Example in Triton:\n    \n\nLibraries like TVM or Triton enable defining custom fused kernels in a hardware-optimized DSL. These can be compiled just-in-time for maximum throughput.\n\nExample in Triton:\n\n![](https://aman.ai/images/copy.png)\n\n`@triton.jit def fused_gemm_relu(...):     # Define fused matmul + bias + relu logic using GPU thread blocks`\n\n![](https://aman.ai/images/copy.png)\n\n`@triton.jit def fused_gemm_relu(...):     # Define fused matmul + bias + relu logic using GPU thread blocks`\n\n#### Performance Impact\n\nOperator fusion can lead to:\n\n*   **30–50% improvement in latency** for attention blocks.\n*   **Higher hardware utilization**, especially on GPUs with tensor cores or vectorized ALUs.\n*   **Reduced memory bandwidth pressure**, which is often the bottleneck in LLM inference.\n\n#### Tooling and Ecosystem\n\n*   **TensorRT**: Extensive fusion for transformer blocks.\n*   **FasterTransformer**: Fused QKV and FFN kernels.\n*   **ONNX Runtime with Graph Optimizer**: Automatic fusion passes.\n*   **TorchScript + FBGEMM**: Fusion of linear + activation ops.\n*   **TVM / Triton**: Customizable and tunable fusion kernels.",
    "contentLength": 29710,
    "wordCount": 1073,
    "hasCode": true,
    "hasMath": true,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/model-acceleration/#operator-fusion"
  },
  {
    "id": "ai-model-acceleration-speculative-decoding-13",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Inference Optimizations",
    "title": "Speculative Decoding",
    "order": 13,
    "orderInChapter": 5,
    "contentHtml": "<ul>\n  <li>\n    <p>Speculative decoding is an inference-time optimization technique designed to reduce the latency of autoregressive sequence generation in large language models (LLMs). Instead of generating one token at a time using the full, expensive model, speculative decoding uses a smaller, faster “draft” model to guess multiple tokens in parallel, then validates these guesses with the full “target” model. If the guesses are correct, they are accepted as part of the output. Otherwise, they are partially or fully discarded and recomputed.</p>\n  </li>\n  <li>\n    <p>This method maintains the output quality of the original model while significantly improving throughput.</p>\n  </li>\n</ul>\n<p>Speculative decoding is an inference-time optimization technique designed to reduce the latency of autoregressive sequence generation in large language models (LLMs). Instead of generating one token at a time using the full, expensive model, speculative decoding uses a smaller, faster “draft” model to guess multiple tokens in parallel, then validates these guesses with the full “target” model. If the guesses are correct, they are accepted as part of the output. Otherwise, they are partially or fully discarded and recomputed.</p>\n<p>This method maintains the output quality of the original model while significantly improving throughput.</p>\n<h4 id=\"motivation-2\">Motivation</h4>\n<ul>\n  <li>\n    <p>Autoregressive decoding is inherently sequential. In a naive setup, the model generates one token, then feeds it back as input to generate the next. This sequential loop introduces latency and becomes a bottleneck during long-form generation.</p>\n  </li>\n  <li>\n    <p>Let:</p>\n\n    <ul>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-270-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2391\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2392\"><span class=\"mi\" id=\"MathJax-Span-2393\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-270\">f</script> be the full model (large, accurate but slow)</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-271-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2394\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2395\"><span class=\"mi\" id=\"MathJax-Span-2396\" style=\"font-family: STIXGeneral-Italic;\">g</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-271\">g</script> be the draft model (smaller, less accurate but fast)</li>\n    </ul>\n  </li>\n  <li>\n    <p>Naively, generation requires <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-272-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2397\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2398\"><span class=\"mi\" id=\"MathJax-Span-2399\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-272\">T</script> forward passes of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-273-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2400\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2401\"><span class=\"mi\" id=\"MathJax-Span-2402\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-273\">f</script> for a sequence of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-274-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2403\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2404\"><span class=\"mi\" id=\"MathJax-Span-2405\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-274\">T</script> tokens. Speculative decoding aims to reduce the number of times <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-275-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2406\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2407\"><span class=\"mi\" id=\"MathJax-Span-2408\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-275\">f</script> is called.</p>\n  </li>\n</ul>\n<p>Autoregressive decoding is inherently sequential. In a naive setup, the model generates one token, then feeds it back as input to generate the next. This sequential loop introduces latency and becomes a bottleneck during long-form generation.</p>\n<p>Let:</p>\n<ul>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-270-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2391\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2392\"><span class=\"mi\" id=\"MathJax-Span-2393\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-270\">f</script> be the full model (large, accurate but slow)</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-271-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2394\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2395\"><span class=\"mi\" id=\"MathJax-Span-2396\" style=\"font-family: STIXGeneral-Italic;\">g</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-271\">g</script> be the draft model (smaller, less accurate but fast)</li>\n    </ul>\n<p>Naively, generation requires <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-272-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2397\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2398\"><span class=\"mi\" id=\"MathJax-Span-2399\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-272\">T</script> forward passes of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-273-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2400\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2401\"><span class=\"mi\" id=\"MathJax-Span-2402\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-273\">f</script> for a sequence of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-274-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2403\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2404\"><span class=\"mi\" id=\"MathJax-Span-2405\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-274\">T</script> tokens. Speculative decoding aims to reduce the number of times <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-275-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2406\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2407\"><span class=\"mi\" id=\"MathJax-Span-2408\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-275\">f</script> is called.</p>\n<h4 id=\"basic-algorithm\">Basic Algorithm</h4>\n<ol>\n  <li><strong>Initialize Context</strong>: Use a prompt or previous tokens <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-276-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>x</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2409\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2410\"><span class=\"mi\" id=\"MathJax-Span-2411\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>x</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-276\">x</script>.</li>\n  <li>\n    <p><strong>Draft Generation</strong>: Use the draft model <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-277-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2412\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2413\"><span class=\"mi\" id=\"MathJax-Span-2414\" style=\"font-family: STIXGeneral-Italic;\">g</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-277\">g</script> to generate a sequence of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-278-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2415\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2416\"><span class=\"mi\" id=\"MathJax-Span-2417\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-278\">k</script> speculative tokens:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-279-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>y</mi><mi>k</mi></msub><mo>=</mo><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2418\" style=\"width: 9.898em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.232em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1008.18em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2419\"><span class=\"msubsup\" id=\"MathJax-Span-2420\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2421\" style=\"font-family: STIXGeneral-Italic;\">y</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-2422\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2423\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-2424\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2425\" style=\"font-family: STIXGeneral-Italic;\">y</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-2426\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2427\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-2428\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">.</span><span class=\"mo\" id=\"MathJax-Span-2429\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">.</span><span class=\"mo\" id=\"MathJax-Span-2430\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">.</span><span class=\"mo\" id=\"MathJax-Span-2431\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-2432\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2433\" style=\"font-family: STIXGeneral-Italic;\">y</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-2434\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2435\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-2436\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">g</span><span class=\"mo\" id=\"MathJax-Span-2437\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2438\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2439\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>y</mi><mi>k</mi></msub><mo>=</mo><mi>g</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-279\">y_1, y_2, ..., y_k = g(x)</script>\n  </li>\n  <li><strong>Validation</strong>: Use the full model <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-280-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2440\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2441\"><span class=\"mi\" id=\"MathJax-Span-2442\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-280\">f</script> to compute the log-probabilities <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-281-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>p</mi><mi>f</mi></msub><mo stretchy=&quot;false&quot;>(</mo><msub><mi>y</mi><mi>t</mi></msub><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>&amp;#x2016;</mo><mi>x</mi><mo>,</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>&amp;#x2212;</mo><mn>1</mn></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2443\" style=\"width: 10.159em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.44em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1008.39em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2444\"><span class=\"msubsup\" id=\"MathJax-Span-2445\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2446\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-2447\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.107em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2448\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2449\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2450\" style=\"font-family: STIXGeneral-Italic;\">y</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-2451\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2452\" style=\"font-family: STIXGeneral-Regular;\">‖</span><span class=\"mi\" id=\"MathJax-Span-2453\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2454\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-2455\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2456\" style=\"font-family: STIXGeneral-Italic;\">y</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-2457\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2458\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-2459\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">.</span><span class=\"mo\" id=\"MathJax-Span-2460\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">.</span><span class=\"mo\" id=\"MathJax-Span-2461\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">.</span><span class=\"mo\" id=\"MathJax-Span-2462\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-2463\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2464\" style=\"font-family: STIXGeneral-Italic;\">y</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-2465\"><span class=\"mrow\" id=\"MathJax-Span-2466\"><span class=\"mi\" id=\"MathJax-Span-2467\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-2468\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-2469\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2470\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>p</mi><mi>f</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mi>t</mi></msub><mo fence=\"false\" stretchy=\"false\">‖</mo><mi>x</mi><mo>,</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>y</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-281\">p_f(y_t \\| x, y_1, ..., y_{n-1})</script>.</li>\n  <li>\n    <p><strong>Accept or Reject Tokens</strong>:</p>\n\n    <ul>\n      <li>Accept as many tokens as <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-282-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2471\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2472\"><span class=\"mi\" id=\"MathJax-Span-2473\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-282\">f</script> agrees with (within a confidence threshold or by matching top-1 outputs).</li>\n      <li>Rewind to the last agreed-upon token and resume with the draft model from there.</li>\n    </ul>\n  </li>\n</ol>\n<p><strong>Draft Generation</strong>: Use the draft model <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-277-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2412\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2413\"><span class=\"mi\" id=\"MathJax-Span-2414\" style=\"font-family: STIXGeneral-Italic;\">g</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-277\">g</script> to generate a sequence of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-278-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2415\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2416\"><span class=\"mi\" id=\"MathJax-Span-2417\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-278\">k</script> speculative tokens:</p>\n<p><strong>Accept or Reject Tokens</strong>:</p>\n<ul>\n      <li>Accept as many tokens as <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-282-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2471\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2472\"><span class=\"mi\" id=\"MathJax-Span-2473\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-282\">f</script> agrees with (within a confidence threshold or by matching top-1 outputs).</li>\n      <li>Rewind to the last agreed-upon token and resume with the draft model from there.</li>\n    </ul>\n<h4 id=\"pseudocode\">Pseudocode</h4>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code8\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code8\"><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">initial_prompt</span>\n<span class=\"k\">while</span> <span class=\"ow\">not</span> <span class=\"n\">done</span><span class=\"p\">:</span>\n    <span class=\"n\">draft_tokens</span> <span class=\"o\">=</span> <span class=\"n\">g</span><span class=\"p\">.</span><span class=\"n\">generate_next_k</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n    <span class=\"n\">probs_f</span> <span class=\"o\">=</span> <span class=\"n\">f</span><span class=\"p\">.</span><span class=\"n\">get_probs</span><span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">draft_tokens</span><span class=\"p\">)</span>\n    <span class=\"n\">accepted_prefix</span> <span class=\"o\">=</span> <span class=\"n\">match</span><span class=\"p\">(</span><span class=\"n\">draft_tokens</span><span class=\"p\">,</span> <span class=\"n\">probs_f</span><span class=\"p\">)</span>\n    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">accepted_prefix</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code8\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code8\"><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">initial_prompt</span>\n<span class=\"k\">while</span> <span class=\"ow\">not</span> <span class=\"n\">done</span><span class=\"p\">:</span>\n    <span class=\"n\">draft_tokens</span> <span class=\"o\">=</span> <span class=\"n\">g</span><span class=\"p\">.</span><span class=\"n\">generate_next_k</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n    <span class=\"n\">probs_f</span> <span class=\"o\">=</span> <span class=\"n\">f</span><span class=\"p\">.</span><span class=\"n\">get_probs</span><span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">draft_tokens</span><span class=\"p\">)</span>\n    <span class=\"n\">accepted_prefix</span> <span class=\"o\">=</span> <span class=\"n\">match</span><span class=\"p\">(</span><span class=\"n\">draft_tokens</span><span class=\"p\">,</span> <span class=\"n\">probs_f</span><span class=\"p\">)</span>\n    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">accepted_prefix</span>\n</code></pre>\n<h4 id=\"key-parameters\">Key Parameters</h4>\n<ul>\n  <li><strong>Draft Model Quality</strong>: Must be fast enough to justify speculative overhead but good enough to match the full model reasonably often.</li>\n  <li><strong>Block Size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-283-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2474\" style=\"width: 0.622em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.519em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.52em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2475\"><span class=\"mi\" id=\"MathJax-Span-2476\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-283\">k</script></strong>: Number of speculative tokens generated per iteration. Larger blocks = fewer full model calls, but higher risk of rejection.</li>\n  <li><strong>Matching Strategy</strong>: Usually uses top-1 match or a log-prob threshold.</li>\n</ul>\n<h4 id=\"mathematical-view\">Mathematical View</h4>\n<ul>\n  <li>Let the probability of accepting each token be <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-284-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B1;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2477\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2478\"><span class=\"mi\" id=\"MathJax-Span-2479\" style=\"font-family: STIXGeneral-Italic;\">α</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>α</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-284\">\\alpha</script>. Then the expected number of full-model calls is:</li>\n</ul>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-285-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>E</mi></mrow><mo stretchy=&quot;false&quot;>[</mo><mtext>full passes</mtext><mo stretchy=&quot;false&quot;>]</mo><mo>&amp;#x2248;</mo><mfrac><mi>T</mi><mrow><mi>k</mi><mo>&amp;#x22C5;</mo><mi>&amp;#x03B1;</mi></mrow></mfrac></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2480\" style=\"width: 10.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.805em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(0.836em, 1008.8em, 3.18em, -999.997em); top: -2.341em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2481\"><span class=\"texatom\" id=\"MathJax-Span-2482\"><span class=\"mrow\" id=\"MathJax-Span-2483\"><span class=\"mi\" id=\"MathJax-Span-2484\" style=\"font-family: STIXGeneral-Regular;\">𝔼</span></span></span><span class=\"mo\" id=\"MathJax-Span-2485\" style=\"font-family: STIXGeneral-Regular;\">[</span><span class=\"mtext\" id=\"MathJax-Span-2486\" style=\"font-family: STIXGeneral-Regular;\">full passes</span><span class=\"mo\" id=\"MathJax-Span-2487\" style=\"font-family: STIXGeneral-Regular;\">]</span><span class=\"mo\" id=\"MathJax-Span-2488\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≈</span><span class=\"mfrac\" id=\"MathJax-Span-2489\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.93em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.31em;\"><span class=\"mi\" id=\"MathJax-Span-2490\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.18em, 1001.83em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.935em;\"><span class=\"mrow\" id=\"MathJax-Span-2491\"><span class=\"mi\" id=\"MathJax-Span-2492\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2493\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-2494\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">α</span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1001.93em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.93em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.346em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.872em; border-left: 0px solid; width: 0px; height: 2.566em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">E</mi></mrow><mo stretchy=\"false\">[</mo><mtext>full passes</mtext><mo stretchy=\"false\">]</mo><mo>≈</mo><mfrac><mi>T</mi><mrow><mi>k</mi><mo>⋅</mo><mi>α</mi></mrow></mfrac></math></span></span></div>\n<ul>\n  <li>If <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-286-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B1;</mi><mo>&amp;#x2248;</mo><mn>0.7</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2495\" style=\"width: 3.648em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.023em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.97em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2496\"><span class=\"mi\" id=\"MathJax-Span-2497\" style=\"font-family: STIXGeneral-Italic;\">α</span><span class=\"mo\" id=\"MathJax-Span-2498\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≈</span><span class=\"mn\" id=\"MathJax-Span-2499\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">0.7</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>α</mi><mo>≈</mo><mn>0.7</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-286\">\\alpha \\approx 0.7</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-287-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi><mo>=</mo><mn>4</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2500\" style=\"width: 2.659em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.19em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.14em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2501\"><span class=\"mi\" id=\"MathJax-Span-2502\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2503\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-2504\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">4</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi><mo>=</mo><mn>4</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-287\">k = 4</script>, we reduce full-model calls by nearly 3<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-288-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2505\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2506\"><span class=\"mo\" id=\"MathJax-Span-2507\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-288\">\\times</script>.</li>\n</ul>\n<h4 id=\"implementation-details-2\">Implementation Details</h4>\n<ul>\n  <li><strong>Parallel Calls</strong>: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-289-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2508\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2509\"><span class=\"mi\" id=\"MathJax-Span-2510\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-289\">f</script> can validate all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-290-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2511\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2512\"><span class=\"mi\" id=\"MathJax-Span-2513\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-290\">k</script> tokens in one forward pass by using cached KV states and batched logits.</li>\n  <li><strong>KV Cache Management</strong>: Efficient speculative decoding updates the cache only after validation.</li>\n  <li><strong>Multimodel Serving</strong>: Systems like NVIDIA’s FasterTransformer or Hugging Face’s <code class=\"language-plaintext highlighter-rouge\">transformers</code> can host both <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-291-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2514\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2515\"><span class=\"mi\" id=\"MathJax-Span-2516\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-291\">f</script> and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-292-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2517\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2518\"><span class=\"mi\" id=\"MathJax-Span-2519\" style=\"font-family: STIXGeneral-Italic;\">g</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-292\">g</script> concurrently with shared memory or GPU residency.</li>\n</ul>\n<h4 id=\"notable-variants\">Notable Variants</h4>\n<ul>\n  <li><strong>Medusa</strong> (Meta): Uses a tree-structured decoder to validate multiple candidates at once.</li>\n  <li><strong>FastRAG</strong>: Combines speculative decoding with retrieval-based models.</li>\n  <li><strong>Draft &amp; Verify</strong> (Google): A formalized framework for plug-and-play speculative decoding with checkpointing.</li>\n</ul>\n<h4 id=\"benefits\">Benefits</h4>\n<ul>\n  <li><strong>Latency Reduction</strong>: 2<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-293-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2520\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2521\"><span class=\"mo\" id=\"MathJax-Span-2522\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-293\">\\times</script>–4<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-294-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2523\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2524\"><span class=\"mo\" id=\"MathJax-Span-2525\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-294\">\\times</script> speedup in decoding for long sequences.</li>\n  <li><strong>Full-Model Accuracy</strong>: Final output matches the output of the full model <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-295-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2526\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2527\"><span class=\"mi\" id=\"MathJax-Span-2528\" style=\"font-family: STIXGeneral-Italic;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>f</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-295\">f</script>, so there’s no accuracy loss.</li>\n  <li><strong>Compatibility</strong>: Can be layered on top of existing decoding strategies (e.g., greedy, top-k, nucleus).</li>\n</ul>\n<h4 id=\"limitations\">Limitations</h4>\n<ul>\n  <li>Requires additional memory and compute for the draft model.</li>\n  <li>Effectiveness depends on alignment between the draft and full model distributions.</li>\n  <li>Complex cache management and integration overhead.</li>\n</ul>",
    "contentMarkdown": "*   Speculative decoding is an inference-time optimization technique designed to reduce the latency of autoregressive sequence generation in large language models (LLMs). Instead of generating one token at a time using the full, expensive model, speculative decoding uses a smaller, faster “draft” model to guess multiple tokens in parallel, then validates these guesses with the full “target” model. If the guesses are correct, they are accepted as part of the output. Otherwise, they are partially or fully discarded and recomputed.\n    \n*   This method maintains the output quality of the original model while significantly improving throughput.\n    \n\nSpeculative decoding is an inference-time optimization technique designed to reduce the latency of autoregressive sequence generation in large language models (LLMs). Instead of generating one token at a time using the full, expensive model, speculative decoding uses a smaller, faster “draft” model to guess multiple tokens in parallel, then validates these guesses with the full “target” model. If the guesses are correct, they are accepted as part of the output. Otherwise, they are partially or fully discarded and recomputed.\n\nThis method maintains the output quality of the original model while significantly improving throughput.\n\n#### Motivation\n\n*   Autoregressive decoding is inherently sequential. In a naive setup, the model generates one token, then feeds it back as input to generate the next. This sequential loop introduces latency and becomes a bottleneck during long-form generation.\n    \n*   Let:\n    \n    *   fff be the full model (large, accurate but slow)\n    *   ggg be the draft model (smaller, less accurate but fast)\n*   Naively, generation requires TTT forward passes of fff for a sequence of TTT tokens. Speculative decoding aims to reduce the number of times fff is called.\n    \n\nAutoregressive decoding is inherently sequential. In a naive setup, the model generates one token, then feeds it back as input to generate the next. This sequential loop introduces latency and becomes a bottleneck during long-form generation.\n\nLet:\n\n*   fff be the full model (large, accurate but slow)\n*   ggg be the draft model (smaller, less accurate but fast)\n\nNaively, generation requires TTT forward passes of fff for a sequence of TTT tokens. Speculative decoding aims to reduce the number of times fff is called.\n\n#### Basic Algorithm\n\n1.  **Initialize Context**: Use a prompt or previous tokens xxx.\n2.  **Draft Generation**: Use the draft model ggg to generate a sequence of kkk speculative tokens:\n    \n    y1,y2,...,yk\\=g(x)y1,y2,...,yk\\=g(x)\n    \n    y\\_1, y\\_2, ..., y\\_k = g(x)\n3.  **Validation**: Use the full model fff to compute the log-probabilities pf(yt‖x,y1,...,yn−1)pf(yt‖x,y1,...,yn−1)p\\_f(y\\_t \\\\| x, y\\_1, ..., y\\_{n-1}).\n4.  **Accept or Reject Tokens**:\n    \n    *   Accept as many tokens as fff agrees with (within a confidence threshold or by matching top-1 outputs).\n    *   Rewind to the last agreed-upon token and resume with the draft model from there.\n\n**Draft Generation**: Use the draft model ggg to generate a sequence of kkk speculative tokens:\n\n**Accept or Reject Tokens**:\n\n*   Accept as many tokens as fff agrees with (within a confidence threshold or by matching top-1 outputs).\n*   Rewind to the last agreed-upon token and resume with the draft model from there.\n\n#### Pseudocode\n\n![](https://aman.ai/images/copy.png)\n\n`x = initial_prompt while not done:     draft_tokens = g.generate_next_k(x)     probs_f = f.get_probs(x + draft_tokens)     accepted_prefix = match(draft_tokens, probs_f)     x = x + accepted_prefix`\n\n![](https://aman.ai/images/copy.png)\n\n`x = initial_prompt while not done:     draft_tokens = g.generate_next_k(x)     probs_f = f.get_probs(x + draft_tokens)     accepted_prefix = match(draft_tokens, probs_f)     x = x + accepted_prefix`\n\n#### Key Parameters\n\n*   **Draft Model Quality**: Must be fast enough to justify speculative overhead but good enough to match the full model reasonably often.\n*   **Block Size kkk**: Number of speculative tokens generated per iteration. Larger blocks = fewer full model calls, but higher risk of rejection.\n*   **Matching Strategy**: Usually uses top-1 match or a log-prob threshold.\n\n#### Mathematical View\n\n*   Let the probability of accepting each token be αα\\\\alpha. Then the expected number of full-model calls is:\n\n𝔼\\[full passes\\]≈Tk⋅αE\\[full passes\\]≈Tk⋅α\n\n*   If α≈0.7α≈0.7\\\\alpha \\\\approx 0.7 and k\\=4k\\=4k = 4, we reduce full-model calls by nearly 3××\\\\times.\n\n#### Implementation Details\n\n*   **Parallel Calls**: fff can validate all kkk tokens in one forward pass by using cached KV states and batched logits.\n*   **KV Cache Management**: Efficient speculative decoding updates the cache only after validation.\n*   **Multimodel Serving**: Systems like NVIDIA’s FasterTransformer or Hugging Face’s `transformers` can host both fff and ggg concurrently with shared memory or GPU residency.\n\n#### Notable Variants\n\n*   **Medusa** (Meta): Uses a tree-structured decoder to validate multiple candidates at once.\n*   **FastRAG**: Combines speculative decoding with retrieval-based models.\n*   **Draft & Verify** (Google): A formalized framework for plug-and-play speculative decoding with checkpointing.\n\n#### Benefits\n\n*   **Latency Reduction**: 2××\\\\times–4××\\\\times speedup in decoding for long sequences.\n*   **Full-Model Accuracy**: Final output matches the output of the full model fff, so there’s no accuracy loss.\n*   **Compatibility**: Can be layered on top of existing decoding strategies (e.g., greedy, top-k, nucleus).\n\n#### Limitations\n\n*   Requires additional memory and compute for the draft model.\n*   Effectiveness depends on alignment between the draft and full model distributions.\n*   Complex cache management and integration overhead.",
    "contentLength": 64611,
    "wordCount": 828,
    "hasCode": true,
    "hasMath": true,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/model-acceleration/#speculative-decoding"
  },
  {
    "id": "ai-model-acceleration-flashattention-and-efficient-attention-kernels-14",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Inference Optimizations",
    "title": "FlashAttention and Efficient Attention Kernels",
    "order": 14,
    "orderInChapter": 6,
    "contentHtml": "<ul>\n  <li>In transformer models, self-attention is a core operation that enables the model to learn relationships between tokens. However, traditional attention implementations scale poorly with sequence length due to quadratic memory and compute complexity. <strong>FlashAttention</strong> and other efficient attention kernels address these bottlenecks by optimizing the attention computation to reduce memory overhead and improve performance.</li>\n</ul>\n<h4 id=\"motivation-3\">Motivation</h4>\n<ul>\n  <li>\n    <p>The standard attention computation involves the following operations for a sequence of length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-296-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2529\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2530\"><span class=\"mi\" id=\"MathJax-Span-2531\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-296\">L</script> and hidden dimension <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-297-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2532\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2533\"><span class=\"mi\" id=\"MathJax-Span-2534\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-297\">d</script>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-298-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>Attention</mtext><mo stretchy=&quot;false&quot;>(</mo><mi>Q</mi><mo>,</mo><mi>K</mi><mo>,</mo><mi>V</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo>(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo>)</mo></mrow><mi>V</mi></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2535\" style=\"width: 20.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(2.451em, 1017.14em, 5.263em, -999.997em); top: -4.112em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2536\"><span class=\"mtext\" id=\"MathJax-Span-2537\" style=\"font-family: STIXGeneral-Regular;\">Attention</span><span class=\"mo\" id=\"MathJax-Span-2538\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2539\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span class=\"mo\" id=\"MathJax-Span-2540\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-2541\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2542\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-2543\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2544\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-2545\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-2546\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">softmax</span><span class=\"mrow\" id=\"MathJax-Span-2547\" style=\"padding-left: 0.211em;\"><span class=\"mo\" id=\"MathJax-Span-2548\" style=\"vertical-align: -0.57em;\"><span style=\"font-family: STIXSizeThreeSym;\">(</span></span><span class=\"mfrac\" id=\"MathJax-Span-2549\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.023em, 1002.03em, 4.326em, -999.997em); top: -4.685em; left: 50%; margin-left: -1.039em;\"><span class=\"mrow\" id=\"MathJax-Span-2550\"><span class=\"mi\" id=\"MathJax-Span-2551\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span class=\"msubsup\" id=\"MathJax-Span-2552\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2553\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.784em;\"><span class=\"mi\" id=\"MathJax-Span-2554\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.023em, 1001.3em, 4.326em, -999.997em); top: -3.227em; left: 50%; margin-left: -0.622em;\"><span class=\"msqrt\" id=\"MathJax-Span-2555\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0.732em;\"><span class=\"mrow\" id=\"MathJax-Span-2556\"><span class=\"mi\" id=\"MathJax-Span-2557\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.023em, 1000.58em, 3.388em, -999.997em); top: -4.008em; left: 0.732em;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px;\"><span style=\"position: absolute; font-family: STIXGeneral-Regular; top: -4.008em; left: 0em;\">‾<span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; font-family: STIXGeneral-Regular; top: -4.008em; left: 0.055em;\">‾<span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(2.919em, 1000.78em, 4.169em, -999.997em); top: -3.904em; left: 0em;\"><span style=\"font-family: STIXVariants;\">√</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1002.14em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.138em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2558\" style=\"vertical-align: -0.57em;\"><span style=\"font-family: STIXSizeThreeSym;\">)</span></span></span><span class=\"mi\" id=\"MathJax-Span-2559\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.117em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -1.247em; border-left: 0px solid; width: 0px; height: 3.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><mo>,</mo><mi>K</mi><mo>,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo>(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo>)</mo></mrow><mi>V</mi></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-298\">\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d}}\\right) V</script>\n  </li>\n  <li>\n    <p>This requires:</p>\n\n    <ul>\n      <li>Computing a full <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-299-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi><mo>&amp;#x00D7;</mo><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2560\" style=\"width: 2.763em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.29em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2561\"><span class=\"mi\" id=\"MathJax-Span-2562\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2563\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-2564\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mo>×</mo><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-299\">L \\times L</script> attention matrix (expensive for long sequences).</li>\n      <li>Storing intermediate results like logits and softmax scores in global memory.</li>\n      <li>Limited reuse of on-chip memory (registers, shared memory), resulting in bandwidth-bound performance.</li>\n    </ul>\n  </li>\n  <li>\n    <p>FlashAttention addresses these inefficiencies by restructuring the attention algorithm to use memory-efficient block-wise computation.</p>\n  </li>\n</ul>\n<p>The standard attention computation involves the following operations for a sequence of length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-296-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2529\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2530\"><span class=\"mi\" id=\"MathJax-Span-2531\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-296\">L</script> and hidden dimension <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-297-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2532\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2533\"><span class=\"mi\" id=\"MathJax-Span-2534\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-297\">d</script>:</p>\n<p>This requires:</p>\n<ul>\n      <li>Computing a full <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-299-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi><mo>&amp;#x00D7;</mo><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2560\" style=\"width: 2.763em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.29em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2561\"><span class=\"mi\" id=\"MathJax-Span-2562\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2563\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-2564\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mo>×</mo><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-299\">L \\times L</script> attention matrix (expensive for long sequences).</li>\n      <li>Storing intermediate results like logits and softmax scores in global memory.</li>\n      <li>Limited reuse of on-chip memory (registers, shared memory), resulting in bandwidth-bound performance.</li>\n    </ul>\n<p>FlashAttention addresses these inefficiencies by restructuring the attention algorithm to use memory-efficient block-wise computation.</p>\n<h4 id=\"flashattention-key-concepts\">FlashAttention: Key Concepts</h4>\n<ul>\n  <li>\n    <p>Originally proposed in Dao et al., 2022 in <a href=\"https://arxiv.org/abs/2205.14135\">FlashAttention: Fast and Memory‑Efficient Exact Attention with IO‑Awareness</a>, FlashAttention is a fused, tiled implementation of scaled dot-product attention that:</p>\n\n    <ul>\n      <li>\n        <p><strong>Eliminates materialization of the full attention matrix</strong>: Avoids creating and storing the entire <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-300-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi><mo>&amp;#x00D7;</mo><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2565\" style=\"width: 2.763em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.29em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2566\"><span class=\"mi\" id=\"MathJax-Span-2567\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2568\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-2569\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mo>×</mo><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-300\">L \\times L</script> attention score matrix in GPU memory. Instead, computes small blocks of logits on-chip, applies masking and softmax immediately, and discards them, drastically reducing memory usage for long sequences.</p>\n      </li>\n      <li>\n        <p><strong>Uses tiling to partition queries, keys, and values into small blocks that fit in GPU shared memory</strong>: Splits <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-301-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>Q</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2570\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2571\"><span class=\"mi\" id=\"MathJax-Span-2572\" style=\"font-family: STIXGeneral-Italic;\">Q</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Q</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-301\">Q</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-302-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2573\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2574\"><span class=\"mi\" id=\"MathJax-Span-2575\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-302\">K</script>, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-303-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2576\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2577\"><span class=\"mi\" id=\"MathJax-Span-2578\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-303\">V</script> into manageable tiles (e.g., <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-304-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>64</mn><mo>&amp;#x00D7;</mo><mn>64</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2579\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2580\"><span class=\"mn\" id=\"MathJax-Span-2581\" style=\"font-family: STIXGeneral-Regular;\">64</span><span class=\"mo\" id=\"MathJax-Span-2582\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-2583\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">64</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>64</mn><mo>×</mo><mn>64</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-304\">64 \\times 64</script>) that can be loaded into fast on-chip shared memory or registers. This improves memory locality, reduces global memory reads/writes, and allows the GPU to reuse loaded data for multiple computations within the block.</p>\n      </li>\n      <li>\n        <p><strong>Fuses softmax, scaling, masking, and matmul into a single kernel</strong>: Combines these operations into one GPU kernel to avoid storing intermediate results in memory. By performing scaling, masking, softmax computation, and the weighted sum with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-305-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2584\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2585\"><span class=\"mi\" id=\"MathJax-Span-2586\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-305\">V</script> in a single pass, FlashAttention reduces memory bandwidth usage and improves computational efficiency.</p>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>Originally proposed in Dao et al., 2022 in <a href=\"https://arxiv.org/abs/2205.14135\">FlashAttention: Fast and Memory‑Efficient Exact Attention with IO‑Awareness</a>, FlashAttention is a fused, tiled implementation of scaled dot-product attention that:</p>\n<ul>\n      <li>\n        <p><strong>Eliminates materialization of the full attention matrix</strong>: Avoids creating and storing the entire <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-300-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi><mo>&amp;#x00D7;</mo><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2565\" style=\"width: 2.763em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.29em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2566\"><span class=\"mi\" id=\"MathJax-Span-2567\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2568\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-2569\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mo>×</mo><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-300\">L \\times L</script> attention score matrix in GPU memory. Instead, computes small blocks of logits on-chip, applies masking and softmax immediately, and discards them, drastically reducing memory usage for long sequences.</p>\n      </li>\n      <li>\n        <p><strong>Uses tiling to partition queries, keys, and values into small blocks that fit in GPU shared memory</strong>: Splits <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-301-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>Q</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2570\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2571\"><span class=\"mi\" id=\"MathJax-Span-2572\" style=\"font-family: STIXGeneral-Italic;\">Q</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Q</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-301\">Q</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-302-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2573\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2574\"><span class=\"mi\" id=\"MathJax-Span-2575\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-302\">K</script>, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-303-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2576\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2577\"><span class=\"mi\" id=\"MathJax-Span-2578\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-303\">V</script> into manageable tiles (e.g., <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-304-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>64</mn><mo>&amp;#x00D7;</mo><mn>64</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2579\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2580\"><span class=\"mn\" id=\"MathJax-Span-2581\" style=\"font-family: STIXGeneral-Regular;\">64</span><span class=\"mo\" id=\"MathJax-Span-2582\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-2583\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">64</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>64</mn><mo>×</mo><mn>64</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-304\">64 \\times 64</script>) that can be loaded into fast on-chip shared memory or registers. This improves memory locality, reduces global memory reads/writes, and allows the GPU to reuse loaded data for multiple computations within the block.</p>\n      </li>\n      <li>\n        <p><strong>Fuses softmax, scaling, masking, and matmul into a single kernel</strong>: Combines these operations into one GPU kernel to avoid storing intermediate results in memory. By performing scaling, masking, softmax computation, and the weighted sum with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-305-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2584\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2585\"><span class=\"mi\" id=\"MathJax-Span-2586\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-305\">V</script> in a single pass, FlashAttention reduces memory bandwidth usage and improves computational efficiency.</p>\n      </li>\n    </ul>\n<p><strong>Eliminates materialization of the full attention matrix</strong>: Avoids creating and storing the entire <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-300-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi><mo>&amp;#x00D7;</mo><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2565\" style=\"width: 2.763em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.29em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2566\"><span class=\"mi\" id=\"MathJax-Span-2567\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2568\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-2569\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mo>×</mo><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-300\">L \\times L</script> attention score matrix in GPU memory. Instead, computes small blocks of logits on-chip, applies masking and softmax immediately, and discards them, drastically reducing memory usage for long sequences.</p>\n<p><strong>Uses tiling to partition queries, keys, and values into small blocks that fit in GPU shared memory</strong>: Splits <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-301-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>Q</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2570\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2571\"><span class=\"mi\" id=\"MathJax-Span-2572\" style=\"font-family: STIXGeneral-Italic;\">Q</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>Q</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-301\">Q</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-302-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2573\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2574\"><span class=\"mi\" id=\"MathJax-Span-2575\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-302\">K</script>, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-303-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2576\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2577\"><span class=\"mi\" id=\"MathJax-Span-2578\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-303\">V</script> into manageable tiles (e.g., <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-304-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>64</mn><mo>&amp;#x00D7;</mo><mn>64</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2579\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2580\"><span class=\"mn\" id=\"MathJax-Span-2581\" style=\"font-family: STIXGeneral-Regular;\">64</span><span class=\"mo\" id=\"MathJax-Span-2582\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-2583\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">64</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>64</mn><mo>×</mo><mn>64</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-304\">64 \\times 64</script>) that can be loaded into fast on-chip shared memory or registers. This improves memory locality, reduces global memory reads/writes, and allows the GPU to reuse loaded data for multiple computations within the block.</p>\n<p><strong>Fuses softmax, scaling, masking, and matmul into a single kernel</strong>: Combines these operations into one GPU kernel to avoid storing intermediate results in memory. By performing scaling, masking, softmax computation, and the weighted sum with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-305-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>V</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2584\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2585\"><span class=\"mi\" id=\"MathJax-Span-2586\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>V</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-305\">V</script> in a single pass, FlashAttention reduces memory bandwidth usage and improves computational efficiency.</p>\n<h5 id=\"high-level-algorithm\">High-Level Algorithm</h5>\n<ol>\n  <li>Load a block of queries <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-306-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>Q</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2587\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2588\"><span class=\"msubsup\" id=\"MathJax-Span-2589\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2590\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-2591\"><span class=\"mrow\" id=\"MathJax-Span-2592\"><span class=\"mi\" id=\"MathJax-Span-2593\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>Q</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-306\">Q_{i}</script> and keys <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-307-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>j</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2594\" style=\"width: 1.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.94em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2595\"><span class=\"msubsup\" id=\"MathJax-Span-2596\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2597\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-2598\"><span class=\"mrow\" id=\"MathJax-Span-2599\"><span class=\"mi\" id=\"MathJax-Span-2600\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>j</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-307\">K_{j}</script> into shared memory.</li>\n  <li>Compute attention logits <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-308-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mfrac><mrow><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi>T</mi></msubsup></mrow><msqrt><mi>d</mi></msqrt></mfrac></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2601\" style=\"width: 2.398em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.982em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(0.68em, 1001.98em, 2.867em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2602\"><span class=\"mfrac\" id=\"MathJax-Span-2603\"><span style=\"display: inline-block; position: relative; width: 1.773em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.284em, 1001.67em, 4.482em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.831em;\"><span class=\"mrow\" id=\"MathJax-Span-2604\"><span class=\"msubsup\" id=\"MathJax-Span-2605\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.47em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2606\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-2607\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-2608\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2609\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.544em, 1000.37em, 4.169em, -999.997em); top: -4.268em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2610\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.544em, 1000.21em, 4.273em, -999.997em); top: -3.799em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-2611\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.284em, 1000.89em, 4.273em, -999.997em); top: -3.539em; left: 50%; margin-left: -0.466em;\"><span class=\"msqrt\" id=\"MathJax-Span-2612\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0.523em;\"><span class=\"mrow\" id=\"MathJax-Span-2613\"><span class=\"mi\" id=\"MathJax-Span-2614\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.94em, 1000.37em, 1.253em, -999.997em); top: -1.612em; left: 0.523em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.049em; border-top: 1.2px solid; width: 0.367em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -3.904em; left: 0em;\"><span><span style=\"font-size: 70.7%; font-family: STIXVariants;\">√</span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1001.77em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.773em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.747em; border-left: 0px solid; width: 0px; height: 2.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mfrac><mrow><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi>T</mi></msubsup></mrow><msqrt><mi>d</mi></msqrt></mfrac></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-308\">\\frac{Q_i K_j^T}{\\sqrt{d}}</script> for the block.</li>\n  <li>Apply mask and softmax <strong>in-place</strong>, updating the running sum of exponents and maximums for numerical stability.</li>\n  <li>Accumulate partial outputs <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-309-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>A</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi>T</mi></msubsup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>/</mo></mrow><msqrt><mi>d</mi></msqrt><mo stretchy=&quot;false&quot;>)</mo><msub><mi>V</mi><mi>j</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2615\" style=\"width: 13.336em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 11.096em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1011.1em, 2.815em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2616\"><span class=\"msubsup\" id=\"MathJax-Span-2617\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2618\" style=\"font-family: STIXGeneral-Italic;\">A</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-2619\"><span class=\"mrow\" id=\"MathJax-Span-2620\"><span class=\"mi\" id=\"MathJax-Span-2621\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mo\" id=\"MathJax-Span-2622\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-2623\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2624\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-2625\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">softmax</span><span class=\"mo\" id=\"MathJax-Span-2626\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2627\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2628\" style=\"font-family: STIXGeneral-Italic;\">Q</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-2629\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-2630\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2631\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.52em, 4.169em, -999.997em); top: -4.372em; left: 0.784em;\"><span class=\"mi\" id=\"MathJax-Span-2632\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.326em, -999.997em); top: -3.695em; left: 0.68em;\"><span class=\"mi\" id=\"MathJax-Span-2633\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"texatom\" id=\"MathJax-Span-2634\"><span class=\"mrow\" id=\"MathJax-Span-2635\"><span class=\"mo\" id=\"MathJax-Span-2636\" style=\"font-family: STIXGeneral-Regular;\">/</span></span></span><span class=\"msqrt\" id=\"MathJax-Span-2637\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0.732em;\"><span class=\"mrow\" id=\"MathJax-Span-2638\"><span class=\"mi\" id=\"MathJax-Span-2639\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.023em, 1000.58em, 3.388em, -999.997em); top: -4.008em; left: 0.732em;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px;\"><span style=\"position: absolute; font-family: STIXGeneral-Regular; top: -4.008em; left: 0em;\">‾<span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; font-family: STIXGeneral-Regular; top: -4.008em; left: 0.055em;\">‾<span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(2.919em, 1000.78em, 4.169em, -999.997em); top: -3.904em; left: 0em;\"><span style=\"font-family: STIXVariants;\">√</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2640\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"msubsup\" id=\"MathJax-Span-2641\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2642\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-2643\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.622em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>A</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy=\"false\">(</mo><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>j</mi><mi>T</mi></msubsup><mrow class=\"MJX-TeXAtom-ORD\"><mo>/</mo></mrow><msqrt><mi>d</mi></msqrt><mo stretchy=\"false\">)</mo><msub><mi>V</mi><mi>j</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-309\">A_{i,j} = \\text{softmax}(Q_i K_j^T / \\sqrt{d}) V_j</script> without storing intermediate attention matrices.</li>\n  <li>Repeat across blocks until the full result is computed.</li>\n</ol>\n<h5 id=\"numerical-stability\">Numerical Stability</h5>\n<ul>\n  <li>\n    <p>To avoid numerical overflow when computing softmax in a block-by-block fashion, FlashAttention keeps running statistics for each query row:</p>\n\n    <ul>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-310-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>m</mi><mi>i</mi></msub><mo>=</mo><munder><mo movablelimits=&quot;true&quot; form=&quot;prefix&quot;>max</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>j</mi></mrow></munder><msub><mi>z</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>j</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2644\" style=\"width: 6.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.211em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1005.21em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2645\"><span class=\"msubsup\" id=\"MathJax-Span-2646\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2647\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-2648\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2649\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"munderover\" id=\"MathJax-Span-2650\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.982em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1001.72em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-2651\" style=\"font-family: STIXGeneral-Regular;\">max</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 1.721em;\"><span class=\"texatom\" id=\"MathJax-Span-2652\"><span class=\"mrow\" id=\"MathJax-Span-2653\"><span class=\"mi\" id=\"MathJax-Span-2654\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-2655\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2656\" style=\"font-family: STIXGeneral-Italic;\">z</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-2657\"><span class=\"mrow\" id=\"MathJax-Span-2658\"><span class=\"mi\" id=\"MathJax-Span-2659\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-2660\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>m</mi><mi>i</mi></msub><mo>=</mo><munder><mo movablelimits=\"true\" form=\"prefix\">max</mo><mrow class=\"MJX-TeXAtom-ORD\"><mi>j</mi></mrow></munder><msub><mi>z</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>j</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-310\">m_i = \\max_{j} z_{ij}</script> — the maximum logit value seen so far for that row, used to shift logits and prevent large exponentials.</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-311-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mi>i</mi></msub><mo>=</mo><munder><mo>&amp;#x2211;</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>j</mi></mrow></munder><mi>exp</mi><mo>&amp;#x2061;</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>j</mi></mrow></msub><mo>&amp;#x2212;</mo><msub><mi>m</mi><mi>i</mi></msub></mrow><mo>)</mo></mrow></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2661\" style=\"width: 10.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.596em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.878em, 1008.44em, 3.544em, -999.997em); top: -2.914em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2662\"><span class=\"msubsup\" id=\"MathJax-Span-2663\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2664\" style=\"font-family: STIXGeneral-Italic;\">s</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-2665\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2666\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"munderover\" id=\"MathJax-Span-2667\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.076em, 1000.84em, 4.43em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-2668\" style=\"font-family: STIXGeneral-Regular; vertical-align: 0.003em;\">∑</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.695em; left: 0.94em;\"><span class=\"texatom\" id=\"MathJax-Span-2669\"><span class=\"mrow\" id=\"MathJax-Span-2670\"><span class=\"mi\" id=\"MathJax-Span-2671\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-2672\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">exp</span><span class=\"mo\" id=\"MathJax-Span-2673\"></span><span class=\"mrow\" id=\"MathJax-Span-2674\"><span class=\"mo\" id=\"MathJax-Span-2675\" style=\"vertical-align: -0.206em;\"><span style=\"font-family: STIXSizeOneSym;\">(</span></span><span class=\"mrow\" id=\"MathJax-Span-2676\"><span class=\"msubsup\" id=\"MathJax-Span-2677\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2678\" style=\"font-family: STIXGeneral-Italic;\">z</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-2679\"><span class=\"mrow\" id=\"MathJax-Span-2680\"><span class=\"mi\" id=\"MathJax-Span-2681\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-2682\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2683\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"msubsup\" id=\"MathJax-Span-2684\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2685\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-2686\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2687\" style=\"vertical-align: -0.206em;\"><span style=\"font-family: STIXSizeOneSym;\">)</span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.919em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.622em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>s</mi><mi>i</mi></msub><mo>=</mo><munder><mo>∑</mo><mrow class=\"MJX-TeXAtom-ORD\"><mi>j</mi></mrow></munder><mi>exp</mi><mo>⁡</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>m</mi><mi>i</mi></msub></mrow><mo>)</mo></mrow></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-311\">s_i = \\sum_{j} \\exp\\left(z_{ij} - m_i\\right)</script> — the running sum of the shifted exponentials, which forms the softmax denominator.</li>\n    </ul>\n  </li>\n  <li>\n    <p>As new blocks are processed, these values are updated using associative operations that merge current and previous block statistics without loss of precision. This ensures the final softmax is mathematically equivalent to computing it on the full <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-312-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi><mo>&amp;#x00D7;</mo><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2688\" style=\"width: 2.763em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.29em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2689\"><span class=\"mi\" id=\"MathJax-Span-2690\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2691\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-2692\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mo>×</mo><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-312\">L \\times L</script> matrix, but without ever storing that matrix.</p>\n  </li>\n</ul>\n<p>To avoid numerical overflow when computing softmax in a block-by-block fashion, FlashAttention keeps running statistics for each query row:</p>\n<ul>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-310-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>m</mi><mi>i</mi></msub><mo>=</mo><munder><mo movablelimits=&quot;true&quot; form=&quot;prefix&quot;>max</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>j</mi></mrow></munder><msub><mi>z</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>j</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2644\" style=\"width: 6.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.211em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1005.21em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2645\"><span class=\"msubsup\" id=\"MathJax-Span-2646\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2647\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-2648\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2649\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"munderover\" id=\"MathJax-Span-2650\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.982em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1001.72em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-2651\" style=\"font-family: STIXGeneral-Regular;\">max</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 1.721em;\"><span class=\"texatom\" id=\"MathJax-Span-2652\"><span class=\"mrow\" id=\"MathJax-Span-2653\"><span class=\"mi\" id=\"MathJax-Span-2654\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-2655\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2656\" style=\"font-family: STIXGeneral-Italic;\">z</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-2657\"><span class=\"mrow\" id=\"MathJax-Span-2658\"><span class=\"mi\" id=\"MathJax-Span-2659\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-2660\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>m</mi><mi>i</mi></msub><mo>=</mo><munder><mo movablelimits=\"true\" form=\"prefix\">max</mo><mrow class=\"MJX-TeXAtom-ORD\"><mi>j</mi></mrow></munder><msub><mi>z</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>j</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-310\">m_i = \\max_{j} z_{ij}</script> — the maximum logit value seen so far for that row, used to shift logits and prevent large exponentials.</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-311-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mi>i</mi></msub><mo>=</mo><munder><mo>&amp;#x2211;</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>j</mi></mrow></munder><mi>exp</mi><mo>&amp;#x2061;</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>j</mi></mrow></msub><mo>&amp;#x2212;</mo><msub><mi>m</mi><mi>i</mi></msub></mrow><mo>)</mo></mrow></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2661\" style=\"width: 10.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.596em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.878em, 1008.44em, 3.544em, -999.997em); top: -2.914em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2662\"><span class=\"msubsup\" id=\"MathJax-Span-2663\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2664\" style=\"font-family: STIXGeneral-Italic;\">s</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-2665\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2666\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"munderover\" id=\"MathJax-Span-2667\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.076em, 1000.84em, 4.43em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-2668\" style=\"font-family: STIXGeneral-Regular; vertical-align: 0.003em;\">∑</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.695em; left: 0.94em;\"><span class=\"texatom\" id=\"MathJax-Span-2669\"><span class=\"mrow\" id=\"MathJax-Span-2670\"><span class=\"mi\" id=\"MathJax-Span-2671\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-2672\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">exp</span><span class=\"mo\" id=\"MathJax-Span-2673\"></span><span class=\"mrow\" id=\"MathJax-Span-2674\"><span class=\"mo\" id=\"MathJax-Span-2675\" style=\"vertical-align: -0.206em;\"><span style=\"font-family: STIXSizeOneSym;\">(</span></span><span class=\"mrow\" id=\"MathJax-Span-2676\"><span class=\"msubsup\" id=\"MathJax-Span-2677\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2678\" style=\"font-family: STIXGeneral-Italic;\">z</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-2679\"><span class=\"mrow\" id=\"MathJax-Span-2680\"><span class=\"mi\" id=\"MathJax-Span-2681\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-2682\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2683\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"msubsup\" id=\"MathJax-Span-2684\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2685\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-2686\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2687\" style=\"vertical-align: -0.206em;\"><span style=\"font-family: STIXSizeOneSym;\">)</span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.919em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.622em; border-left: 0px solid; width: 0px; height: 1.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>s</mi><mi>i</mi></msub><mo>=</mo><munder><mo>∑</mo><mrow class=\"MJX-TeXAtom-ORD\"><mi>j</mi></mrow></munder><mi>exp</mi><mo>⁡</mo><mrow><mo>(</mo><mrow><msub><mi>z</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>m</mi><mi>i</mi></msub></mrow><mo>)</mo></mrow></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-311\">s_i = \\sum_{j} \\exp\\left(z_{ij} - m_i\\right)</script> — the running sum of the shifted exponentials, which forms the softmax denominator.</li>\n    </ul>\n<p>As new blocks are processed, these values are updated using associative operations that merge current and previous block statistics without loss of precision. This ensures the final softmax is mathematically equivalent to computing it on the full <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-312-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi><mo>&amp;#x00D7;</mo><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2688\" style=\"width: 2.763em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.29em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2689\"><span class=\"mi\" id=\"MathJax-Span-2690\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2691\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-2692\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mo>×</mo><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-312\">L \\times L</script> matrix, but without ever storing that matrix.</p>\n<h4 id=\"implementation-details-3\">Implementation Details</h4>\n<ul>\n  <li>Written as a custom CUDA kernel.</li>\n  <li>Uses <strong>shared memory</strong> to hold Q/K/V tiles and compute locally.</li>\n  <li>Optimized to run in <strong>mixed precision</strong> (e.g., FP16 or BF16) for speed and memory efficiency.</li>\n  <li>Compatible with dropout, masking, and rotary embeddings.</li>\n</ul>\n<h4 id=\"flashattention-2-improvements\">FlashAttention-2 Improvements</h4>\n<ul>\n  <li>Adds support for <strong>non-causal attention</strong>, <strong>variable-length sequences</strong>, and better <strong>warp-level parallelism</strong>.</li>\n  <li>Removes redundant memory loads through more aggressive caching and loop unrolling.</li>\n  <li>Enables <strong>backward pass efficiency</strong>, making it useful not only for inference but also for training.</li>\n</ul>\n<h4 id=\"other-efficient-kernels\">Other Efficient Kernels</h4>\n<ul>\n  <li><strong>xFormers</strong> (Meta): Modular attention implementations that support Flash, sparse, and memory-efficient variants.</li>\n  <li><strong>Triton-based Attention</strong>: Enables easy definition of fused attention kernels using Triton’s GPU DSL.</li>\n  <li><strong>PagedAttention (vLLM)</strong>: Optimizes KV cache access for batch inference, reducing memory fragmentation and improving latency.</li>\n</ul>\n<h4 id=\"performance-gains\">Performance Gains</h4>\n<ul>\n  <li>\n    <p>FlashAttention reduces attention memory complexity from:</p>\n\n    <ul>\n      <li><strong><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-313-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;>O</mi></mrow><mo stretchy=&quot;false&quot;>(</mo><msup><mi>L</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2693\" style=\"width: 2.947em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.43em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.191em, 1002.38em, 2.482em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2694\"><span class=\"texatom\" id=\"MathJax-Span-2695\"><span class=\"mrow\" id=\"MathJax-Span-2696\"><span class=\"mi\" id=\"MathJax-Span-2697\" style=\"font-family: STIXNonUnicode-Italic;\"></span></span></span><span class=\"mo\" id=\"MathJax-Span-2698\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2699\"><span style=\"display: inline-block; position: relative; width: 1.036em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.153em, 1000.57em, 4.135em, -999.997em); top: -3.975em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2700\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 3.98em;\"></span></span><span style=\"position: absolute; top: -4.336em; left: 0.622em;\"><span class=\"mn\" id=\"MathJax-Span-2701\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 3.98em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2702\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow class=\"MJX-TeXAtom-ORD\"><mi class=\"MJX-tex-caligraphic\" mathvariant=\"script\">O</mi></mrow><mo stretchy=\"false\">(</mo><msup><mi>L</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-313\">\\mathcal{O}(L^2)</script></strong> to <strong><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-314-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;>O</mi></mrow><mo stretchy=&quot;false&quot;>(</mo><mi>L</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2703\" style=\"width: 2.43em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.017em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1001.97em, 2.482em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2704\"><span class=\"texatom\" id=\"MathJax-Span-2705\"><span class=\"mrow\" id=\"MathJax-Span-2706\"><span class=\"mi\" id=\"MathJax-Span-2707\" style=\"font-family: STIXNonUnicode-Italic;\"></span></span></span><span class=\"mo\" id=\"MathJax-Span-2708\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2709\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2710\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow class=\"MJX-TeXAtom-ORD\"><mi class=\"MJX-tex-caligraphic\" mathvariant=\"script\">O</mi></mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-314\">\\mathcal{O}(L)</script></strong> for memory consumption.</li>\n      <li>Achieves <strong>1.7–2.7<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-315-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2711\" style=\"width: 0.726em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.571em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.501em, 1000.52em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2712\"><span class=\"mo\" id=\"MathJax-Span-2713\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-315\">\\times</script> speedup</strong> on A100 GPUs for long sequence lengths (&gt; 1k tokens).</li>\n      <li>Maintains exact attention output (within floating-point precision), unlike approximate methods.</li>\n    </ul>\n  </li>\n</ul>\n<p>FlashAttention reduces attention memory complexity from:</p>\n<ul>\n      <li><strong><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-313-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;>O</mi></mrow><mo stretchy=&quot;false&quot;>(</mo><msup><mi>L</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2693\" style=\"width: 2.947em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.43em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.191em, 1002.38em, 2.482em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2694\"><span class=\"texatom\" id=\"MathJax-Span-2695\"><span class=\"mrow\" id=\"MathJax-Span-2696\"><span class=\"mi\" id=\"MathJax-Span-2697\" style=\"font-family: STIXNonUnicode-Italic;\"></span></span></span><span class=\"mo\" id=\"MathJax-Span-2698\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2699\"><span style=\"display: inline-block; position: relative; width: 1.036em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.153em, 1000.57em, 4.135em, -999.997em); top: -3.975em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2700\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 3.98em;\"></span></span><span style=\"position: absolute; top: -4.336em; left: 0.622em;\"><span class=\"mn\" id=\"MathJax-Span-2701\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 3.98em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2702\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow class=\"MJX-TeXAtom-ORD\"><mi class=\"MJX-tex-caligraphic\" mathvariant=\"script\">O</mi></mrow><mo stretchy=\"false\">(</mo><msup><mi>L</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-313\">\\mathcal{O}(L^2)</script></strong> to <strong><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-314-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi class=&quot;MJX-tex-caligraphic&quot; mathvariant=&quot;script&quot;>O</mi></mrow><mo stretchy=&quot;false&quot;>(</mo><mi>L</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2703\" style=\"width: 2.43em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.017em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1001.97em, 2.482em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2704\"><span class=\"texatom\" id=\"MathJax-Span-2705\"><span class=\"mrow\" id=\"MathJax-Span-2706\"><span class=\"mi\" id=\"MathJax-Span-2707\" style=\"font-family: STIXNonUnicode-Italic;\"></span></span></span><span class=\"mo\" id=\"MathJax-Span-2708\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2709\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2710\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mrow class=\"MJX-TeXAtom-ORD\"><mi class=\"MJX-tex-caligraphic\" mathvariant=\"script\">O</mi></mrow><mo stretchy=\"false\">(</mo><mi>L</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-314\">\\mathcal{O}(L)</script></strong> for memory consumption.</li>\n      <li>Achieves <strong>1.7–2.7<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-315-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2711\" style=\"width: 0.726em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.571em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.501em, 1000.52em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2712\"><span class=\"mo\" id=\"MathJax-Span-2713\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-315\">\\times</script> speedup</strong> on A100 GPUs for long sequence lengths (&gt; 1k tokens).</li>\n      <li>Maintains exact attention output (within floating-point precision), unlike approximate methods.</li>\n    </ul>\n<h4 id=\"use-in-inference\">Use in Inference</h4>\n<ul>\n  <li>\n    <p>FlashAttention is especially beneficial for:</p>\n\n    <ul>\n      <li>Long-context models (e.g., 4k to 128k tokens).</li>\n      <li>Multi-head attention, where per-head memory use adds up quickly.</li>\n      <li>Deployment on GPUs with large shared memory (e.g., NVIDIA A100, H100).</li>\n    </ul>\n  </li>\n</ul>\n<p>FlashAttention is especially beneficial for:</p>\n<ul>\n      <li>Long-context models (e.g., 4k to 128k tokens).</li>\n      <li>Multi-head attention, where per-head memory use adds up quickly.</li>\n      <li>Deployment on GPUs with large shared memory (e.g., NVIDIA A100, H100).</li>\n    </ul>\n<h4 id=\"integration\">Integration</h4>\n<ul>\n  <li>\n    <p>Supported in:</p>\n\n    <ul>\n      <li><strong>Hugging Face Transformers</strong> via <code class=\"language-plaintext highlighter-rouge\">use_flash_attention_2=True</code></li>\n      <li><strong>PyTorch</strong> through custom CUDA extensions or Triton kernels</li>\n      <li><strong>DeepSpeed</strong>, <strong>FasterTransformer</strong>, and <strong>xFormers</strong></li>\n    </ul>\n  </li>\n</ul>\n<p>Supported in:</p>\n<ul>\n      <li><strong>Hugging Face Transformers</strong> via <code class=\"language-plaintext highlighter-rouge\">use_flash_attention_2=True</code></li>\n      <li><strong>PyTorch</strong> through custom CUDA extensions or Triton kernels</li>\n      <li><strong>DeepSpeed</strong>, <strong>FasterTransformer</strong>, and <strong>xFormers</strong></li>\n    </ul>",
    "contentMarkdown": "*   In transformer models, self-attention is a core operation that enables the model to learn relationships between tokens. However, traditional attention implementations scale poorly with sequence length due to quadratic memory and compute complexity. **FlashAttention** and other efficient attention kernels address these bottlenecks by optimizing the attention computation to reduce memory overhead and improve performance.\n\n#### Motivation\n\n*   The standard attention computation involves the following operations for a sequence of length LLL and hidden dimension ddd:\n    \n    Attention(Q,K,V)\\=softmax(QKTd‾‾√)VAttention(Q,K,V)\\=softmax(QKTd)V\n    \n    \\\\text{Attention}(Q, K, V) = \\\\text{softmax}\\\\left(\\\\frac{QK^T}{\\\\sqrt{d}}\\\\right) V\n*   This requires:\n    \n    *   Computing a full L×LL×LL \\\\times L attention matrix (expensive for long sequences).\n    *   Storing intermediate results like logits and softmax scores in global memory.\n    *   Limited reuse of on-chip memory (registers, shared memory), resulting in bandwidth-bound performance.\n*   FlashAttention addresses these inefficiencies by restructuring the attention algorithm to use memory-efficient block-wise computation.\n    \n\nThe standard attention computation involves the following operations for a sequence of length LLL and hidden dimension ddd:\n\nThis requires:\n\n*   Computing a full L×LL×LL \\\\times L attention matrix (expensive for long sequences).\n*   Storing intermediate results like logits and softmax scores in global memory.\n*   Limited reuse of on-chip memory (registers, shared memory), resulting in bandwidth-bound performance.\n\nFlashAttention addresses these inefficiencies by restructuring the attention algorithm to use memory-efficient block-wise computation.\n\n#### FlashAttention: Key Concepts\n\n*   Originally proposed in Dao et al., 2022 in [FlashAttention: Fast and Memory‑Efficient Exact Attention with IO‑Awareness](https://arxiv.org/abs/2205.14135), FlashAttention is a fused, tiled implementation of scaled dot-product attention that:\n    \n    *   **Eliminates materialization of the full attention matrix**: Avoids creating and storing the entire L×LL×LL \\\\times L attention score matrix in GPU memory. Instead, computes small blocks of logits on-chip, applies masking and softmax immediately, and discards them, drastically reducing memory usage for long sequences.\n        \n    *   **Uses tiling to partition queries, keys, and values into small blocks that fit in GPU shared memory**: Splits QQQ, KKK, and VVV into manageable tiles (e.g., 64×6464×6464 \\\\times 64) that can be loaded into fast on-chip shared memory or registers. This improves memory locality, reduces global memory reads/writes, and allows the GPU to reuse loaded data for multiple computations within the block.\n        \n    *   **Fuses softmax, scaling, masking, and matmul into a single kernel**: Combines these operations into one GPU kernel to avoid storing intermediate results in memory. By performing scaling, masking, softmax computation, and the weighted sum with VVV in a single pass, FlashAttention reduces memory bandwidth usage and improves computational efficiency.\n        \n\nOriginally proposed in Dao et al., 2022 in [FlashAttention: Fast and Memory‑Efficient Exact Attention with IO‑Awareness](https://arxiv.org/abs/2205.14135), FlashAttention is a fused, tiled implementation of scaled dot-product attention that:\n\n*   **Eliminates materialization of the full attention matrix**: Avoids creating and storing the entire L×LL×LL \\\\times L attention score matrix in GPU memory. Instead, computes small blocks of logits on-chip, applies masking and softmax immediately, and discards them, drastically reducing memory usage for long sequences.\n    \n*   **Uses tiling to partition queries, keys, and values into small blocks that fit in GPU shared memory**: Splits QQQ, KKK, and VVV into manageable tiles (e.g., 64×6464×6464 \\\\times 64) that can be loaded into fast on-chip shared memory or registers. This improves memory locality, reduces global memory reads/writes, and allows the GPU to reuse loaded data for multiple computations within the block.\n    \n*   **Fuses softmax, scaling, masking, and matmul into a single kernel**: Combines these operations into one GPU kernel to avoid storing intermediate results in memory. By performing scaling, masking, softmax computation, and the weighted sum with VVV in a single pass, FlashAttention reduces memory bandwidth usage and improves computational efficiency.\n    \n\n**Eliminates materialization of the full attention matrix**: Avoids creating and storing the entire L×LL×LL \\\\times L attention score matrix in GPU memory. Instead, computes small blocks of logits on-chip, applies masking and softmax immediately, and discards them, drastically reducing memory usage for long sequences.\n\n**Uses tiling to partition queries, keys, and values into small blocks that fit in GPU shared memory**: Splits QQQ, KKK, and VVV into manageable tiles (e.g., 64×6464×6464 \\\\times 64) that can be loaded into fast on-chip shared memory or registers. This improves memory locality, reduces global memory reads/writes, and allows the GPU to reuse loaded data for multiple computations within the block.\n\n**Fuses softmax, scaling, masking, and matmul into a single kernel**: Combines these operations into one GPU kernel to avoid storing intermediate results in memory. By performing scaling, masking, softmax computation, and the weighted sum with VVV in a single pass, FlashAttention reduces memory bandwidth usage and improves computational efficiency.\n\n##### High-Level Algorithm\n\n1.  Load a block of queries QiQiQ\\_{i} and keys KjKjK\\_{j} into shared memory.\n2.  Compute attention logits QiKTjd√QiKjTd\\\\frac{Q\\_i K\\_j^T}{\\\\sqrt{d}} for the block.\n3.  Apply mask and softmax **in-place**, updating the running sum of exponents and maximums for numerical stability.\n4.  Accumulate partial outputs Ai,j\\=softmax(QiKTj/d‾‾√)VjAi,j\\=softmax(QiKjT/d)VjA\\_{i,j} = \\\\text{softmax}(Q\\_i K\\_j^T / \\\\sqrt{d}) V\\_j without storing intermediate attention matrices.\n5.  Repeat across blocks until the full result is computed.\n\n##### Numerical Stability\n\n*   To avoid numerical overflow when computing softmax in a block-by-block fashion, FlashAttention keeps running statistics for each query row:\n    \n    *   mi\\=maxjzijmi\\=maxjzijm\\_i = \\\\max\\_{j} z\\_{ij} — the maximum logit value seen so far for that row, used to shift logits and prevent large exponentials.\n    *   si\\=∑jexp(zij−mi)si\\=∑jexp⁡(zij−mi)s\\_i = \\\\sum\\_{j} \\\\exp\\\\left(z\\_{ij} - m\\_i\\\\right) — the running sum of the shifted exponentials, which forms the softmax denominator.\n*   As new blocks are processed, these values are updated using associative operations that merge current and previous block statistics without loss of precision. This ensures the final softmax is mathematically equivalent to computing it on the full L×LL×LL \\\\times L matrix, but without ever storing that matrix.\n    \n\nTo avoid numerical overflow when computing softmax in a block-by-block fashion, FlashAttention keeps running statistics for each query row:\n\n*   mi\\=maxjzijmi\\=maxjzijm\\_i = \\\\max\\_{j} z\\_{ij} — the maximum logit value seen so far for that row, used to shift logits and prevent large exponentials.\n*   si\\=∑jexp(zij−mi)si\\=∑jexp⁡(zij−mi)s\\_i = \\\\sum\\_{j} \\\\exp\\\\left(z\\_{ij} - m\\_i\\\\right) — the running sum of the shifted exponentials, which forms the softmax denominator.\n\nAs new blocks are processed, these values are updated using associative operations that merge current and previous block statistics without loss of precision. This ensures the final softmax is mathematically equivalent to computing it on the full L×LL×LL \\\\times L matrix, but without ever storing that matrix.\n\n#### Implementation Details\n\n*   Written as a custom CUDA kernel.\n*   Uses **shared memory** to hold Q/K/V tiles and compute locally.\n*   Optimized to run in **mixed precision** (e.g., FP16 or BF16) for speed and memory efficiency.\n*   Compatible with dropout, masking, and rotary embeddings.\n\n#### FlashAttention-2 Improvements\n\n*   Adds support for **non-causal attention**, **variable-length sequences**, and better **warp-level parallelism**.\n*   Removes redundant memory loads through more aggressive caching and loop unrolling.\n*   Enables **backward pass efficiency**, making it useful not only for inference but also for training.\n\n#### Other Efficient Kernels\n\n*   **xFormers** (Meta): Modular attention implementations that support Flash, sparse, and memory-efficient variants.\n*   **Triton-based Attention**: Enables easy definition of fused attention kernels using Triton’s GPU DSL.\n*   **PagedAttention (vLLM)**: Optimizes KV cache access for batch inference, reducing memory fragmentation and improving latency.\n\n#### Performance Gains\n\n*   FlashAttention reduces attention memory complexity from:\n    \n    *   **(L2)O(L2)\\\\mathcal{O}(L^2)** to **(L)O(L)\\\\mathcal{O}(L)** for memory consumption.\n    *   Achieves **1.7–2.7××\\\\times speedup** on A100 GPUs for long sequence lengths (> 1k tokens).\n    *   Maintains exact attention output (within floating-point precision), unlike approximate methods.\n\nFlashAttention reduces attention memory complexity from:\n\n*   **(L2)O(L2)\\\\mathcal{O}(L^2)** to **(L)O(L)\\\\mathcal{O}(L)** for memory consumption.\n*   Achieves **1.7–2.7××\\\\times speedup** on A100 GPUs for long sequence lengths (> 1k tokens).\n*   Maintains exact attention output (within floating-point precision), unlike approximate methods.\n\n#### Use in Inference\n\n*   FlashAttention is especially beneficial for:\n    \n    *   Long-context models (e.g., 4k to 128k tokens).\n    *   Multi-head attention, where per-head memory use adds up quickly.\n    *   Deployment on GPUs with large shared memory (e.g., NVIDIA A100, H100).\n\nFlashAttention is especially beneficial for:\n\n*   Long-context models (e.g., 4k to 128k tokens).\n*   Multi-head attention, where per-head memory use adds up quickly.\n*   Deployment on GPUs with large shared memory (e.g., NVIDIA A100, H100).\n\n#### Integration\n\n*   Supported in:\n    \n    *   **Hugging Face Transformers** via `use_flash_attention_2=True`\n    *   **PyTorch** through custom CUDA extensions or Triton kernels\n    *   **DeepSpeed**, **FasterTransformer**, and **xFormers**\n\nSupported in:\n\n*   **Hugging Face Transformers** via `use_flash_attention_2=True`\n*   **PyTorch** through custom CUDA extensions or Triton kernels\n*   **DeepSpeed**, **FasterTransformer**, and **xFormers**",
    "contentLength": 104322,
    "wordCount": 1371,
    "hasCode": true,
    "hasMath": true,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/model-acceleration/#flashattention-and-efficient-attention-kernels"
  },
  {
    "id": "ai-model-acceleration-batching-sequence-packing-and-prefilling-15",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Inference Optimizations",
    "title": "Batching, Sequence Packing, and Prefilling",
    "order": 15,
    "orderInChapter": 7,
    "contentHtml": "<ul>\n  <li><strong>Batching</strong> and <strong>prefilling</strong> are inference-time optimization techniques that improve efficiency and throughput by better utilizing hardware and avoiding redundant computations. These are especially critical when serving LLMs in real-time or at high concurrency.</li>\n</ul>\n<h4 id=\"batching\">Batching</h4>\n<ul>\n  <li>Batching refers to the process of grouping multiple inference requests into a single forward pass through the model. This increases hardware utilization, amortizes overhead, and reduces latency per request (on average), particularly on GPUs that are optimized for matrix-heavy workloads.</li>\n</ul>\n<h5 id=\"motivation-4\">Motivation</h5>\n<ul>\n  <li>\n    <p>Without batching, each request results in an under-utilized forward pass:</p>\n\n    <ul>\n      <li>Small input tensor <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-316-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>&amp;#x2192;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2714\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.94em, 2.294em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2715\"><span class=\"mo\" id=\"MathJax-Span-2716\" style=\"font-family: STIXGeneral-Regular;\">→</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: 0.003em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">→</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-316\">\\rightarrow</script> Poor occupancy/utilization of GPU cores</li>\n      <li>High overhead per kernel launch</li>\n      <li>Wasted memory bandwidth</li>\n    </ul>\n  </li>\n  <li>\n    <p>Batching solves this by aligning multiple requests into a tensor of shape:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-317-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>Batch Tensor:&amp;#xA0;</mtext><mo stretchy=&quot;false&quot;>(</mo><mi>B</mi><mo>,</mo><mi>L</mi><mo>,</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2717\" style=\"width: 11.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 9.221em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1009.17em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2718\"><span class=\"mtext\" id=\"MathJax-Span-2719\" style=\"font-family: STIXGeneral-Regular;\">Batch Tensor:&nbsp;</span><span class=\"mo\" id=\"MathJax-Span-2720\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2721\" style=\"font-family: STIXGeneral-Italic;\">B</span><span class=\"mo\" id=\"MathJax-Span-2722\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-2723\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2724\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-2725\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2726\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>Batch Tensor:&nbsp;</mtext><mo stretchy=\"false\">(</mo><mi>B</mi><mo>,</mo><mi>L</mi><mo>,</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-317\">\\text{Batch Tensor: } (B, L, d)</script>\n\n    <ul>\n      <li>where:\n        <ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-318-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2727\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2728\"><span class=\"mi\" id=\"MathJax-Span-2729\" style=\"font-family: STIXGeneral-Italic;\">B</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-318\">B</script> is batch size</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-319-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2730\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2731\"><span class=\"mi\" id=\"MathJax-Span-2732\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-319\">L</script> is sequence length</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-320-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2733\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2734\"><span class=\"mi\" id=\"MathJax-Span-2735\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-320\">d</script> is hidden dimension</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>Without batching, each request results in an under-utilized forward pass:</p>\n<ul>\n      <li>Small input tensor <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-316-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>&amp;#x2192;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2714\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.94em, 2.294em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2715\"><span class=\"mo\" id=\"MathJax-Span-2716\" style=\"font-family: STIXGeneral-Regular;\">→</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: 0.003em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">→</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-316\">\\rightarrow</script> Poor occupancy/utilization of GPU cores</li>\n      <li>High overhead per kernel launch</li>\n      <li>Wasted memory bandwidth</li>\n    </ul>\n<p>Batching solves this by aligning multiple requests into a tensor of shape:</p>\n<ul>\n      <li>where:\n        <ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-318-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2727\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2728\"><span class=\"mi\" id=\"MathJax-Span-2729\" style=\"font-family: STIXGeneral-Italic;\">B</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-318\">B</script> is batch size</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-319-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2730\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2731\"><span class=\"mi\" id=\"MathJax-Span-2732\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-319\">L</script> is sequence length</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-320-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2733\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2734\"><span class=\"mi\" id=\"MathJax-Span-2735\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-320\">d</script> is hidden dimension</li>\n        </ul>\n      </li>\n    </ul>\n<ul>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-318-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2727\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2728\"><span class=\"mi\" id=\"MathJax-Span-2729\" style=\"font-family: STIXGeneral-Italic;\">B</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>B</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-318\">B</script> is batch size</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-319-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2730\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2731\"><span class=\"mi\" id=\"MathJax-Span-2732\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-319\">L</script> is sequence length</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-320-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2733\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2734\"><span class=\"mi\" id=\"MathJax-Span-2735\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-320\">d</script> is hidden dimension</li>\n        </ul>\n<h5 id=\"types-of-batching\">Types of Batching</h5>\n<ol>\n  <li><strong>Static Batching</strong>: Requests are grouped together at fixed time intervals. Simple but less flexible.</li>\n  <li><strong>Dynamic Batching</strong>: Requests are buffered and grouped at runtime based on heuristics like request arrival time, sequence length, or prompt similarity.</li>\n  <li><strong>Token-Level Batching</strong>: Pioneered by vLLM, this groups sequences by shared decoding step instead of sequence. Supports long-running generation jobs without blocking new ones.</li>\n  <li><strong>Asynchronous Batching</strong>: Uses request queues and a scheduler to decide when to batch based on hardware load.</li>\n</ol>\n<h5 id=\"padding-and-masking\">Padding and Masking</h5>\n<ul>\n  <li>\n    <p>Since sequences may vary in length, shorter ones are padded and masked accordingly. Padding increases memory cost but enables unified matrix operations.</p>\n  </li>\n  <li>\n    <p>Example:</p>\n\n    <ul>\n      <li>Sequence A: <code class=\"language-plaintext highlighter-rouge\">[Hello, how, are, you]</code> <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-321-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>&amp;#x2192;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2736\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.94em, 2.294em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2737\"><span class=\"mo\" id=\"MathJax-Span-2738\" style=\"font-family: STIXGeneral-Regular;\">→</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: 0.003em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">→</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-321\">\\rightarrow</script> length 4</li>\n      <li>Sequence B: <code class=\"language-plaintext highlighter-rouge\">[Hi]</code> <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-322-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>&amp;#x2192;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2739\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.94em, 2.294em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2740\"><span class=\"mo\" id=\"MathJax-Span-2741\" style=\"font-family: STIXGeneral-Regular;\">→</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: 0.003em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">→</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-322\">\\rightarrow</script> length 1</li>\n      <li>Batched input: <code class=\"language-plaintext highlighter-rouge\">[[Hello, how, are, you], [Hi, PAD, PAD, PAD]]</code></li>\n    </ul>\n  </li>\n</ul>\n<p>Since sequences may vary in length, shorter ones are padded and masked accordingly. Padding increases memory cost but enables unified matrix operations.</p>\n<p>Example:</p>\n<ul>\n      <li>Sequence A: <code class=\"language-plaintext highlighter-rouge\">[Hello, how, are, you]</code> <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-321-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>&amp;#x2192;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2736\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.94em, 2.294em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2737\"><span class=\"mo\" id=\"MathJax-Span-2738\" style=\"font-family: STIXGeneral-Regular;\">→</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: 0.003em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">→</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-321\">\\rightarrow</script> length 4</li>\n      <li>Sequence B: <code class=\"language-plaintext highlighter-rouge\">[Hi]</code> <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-322-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>&amp;#x2192;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2739\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.94em, 2.294em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2740\"><span class=\"mo\" id=\"MathJax-Span-2741\" style=\"font-family: STIXGeneral-Regular;\">→</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: 0.003em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">→</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-322\">\\rightarrow</script> length 1</li>\n      <li>Batched input: <code class=\"language-plaintext highlighter-rouge\">[[Hello, how, are, you], [Hi, PAD, PAD, PAD]]</code></li>\n    </ul>\n<h5 id=\"performance-benefits\">Performance Benefits</h5>\n<ul>\n  <li>Higher throughput: GPUs can process large matrices in parallel.</li>\n  <li>Lower kernel launch overhead.</li>\n  <li>Amortized use of KV cache and memory bandwidth.</li>\n</ul>\n<h4 id=\"sequence-packing\">Sequence Packing</h4>\n<ul>\n  <li>\n    <p><strong>Sequence packing</strong> is an optimization that reduces padding overhead when batching variable-length sequences. Instead of padding all sequences in a batch to the maximum length, multiple shorter sequences are concatenated into a single continuous sequence within the same batch element.</p>\n  </li>\n  <li>\n    <p>This approach stores and processes only actual tokens, using an <strong>attention mask</strong> to ensure tokens from different original sequences do not attend to each other.</p>\n  </li>\n</ul>\n<p><strong>Sequence packing</strong> is an optimization that reduces padding overhead when batching variable-length sequences. Instead of padding all sequences in a batch to the maximum length, multiple shorter sequences are concatenated into a single continuous sequence within the same batch element.</p>\n<p>This approach stores and processes only actual tokens, using an <strong>attention mask</strong> to ensure tokens from different original sequences do not attend to each other.</p>\n<h5 id=\"example\">Example</h5>\n<ul>\n  <li>\n    <p>Without packing:</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code9\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code9\">[Hello, how, are, you, PAD, PAD, PAD]\n[Hi, there, PAD, PAD, PAD, PAD, PAD]\n</code></pre></div>    </div>\n\n    <ul>\n      <li><strong>Memory usage:</strong> proportional to 7 tokens per sequence (including pads).</li>\n    </ul>\n  </li>\n  <li>\n    <p>With packing:</p>\n\n    <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code10\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code10\">[Hello, how, are, you, Hi, there]\n</code></pre></div>    </div>\n\n    <ul>\n      <li>Plus a mask to block attention between <code class=\"language-plaintext highlighter-rouge\">you</code> and <code class=\"language-plaintext highlighter-rouge\">Hi</code>.</li>\n    </ul>\n  </li>\n</ul>\n<p>Without packing:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code9\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code9\">[Hello, how, are, you, PAD, PAD, PAD]\n[Hi, there, PAD, PAD, PAD, PAD, PAD]\n</code></pre>\n<ul>\n      <li><strong>Memory usage:</strong> proportional to 7 tokens per sequence (including pads).</li>\n    </ul>\n<p>With packing:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code10\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code10\">[Hello, how, are, you, Hi, there]\n</code></pre>\n<ul>\n      <li>Plus a mask to block attention between <code class=\"language-plaintext highlighter-rouge\">you</code> and <code class=\"language-plaintext highlighter-rouge\">Hi</code>.</li>\n    </ul>\n<h5 id=\"benefits-1\">Benefits</h5>\n<ul>\n  <li><strong>Reduced memory footprint</strong> — fewer padding tokens stored and processed.</li>\n  <li><strong>Better hardware utilization</strong> — higher effective sequence density in each batch.</li>\n  <li><strong>Lower latency for mixed-length workloads</strong> — especially beneficial when many short sequences are served alongside long ones.</li>\n</ul>\n<h5 id=\"trade-offs\">Trade-offs</h5>\n<ul>\n  <li>Slight overhead in constructing and applying more complex attention masks.</li>\n  <li>May require specialized batching logic and kernel support for optimal performance.</li>\n</ul>\n<h4 id=\"prefilling\">Prefilling</h4>\n<ul>\n  <li>Prefilling refers to the one-time computation of model activations (primarily KV cache) for the prompt or context tokens before autoregressive decoding begins.</li>\n</ul>\n<h5 id=\"motivation-5\">Motivation</h5>\n<ul>\n  <li>\n    <p>Transformer inference separates the process into:</p>\n\n    <ol>\n      <li><strong>Prompt Phase (Prefill)</strong>: Process entire prompt to initialize the KV cache.</li>\n      <li><strong>Generation Phase (Decode)</strong>: Generate one token at a time using cached keys and values.</li>\n    </ol>\n  </li>\n  <li>\n    <p>The prompt phase is significantly more expensive because it processes multiple tokens without caching, while the decode phase uses KV caching for each new token.</p>\n  </li>\n</ul>\n<p>Transformer inference separates the process into:</p>\n<ol>\n      <li><strong>Prompt Phase (Prefill)</strong>: Process entire prompt to initialize the KV cache.</li>\n      <li><strong>Generation Phase (Decode)</strong>: Generate one token at a time using cached keys and values.</li>\n    </ol>\n<p>The prompt phase is significantly more expensive because it processes multiple tokens without caching, while the decode phase uses KV caching for each new token.</p>\n<h5 id=\"prefilling-logic\">Prefilling Logic</h5>\n<ul>\n  <li>\n    <p>Given a prompt of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-323-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2742\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2743\"><span class=\"mi\" id=\"MathJax-Span-2744\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-323\">n</script> tokens:</p>\n\n    <ul>\n      <li>The model performs a full forward pass to compute attention outputs for all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-324-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2745\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2746\"><span class=\"mi\" id=\"MathJax-Span-2747\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-324\">n</script> positions.</li>\n      <li>\n        <p>During this, it initializes the KV cache tensors:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-325-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2748\" style=\"width: 4.534em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.753em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.75em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2749\"><span class=\"msubsup\" id=\"MathJax-Span-2750\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2751\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-2752\"><span class=\"mrow\" id=\"MathJax-Span-2753\"><span class=\"mn\" id=\"MathJax-Span-2754\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-2755\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-2756\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2757\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-2758\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2759\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-2760\"><span class=\"mrow\" id=\"MathJax-Span-2761\"><span class=\"mn\" id=\"MathJax-Span-2762\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-2763\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-2764\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-325\">K_{1:n}, V_{1:n}</script>\n      </li>\n      <li>These are used in all subsequent generation steps to avoid recomputation.</li>\n    </ul>\n  </li>\n</ul>\n<p>Given a prompt of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-323-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2742\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2743\"><span class=\"mi\" id=\"MathJax-Span-2744\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-323\">n</script> tokens:</p>\n<ul>\n      <li>The model performs a full forward pass to compute attention outputs for all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-324-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2745\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2746\"><span class=\"mi\" id=\"MathJax-Span-2747\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-324\">n</script> positions.</li>\n      <li>\n        <p>During this, it initializes the KV cache tensors:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-325-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2748\" style=\"width: 4.534em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.753em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.75em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2749\"><span class=\"msubsup\" id=\"MathJax-Span-2750\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2751\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-2752\"><span class=\"mrow\" id=\"MathJax-Span-2753\"><span class=\"mn\" id=\"MathJax-Span-2754\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-2755\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-2756\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2757\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-2758\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2759\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-2760\"><span class=\"mrow\" id=\"MathJax-Span-2761\"><span class=\"mn\" id=\"MathJax-Span-2762\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-2763\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-2764\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-325\">K_{1:n}, V_{1:n}</script>\n      </li>\n      <li>These are used in all subsequent generation steps to avoid recomputation.</li>\n    </ul>\n<p>During this, it initializes the KV cache tensors:</p>\n<h5 id=\"optimizations\">Optimizations</h5>\n<ul>\n  <li><strong>Fused Prefill Kernels</strong>: Libraries like FasterTransformer use specialized kernels to batch and prefill KV caches in a single efficient pass.</li>\n  <li><strong>Prompt Sharing</strong>: If multiple requests use the same prompt (e.g., “You are a helpful assistant…”), cache the prefilled results and reuse them across requests.</li>\n  <li><strong>Layer-Wise Streaming</strong>: Some implementations stream KV cache population layer-by-layer to overlap computation and memory operations.</li>\n</ul>\n<h5 id=\"real-world-use\">Real-World Use</h5>\n<ul>\n  <li>\n    <p>In production systems:</p>\n\n    <ul>\n      <li>Prompt prefill is often the <strong>dominant source of latency</strong>, especially with long prompts (e.g., 1k+ tokens).</li>\n      <li>Prefilling is <strong>not cacheable</strong> unless the prompt is reused. That’s where <a href=\"#prompt-caching\">prompt caching</a> comes in.</li>\n      <li>Systems may delay decoding until all requests in a batch complete their prefill phase.</li>\n    </ul>\n  </li>\n</ul>\n<p>In production systems:</p>\n<ul>\n      <li>Prompt prefill is often the <strong>dominant source of latency</strong>, especially with long prompts (e.g., 1k+ tokens).</li>\n      <li>Prefilling is <strong>not cacheable</strong> unless the prompt is reused. That’s where <a href=\"#prompt-caching\">prompt caching</a> comes in.</li>\n      <li>Systems may delay decoding until all requests in a batch complete their prefill phase.</li>\n    </ul>\n<h5 id=\"performance-benefits-1\">Performance Benefits</h5>\n<ul>\n  <li>Avoids redundant computation across decoding steps.</li>\n  <li>Enables efficient reuse of memory and attention context.</li>\n  <li>Critical for long-context inference and multi-user serving.</li>\n</ul>",
    "contentMarkdown": "*   **Batching** and **prefilling** are inference-time optimization techniques that improve efficiency and throughput by better utilizing hardware and avoiding redundant computations. These are especially critical when serving LLMs in real-time or at high concurrency.\n\n#### Batching\n\n*   Batching refers to the process of grouping multiple inference requests into a single forward pass through the model. This increases hardware utilization, amortizes overhead, and reduces latency per request (on average), particularly on GPUs that are optimized for matrix-heavy workloads.\n\n##### Motivation\n\n*   Without batching, each request results in an under-utilized forward pass:\n    \n    *   Small input tensor →→\\\\rightarrow Poor occupancy/utilization of GPU cores\n    *   High overhead per kernel launch\n    *   Wasted memory bandwidth\n*   Batching solves this by aligning multiple requests into a tensor of shape:\n    \n    Batch Tensor: (B,L,d)Batch Tensor: (B,L,d)\n    \n    \\\\text{Batch Tensor: } (B, L, d)\n    *   where:\n        *   BBB is batch size\n        *   LLL is sequence length\n        *   ddd is hidden dimension\n\nWithout batching, each request results in an under-utilized forward pass:\n\n*   Small input tensor →→\\\\rightarrow Poor occupancy/utilization of GPU cores\n*   High overhead per kernel launch\n*   Wasted memory bandwidth\n\nBatching solves this by aligning multiple requests into a tensor of shape:\n\n*   where:\n    *   BBB is batch size\n    *   LLL is sequence length\n    *   ddd is hidden dimension\n\n*   BBB is batch size\n*   LLL is sequence length\n*   ddd is hidden dimension\n\n##### Types of Batching\n\n1.  **Static Batching**: Requests are grouped together at fixed time intervals. Simple but less flexible.\n2.  **Dynamic Batching**: Requests are buffered and grouped at runtime based on heuristics like request arrival time, sequence length, or prompt similarity.\n3.  **Token-Level Batching**: Pioneered by vLLM, this groups sequences by shared decoding step instead of sequence. Supports long-running generation jobs without blocking new ones.\n4.  **Asynchronous Batching**: Uses request queues and a scheduler to decide when to batch based on hardware load.\n\n##### Padding and Masking\n\n*   Since sequences may vary in length, shorter ones are padded and masked accordingly. Padding increases memory cost but enables unified matrix operations.\n    \n*   Example:\n    \n    *   Sequence A: `[Hello, how, are, you]` →→\\\\rightarrow length 4\n    *   Sequence B: `[Hi]` →→\\\\rightarrow length 1\n    *   Batched input: `[[Hello, how, are, you], [Hi, PAD, PAD, PAD]]`\n\nSince sequences may vary in length, shorter ones are padded and masked accordingly. Padding increases memory cost but enables unified matrix operations.\n\nExample:\n\n*   Sequence A: `[Hello, how, are, you]` →→\\\\rightarrow length 4\n*   Sequence B: `[Hi]` →→\\\\rightarrow length 1\n*   Batched input: `[[Hello, how, are, you], [Hi, PAD, PAD, PAD]]`\n\n##### Performance Benefits\n\n*   Higher throughput: GPUs can process large matrices in parallel.\n*   Lower kernel launch overhead.\n*   Amortized use of KV cache and memory bandwidth.\n\n#### Sequence Packing\n\n*   **Sequence packing** is an optimization that reduces padding overhead when batching variable-length sequences. Instead of padding all sequences in a batch to the maximum length, multiple shorter sequences are concatenated into a single continuous sequence within the same batch element.\n    \n*   This approach stores and processes only actual tokens, using an **attention mask** to ensure tokens from different original sequences do not attend to each other.\n    \n\n**Sequence packing** is an optimization that reduces padding overhead when batching variable-length sequences. Instead of padding all sequences in a batch to the maximum length, multiple shorter sequences are concatenated into a single continuous sequence within the same batch element.\n\nThis approach stores and processes only actual tokens, using an **attention mask** to ensure tokens from different original sequences do not attend to each other.\n\n##### Example\n\n*   Without packing:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n    `[Hello, how, are, you, PAD, PAD, PAD] [Hi, there, PAD, PAD, PAD, PAD, PAD]`\n    \n    *   **Memory usage:** proportional to 7 tokens per sequence (including pads).\n*   With packing:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n    `[Hello, how, are, you, Hi, there]`\n    \n    *   Plus a mask to block attention between `you` and `Hi`.\n\nWithout packing:\n\n![](https://aman.ai/images/copy.png)\n\n`[Hello, how, are, you, PAD, PAD, PAD] [Hi, there, PAD, PAD, PAD, PAD, PAD]`\n\n*   **Memory usage:** proportional to 7 tokens per sequence (including pads).\n\nWith packing:\n\n![](https://aman.ai/images/copy.png)\n\n`[Hello, how, are, you, Hi, there]`\n\n*   Plus a mask to block attention between `you` and `Hi`.\n\n##### Benefits\n\n*   **Reduced memory footprint** — fewer padding tokens stored and processed.\n*   **Better hardware utilization** — higher effective sequence density in each batch.\n*   **Lower latency for mixed-length workloads** — especially beneficial when many short sequences are served alongside long ones.\n\n##### Trade-offs\n\n*   Slight overhead in constructing and applying more complex attention masks.\n*   May require specialized batching logic and kernel support for optimal performance.\n\n#### Prefilling\n\n*   Prefilling refers to the one-time computation of model activations (primarily KV cache) for the prompt or context tokens before autoregressive decoding begins.\n\n##### Motivation\n\n*   Transformer inference separates the process into:\n    \n    1.  **Prompt Phase (Prefill)**: Process entire prompt to initialize the KV cache.\n    2.  **Generation Phase (Decode)**: Generate one token at a time using cached keys and values.\n*   The prompt phase is significantly more expensive because it processes multiple tokens without caching, while the decode phase uses KV caching for each new token.\n    \n\nTransformer inference separates the process into:\n\n1.  **Prompt Phase (Prefill)**: Process entire prompt to initialize the KV cache.\n2.  **Generation Phase (Decode)**: Generate one token at a time using cached keys and values.\n\nThe prompt phase is significantly more expensive because it processes multiple tokens without caching, while the decode phase uses KV caching for each new token.\n\n##### Prefilling Logic\n\n*   Given a prompt of nnn tokens:\n    \n    *   The model performs a full forward pass to compute attention outputs for all nnn positions.\n    *   During this, it initializes the KV cache tensors:\n        \n        K1:n,V1:nK1:n,V1:n\n        \n        K\\_{1:n}, V\\_{1:n}\n    *   These are used in all subsequent generation steps to avoid recomputation.\n\nGiven a prompt of nnn tokens:\n\n*   The model performs a full forward pass to compute attention outputs for all nnn positions.\n*   During this, it initializes the KV cache tensors:\n    \n    K1:n,V1:nK1:n,V1:n\n    \n    K\\_{1:n}, V\\_{1:n}\n*   These are used in all subsequent generation steps to avoid recomputation.\n\nDuring this, it initializes the KV cache tensors:\n\n##### Optimizations\n\n*   **Fused Prefill Kernels**: Libraries like FasterTransformer use specialized kernels to batch and prefill KV caches in a single efficient pass.\n*   **Prompt Sharing**: If multiple requests use the same prompt (e.g., “You are a helpful assistant…”), cache the prefilled results and reuse them across requests.\n*   **Layer-Wise Streaming**: Some implementations stream KV cache population layer-by-layer to overlap computation and memory operations.\n\n##### Real-World Use\n\n*   In production systems:\n    \n    *   Prompt prefill is often the **dominant source of latency**, especially with long prompts (e.g., 1k+ tokens).\n    *   Prefilling is **not cacheable** unless the prompt is reused. That’s where [prompt caching](#prompt-caching) comes in.\n    *   Systems may delay decoding until all requests in a batch complete their prefill phase.\n\nIn production systems:\n\n*   Prompt prefill is often the **dominant source of latency**, especially with long prompts (e.g., 1k+ tokens).\n*   Prefilling is **not cacheable** unless the prompt is reused. That’s where [prompt caching](#prompt-caching) comes in.\n*   Systems may delay decoding until all requests in a batch complete their prefill phase.\n\n##### Performance Benefits\n\n*   Avoids redundant computation across decoding steps.\n*   Enables efficient reuse of memory and attention context.\n*   Critical for long-context inference and multi-user serving.",
    "contentLength": 45834,
    "wordCount": 1192,
    "hasCode": true,
    "hasMath": true,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/model-acceleration/#batching,-sequence-packing,-and-prefilling"
  },
  {
    "id": "ai-model-acceleration-prompt-caching-16",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Inference Optimizations",
    "title": "Prompt Caching",
    "order": 16,
    "orderInChapter": 8,
    "contentHtml": "<ul>\n  <li>\n    <p>Prompt caching is an inference-time optimization that reuses the computed key-value (KV) attention states for frequently occurring or repeated prompt tokens. It eliminates the need to recompute the prefill phase of autoregressive decoding, which is typically the most computationally expensive part of the inference pipeline for long prompts.</p>\n  </li>\n  <li>\n    <p>This technique is especially effective in systems with repeated system messages, user templates, or static few-shot examples.</p>\n  </li>\n</ul>\n<p>Prompt caching is an inference-time optimization that reuses the computed key-value (KV) attention states for frequently occurring or repeated prompt tokens. It eliminates the need to recompute the prefill phase of autoregressive decoding, which is typically the most computationally expensive part of the inference pipeline for long prompts.</p>\n<p>This technique is especially effective in systems with repeated system messages, user templates, or static few-shot examples.</p>\n<h4 id=\"motivation-6\">Motivation</h4>\n<ul>\n  <li>During autoregressive generation, transformer models process the prompt (or context) once to initialize the attention cache. For a prompt of length <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-326-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2765\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2766\"><span class=\"mi\" id=\"MathJax-Span-2767\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-326\">n</script>, this involves a full forward pass through all transformer layers to compute the KV tensors:</li>\n</ul>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-327-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>K</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>V</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mspace width=&quot;1em&quot; /><mtext>for all layers&amp;#xA0;</mtext><mi>l</mi></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2768\" style=\"width: 12.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1010.47em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2769\"><span class=\"msubsup\" id=\"MathJax-Span-2770\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2771\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.73em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-2772\"><span class=\"mrow\" id=\"MathJax-Span-2773\"><span class=\"mo\" id=\"MathJax-Span-2774\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2775\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2776\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.99em, 4.169em, -999.997em); top: -3.695em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-2777\"><span class=\"mrow\" id=\"MathJax-Span-2778\"><span class=\"mn\" id=\"MathJax-Span-2779\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-2780\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-2781\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2782\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-2783\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2784\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.73em, 4.273em, -999.997em); top: -4.477em; left: 0.784em;\"><span class=\"texatom\" id=\"MathJax-Span-2785\"><span class=\"mrow\" id=\"MathJax-Span-2786\"><span class=\"mo\" id=\"MathJax-Span-2787\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2788\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2789\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.99em, 4.169em, -999.997em); top: -3.695em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-2790\"><span class=\"mrow\" id=\"MathJax-Span-2791\"><span class=\"mn\" id=\"MathJax-Span-2792\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-2793\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-2794\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mspace\" id=\"MathJax-Span-2795\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"mtext\" id=\"MathJax-Span-2796\" style=\"font-family: STIXGeneral-Regular;\">for all layers&nbsp;</span><span class=\"mi\" id=\"MathJax-Span-2797\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>K</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>,</mo><msubsup><mi>V</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>n</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mspace width=\"1em\"></mspace><mtext>for all layers&nbsp;</mtext><mi>l</mi></math></span></span></div>\n<ul>\n  <li>\n    <p>This prefill step is expensive and must be repeated for every new request — even if the prompt is the same.</p>\n  </li>\n  <li>\n    <p><strong>Observation</strong>: Many applications use identical or highly similar prompts repeatedly. For example:</p>\n\n    <ul>\n      <li>Instructional prompts like: “You are a helpful assistant.”</li>\n      <li>Few-shot templates in customer support bots.</li>\n      <li>System prompts in chat APIs.</li>\n    </ul>\n  </li>\n  <li>\n    <p>Prompt caching avoids repeated prefill for these common contexts.</p>\n  </li>\n</ul>\n<p>This prefill step is expensive and must be repeated for every new request — even if the prompt is the same.</p>\n<p><strong>Observation</strong>: Many applications use identical or highly similar prompts repeatedly. For example:</p>\n<ul>\n      <li>Instructional prompts like: “You are a helpful assistant.”</li>\n      <li>Few-shot templates in customer support bots.</li>\n      <li>System prompts in chat APIs.</li>\n    </ul>\n<p>Prompt caching avoids repeated prefill for these common contexts.</p>\n<h4 id=\"basic-mechanism\">Basic Mechanism</h4>\n<ol>\n  <li>\n    <p><strong>Cache Initialization</strong>:</p>\n\n    <ul>\n      <li>\n        <p>Compute and store KV tensors for a given prompt:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-328-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mtext>KV</mtext><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>prompt</mtext></mrow></msub><mo>=</mo><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mtext>prompt</mtext><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2798\" style=\"width: 10.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.805em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1008.75em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2799\"><span class=\"msubsup\" id=\"MathJax-Span-2800\"><span style=\"display: inline-block; position: relative; width: 3.544em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1001.41em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mtext\" id=\"MathJax-Span-2801\" style=\"font-family: STIXGeneral-Regular;\">KV</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 1.461em;\"><span class=\"texatom\" id=\"MathJax-Span-2802\"><span class=\"mrow\" id=\"MathJax-Span-2803\"><span class=\"mtext\" id=\"MathJax-Span-2804\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">prompt</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2805\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-2806\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2807\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-2808\" style=\"font-family: STIXGeneral-Regular;\">prompt</span><span class=\"mo\" id=\"MathJax-Span-2809\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mtext>KV</mtext><mrow class=\"MJX-TeXAtom-ORD\"><mtext>prompt</mtext></mrow></msub><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mtext>prompt</mtext><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-328\">\\text{KV}_{\\text{prompt}} = f(\\text{prompt})</script>\n      </li>\n      <li>\n        <p>Store in memory or disk with a unique key (e.g., hash of token IDs).</p>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Cache Lookup</strong>:</p>\n\n    <ul>\n      <li>For each incoming request, compute a cache key from its prompt.</li>\n      <li>If a match is found, retrieve KV tensors instead of recomputing them.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Continue Decoding</strong>:</p>\n\n    <ul>\n      <li>\n        <p>Begin token-by-token generation using the cached KV state:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-329-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>Generate</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>&amp;#x2223;</mo><msub><mtext>KV</mtext><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>prompt</mtext></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2810\" style=\"width: 12.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.419em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1010.37em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2811\"><span class=\"mtext\" id=\"MathJax-Span-2812\" style=\"font-family: STIXGeneral-Regular;\">Generate</span><span class=\"mo\" id=\"MathJax-Span-2813\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2814\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2815\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-2816\"><span class=\"mrow\" id=\"MathJax-Span-2817\"><span class=\"mi\" id=\"MathJax-Span-2818\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-2819\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-2820\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2821\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∣</span><span class=\"msubsup\" id=\"MathJax-Span-2822\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.544em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1001.41em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mtext\" id=\"MathJax-Span-2823\" style=\"font-family: STIXGeneral-Regular;\">KV</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 1.461em;\"><span class=\"texatom\" id=\"MathJax-Span-2824\"><span class=\"mrow\" id=\"MathJax-Span-2825\"><span class=\"mtext\" id=\"MathJax-Span-2826\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">prompt</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2827\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>Generate</mtext><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>∣</mo><msub><mtext>KV</mtext><mrow class=\"MJX-TeXAtom-ORD\"><mtext>prompt</mtext></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-329\">\\text{Generate}(x_{n+1} \\mid \\text{KV}_{\\text{prompt}})</script>\n      </li>\n    </ul>\n  </li>\n</ol>\n<p><strong>Cache Initialization</strong>:</p>\n<ul>\n      <li>\n        <p>Compute and store KV tensors for a given prompt:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-328-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mtext>KV</mtext><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>prompt</mtext></mrow></msub><mo>=</mo><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mtext>prompt</mtext><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2798\" style=\"width: 10.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.805em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1008.75em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2799\"><span class=\"msubsup\" id=\"MathJax-Span-2800\"><span style=\"display: inline-block; position: relative; width: 3.544em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1001.41em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mtext\" id=\"MathJax-Span-2801\" style=\"font-family: STIXGeneral-Regular;\">KV</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 1.461em;\"><span class=\"texatom\" id=\"MathJax-Span-2802\"><span class=\"mrow\" id=\"MathJax-Span-2803\"><span class=\"mtext\" id=\"MathJax-Span-2804\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">prompt</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2805\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-2806\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2807\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-2808\" style=\"font-family: STIXGeneral-Regular;\">prompt</span><span class=\"mo\" id=\"MathJax-Span-2809\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mtext>KV</mtext><mrow class=\"MJX-TeXAtom-ORD\"><mtext>prompt</mtext></mrow></msub><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mtext>prompt</mtext><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-328\">\\text{KV}_{\\text{prompt}} = f(\\text{prompt})</script>\n      </li>\n      <li>\n        <p>Store in memory or disk with a unique key (e.g., hash of token IDs).</p>\n      </li>\n    </ul>\n<p>Compute and store KV tensors for a given prompt:</p>\n<p>Store in memory or disk with a unique key (e.g., hash of token IDs).</p>\n<p><strong>Cache Lookup</strong>:</p>\n<ul>\n      <li>For each incoming request, compute a cache key from its prompt.</li>\n      <li>If a match is found, retrieve KV tensors instead of recomputing them.</li>\n    </ul>\n<p><strong>Continue Decoding</strong>:</p>\n<ul>\n      <li>\n        <p>Begin token-by-token generation using the cached KV state:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-329-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>Generate</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>&amp;#x2223;</mo><msub><mtext>KV</mtext><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>prompt</mtext></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2810\" style=\"width: 12.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.419em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1010.37em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2811\"><span class=\"mtext\" id=\"MathJax-Span-2812\" style=\"font-family: STIXGeneral-Regular;\">Generate</span><span class=\"mo\" id=\"MathJax-Span-2813\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2814\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2815\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-2816\"><span class=\"mrow\" id=\"MathJax-Span-2817\"><span class=\"mi\" id=\"MathJax-Span-2818\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mo\" id=\"MathJax-Span-2819\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-2820\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2821\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∣</span><span class=\"msubsup\" id=\"MathJax-Span-2822\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.544em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1001.41em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mtext\" id=\"MathJax-Span-2823\" style=\"font-family: STIXGeneral-Regular;\">KV</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 1.461em;\"><span class=\"texatom\" id=\"MathJax-Span-2824\"><span class=\"mrow\" id=\"MathJax-Span-2825\"><span class=\"mtext\" id=\"MathJax-Span-2826\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">prompt</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2827\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>Generate</mtext><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>∣</mo><msub><mtext>KV</mtext><mrow class=\"MJX-TeXAtom-ORD\"><mtext>prompt</mtext></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-329\">\\text{Generate}(x_{n+1} \\mid \\text{KV}_{\\text{prompt}})</script>\n      </li>\n    </ul>\n<p>Begin token-by-token generation using the cached KV state:</p>\n<h4 id=\"implementation-details-4\">Implementation Details</h4>\n<h5 id=\"cache-granularity\">Cache Granularity</h5>\n<ul>\n  <li><strong>Full Prompt Cache</strong>: Caches the entire KV cache of a prompt. Simple and effective but can use a lot of memory.</li>\n  <li><strong>Prefix Sharing</strong>: If prompts differ by suffix (e.g., <code class=\"language-plaintext highlighter-rouge\">Prompt A + User 1</code> and <code class=\"language-plaintext highlighter-rouge\">Prompt A + User 2</code>), share the KV prefix and compute only the delta.</li>\n  <li><strong>Subgraph Caching</strong>: In more advanced systems, only the first few layers or tokens may be cached.</li>\n</ul>\n<h5 id=\"cache-storage\">Cache Storage</h5>\n<ul>\n  <li><strong>In-Memory KV Cache</strong>: For maximum performance, use GPU or CPU memory with LRU eviction.</li>\n  <li><strong>On-Disk Cache</strong>: Slower but scalable for cold-start scenarios.</li>\n  <li><strong>Keyed by Hash</strong>: Tokenized input is hashed using SHA or CRC to form a cache key. Some systems normalize prompts before hashing.</li>\n</ul>\n<h5 id=\"integration-with-serving-systems\">Integration with Serving Systems</h5>\n<ul>\n  <li>Requires cache-aware batch scheduling.</li>\n  <li>Works best when integrated with dynamic batching and token-level schedulers (e.g., vLLM).</li>\n  <li>May include cache warming: preloading common prompts at system startup.</li>\n</ul>\n<h4 id=\"performance-impact-1\">Performance Impact</h4>\n<ul>\n  <li>\n    <p>Let:</p>\n\n    <ul>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-330-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mi>p</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2828\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2829\"><span class=\"msubsup\" id=\"MathJax-Span-2830\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2831\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2832\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mi>p</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-330\">T_p</script> = time to prefill prompt</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-331-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mi>d</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2833\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2834\"><span class=\"msubsup\" id=\"MathJax-Span-2835\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2836\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2837\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mi>d</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-331\">T_d</script> = time per token for decode</li>\n    </ul>\n  </li>\n  <li>\n    <p>For long prompts (e.g., 1000+ tokens), <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-332-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mi>p</mi></msub><mo>&amp;#x226B;</mo><msub><mi>T</mi><mi>d</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2838\" style=\"width: 4.013em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.336em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1003.34em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2839\"><span class=\"msubsup\" id=\"MathJax-Span-2840\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2841\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2842\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2843\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≫</span><span class=\"msubsup\" id=\"MathJax-Span-2844\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2845\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2846\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mi>p</mi></msub><mo>≫</mo><msub><mi>T</mi><mi>d</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-332\">T_p \\gg T_d</script>, so caching the prefill can save <strong>80–95%</strong> of per-request compute for repeated prompts.</p>\n  </li>\n</ul>\n<p>Let:</p>\n<ul>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-330-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mi>p</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2828\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2829\"><span class=\"msubsup\" id=\"MathJax-Span-2830\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2831\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2832\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mi>p</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-330\">T_p</script> = time to prefill prompt</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-331-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mi>d</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2833\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2834\"><span class=\"msubsup\" id=\"MathJax-Span-2835\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2836\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2837\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mi>d</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-331\">T_d</script> = time per token for decode</li>\n    </ul>\n<p>For long prompts (e.g., 1000+ tokens), <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-332-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mi>p</mi></msub><mo>&amp;#x226B;</mo><msub><mi>T</mi><mi>d</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2838\" style=\"width: 4.013em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.336em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1003.34em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2839\"><span class=\"msubsup\" id=\"MathJax-Span-2840\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2841\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2842\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2843\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≫</span><span class=\"msubsup\" id=\"MathJax-Span-2844\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2845\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2846\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mi>p</mi></msub><mo>≫</mo><msub><mi>T</mi><mi>d</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-332\">T_p \\gg T_d</script>, so caching the prefill can save <strong>80–95%</strong> of per-request compute for repeated prompts.</p>\n<h4 id=\"applications\">Applications</h4>\n<ul>\n  <li><strong>Chat APIs</strong>: System messages or few-shot exemplars remain fixed across turns.</li>\n  <li><strong>Agent Frameworks</strong>: Tools like LangChain often replay the same template structure.</li>\n  <li><strong>Batch Inference</strong>: Multi-user prompts often share context headers (e.g., “Summarize the following…”).</li>\n</ul>\n<h4 id=\"limitations-1\">Limitations</h4>\n<ul>\n  <li>Prompt cache is only useful for <strong>identical</strong> or <strong>prefix-matching</strong> prompts.</li>\n  <li>Memory usage scales with prompt length and cache size.</li>\n  <li>May add overhead for hash computation or miss rate handling.</li>\n  <li>Not helpful for fully dynamic, unique user inputs.</li>\n</ul>",
    "contentMarkdown": "*   Prompt caching is an inference-time optimization that reuses the computed key-value (KV) attention states for frequently occurring or repeated prompt tokens. It eliminates the need to recompute the prefill phase of autoregressive decoding, which is typically the most computationally expensive part of the inference pipeline for long prompts.\n    \n*   This technique is especially effective in systems with repeated system messages, user templates, or static few-shot examples.\n    \n\nPrompt caching is an inference-time optimization that reuses the computed key-value (KV) attention states for frequently occurring or repeated prompt tokens. It eliminates the need to recompute the prefill phase of autoregressive decoding, which is typically the most computationally expensive part of the inference pipeline for long prompts.\n\nThis technique is especially effective in systems with repeated system messages, user templates, or static few-shot examples.\n\n#### Motivation\n\n*   During autoregressive generation, transformer models process the prompt (or context) once to initialize the attention cache. For a prompt of length nnn, this involves a full forward pass through all transformer layers to compute the KV tensors:\n\nK(l)1:n,V(l)1:nfor all layers lK1:n(l),V1:n(l)for all layers l\n\n*   This prefill step is expensive and must be repeated for every new request — even if the prompt is the same.\n    \n*   **Observation**: Many applications use identical or highly similar prompts repeatedly. For example:\n    \n    *   Instructional prompts like: “You are a helpful assistant.”\n    *   Few-shot templates in customer support bots.\n    *   System prompts in chat APIs.\n*   Prompt caching avoids repeated prefill for these common contexts.\n    \n\nThis prefill step is expensive and must be repeated for every new request — even if the prompt is the same.\n\n**Observation**: Many applications use identical or highly similar prompts repeatedly. For example:\n\n*   Instructional prompts like: “You are a helpful assistant.”\n*   Few-shot templates in customer support bots.\n*   System prompts in chat APIs.\n\nPrompt caching avoids repeated prefill for these common contexts.\n\n#### Basic Mechanism\n\n1.  **Cache Initialization**:\n    \n    *   Compute and store KV tensors for a given prompt:\n        \n        KVprompt\\=f(prompt)KVprompt\\=f(prompt)\n        \n        \\\\text{KV}\\_{\\\\text{prompt}} = f(\\\\text{prompt})\n    *   Store in memory or disk with a unique key (e.g., hash of token IDs).\n        \n2.  **Cache Lookup**:\n    \n    *   For each incoming request, compute a cache key from its prompt.\n    *   If a match is found, retrieve KV tensors instead of recomputing them.\n3.  **Continue Decoding**:\n    \n    *   Begin token-by-token generation using the cached KV state:\n        \n        Generate(xn+1∣KVprompt)Generate(xn+1∣KVprompt)\n        \n        \\\\text{Generate}(x\\_{n+1} \\\\mid \\\\text{KV}\\_{\\\\text{prompt}})\n\n**Cache Initialization**:\n\n*   Compute and store KV tensors for a given prompt:\n    \n    KVprompt\\=f(prompt)KVprompt\\=f(prompt)\n    \n    \\\\text{KV}\\_{\\\\text{prompt}} = f(\\\\text{prompt})\n*   Store in memory or disk with a unique key (e.g., hash of token IDs).\n    \n\nCompute and store KV tensors for a given prompt:\n\nStore in memory or disk with a unique key (e.g., hash of token IDs).\n\n**Cache Lookup**:\n\n*   For each incoming request, compute a cache key from its prompt.\n*   If a match is found, retrieve KV tensors instead of recomputing them.\n\n**Continue Decoding**:\n\n*   Begin token-by-token generation using the cached KV state:\n    \n    Generate(xn+1∣KVprompt)Generate(xn+1∣KVprompt)\n    \n    \\\\text{Generate}(x\\_{n+1} \\\\mid \\\\text{KV}\\_{\\\\text{prompt}})\n\nBegin token-by-token generation using the cached KV state:\n\n#### Implementation Details\n\n##### Cache Granularity\n\n*   **Full Prompt Cache**: Caches the entire KV cache of a prompt. Simple and effective but can use a lot of memory.\n*   **Prefix Sharing**: If prompts differ by suffix (e.g., `Prompt A + User 1` and `Prompt A + User 2`), share the KV prefix and compute only the delta.\n*   **Subgraph Caching**: In more advanced systems, only the first few layers or tokens may be cached.\n\n##### Cache Storage\n\n*   **In-Memory KV Cache**: For maximum performance, use GPU or CPU memory with LRU eviction.\n*   **On-Disk Cache**: Slower but scalable for cold-start scenarios.\n*   **Keyed by Hash**: Tokenized input is hashed using SHA or CRC to form a cache key. Some systems normalize prompts before hashing.\n\n##### Integration with Serving Systems\n\n*   Requires cache-aware batch scheduling.\n*   Works best when integrated with dynamic batching and token-level schedulers (e.g., vLLM).\n*   May include cache warming: preloading common prompts at system startup.\n\n#### Performance Impact\n\n*   Let:\n    \n    *   TpTpT\\_p = time to prefill prompt\n    *   TdTdT\\_d = time per token for decode\n*   For long prompts (e.g., 1000+ tokens), Tp≫TdTp≫TdT\\_p \\\\gg T\\_d, so caching the prefill can save **80–95%** of per-request compute for repeated prompts.\n    \n\nLet:\n\n*   TpTpT\\_p = time to prefill prompt\n*   TdTdT\\_d = time per token for decode\n\nFor long prompts (e.g., 1000+ tokens), Tp≫TdTp≫TdT\\_p \\\\gg T\\_d, so caching the prefill can save **80–95%** of per-request compute for repeated prompts.\n\n#### Applications\n\n*   **Chat APIs**: System messages or few-shot exemplars remain fixed across turns.\n*   **Agent Frameworks**: Tools like LangChain often replay the same template structure.\n*   **Batch Inference**: Multi-user prompts often share context headers (e.g., “Summarize the following…”).\n\n#### Limitations\n\n*   Prompt cache is only useful for **identical** or **prefix-matching** prompts.\n*   Memory usage scales with prompt length and cache size.\n*   May add overhead for hash computation or miss rate handling.\n*   Not helpful for fully dynamic, unique user inputs.",
    "contentLength": 42719,
    "wordCount": 814,
    "hasCode": true,
    "hasMath": true,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/model-acceleration/#prompt-caching"
  },
  {
    "id": "ai-model-acceleration-early-exit-and-token-pruning-17",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Inference Optimizations",
    "title": "Early Exit and Token Pruning",
    "order": 17,
    "orderInChapter": 9,
    "contentHtml": "<ul>\n  <li>\n    <p><strong>Early exit</strong> and <strong>token pruning</strong> are inference-time optimizations designed to reduce computation in large transformer models by selectively skipping or trimming parts of the computation graph that have diminishing contribution to the final output. These methods exploit redundancy in token representations and layer-wise stability in transformer models.</p>\n  </li>\n  <li>\n    <p>Both techniques aim to speed up inference without significantly affecting model output quality, making them valuable in latency-sensitive or resource-constrained applications.</p>\n  </li>\n</ul>\n<p><strong>Early exit</strong> and <strong>token pruning</strong> are inference-time optimizations designed to reduce computation in large transformer models by selectively skipping or trimming parts of the computation graph that have diminishing contribution to the final output. These methods exploit redundancy in token representations and layer-wise stability in transformer models.</p>\n<p>Both techniques aim to speed up inference without significantly affecting model output quality, making them valuable in latency-sensitive or resource-constrained applications.</p>\n<h4 id=\"early-exit\">Early Exit</h4>\n<ul>\n  <li><strong>Early exit</strong> allows the model to stop processing certain tokens or even entire sequences at intermediate layers if the model’s confidence in the prediction is already high.</li>\n</ul>\n<h5 id=\"motivation-7\">Motivation</h5>\n<ul>\n  <li>Transformer models use a fixed number of layers (e.g., 24 or 96), but not all tokens require the full depth to make a confident prediction. For example, easily classifiable tokens (like punctuation or common stopwords) may converge earlier than rare or ambiguous tokens.</li>\n</ul>\n<h5 id=\"mechanism\">Mechanism</h5>\n<ul>\n  <li>At each transformer layer <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-333-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2847\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2848\"><span class=\"mi\" id=\"MathJax-Span-2849\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-333\">l</script>, evaluate a confidence metric based on the current token representation:</li>\n</ul>\n<ol>\n  <li>\n    <p><strong>Entropy-Based Confidence</strong>:</p>\n\n    <ul>\n      <li>Compute the softmax output <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-334-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>p</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2850\" style=\"width: 1.513em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1001.25em, 2.503em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2851\"><span class=\"msubsup\" id=\"MathJax-Span-2852\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2853\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-2854\"><span class=\"mrow\" id=\"MathJax-Span-2855\"><span class=\"mo\" id=\"MathJax-Span-2856\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2857\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2858\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>p</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-334\">p^{(l)}</script> from the current logits.</li>\n      <li>\n        <p>Compute entropy:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-335-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>H</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>p</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mo>&amp;#x2212;</mo><munder><mo>&amp;#x2211;</mo><mi>i</mi></munder><msubsup><mi>p</mi><mi>i</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mi>log</mi><mo>&amp;#x2061;</mo><msubsup><mi>p</mi><mi>i</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2859\" style=\"width: 12.451em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.367em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.044em, 1010.37em, 3.596em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2860\"><span class=\"mi\" id=\"MathJax-Span-2861\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2862\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2863\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2864\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-2865\"><span class=\"mrow\" id=\"MathJax-Span-2866\"><span class=\"mo\" id=\"MathJax-Span-2867\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2868\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2869\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2870\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-2871\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mo\" id=\"MathJax-Span-2872\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">−</span><span class=\"munderover\" id=\"MathJax-Span-2873\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(2.867em, 1001.2em, 4.638em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-2874\" style=\"font-family: STIXSizeOneSym; vertical-align: -0.518em;\">∑</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.21em, 4.273em, -999.997em); top: -2.862em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2875\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-2876\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2877\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.73em, 4.273em, -999.997em); top: -4.477em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-2878\"><span class=\"mrow\" id=\"MathJax-Span-2879\"><span class=\"mo\" id=\"MathJax-Span-2880\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2881\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2882\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-2883\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-2884\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">log</span><span class=\"mo\" id=\"MathJax-Span-2885\"></span><span class=\"msubsup\" id=\"MathJax-Span-2886\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2887\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.73em, 4.273em, -999.997em); top: -4.477em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-2888\"><span class=\"mrow\" id=\"MathJax-Span-2889\"><span class=\"mo\" id=\"MathJax-Span-2890\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2891\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2892\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-2893\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -1.559em; border-left: 0px solid; width: 0px; height: 2.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>H</mi><mo stretchy=\"false\">(</mo><msup><mi>p</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo><mo>=</mo><mo>−</mo><munder><mo>∑</mo><mi>i</mi></munder><msubsup><mi>p</mi><mi>i</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mi>log</mi><mo>⁡</mo><msubsup><mi>p</mi><mi>i</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-335\">H(p^{(l)}) = - \\sum_i p_i^{(l)} \\log p_i^{(l)}</script>\n      </li>\n      <li>If entropy <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-336-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;lt;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2894\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2895\"><span class=\"mo\" id=\"MathJax-Span-2896\" style=\"font-family: STIXGeneral-Regular;\">&lt;</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>&lt;</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-336\"><</script> threshold, consider the prediction confident enough to exit.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Cosine Similarity to Previous Layer</strong>:</p>\n\n    <ul>\n      <li>If representation at layer <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-337-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2897\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2898\"><span class=\"mi\" id=\"MathJax-Span-2899\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-337\">l</script> is similar to layer <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-338-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi><mo>&amp;#x2212;</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2900\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.77em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2901\"><span class=\"mi\" id=\"MathJax-Span-2902\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2903\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"mn\" id=\"MathJax-Span-2904\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi><mo>−</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-338\">l-1</script>, the token may have converged.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Learned Gates</strong>:</p>\n\n    <ul>\n      <li>Add a small classification head to each layer to learn exit decisions during training (as in <strong>BranchyNet</strong> or <strong>LayerDrop</strong> approaches).</li>\n    </ul>\n  </li>\n</ol>\n<p><strong>Entropy-Based Confidence</strong>:</p>\n<ul>\n      <li>Compute the softmax output <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-334-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>p</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2850\" style=\"width: 1.513em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1001.25em, 2.503em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2851\"><span class=\"msubsup\" id=\"MathJax-Span-2852\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2853\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-2854\"><span class=\"mrow\" id=\"MathJax-Span-2855\"><span class=\"mo\" id=\"MathJax-Span-2856\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2857\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2858\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>p</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-334\">p^{(l)}</script> from the current logits.</li>\n      <li>\n        <p>Compute entropy:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-335-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>H</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>p</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mo>&amp;#x2212;</mo><munder><mo>&amp;#x2211;</mo><mi>i</mi></munder><msubsup><mi>p</mi><mi>i</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup><mi>log</mi><mo>&amp;#x2061;</mo><msubsup><mi>p</mi><mi>i</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msubsup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2859\" style=\"width: 12.451em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.367em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.044em, 1010.37em, 3.596em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2860\"><span class=\"mi\" id=\"MathJax-Span-2861\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2862\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2863\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2864\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-2865\"><span class=\"mrow\" id=\"MathJax-Span-2866\"><span class=\"mo\" id=\"MathJax-Span-2867\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2868\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2869\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2870\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-2871\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mo\" id=\"MathJax-Span-2872\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">−</span><span class=\"munderover\" id=\"MathJax-Span-2873\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(2.867em, 1001.2em, 4.638em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-2874\" style=\"font-family: STIXSizeOneSym; vertical-align: -0.518em;\">∑</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.21em, 4.273em, -999.997em); top: -2.862em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2875\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-2876\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2877\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.73em, 4.273em, -999.997em); top: -4.477em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-2878\"><span class=\"mrow\" id=\"MathJax-Span-2879\"><span class=\"mo\" id=\"MathJax-Span-2880\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2881\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2882\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-2883\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-2884\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">log</span><span class=\"mo\" id=\"MathJax-Span-2885\"></span><span class=\"msubsup\" id=\"MathJax-Span-2886\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2887\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.73em, 4.273em, -999.997em); top: -4.477em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-2888\"><span class=\"mrow\" id=\"MathJax-Span-2889\"><span class=\"mo\" id=\"MathJax-Span-2890\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-2891\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2892\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -3.695em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-2893\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -1.559em; border-left: 0px solid; width: 0px; height: 2.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>H</mi><mo stretchy=\"false\">(</mo><msup><mi>p</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo><mo>=</mo><mo>−</mo><munder><mo>∑</mo><mi>i</mi></munder><msubsup><mi>p</mi><mi>i</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mi>log</mi><mo>⁡</mo><msubsup><mi>p</mi><mi>i</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">(</mo><mi>l</mi><mo stretchy=\"false\">)</mo></mrow></msubsup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-335\">H(p^{(l)}) = - \\sum_i p_i^{(l)} \\log p_i^{(l)}</script>\n      </li>\n      <li>If entropy <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-336-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;lt;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2894\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2895\"><span class=\"mo\" id=\"MathJax-Span-2896\" style=\"font-family: STIXGeneral-Regular;\">&lt;</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>&lt;</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-336\"><</script> threshold, consider the prediction confident enough to exit.</li>\n    </ul>\n<p>Compute entropy:</p>\n<p><strong>Cosine Similarity to Previous Layer</strong>:</p>\n<ul>\n      <li>If representation at layer <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-337-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2897\" style=\"width: 0.315em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.26em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2898\"><span class=\"mi\" id=\"MathJax-Span-2899\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-337\">l</script> is similar to layer <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-338-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>l</mi><mo>&amp;#x2212;</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2900\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.77em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2901\"><span class=\"mi\" id=\"MathJax-Span-2902\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-2903\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">−</span><span class=\"mn\" id=\"MathJax-Span-2904\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>l</mi><mo>−</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-338\">l-1</script>, the token may have converged.</li>\n    </ul>\n<p><strong>Learned Gates</strong>:</p>\n<ul>\n      <li>Add a small classification head to each layer to learn exit decisions during training (as in <strong>BranchyNet</strong> or <strong>LayerDrop</strong> approaches).</li>\n    </ul>\n<h5 id=\"implementation\">Implementation</h5>\n<ul>\n  <li>Models like <strong>BERT with Early Exit</strong> (DEEPL) implement classifier heads at multiple depths.</li>\n  <li>Hugging Face <code class=\"language-plaintext highlighter-rouge\">transformers</code> has prototype support for early exit in sequence classification.</li>\n  <li>Requires threshold tuning to balance accuracy and latency.</li>\n</ul>\n<h5 id=\"benefits-2\">Benefits</h5>\n<ul>\n  <li>Reduces average inference depth (e.g., from 24 layers to 12–16 for many tokens).</li>\n  <li>Saves computation for simpler or high-confidence examples.</li>\n  <li>Ideal for classification or QA tasks where tokenwise prediction is not necessary.</li>\n</ul>\n<h5 id=\"limitations-2\">Limitations</h5>\n<ul>\n  <li>Adds overhead from confidence computation at intermediate layers.</li>\n  <li>Not widely adopted in generation tasks due to sequential dependencies between tokens.</li>\n</ul>\n<h4 id=\"token-pruning\">Token Pruning</h4>\n<ul>\n  <li><strong>Token pruning</strong> reduces the number of tokens that are propagated through the deeper layers of a transformer by identifying and removing tokens with low contextual importance.</li>\n</ul>\n<h5 id=\"motivation-8\">Motivation</h5>\n<ul>\n  <li>\n    <p>In many attention-based computations, some tokens contribute very little to the output. For example, padding tokens or tokens with low attention weights to the rest of the sequence.</p>\n  </li>\n  <li>\n    <p>Pruning these tokens saves compute in later layers, especially in long-context models or batch scenarios.</p>\n  </li>\n</ul>\n<p>In many attention-based computations, some tokens contribute very little to the output. For example, padding tokens or tokens with low attention weights to the rest of the sequence.</p>\n<p>Pruning these tokens saves compute in later layers, especially in long-context models or batch scenarios.</p>\n<h5 id=\"mechanism-1\">Mechanism</h5>\n<ol>\n  <li>\n    <p><strong>Attention-Based Pruning</strong>:</p>\n\n    <ul>\n      <li>\n        <p>Compute the <strong>attention score variance</strong> or <strong>total attention mass</strong> a token receives:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-339-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>&amp;#x03B1;</mi><mi>i</mi></msub><mo>=</mo><munder><mo>&amp;#x2211;</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>j</mi></mrow></munder><mtext>Attention</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2905\" style=\"width: 11.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 9.898em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.044em, 1009.85em, 3.753em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2906\"><span class=\"msubsup\" id=\"MathJax-Span-2907\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2908\" style=\"font-family: STIXGeneral-Italic;\">α</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2909\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2910\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"munderover\" id=\"MathJax-Span-2911\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(2.867em, 1001.2em, 4.638em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-2912\" style=\"font-family: STIXSizeOneSym; vertical-align: -0.518em;\">∑</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.21em, 4.43em, -999.997em); top: -2.862em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-2913\"><span class=\"mrow\" id=\"MathJax-Span-2914\"><span class=\"mi\" id=\"MathJax-Span-2915\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mtext\" id=\"MathJax-Span-2916\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">Attention</span><span class=\"mo\" id=\"MathJax-Span-2917\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2918\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2919\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-2920\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2921\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-2922\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2923\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-2924\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2925\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -1.747em; border-left: 0px solid; width: 0px; height: 3.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>α</mi><mi>i</mi></msub><mo>=</mo><munder><mo>∑</mo><mrow class=\"MJX-TeXAtom-ORD\"><mi>j</mi></mrow></munder><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-339\">\\alpha_i = \\sum_{j} \\text{Attention}(x_i, x_j)</script>\n      </li>\n      <li>\n        <p>Prune tokens with low total attention received or given.</p>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Top-<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-340-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2926\" style=\"width: 0.622em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.519em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.52em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2927\"><span class=\"mi\" id=\"MathJax-Span-2928\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-340\">k</script> Token Selection</strong>:</p>\n\n    <ul>\n      <li>Keep only the top-<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-341-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2929\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2930\"><span class=\"mi\" id=\"MathJax-Span-2931\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-341\">k</script> most important tokens per head or per sequence based on learned importance scores.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Dynamic Thresholding</strong>:</p>\n\n    <ul>\n      <li>Use learned or rule-based thresholds to drop tokens whose impact is below a tunable cutoff.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Progressive Pruning</strong>:</p>\n\n    <ul>\n      <li>Start with full tokens, and prune more aggressively as layers go deeper.</li>\n    </ul>\n  </li>\n</ol>\n<p><strong>Attention-Based Pruning</strong>:</p>\n<ul>\n      <li>\n        <p>Compute the <strong>attention score variance</strong> or <strong>total attention mass</strong> a token receives:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-339-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>&amp;#x03B1;</mi><mi>i</mi></msub><mo>=</mo><munder><mo>&amp;#x2211;</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>j</mi></mrow></munder><mtext>Attention</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2905\" style=\"width: 11.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 9.898em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.044em, 1009.85em, 3.753em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2906\"><span class=\"msubsup\" id=\"MathJax-Span-2907\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2908\" style=\"font-family: STIXGeneral-Italic;\">α</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-2909\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2910\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"munderover\" id=\"MathJax-Span-2911\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(2.867em, 1001.2em, 4.638em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-2912\" style=\"font-family: STIXSizeOneSym; vertical-align: -0.518em;\">∑</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.21em, 4.43em, -999.997em); top: -2.862em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-2913\"><span class=\"mrow\" id=\"MathJax-Span-2914\"><span class=\"mi\" id=\"MathJax-Span-2915\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mtext\" id=\"MathJax-Span-2916\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">Attention</span><span class=\"mo\" id=\"MathJax-Span-2917\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-2918\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2919\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-2920\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2921\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-2922\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-2923\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-2924\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-2925\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -1.747em; border-left: 0px solid; width: 0px; height: 3.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>α</mi><mi>i</mi></msub><mo>=</mo><munder><mo>∑</mo><mrow class=\"MJX-TeXAtom-ORD\"><mi>j</mi></mrow></munder><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-339\">\\alpha_i = \\sum_{j} \\text{Attention}(x_i, x_j)</script>\n      </li>\n      <li>\n        <p>Prune tokens with low total attention received or given.</p>\n      </li>\n    </ul>\n<p>Compute the <strong>attention score variance</strong> or <strong>total attention mass</strong> a token receives:</p>\n<p>Prune tokens with low total attention received or given.</p>\n<p><strong>Top-<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-340-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2926\" style=\"width: 0.622em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.519em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.52em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2927\"><span class=\"mi\" id=\"MathJax-Span-2928\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-340\">k</script> Token Selection</strong>:</p>\n<ul>\n      <li>Keep only the top-<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-341-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2929\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2930\"><span class=\"mi\" id=\"MathJax-Span-2931\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-341\">k</script> most important tokens per head or per sequence based on learned importance scores.</li>\n    </ul>\n<p><strong>Dynamic Thresholding</strong>:</p>\n<ul>\n      <li>Use learned or rule-based thresholds to drop tokens whose impact is below a tunable cutoff.</li>\n    </ul>\n<p><strong>Progressive Pruning</strong>:</p>\n<ul>\n      <li>Start with full tokens, and prune more aggressively as layers go deeper.</li>\n    </ul>\n<h5 id=\"implementation-1\">Implementation</h5>\n<ul>\n  <li>Typically done at attention module boundaries.</li>\n  <li>Can be combined with sparse attention mechanisms.</li>\n  <li>Token indices need to be tracked to reconstruct output or map back to the original sequence.</li>\n</ul>\n<h5 id=\"benefits-3\">Benefits</h5>\n<ul>\n  <li>Reduces computation in deeper layers, especially for long sequences.</li>\n  <li>Improves throughput with minimal impact on quality in summarization, QA, and retrieval tasks.</li>\n  <li>Can be applied during training for alignment with inference.</li>\n</ul>\n<h5 id=\"limitations-3\">Limitations</h5>\n<ul>\n  <li>May degrade quality if pruning is too aggressive or incorrectly calibrated.</li>\n  <li>Requires complex index tracking and masking logic.</li>\n  <li>Harder to apply in autoregressive settings where all tokens are sequentially dependent.</li>\n</ul>\n<h4 id=\"tools-and-research\">Tools and Research</h4>\n<ul>\n  <li><strong>DeLighT</strong>, <strong>LayerDrop</strong>, and <strong>EarlyBERT</strong> for early exit variants.</li>\n  <li><strong>SparseFormer</strong>, <strong>Synthesizer</strong>, and <strong>Longformer</strong> introduce related token reduction ideas.</li>\n  <li>Hugging Face and NVIDIA’s Megatron support token pruning hooks in research branches.</li>\n</ul>",
    "contentMarkdown": "*   **Early exit** and **token pruning** are inference-time optimizations designed to reduce computation in large transformer models by selectively skipping or trimming parts of the computation graph that have diminishing contribution to the final output. These methods exploit redundancy in token representations and layer-wise stability in transformer models.\n    \n*   Both techniques aim to speed up inference without significantly affecting model output quality, making them valuable in latency-sensitive or resource-constrained applications.\n    \n\n**Early exit** and **token pruning** are inference-time optimizations designed to reduce computation in large transformer models by selectively skipping or trimming parts of the computation graph that have diminishing contribution to the final output. These methods exploit redundancy in token representations and layer-wise stability in transformer models.\n\nBoth techniques aim to speed up inference without significantly affecting model output quality, making them valuable in latency-sensitive or resource-constrained applications.\n\n#### Early Exit\n\n*   **Early exit** allows the model to stop processing certain tokens or even entire sequences at intermediate layers if the model’s confidence in the prediction is already high.\n\n##### Motivation\n\n*   Transformer models use a fixed number of layers (e.g., 24 or 96), but not all tokens require the full depth to make a confident prediction. For example, easily classifiable tokens (like punctuation or common stopwords) may converge earlier than rare or ambiguous tokens.\n\n##### Mechanism\n\n*   At each transformer layer lll, evaluate a confidence metric based on the current token representation:\n\n1.  **Entropy-Based Confidence**:\n    \n    *   Compute the softmax output p(l)p(l)p^{(l)} from the current logits.\n    *   Compute entropy:\n        \n        H(p(l))\\=−∑ip(l)ilogp(l)iH(p(l))\\=−∑ipi(l)log⁡pi(l)\n        \n        H(p^{(l)}) = - \\\\sum\\_i p\\_i^{(l)} \\\\log p\\_i^{(l)}\n    *   If entropy <<< threshold, consider the prediction confident enough to exit.\n2.  **Cosine Similarity to Previous Layer**:\n    \n    *   If representation at layer lll is similar to layer l−1l−1l-1, the token may have converged.\n3.  **Learned Gates**:\n    \n    *   Add a small classification head to each layer to learn exit decisions during training (as in **BranchyNet** or **LayerDrop** approaches).\n\n**Entropy-Based Confidence**:\n\n*   Compute the softmax output p(l)p(l)p^{(l)} from the current logits.\n*   Compute entropy:\n    \n    H(p(l))\\=−∑ip(l)ilogp(l)iH(p(l))\\=−∑ipi(l)log⁡pi(l)\n    \n    H(p^{(l)}) = - \\\\sum\\_i p\\_i^{(l)} \\\\log p\\_i^{(l)}\n*   If entropy <<< threshold, consider the prediction confident enough to exit.\n\nCompute entropy:\n\n**Cosine Similarity to Previous Layer**:\n\n*   If representation at layer lll is similar to layer l−1l−1l-1, the token may have converged.\n\n**Learned Gates**:\n\n*   Add a small classification head to each layer to learn exit decisions during training (as in **BranchyNet** or **LayerDrop** approaches).\n\n##### Implementation\n\n*   Models like **BERT with Early Exit** (DEEPL) implement classifier heads at multiple depths.\n*   Hugging Face `transformers` has prototype support for early exit in sequence classification.\n*   Requires threshold tuning to balance accuracy and latency.\n\n##### Benefits\n\n*   Reduces average inference depth (e.g., from 24 layers to 12–16 for many tokens).\n*   Saves computation for simpler or high-confidence examples.\n*   Ideal for classification or QA tasks where tokenwise prediction is not necessary.\n\n##### Limitations\n\n*   Adds overhead from confidence computation at intermediate layers.\n*   Not widely adopted in generation tasks due to sequential dependencies between tokens.\n\n#### Token Pruning\n\n*   **Token pruning** reduces the number of tokens that are propagated through the deeper layers of a transformer by identifying and removing tokens with low contextual importance.\n\n##### Motivation\n\n*   In many attention-based computations, some tokens contribute very little to the output. For example, padding tokens or tokens with low attention weights to the rest of the sequence.\n    \n*   Pruning these tokens saves compute in later layers, especially in long-context models or batch scenarios.\n    \n\nIn many attention-based computations, some tokens contribute very little to the output. For example, padding tokens or tokens with low attention weights to the rest of the sequence.\n\nPruning these tokens saves compute in later layers, especially in long-context models or batch scenarios.\n\n##### Mechanism\n\n1.  **Attention-Based Pruning**:\n    \n    *   Compute the **attention score variance** or **total attention mass** a token receives:\n        \n        αi\\=∑jAttention(xi,xj)αi\\=∑jAttention(xi,xj)\n        \n        \\\\alpha\\_i = \\\\sum\\_{j} \\\\text{Attention}(x\\_i, x\\_j)\n    *   Prune tokens with low total attention received or given.\n        \n2.  **Top-kkk Token Selection**:\n    \n    *   Keep only the top-kkk most important tokens per head or per sequence based on learned importance scores.\n3.  **Dynamic Thresholding**:\n    \n    *   Use learned or rule-based thresholds to drop tokens whose impact is below a tunable cutoff.\n4.  **Progressive Pruning**:\n    \n    *   Start with full tokens, and prune more aggressively as layers go deeper.\n\n**Attention-Based Pruning**:\n\n*   Compute the **attention score variance** or **total attention mass** a token receives:\n    \n    αi\\=∑jAttention(xi,xj)αi\\=∑jAttention(xi,xj)\n    \n    \\\\alpha\\_i = \\\\sum\\_{j} \\\\text{Attention}(x\\_i, x\\_j)\n*   Prune tokens with low total attention received or given.\n    \n\nCompute the **attention score variance** or **total attention mass** a token receives:\n\nPrune tokens with low total attention received or given.\n\n**Top-kkk Token Selection**:\n\n*   Keep only the top-kkk most important tokens per head or per sequence based on learned importance scores.\n\n**Dynamic Thresholding**:\n\n*   Use learned or rule-based thresholds to drop tokens whose impact is below a tunable cutoff.\n\n**Progressive Pruning**:\n\n*   Start with full tokens, and prune more aggressively as layers go deeper.\n\n##### Implementation\n\n*   Typically done at attention module boundaries.\n*   Can be combined with sparse attention mechanisms.\n*   Token indices need to be tracked to reconstruct output or map back to the original sequence.\n\n##### Benefits\n\n*   Reduces computation in deeper layers, especially for long sequences.\n*   Improves throughput with minimal impact on quality in summarization, QA, and retrieval tasks.\n*   Can be applied during training for alignment with inference.\n\n##### Limitations\n\n*   May degrade quality if pruning is too aggressive or incorrectly calibrated.\n*   Requires complex index tracking and masking logic.\n*   Harder to apply in autoregressive settings where all tokens are sequentially dependent.\n\n#### Tools and Research\n\n*   **DeLighT**, **LayerDrop**, and **EarlyBERT** for early exit variants.\n*   **SparseFormer**, **Synthesizer**, and **Longformer** introduce related token reduction ideas.\n*   Hugging Face and NVIDIA’s Megatron support token pruning hooks in research branches.",
    "contentLength": 55417,
    "wordCount": 953,
    "hasCode": true,
    "hasMath": true,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/model-acceleration/#early-exit-and-token-pruning"
  },
  {
    "id": "ai-model-acceleration-hardware-aware-scheduling-18",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Inference Optimizations",
    "title": "Hardware-Aware Scheduling",
    "order": 18,
    "orderInChapter": 10,
    "contentHtml": "<ul>\n  <li>\n    <p><strong>Hardware-aware scheduling</strong> refers to a set of optimization strategies that tailor the execution of neural network inference to the specific architecture and performance characteristics of the underlying hardware—such as GPUs, TPUs, or specialized accelerators. These optimizations aim to improve compute throughput, memory utilization, and latency by orchestrating how and when operations are executed.</p>\n  </li>\n  <li>\n    <p>This is especially important for transformer inference, where workloads are large, heterogeneous (e.g., KV cache lookups, matrix multiplies, normalization), and sensitive to memory bandwidth and parallelism.</p>\n  </li>\n</ul>\n<p><strong>Hardware-aware scheduling</strong> refers to a set of optimization strategies that tailor the execution of neural network inference to the specific architecture and performance characteristics of the underlying hardware—such as GPUs, TPUs, or specialized accelerators. These optimizations aim to improve compute throughput, memory utilization, and latency by orchestrating how and when operations are executed.</p>\n<p>This is especially important for transformer inference, where workloads are large, heterogeneous (e.g., KV cache lookups, matrix multiplies, normalization), and sensitive to memory bandwidth and parallelism.</p>\n<h4 id=\"motivation-9\">Motivation</h4>\n<ul>\n  <li>\n    <p>Transformer inference involves many stages of computation and memory access:</p>\n\n    <ul>\n      <li>Matrix multiplications (GEMMs) in attention and feed-forward blocks.</li>\n      <li>Data movement between layers and devices.</li>\n      <li>KV cache management and resizing.</li>\n      <li>Softmax, activation, and normalization operations.</li>\n    </ul>\n  </li>\n  <li>\n    <p>Without careful scheduling, bottlenecks can emerge due to:</p>\n\n    <ul>\n      <li>Underutilized compute units (e.g., Tensor Cores).</li>\n      <li>Memory stalls and cache thrashing.</li>\n      <li>Synchronization overhead between layers or streams.</li>\n    </ul>\n  </li>\n  <li>\n    <p>Hardware-aware scheduling optimizes these execution flows to keep the pipeline full and latency low.</p>\n  </li>\n</ul>\n<p>Transformer inference involves many stages of computation and memory access:</p>\n<ul>\n      <li>Matrix multiplications (GEMMs) in attention and feed-forward blocks.</li>\n      <li>Data movement between layers and devices.</li>\n      <li>KV cache management and resizing.</li>\n      <li>Softmax, activation, and normalization operations.</li>\n    </ul>\n<p>Without careful scheduling, bottlenecks can emerge due to:</p>\n<ul>\n      <li>Underutilized compute units (e.g., Tensor Cores).</li>\n      <li>Memory stalls and cache thrashing.</li>\n      <li>Synchronization overhead between layers or streams.</li>\n    </ul>\n<p>Hardware-aware scheduling optimizes these execution flows to keep the pipeline full and latency low.</p>\n<h4 id=\"core-techniques\">Core Techniques</h4>\n<h5 id=\"stream-parallelism\">Stream Parallelism</h5>\n<ul>\n  <li>\n    <p>Modern GPUs support multiple concurrent execution streams (e.g., via CUDA). In transformer inference:</p>\n\n    <ul>\n      <li>Use separate CUDA streams for different model stages (e.g., one for KV cache update, one for GEMM).</li>\n      <li>Overlap memory copies (e.g., <code class=\"language-plaintext highlighter-rouge\">cudaMemcpyAsync</code>) with compute to hide latency.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Example</strong>:</p>\n\n    <div class=\"language-cpp highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code11\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code11\"> <span class=\"n\">cudaMemcpyAsync</span><span class=\"p\">(...,</span> <span class=\"n\">stream1</span><span class=\"p\">);</span>\n <span class=\"n\">cublasGemmEx</span><span class=\"p\">(...,</span> <span class=\"n\">stream2</span><span class=\"p\">);</span>  <span class=\"c1\">// runs concurrently with stream1</span>\n</code></pre></div>    </div>\n  </li>\n</ul>\n<p>Modern GPUs support multiple concurrent execution streams (e.g., via CUDA). In transformer inference:</p>\n<ul>\n      <li>Use separate CUDA streams for different model stages (e.g., one for KV cache update, one for GEMM).</li>\n      <li>Overlap memory copies (e.g., <code class=\"language-plaintext highlighter-rouge\">cudaMemcpyAsync</code>) with compute to hide latency.</li>\n    </ul>\n<p><strong>Example</strong>:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code11\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code11\"> <span class=\"n\">cudaMemcpyAsync</span><span class=\"p\">(...,</span> <span class=\"n\">stream1</span><span class=\"p\">);</span>\n <span class=\"n\">cublasGemmEx</span><span class=\"p\">(...,</span> <span class=\"n\">stream2</span><span class=\"p\">);</span>  <span class=\"c1\">// runs concurrently with stream1</span>\n</code></pre>\n<h5 id=\"tensor-core-utilization\">Tensor Core Utilization</h5>\n<ul>\n  <li>\n    <p>Tensor cores are specialized units in NVIDIA GPUs for low-precision matrix ops (e.g., <code class=\"language-plaintext highlighter-rouge\">float16</code>, <code class=\"language-plaintext highlighter-rouge\">bfloat16</code>, <code class=\"language-plaintext highlighter-rouge\">int8</code>). To maximize their usage:</p>\n\n    <ul>\n      <li>Ensure all matrix multiplications are aligned to multiple-of-8 dimensions.</li>\n      <li>Use fused kernels to eliminate intermediate <code class=\"language-plaintext highlighter-rouge\">float32</code> conversions.</li>\n      <li>Prefer mixed-precision pipelines (AMP / <code class=\"language-plaintext highlighter-rouge\">float16</code>) for higher throughput.</li>\n    </ul>\n  </li>\n  <li>\n    <p>Libraries like <strong>cuBLAS</strong>, <strong>FlashAttention</strong>, and <strong>TensorRT</strong> handle these optimizations automatically when configured correctly.</p>\n  </li>\n</ul>\n<p>Tensor cores are specialized units in NVIDIA GPUs for low-precision matrix ops (e.g., <code class=\"language-plaintext highlighter-rouge\">float16</code>, <code class=\"language-plaintext highlighter-rouge\">bfloat16</code>, <code class=\"language-plaintext highlighter-rouge\">int8</code>). To maximize their usage:</p>\n<ul>\n      <li>Ensure all matrix multiplications are aligned to multiple-of-8 dimensions.</li>\n      <li>Use fused kernels to eliminate intermediate <code class=\"language-plaintext highlighter-rouge\">float32</code> conversions.</li>\n      <li>Prefer mixed-precision pipelines (AMP / <code class=\"language-plaintext highlighter-rouge\">float16</code>) for higher throughput.</li>\n    </ul>\n<p>Libraries like <strong>cuBLAS</strong>, <strong>FlashAttention</strong>, and <strong>TensorRT</strong> handle these optimizations automatically when configured correctly.</p>\n<h5 id=\"operator-placement-and-reordering\">Operator Placement and Reordering</h5>\n<ul>\n  <li>\n    <p>Efficient inference scheduling may involve reordering or co-locating operations based on:</p>\n\n    <ul>\n      <li><strong>Memory locality:</strong> Fuse or group operations that share data.</li>\n      <li><strong>Execution time:</strong> Prioritize long-running ops earlier in the pipeline.</li>\n      <li><strong>Device affinity:</strong> Keep frequently accessed data on the same GPU or chip.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Example</strong>: Run attention blocks first in multi-layer transformer if they dominate compute time, allowing FFNs to be prefetched concurrently.</p>\n  </li>\n</ul>\n<p>Efficient inference scheduling may involve reordering or co-locating operations based on:</p>\n<ul>\n      <li><strong>Memory locality:</strong> Fuse or group operations that share data.</li>\n      <li><strong>Execution time:</strong> Prioritize long-running ops earlier in the pipeline.</li>\n      <li><strong>Device affinity:</strong> Keep frequently accessed data on the same GPU or chip.</li>\n    </ul>\n<p><strong>Example</strong>: Run attention blocks first in multi-layer transformer if they dominate compute time, allowing FFNs to be prefetched concurrently.</p>\n<h5 id=\"kv-cache-management\">KV Cache Management</h5>\n<ul>\n  <li>\n    <p>Efficient KV cache handling is essential in decoder models:</p>\n\n    <ul>\n      <li><strong>Paged KV Cache</strong>: Used in systems like vLLM, stores KV in contiguous memory pages and allows random-access updates.</li>\n      <li><strong>Memory Pools</strong>: Preallocate KV buffers for each request and reuse them to avoid memory fragmentation.</li>\n      <li><strong>Lazy Allocation</strong>: Delay cache instantiation until first generation step to save memory for short prompts.</li>\n    </ul>\n  </li>\n</ul>\n<p>Efficient KV cache handling is essential in decoder models:</p>\n<ul>\n      <li><strong>Paged KV Cache</strong>: Used in systems like vLLM, stores KV in contiguous memory pages and allows random-access updates.</li>\n      <li><strong>Memory Pools</strong>: Preallocate KV buffers for each request and reuse them to avoid memory fragmentation.</li>\n      <li><strong>Lazy Allocation</strong>: Delay cache instantiation until first generation step to save memory for short prompts.</li>\n    </ul>\n<h5 id=\"pipeline-and-model-parallelism\">Pipeline and Model Parallelism</h5>\n<ul>\n  <li>\n    <p>In large-model deployments:</p>\n\n    <ul>\n      <li><strong>Pipeline Parallelism</strong>: Distribute transformer layers across devices. Stage execution overlaps compute and communication.</li>\n      <li><strong>Tensor Parallelism</strong>: Split individual tensor dimensions (e.g., weights) across devices for large GEMMs.</li>\n    </ul>\n  </li>\n  <li>\n    <p>Combined, these allow serving models with billions of parameters across multiple GPUs efficiently.</p>\n  </li>\n</ul>\n<p>In large-model deployments:</p>\n<ul>\n      <li><strong>Pipeline Parallelism</strong>: Distribute transformer layers across devices. Stage execution overlaps compute and communication.</li>\n      <li><strong>Tensor Parallelism</strong>: Split individual tensor dimensions (e.g., weights) across devices for large GEMMs.</li>\n    </ul>\n<p>Combined, these allow serving models with billions of parameters across multiple GPUs efficiently.</p>\n<h5 id=\"custom-kernel-scheduling\">Custom Kernel Scheduling</h5>\n<ul>\n  <li>\n    <p>Frameworks like Triton and TVM allow defining and tuning custom kernels:</p>\n\n    <ul>\n      <li>Auto-tune tiling sizes and shared memory usage.</li>\n      <li>Schedule GPU threads based on warp/block-level parallelism.</li>\n      <li>Implement custom token-wise or layer-wise scheduling logic.</li>\n    </ul>\n  </li>\n</ul>\n<p>Frameworks like Triton and TVM allow defining and tuning custom kernels:</p>\n<ul>\n      <li>Auto-tune tiling sizes and shared memory usage.</li>\n      <li>Schedule GPU threads based on warp/block-level parallelism.</li>\n      <li>Implement custom token-wise or layer-wise scheduling logic.</li>\n    </ul>\n<h5 id=\"cache-and-memory-prefetching\">Cache and Memory Prefetching</h5>\n<ul>\n  <li>Use <code class=\"language-plaintext highlighter-rouge\">__prefetch</code> instructions or async loads to bring data into shared memory before it is needed.</li>\n  <li>Overlap KV fetches with matmul execution to hide memory latency.</li>\n</ul>\n<h4 id=\"deployment-aware-strategies\">Deployment-Aware Strategies</h4>\n<ul>\n  <li><strong>Load Balancing</strong>: Use dynamic batching queues with GPU-aware request routing (e.g., based on latency or memory pressure).</li>\n  <li><strong>Thread Affinity</strong>: Bind computation to specific CPU cores or NUMA zones in CPU-bound systems.</li>\n  <li><strong>Execution Profiling</strong>: Use profilers like NVIDIA Nsight Systems or PyTorch Profiler to tune for bottlenecks.</li>\n</ul>\n<h4 id=\"ecosystem-support\">Ecosystem Support</h4>\n<ul>\n  <li><strong>NVIDIA TensorRT</strong> and <strong>FasterTransformer</strong>: Hardware-aware fused kernels and scheduling policies.</li>\n  <li><strong>ONNX Runtime (ORT)</strong>: Execution providers tuned for different hardware (CUDA, DirectML, TensorRT).</li>\n  <li><strong>DeepSpeed</strong>, <strong>vLLM</strong>, <strong>Triton</strong>, and <strong>TVM</strong>: Offer fine-grained control over scheduling and memory layout.</li>\n</ul>\n<h4 id=\"performance-impact-2\">Performance Impact</h4>\n<ul>\n  <li>\n    <p>Hardware-aware scheduling can yield:</p>\n\n    <ul>\n      <li><strong>1.5<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-342-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2932\" style=\"width: 0.726em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.571em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.501em, 1000.52em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2933\"><span class=\"mo\" id=\"MathJax-Span-2934\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-342\">\\times</script>–4<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-343-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2935\" style=\"width: 0.726em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.571em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.501em, 1000.52em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2936\"><span class=\"mo\" id=\"MathJax-Span-2937\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-343\">\\times</script> speedup</strong> over naive scheduling for long sequences or large batches.</li>\n      <li>Better <strong>multi-GPU scaling</strong> for high-throughput inference.</li>\n      <li>Lower <strong>latency variability</strong> in real-time serving environments.</li>\n    </ul>\n  </li>\n</ul>\n<p>Hardware-aware scheduling can yield:</p>\n<ul>\n      <li><strong>1.5<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-342-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2932\" style=\"width: 0.726em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.571em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.501em, 1000.52em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2933\"><span class=\"mo\" id=\"MathJax-Span-2934\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-342\">\\times</script>–4<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-343-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-2935\" style=\"width: 0.726em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.571em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.501em, 1000.52em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2936\"><span class=\"mo\" id=\"MathJax-Span-2937\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-343\">\\times</script> speedup</strong> over naive scheduling for long sequences or large batches.</li>\n      <li>Better <strong>multi-GPU scaling</strong> for high-throughput inference.</li>\n      <li>Lower <strong>latency variability</strong> in real-time serving environments.</li>\n    </ul>",
    "contentMarkdown": "*   **Hardware-aware scheduling** refers to a set of optimization strategies that tailor the execution of neural network inference to the specific architecture and performance characteristics of the underlying hardware—such as GPUs, TPUs, or specialized accelerators. These optimizations aim to improve compute throughput, memory utilization, and latency by orchestrating how and when operations are executed.\n    \n*   This is especially important for transformer inference, where workloads are large, heterogeneous (e.g., KV cache lookups, matrix multiplies, normalization), and sensitive to memory bandwidth and parallelism.\n    \n\n**Hardware-aware scheduling** refers to a set of optimization strategies that tailor the execution of neural network inference to the specific architecture and performance characteristics of the underlying hardware—such as GPUs, TPUs, or specialized accelerators. These optimizations aim to improve compute throughput, memory utilization, and latency by orchestrating how and when operations are executed.\n\nThis is especially important for transformer inference, where workloads are large, heterogeneous (e.g., KV cache lookups, matrix multiplies, normalization), and sensitive to memory bandwidth and parallelism.\n\n#### Motivation\n\n*   Transformer inference involves many stages of computation and memory access:\n    \n    *   Matrix multiplications (GEMMs) in attention and feed-forward blocks.\n    *   Data movement between layers and devices.\n    *   KV cache management and resizing.\n    *   Softmax, activation, and normalization operations.\n*   Without careful scheduling, bottlenecks can emerge due to:\n    \n    *   Underutilized compute units (e.g., Tensor Cores).\n    *   Memory stalls and cache thrashing.\n    *   Synchronization overhead between layers or streams.\n*   Hardware-aware scheduling optimizes these execution flows to keep the pipeline full and latency low.\n    \n\nTransformer inference involves many stages of computation and memory access:\n\n*   Matrix multiplications (GEMMs) in attention and feed-forward blocks.\n*   Data movement between layers and devices.\n*   KV cache management and resizing.\n*   Softmax, activation, and normalization operations.\n\nWithout careful scheduling, bottlenecks can emerge due to:\n\n*   Underutilized compute units (e.g., Tensor Cores).\n*   Memory stalls and cache thrashing.\n*   Synchronization overhead between layers or streams.\n\nHardware-aware scheduling optimizes these execution flows to keep the pipeline full and latency low.\n\n#### Core Techniques\n\n##### Stream Parallelism\n\n*   Modern GPUs support multiple concurrent execution streams (e.g., via CUDA). In transformer inference:\n    \n    *   Use separate CUDA streams for different model stages (e.g., one for KV cache update, one for GEMM).\n    *   Overlap memory copies (e.g., `cudaMemcpyAsync`) with compute to hide latency.\n*   **Example**:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n     `cudaMemcpyAsync(..., stream1);  cublasGemmEx(..., stream2);  // runs concurrently with stream1`\n    \n\nModern GPUs support multiple concurrent execution streams (e.g., via CUDA). In transformer inference:\n\n*   Use separate CUDA streams for different model stages (e.g., one for KV cache update, one for GEMM).\n*   Overlap memory copies (e.g., `cudaMemcpyAsync`) with compute to hide latency.\n\n**Example**:\n\n![](https://aman.ai/images/copy.png)\n\n `cudaMemcpyAsync(..., stream1);  cublasGemmEx(..., stream2);  // runs concurrently with stream1`\n\n##### Tensor Core Utilization\n\n*   Tensor cores are specialized units in NVIDIA GPUs for low-precision matrix ops (e.g., `float16`, `bfloat16`, `int8`). To maximize their usage:\n    \n    *   Ensure all matrix multiplications are aligned to multiple-of-8 dimensions.\n    *   Use fused kernels to eliminate intermediate `float32` conversions.\n    *   Prefer mixed-precision pipelines (AMP / `float16`) for higher throughput.\n*   Libraries like **cuBLAS**, **FlashAttention**, and **TensorRT** handle these optimizations automatically when configured correctly.\n    \n\nTensor cores are specialized units in NVIDIA GPUs for low-precision matrix ops (e.g., `float16`, `bfloat16`, `int8`). To maximize their usage:\n\n*   Ensure all matrix multiplications are aligned to multiple-of-8 dimensions.\n*   Use fused kernels to eliminate intermediate `float32` conversions.\n*   Prefer mixed-precision pipelines (AMP / `float16`) for higher throughput.\n\nLibraries like **cuBLAS**, **FlashAttention**, and **TensorRT** handle these optimizations automatically when configured correctly.\n\n##### Operator Placement and Reordering\n\n*   Efficient inference scheduling may involve reordering or co-locating operations based on:\n    \n    *   **Memory locality:** Fuse or group operations that share data.\n    *   **Execution time:** Prioritize long-running ops earlier in the pipeline.\n    *   **Device affinity:** Keep frequently accessed data on the same GPU or chip.\n*   **Example**: Run attention blocks first in multi-layer transformer if they dominate compute time, allowing FFNs to be prefetched concurrently.\n    \n\nEfficient inference scheduling may involve reordering or co-locating operations based on:\n\n*   **Memory locality:** Fuse or group operations that share data.\n*   **Execution time:** Prioritize long-running ops earlier in the pipeline.\n*   **Device affinity:** Keep frequently accessed data on the same GPU or chip.\n\n**Example**: Run attention blocks first in multi-layer transformer if they dominate compute time, allowing FFNs to be prefetched concurrently.\n\n##### KV Cache Management\n\n*   Efficient KV cache handling is essential in decoder models:\n    \n    *   **Paged KV Cache**: Used in systems like vLLM, stores KV in contiguous memory pages and allows random-access updates.\n    *   **Memory Pools**: Preallocate KV buffers for each request and reuse them to avoid memory fragmentation.\n    *   **Lazy Allocation**: Delay cache instantiation until first generation step to save memory for short prompts.\n\nEfficient KV cache handling is essential in decoder models:\n\n*   **Paged KV Cache**: Used in systems like vLLM, stores KV in contiguous memory pages and allows random-access updates.\n*   **Memory Pools**: Preallocate KV buffers for each request and reuse them to avoid memory fragmentation.\n*   **Lazy Allocation**: Delay cache instantiation until first generation step to save memory for short prompts.\n\n##### Pipeline and Model Parallelism\n\n*   In large-model deployments:\n    \n    *   **Pipeline Parallelism**: Distribute transformer layers across devices. Stage execution overlaps compute and communication.\n    *   **Tensor Parallelism**: Split individual tensor dimensions (e.g., weights) across devices for large GEMMs.\n*   Combined, these allow serving models with billions of parameters across multiple GPUs efficiently.\n    \n\nIn large-model deployments:\n\n*   **Pipeline Parallelism**: Distribute transformer layers across devices. Stage execution overlaps compute and communication.\n*   **Tensor Parallelism**: Split individual tensor dimensions (e.g., weights) across devices for large GEMMs.\n\nCombined, these allow serving models with billions of parameters across multiple GPUs efficiently.\n\n##### Custom Kernel Scheduling\n\n*   Frameworks like Triton and TVM allow defining and tuning custom kernels:\n    \n    *   Auto-tune tiling sizes and shared memory usage.\n    *   Schedule GPU threads based on warp/block-level parallelism.\n    *   Implement custom token-wise or layer-wise scheduling logic.\n\nFrameworks like Triton and TVM allow defining and tuning custom kernels:\n\n*   Auto-tune tiling sizes and shared memory usage.\n*   Schedule GPU threads based on warp/block-level parallelism.\n*   Implement custom token-wise or layer-wise scheduling logic.\n\n##### Cache and Memory Prefetching\n\n*   Use `__prefetch` instructions or async loads to bring data into shared memory before it is needed.\n*   Overlap KV fetches with matmul execution to hide memory latency.\n\n#### Deployment-Aware Strategies\n\n*   **Load Balancing**: Use dynamic batching queues with GPU-aware request routing (e.g., based on latency or memory pressure).\n*   **Thread Affinity**: Bind computation to specific CPU cores or NUMA zones in CPU-bound systems.\n*   **Execution Profiling**: Use profilers like NVIDIA Nsight Systems or PyTorch Profiler to tune for bottlenecks.\n\n#### Ecosystem Support\n\n*   **NVIDIA TensorRT** and **FasterTransformer**: Hardware-aware fused kernels and scheduling policies.\n*   **ONNX Runtime (ORT)**: Execution providers tuned for different hardware (CUDA, DirectML, TensorRT).\n*   **DeepSpeed**, **vLLM**, **Triton**, and **TVM**: Offer fine-grained control over scheduling and memory layout.\n\n#### Performance Impact\n\n*   Hardware-aware scheduling can yield:\n    \n    *   **1.5××\\\\times–4××\\\\times speedup** over naive scheduling for long sequences or large batches.\n    *   Better **multi-GPU scaling** for high-throughput inference.\n    *   Lower **latency variability** in real-time serving environments.\n\nHardware-aware scheduling can yield:\n\n*   **1.5××\\\\times–4××\\\\times speedup** over naive scheduling for long sequences or large batches.\n*   Better **multi-GPU scaling** for high-throughput inference.\n*   Lower **latency variability** in real-time serving environments.",
    "contentLength": 18037,
    "wordCount": 1189,
    "hasCode": true,
    "hasMath": true,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/model-acceleration/#hardware-aware-scheduling"
  },
  {
    "id": "ai-model-acceleration-comparative-analysis-19",
    "articleSlug": "model-acceleration",
    "articleTitle": "Model Acceleration",
    "category": "Algorithms/Architecture",
    "chapter": "Inference Optimizations",
    "title": "Comparative Analysis",
    "order": 19,
    "orderInChapter": 11,
    "contentHtml": "<div align=\"center\">\n<table class=\"tg\">\n<thead>\n<tr>\n<th class=\"tg-hcenter-valign-first\"><strong>Technique</strong></th>\n<th class=\"tg-hcenter-valign-first\"><strong>Purpose</strong></th>\n<th class=\"tg-hcenter-valign-first\"><strong>Key Benefits</strong></th>\n<th class=\"tg-hcenter-valign-first\"><strong>Primary Use Cases</strong></th>\n<th class=\"tg-hcenter-valign-second\"><strong>Implementation Notes</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tg-tleft-valign-first\">KV Caching</td>\n<td class=\"tg-tleft-valign-first\">Reuse attention keys/values from previous tokens</td>\n<td class=\"tg-tleft-valign-first\">Reduces per-token latency after first step</td>\n<td class=\"tg-tleft-valign-first\">Autoregressive decoding (GPT, LLaMA)</td>\n<td class=\"tg-tleft-valign-second\">Requires careful cache management; starts from second token onward</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Model Quantization</td>\n<td class=\"tg-tleft-valign-first\">Use lower-precision weights/activations</td>\n<td class=\"tg-tleft-valign-first\">Reduces memory and compute cost</td>\n<td class=\"tg-tleft-valign-first\">Edge inference, high-throughput serving</td>\n<td class=\"tg-tleft-valign-second\"><code class=\"language-plaintext highlighter-rouge\">int8</code>/PTQ for speed; QAT for better accuracy; needs hardware with quantization support</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Operator Fusion</td>\n<td class=\"tg-tleft-valign-first\">Combine adjacent ops into single kernel</td>\n<td class=\"tg-tleft-valign-first\">Reduces memory access and kernel launch overhead</td>\n<td class=\"tg-tleft-valign-first\">Attention blocks, FFNs, LayerNorm + activation</td>\n<td class=\"tg-tleft-valign-second\">Use graph compilers (XLA, TorchScript), or fused CUDA kernels (TensorRT, FasterTransformer)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Speculative Decoding</td>\n<td class=\"tg-tleft-valign-first\">Use draft model to guess multiple tokens</td>\n<td class=\"tg-tleft-valign-first\">Reduces number of full-model forward passes</td>\n<td class=\"tg-tleft-valign-first\">Long-form generation, chatbots</td>\n<td class=\"tg-tleft-valign-second\">Needs a lightweight auxiliary model; uses top-1 match or log-prob threshold for validation</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">FlashAttention &amp; Kernels</td>\n<td class=\"tg-tleft-valign-first\">Memory-efficient attention computation</td>\n<td class=\"tg-tleft-valign-first\">Reduces memory usage and boosts speed</td>\n<td class=\"tg-tleft-valign-first\">Long-sequence LLMs, multi-head attention</td>\n<td class=\"tg-tleft-valign-second\">Implemented with CUDA (FlashAttention), or Triton/xFormers; avoids storing full attention matrix</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Batching</td>\n<td class=\"tg-tleft-valign-first\">Process multiple requests together</td>\n<td class=\"tg-tleft-valign-first\">Increases throughput and GPU utilization</td>\n<td class=\"tg-tleft-valign-first\">High-concurrency inference (API servers, batch jobs)</td>\n<td class=\"tg-tleft-valign-second\">Dynamic and token-level batching supported in vLLM, DeepSpeed, TensorRT</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Prefilling</td>\n<td class=\"tg-tleft-valign-first\">Precompute KV cache from prompt tokens</td>\n<td class=\"tg-tleft-valign-first\">Avoids recomputation in autoregressive models</td>\n<td class=\"tg-tleft-valign-first\">Chat and generation tasks with long prompts</td>\n<td class=\"tg-tleft-valign-second\">Often paired with batching; prompt KV cache initialized before decoding begins</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Prompt Caching</td>\n<td class=\"tg-tleft-valign-first\">Cache KV states of repeated prompts</td>\n<td class=\"tg-tleft-valign-first\">Saves time and compute on repeated static contexts</td>\n<td class=\"tg-tleft-valign-first\">Chat APIs, few-shot prompt templates</td>\n<td class=\"tg-tleft-valign-second\">Requires hashing/tokenizing prompt and storing cache; memory usage grows with cache diversity</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Early Exit</td>\n<td class=\"tg-tleft-valign-first\">Stop processing tokens/layers early based on confidence</td>\n<td class=\"tg-tleft-valign-first\">Reduces per-token compute in deep models</td>\n<td class=\"tg-tleft-valign-first\">Classification, QA tasks</td>\n<td class=\"tg-tleft-valign-second\">Needs entropy or learned gating logic; difficult to apply in token-dependent generation</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Token Pruning</td>\n<td class=\"tg-tleft-valign-first\">Discard low-importance tokens during inference</td>\n<td class=\"tg-tleft-valign-first\">Reduces sequence length in deeper layers</td>\n<td class=\"tg-tleft-valign-first\">Long-sequence summarization, QA</td>\n<td class=\"tg-tleft-valign-second\">Attention-based importance scoring; careful masking and index tracking required</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Hardware-Aware Scheduling</td>\n<td class=\"tg-tleft-valign-first\">Optimize kernel execution for specific hardware</td>\n<td class=\"tg-tleft-valign-first\">Maximizes throughput and minimizes latency</td>\n<td class=\"tg-tleft-valign-first\">All transformer-based workloads</td>\n<td class=\"tg-tleft-valign-second\">Includes stream parallelism, memory prefetch, cache layout, tensor core tuning, and multi-GPU distribution</td>\n</tr>\n</tbody>\n</table>\n</div>\n<table class=\"tg\">\n<thead>\n<tr>\n<th class=\"tg-hcenter-valign-first\"><strong>Technique</strong></th>\n<th class=\"tg-hcenter-valign-first\"><strong>Purpose</strong></th>\n<th class=\"tg-hcenter-valign-first\"><strong>Key Benefits</strong></th>\n<th class=\"tg-hcenter-valign-first\"><strong>Primary Use Cases</strong></th>\n<th class=\"tg-hcenter-valign-second\"><strong>Implementation Notes</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tg-tleft-valign-first\">KV Caching</td>\n<td class=\"tg-tleft-valign-first\">Reuse attention keys/values from previous tokens</td>\n<td class=\"tg-tleft-valign-first\">Reduces per-token latency after first step</td>\n<td class=\"tg-tleft-valign-first\">Autoregressive decoding (GPT, LLaMA)</td>\n<td class=\"tg-tleft-valign-second\">Requires careful cache management; starts from second token onward</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Model Quantization</td>\n<td class=\"tg-tleft-valign-first\">Use lower-precision weights/activations</td>\n<td class=\"tg-tleft-valign-first\">Reduces memory and compute cost</td>\n<td class=\"tg-tleft-valign-first\">Edge inference, high-throughput serving</td>\n<td class=\"tg-tleft-valign-second\"><code class=\"language-plaintext highlighter-rouge\">int8</code>/PTQ for speed; QAT for better accuracy; needs hardware with quantization support</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Operator Fusion</td>\n<td class=\"tg-tleft-valign-first\">Combine adjacent ops into single kernel</td>\n<td class=\"tg-tleft-valign-first\">Reduces memory access and kernel launch overhead</td>\n<td class=\"tg-tleft-valign-first\">Attention blocks, FFNs, LayerNorm + activation</td>\n<td class=\"tg-tleft-valign-second\">Use graph compilers (XLA, TorchScript), or fused CUDA kernels (TensorRT, FasterTransformer)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Speculative Decoding</td>\n<td class=\"tg-tleft-valign-first\">Use draft model to guess multiple tokens</td>\n<td class=\"tg-tleft-valign-first\">Reduces number of full-model forward passes</td>\n<td class=\"tg-tleft-valign-first\">Long-form generation, chatbots</td>\n<td class=\"tg-tleft-valign-second\">Needs a lightweight auxiliary model; uses top-1 match or log-prob threshold for validation</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">FlashAttention &amp; Kernels</td>\n<td class=\"tg-tleft-valign-first\">Memory-efficient attention computation</td>\n<td class=\"tg-tleft-valign-first\">Reduces memory usage and boosts speed</td>\n<td class=\"tg-tleft-valign-first\">Long-sequence LLMs, multi-head attention</td>\n<td class=\"tg-tleft-valign-second\">Implemented with CUDA (FlashAttention), or Triton/xFormers; avoids storing full attention matrix</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Batching</td>\n<td class=\"tg-tleft-valign-first\">Process multiple requests together</td>\n<td class=\"tg-tleft-valign-first\">Increases throughput and GPU utilization</td>\n<td class=\"tg-tleft-valign-first\">High-concurrency inference (API servers, batch jobs)</td>\n<td class=\"tg-tleft-valign-second\">Dynamic and token-level batching supported in vLLM, DeepSpeed, TensorRT</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Prefilling</td>\n<td class=\"tg-tleft-valign-first\">Precompute KV cache from prompt tokens</td>\n<td class=\"tg-tleft-valign-first\">Avoids recomputation in autoregressive models</td>\n<td class=\"tg-tleft-valign-first\">Chat and generation tasks with long prompts</td>\n<td class=\"tg-tleft-valign-second\">Often paired with batching; prompt KV cache initialized before decoding begins</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Prompt Caching</td>\n<td class=\"tg-tleft-valign-first\">Cache KV states of repeated prompts</td>\n<td class=\"tg-tleft-valign-first\">Saves time and compute on repeated static contexts</td>\n<td class=\"tg-tleft-valign-first\">Chat APIs, few-shot prompt templates</td>\n<td class=\"tg-tleft-valign-second\">Requires hashing/tokenizing prompt and storing cache; memory usage grows with cache diversity</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Early Exit</td>\n<td class=\"tg-tleft-valign-first\">Stop processing tokens/layers early based on confidence</td>\n<td class=\"tg-tleft-valign-first\">Reduces per-token compute in deep models</td>\n<td class=\"tg-tleft-valign-first\">Classification, QA tasks</td>\n<td class=\"tg-tleft-valign-second\">Needs entropy or learned gating logic; difficult to apply in token-dependent generation</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Token Pruning</td>\n<td class=\"tg-tleft-valign-first\">Discard low-importance tokens during inference</td>\n<td class=\"tg-tleft-valign-first\">Reduces sequence length in deeper layers</td>\n<td class=\"tg-tleft-valign-first\">Long-sequence summarization, QA</td>\n<td class=\"tg-tleft-valign-second\">Attention-based importance scoring; careful masking and index tracking required</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Hardware-Aware Scheduling</td>\n<td class=\"tg-tleft-valign-first\">Optimize kernel execution for specific hardware</td>\n<td class=\"tg-tleft-valign-first\">Maximizes throughput and minimizes latency</td>\n<td class=\"tg-tleft-valign-first\">All transformer-based workloads</td>\n<td class=\"tg-tleft-valign-second\">Includes stream parallelism, memory prefetch, cache layout, tensor core tuning, and multi-GPU distribution</td>\n</tr>\n</tbody>\n</table>",
    "contentMarkdown": "**Technique**\n\n**Purpose**\n\n**Key Benefits**\n\n**Primary Use Cases**\n\n**Implementation Notes**\n\nKV Caching\n\nReuse attention keys/values from previous tokens\n\nReduces per-token latency after first step\n\nAutoregressive decoding (GPT, LLaMA)\n\nRequires careful cache management; starts from second token onward\n\nModel Quantization\n\nUse lower-precision weights/activations\n\nReduces memory and compute cost\n\nEdge inference, high-throughput serving\n\n`int8`/PTQ for speed; QAT for better accuracy; needs hardware with quantization support\n\nOperator Fusion\n\nCombine adjacent ops into single kernel\n\nReduces memory access and kernel launch overhead\n\nAttention blocks, FFNs, LayerNorm + activation\n\nUse graph compilers (XLA, TorchScript), or fused CUDA kernels (TensorRT, FasterTransformer)\n\nSpeculative Decoding\n\nUse draft model to guess multiple tokens\n\nReduces number of full-model forward passes\n\nLong-form generation, chatbots\n\nNeeds a lightweight auxiliary model; uses top-1 match or log-prob threshold for validation\n\nFlashAttention & Kernels\n\nMemory-efficient attention computation\n\nReduces memory usage and boosts speed\n\nLong-sequence LLMs, multi-head attention\n\nImplemented with CUDA (FlashAttention), or Triton/xFormers; avoids storing full attention matrix\n\nBatching\n\nProcess multiple requests together\n\nIncreases throughput and GPU utilization\n\nHigh-concurrency inference (API servers, batch jobs)\n\nDynamic and token-level batching supported in vLLM, DeepSpeed, TensorRT\n\nPrefilling\n\nPrecompute KV cache from prompt tokens\n\nAvoids recomputation in autoregressive models\n\nChat and generation tasks with long prompts\n\nOften paired with batching; prompt KV cache initialized before decoding begins\n\nPrompt Caching\n\nCache KV states of repeated prompts\n\nSaves time and compute on repeated static contexts\n\nChat APIs, few-shot prompt templates\n\nRequires hashing/tokenizing prompt and storing cache; memory usage grows with cache diversity\n\nEarly Exit\n\nStop processing tokens/layers early based on confidence\n\nReduces per-token compute in deep models\n\nClassification, QA tasks\n\nNeeds entropy or learned gating logic; difficult to apply in token-dependent generation\n\nToken Pruning\n\nDiscard low-importance tokens during inference\n\nReduces sequence length in deeper layers\n\nLong-sequence summarization, QA\n\nAttention-based importance scoring; careful masking and index tracking required\n\nHardware-Aware Scheduling\n\nOptimize kernel execution for specific hardware\n\nMaximizes throughput and minimizes latency\n\nAll transformer-based workloads\n\nIncludes stream parallelism, memory prefetch, cache layout, tensor core tuning, and multi-GPU distribution\n\n**Technique**\n\n**Purpose**\n\n**Key Benefits**\n\n**Primary Use Cases**\n\n**Implementation Notes**\n\nKV Caching\n\nReuse attention keys/values from previous tokens\n\nReduces per-token latency after first step\n\nAutoregressive decoding (GPT, LLaMA)\n\nRequires careful cache management; starts from second token onward\n\nModel Quantization\n\nUse lower-precision weights/activations\n\nReduces memory and compute cost\n\nEdge inference, high-throughput serving\n\n`int8`/PTQ for speed; QAT for better accuracy; needs hardware with quantization support\n\nOperator Fusion\n\nCombine adjacent ops into single kernel\n\nReduces memory access and kernel launch overhead\n\nAttention blocks, FFNs, LayerNorm + activation\n\nUse graph compilers (XLA, TorchScript), or fused CUDA kernels (TensorRT, FasterTransformer)\n\nSpeculative Decoding\n\nUse draft model to guess multiple tokens\n\nReduces number of full-model forward passes\n\nLong-form generation, chatbots\n\nNeeds a lightweight auxiliary model; uses top-1 match or log-prob threshold for validation\n\nFlashAttention & Kernels\n\nMemory-efficient attention computation\n\nReduces memory usage and boosts speed\n\nLong-sequence LLMs, multi-head attention\n\nImplemented with CUDA (FlashAttention), or Triton/xFormers; avoids storing full attention matrix\n\nBatching\n\nProcess multiple requests together\n\nIncreases throughput and GPU utilization\n\nHigh-concurrency inference (API servers, batch jobs)\n\nDynamic and token-level batching supported in vLLM, DeepSpeed, TensorRT\n\nPrefilling\n\nPrecompute KV cache from prompt tokens\n\nAvoids recomputation in autoregressive models\n\nChat and generation tasks with long prompts\n\nOften paired with batching; prompt KV cache initialized before decoding begins\n\nPrompt Caching\n\nCache KV states of repeated prompts\n\nSaves time and compute on repeated static contexts\n\nChat APIs, few-shot prompt templates\n\nRequires hashing/tokenizing prompt and storing cache; memory usage grows with cache diversity\n\nEarly Exit\n\nStop processing tokens/layers early based on confidence\n\nReduces per-token compute in deep models\n\nClassification, QA tasks\n\nNeeds entropy or learned gating logic; difficult to apply in token-dependent generation\n\nToken Pruning\n\nDiscard low-importance tokens during inference\n\nReduces sequence length in deeper layers\n\nLong-sequence summarization, QA\n\nAttention-based importance scoring; careful masking and index tracking required\n\nHardware-Aware Scheduling\n\nOptimize kernel execution for specific hardware\n\nMaximizes throughput and minimizes latency\n\nAll transformer-based workloads\n\nIncludes stream parallelism, memory prefetch, cache layout, tensor core tuning, and multi-GPU distribution",
    "contentLength": 10551,
    "wordCount": 648,
    "hasCode": true,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/model-acceleration/#comparative-analysis"
  }
]