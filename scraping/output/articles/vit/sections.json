[
  {
    "id": "ai-vit-code-explanation-1",
    "articleSlug": "vit",
    "articleTitle": "Vision Transformer (ViT)",
    "category": "Vision",
    "chapter": "Implementation",
    "title": "Code Explanation",
    "order": 1,
    "orderInChapter": 1,
    "contentHtml": "<ul>\n  <li>\n    <p>In this implementation:</p>\n\n    <ul>\n      <li>The <code class=\"language-plaintext highlighter-rouge\">rearrange</code> function from <code class=\"language-plaintext highlighter-rouge\">einops</code> reshapes the input tensor into a sequence of flattened image patches. Each patch is of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-158\" style=\"width: 2.086em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1001.72em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-159\"><span class=\"msubsup\" id=\"MathJax-Span-160\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-161\" style=\"font-family: STIXGeneral-Italic;\">P</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.628em;\"><span class=\"mn\" id=\"MathJax-Span-162\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-163\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">P^2 C</script>, where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-164\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-165\"><span class=\"mi\" id=\"MathJax-Span-166\" style=\"font-family: STIXGeneral-Italic;\">P</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">P</script> is the patch size and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-26-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-167\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-168\"><span class=\"mi\" id=\"MathJax-Span-169\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-26\">C</script> is the number of image channels.</li>\n      <li>The <code class=\"language-plaintext highlighter-rouge\">nn.Linear</code> layer (<code class=\"language-plaintext highlighter-rouge\">self.project_patches</code>) acts as the learnable fully connected projection, mapping each flattened patch to a <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-27-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-170\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-171\"><span class=\"mi\" id=\"MathJax-Span-172\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-27\">D</script>-dimensional embedding vector. This corresponds to the initial linear projection stage in ViT.</li>\n      <li>A learnable classification token (<code class=\"language-plaintext highlighter-rouge\">cls_token</code>) is optionally prepended to the patch sequence when <code class=\"language-plaintext highlighter-rouge\">classification=True</code>.</li>\n      <li>Learnable positional embeddings (<code class=\"language-plaintext highlighter-rouge\">pos_emb1D</code>) are added to each token to encode spatial information.</li>\n      <li>The resulting sequence is processed by a Transformer encoder, which models global dependencies between patches.</li>\n      <li>For classification tasks, only the output corresponding to the classification token is passed through a final linear layer (<code class=\"language-plaintext highlighter-rouge\">mlp_head</code>) to produce class logits. For non-classification tasks, the output embeddings for all tokens are returned.</li>\n    </ul>\n  </li>\n  <li>\n    <p>This structure provides a clean and modular ViT design while retaining flexibility for experimentation with architectural parameters.</p>\n  </li>\n</ul>\n<p>In this implementation:</p>\n<ul>\n      <li>The <code class=\"language-plaintext highlighter-rouge\">rearrange</code> function from <code class=\"language-plaintext highlighter-rouge\">einops</code> reshapes the input tensor into a sequence of flattened image patches. Each patch is of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-158\" style=\"width: 2.086em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1001.72em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-159\"><span class=\"msubsup\" id=\"MathJax-Span-160\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-161\" style=\"font-family: STIXGeneral-Italic;\">P</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.628em;\"><span class=\"mn\" id=\"MathJax-Span-162\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-163\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">P^2 C</script>, where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-164\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-165\"><span class=\"mi\" id=\"MathJax-Span-166\" style=\"font-family: STIXGeneral-Italic;\">P</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">P</script> is the patch size and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-26-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-167\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-168\"><span class=\"mi\" id=\"MathJax-Span-169\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-26\">C</script> is the number of image channels.</li>\n      <li>The <code class=\"language-plaintext highlighter-rouge\">nn.Linear</code> layer (<code class=\"language-plaintext highlighter-rouge\">self.project_patches</code>) acts as the learnable fully connected projection, mapping each flattened patch to a <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-27-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-170\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-171\"><span class=\"mi\" id=\"MathJax-Span-172\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-27\">D</script>-dimensional embedding vector. This corresponds to the initial linear projection stage in ViT.</li>\n      <li>A learnable classification token (<code class=\"language-plaintext highlighter-rouge\">cls_token</code>) is optionally prepended to the patch sequence when <code class=\"language-plaintext highlighter-rouge\">classification=True</code>.</li>\n      <li>Learnable positional embeddings (<code class=\"language-plaintext highlighter-rouge\">pos_emb1D</code>) are added to each token to encode spatial information.</li>\n      <li>The resulting sequence is processed by a Transformer encoder, which models global dependencies between patches.</li>\n      <li>For classification tasks, only the output corresponding to the classification token is passed through a final linear layer (<code class=\"language-plaintext highlighter-rouge\">mlp_head</code>) to produce class logits. For non-classification tasks, the output embeddings for all tokens are returned.</li>\n    </ul>\n<p>This structure provides a clean and modular ViT design while retaining flexibility for experimentation with architectural parameters.</p>",
    "contentMarkdown": "*   In this implementation:\n    \n    *   The `rearrange` function from `einops` reshapes the input tensor into a sequence of flattened image patches. Each patch is of shape P2CP2CP^2 C, where PPP is the patch size and CCC is the number of image channels.\n    *   The `nn.Linear` layer (`self.project_patches`) acts as the learnable fully connected projection, mapping each flattened patch to a DDD\\-dimensional embedding vector. This corresponds to the initial linear projection stage in ViT.\n    *   A learnable classification token (`cls_token`) is optionally prepended to the patch sequence when `classification=True`.\n    *   Learnable positional embeddings (`pos_emb1D`) are added to each token to encode spatial information.\n    *   The resulting sequence is processed by a Transformer encoder, which models global dependencies between patches.\n    *   For classification tasks, only the output corresponding to the classification token is passed through a final linear layer (`mlp_head`) to produce class logits. For non-classification tasks, the output embeddings for all tokens are returned.\n*   This structure provides a clean and modular ViT design while retaining flexibility for experimentation with architectural parameters.\n    \n\nIn this implementation:\n\n*   The `rearrange` function from `einops` reshapes the input tensor into a sequence of flattened image patches. Each patch is of shape P2CP2CP^2 C, where PPP is the patch size and CCC is the number of image channels.\n*   The `nn.Linear` layer (`self.project_patches`) acts as the learnable fully connected projection, mapping each flattened patch to a DDD\\-dimensional embedding vector. This corresponds to the initial linear projection stage in ViT.\n*   A learnable classification token (`cls_token`) is optionally prepended to the patch sequence when `classification=True`.\n*   Learnable positional embeddings (`pos_emb1D`) are added to each token to encode spatial information.\n*   The resulting sequence is processed by a Transformer encoder, which models global dependencies between patches.\n*   For classification tasks, only the output corresponding to the classification token is passed through a final linear layer (`mlp_head`) to produce class logits. For non-classification tasks, the output embeddings for all tokens are returned.\n\nThis structure provides a clean and modular ViT design while retaining flexibility for experimentation with architectural parameters.",
    "contentLength": 14785,
    "wordCount": 340,
    "hasCode": true,
    "hasMath": true,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/vit/#code-explanation"
  },
  {
    "id": "ai-vit-conv2d-equivalence-for-patch-projection-2",
    "articleSlug": "vit",
    "articleTitle": "Vision Transformer (ViT)",
    "category": "Vision",
    "chapter": "Implementation",
    "title": "Conv2D Equivalence for Patch Projection",
    "order": 2,
    "orderInChapter": 2,
    "contentHtml": "<ul>\n  <li>\n    <p>Although this code uses <code class=\"language-plaintext highlighter-rouge\">nn.Linear</code> for patch projection, such as the <a href=\"https://github.com/google-research/vision_transformer\">official Google ViT code</a> and <a href=\"https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/layers/patch_embed.py\">timm’s <code class=\"language-plaintext highlighter-rouge\">PatchEmbed</code> module</a> replace it with a <code class=\"language-plaintext highlighter-rouge\">nn.Conv2d</code> layer, where:</p>\n\n    <ul>\n      <li><strong>Kernel size</strong> = patch size (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-28-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-173\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-174\"><span class=\"mi\" id=\"MathJax-Span-175\" style=\"font-family: STIXGeneral-Italic;\">P</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-28\">P</script>)</li>\n      <li><strong>Stride</strong> = patch size (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-29-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-176\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-177\"><span class=\"mi\" id=\"MathJax-Span-178\" style=\"font-family: STIXGeneral-Italic;\">P</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-29\">P</script>)</li>\n      <li><strong>Input channels</strong> = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-179\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-180\"><span class=\"mi\" id=\"MathJax-Span-181\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-30\">C</script> (number of image channels)</li>\n      <li><strong>Output channels</strong> = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-182\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-183\"><span class=\"mi\" id=\"MathJax-Span-184\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-31\">D</script> (embedding dimension)</li>\n    </ul>\n  </li>\n  <li>\n    <p>This convolution operation directly extracts and projects patches without explicit flattening. It is mathematically equivalent to the linear projection in this implementation, but it is more efficient on GPUs due to optimized convolution kernels.</p>\n  </li>\n</ul>\n<p>Although this code uses <code class=\"language-plaintext highlighter-rouge\">nn.Linear</code> for patch projection, such as the <a href=\"https://github.com/google-research/vision_transformer\">official Google ViT code</a> and <a href=\"https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/layers/patch_embed.py\">timm’s <code class=\"language-plaintext highlighter-rouge\">PatchEmbed</code> module</a> replace it with a <code class=\"language-plaintext highlighter-rouge\">nn.Conv2d</code> layer, where:</p>\n<ul>\n      <li><strong>Kernel size</strong> = patch size (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-28-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-173\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-174\"><span class=\"mi\" id=\"MathJax-Span-175\" style=\"font-family: STIXGeneral-Italic;\">P</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-28\">P</script>)</li>\n      <li><strong>Stride</strong> = patch size (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-29-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-176\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-177\"><span class=\"mi\" id=\"MathJax-Span-178\" style=\"font-family: STIXGeneral-Italic;\">P</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-29\">P</script>)</li>\n      <li><strong>Input channels</strong> = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-179\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-180\"><span class=\"mi\" id=\"MathJax-Span-181\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-30\">C</script> (number of image channels)</li>\n      <li><strong>Output channels</strong> = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-182\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-183\"><span class=\"mi\" id=\"MathJax-Span-184\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-31\">D</script> (embedding dimension)</li>\n    </ul>\n<p>This convolution operation directly extracts and projects patches without explicit flattening. It is mathematically equivalent to the linear projection in this implementation, but it is more efficient on GPUs due to optimized convolution kernels.</p>",
    "contentMarkdown": "*   Although this code uses `nn.Linear` for patch projection, such as the [official Google ViT code](https://github.com/google-research/vision_transformer) and [timm’s `PatchEmbed` module](https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/layers/patch_embed.py) replace it with a `nn.Conv2d` layer, where:\n    \n    *   **Kernel size** = patch size (PPP)\n    *   **Stride** = patch size (PPP)\n    *   **Input channels** = CCC (number of image channels)\n    *   **Output channels** = DDD (embedding dimension)\n*   This convolution operation directly extracts and projects patches without explicit flattening. It is mathematically equivalent to the linear projection in this implementation, but it is more efficient on GPUs due to optimized convolution kernels.\n    \n\nAlthough this code uses `nn.Linear` for patch projection, such as the [official Google ViT code](https://github.com/google-research/vision_transformer) and [timm’s `PatchEmbed` module](https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/layers/patch_embed.py) replace it with a `nn.Conv2d` layer, where:\n\n*   **Kernel size** = patch size (PPP)\n*   **Stride** = patch size (PPP)\n*   **Input channels** = CCC (number of image channels)\n*   **Output channels** = DDD (embedding dimension)\n\nThis convolution operation directly extracts and projects patches without explicit flattening. It is mathematically equivalent to the linear projection in this implementation, but it is more efficient on GPUs due to optimized convolution kernels.",
    "contentLength": 11779,
    "wordCount": 180,
    "hasCode": true,
    "hasMath": true,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/vit/#conv2d-equivalence-for-patch-projection"
  },
  {
    "id": "ai-vit-why-does-vit-use-linear-projections-of-flattened-p-3",
    "articleSlug": "vit",
    "articleTitle": "Vision Transformer (ViT)",
    "category": "Vision",
    "chapter": "FAQs",
    "title": "Why Does ViT Use Linear Projections of Flattened Patches at the Input?",
    "order": 3,
    "orderInChapter": 1,
    "contentHtml": "<ul>\n  <li>\n    <p>The ViT model uses linear projections of flattened patches at the input for several reasons:</p>\n\n    <ol>\n      <li>\n        <p><strong>Reduction of Dimensionality</strong>: Images are inherently high-dimensional data. Flattening and projecting the patches into a lower-dimensional space makes the computation more manageable and efficient. This process is analogous to reducing the resolution of an image while retaining essential features.</p>\n      </li>\n      <li>\n        <p><strong>Uniform Data Representation</strong>: By flattening and projecting, the vision transformer treats the image patches similarly to how tokens (words) are treated in a language model. This uniformity allows the use of transformer architecture, originally designed for NLP tasks, in processing visual data.</p>\n      </li>\n      <li>\n        <p><strong>Capturing Local Features</strong>: Each patch represents local features of the image. By projecting these patches, the model can capture and process these local features effectively. This is akin to how convolutional neural networks (CNNs) operate, but with a different approach.</p>\n      </li>\n      <li>\n        <p><strong>Scalability and Flexibility</strong>: The approach allows the model to be scalable to different image sizes and resolutions. It also offers flexibility in terms of the size of the patches and the depth of the network.</p>\n      </li>\n      <li>\n        <p><strong>Enabling Positional Encoding</strong>: Flattening and projecting the patches allow for the addition of positional encodings. In transformers, positional encodings are crucial as they provide the model with information about the relative or absolute position of the patches in the image. Unlike CNNs, transformers do not inherently understand the order or position of the input data, so positional encodings are necessary.</p>\n      </li>\n      <li>\n        <p><strong>Facilitating Self-Attention Mechanism</strong>: The transformer architecture relies heavily on the self-attention mechanism, which computes the response at a position in a sequence (in this case, a sequence of patches) by attending to all positions and computing a weighted sum of their features. Flattened and projected patches are conducive to this mechanism.</p>\n      </li>\n    </ol>\n  </li>\n  <li>\n    <p>In summary, the use of linear projections of flattened patches in ViT is a strategic design choice that leverages the strengths of transformer architecture while making it suitable for processing visual data. This method allows the model to handle high-dimensional image data efficiently, capture local features, and utilize the self-attention mechanism effectively.</p>\n  </li>\n</ul>\n<p>The ViT model uses linear projections of flattened patches at the input for several reasons:</p>\n<ol>\n      <li>\n        <p><strong>Reduction of Dimensionality</strong>: Images are inherently high-dimensional data. Flattening and projecting the patches into a lower-dimensional space makes the computation more manageable and efficient. This process is analogous to reducing the resolution of an image while retaining essential features.</p>\n      </li>\n      <li>\n        <p><strong>Uniform Data Representation</strong>: By flattening and projecting, the vision transformer treats the image patches similarly to how tokens (words) are treated in a language model. This uniformity allows the use of transformer architecture, originally designed for NLP tasks, in processing visual data.</p>\n      </li>\n      <li>\n        <p><strong>Capturing Local Features</strong>: Each patch represents local features of the image. By projecting these patches, the model can capture and process these local features effectively. This is akin to how convolutional neural networks (CNNs) operate, but with a different approach.</p>\n      </li>\n      <li>\n        <p><strong>Scalability and Flexibility</strong>: The approach allows the model to be scalable to different image sizes and resolutions. It also offers flexibility in terms of the size of the patches and the depth of the network.</p>\n      </li>\n      <li>\n        <p><strong>Enabling Positional Encoding</strong>: Flattening and projecting the patches allow for the addition of positional encodings. In transformers, positional encodings are crucial as they provide the model with information about the relative or absolute position of the patches in the image. Unlike CNNs, transformers do not inherently understand the order or position of the input data, so positional encodings are necessary.</p>\n      </li>\n      <li>\n        <p><strong>Facilitating Self-Attention Mechanism</strong>: The transformer architecture relies heavily on the self-attention mechanism, which computes the response at a position in a sequence (in this case, a sequence of patches) by attending to all positions and computing a weighted sum of their features. Flattened and projected patches are conducive to this mechanism.</p>\n      </li>\n    </ol>\n<p><strong>Reduction of Dimensionality</strong>: Images are inherently high-dimensional data. Flattening and projecting the patches into a lower-dimensional space makes the computation more manageable and efficient. This process is analogous to reducing the resolution of an image while retaining essential features.</p>\n<p><strong>Uniform Data Representation</strong>: By flattening and projecting, the vision transformer treats the image patches similarly to how tokens (words) are treated in a language model. This uniformity allows the use of transformer architecture, originally designed for NLP tasks, in processing visual data.</p>\n<p><strong>Capturing Local Features</strong>: Each patch represents local features of the image. By projecting these patches, the model can capture and process these local features effectively. This is akin to how convolutional neural networks (CNNs) operate, but with a different approach.</p>\n<p><strong>Scalability and Flexibility</strong>: The approach allows the model to be scalable to different image sizes and resolutions. It also offers flexibility in terms of the size of the patches and the depth of the network.</p>\n<p><strong>Enabling Positional Encoding</strong>: Flattening and projecting the patches allow for the addition of positional encodings. In transformers, positional encodings are crucial as they provide the model with information about the relative or absolute position of the patches in the image. Unlike CNNs, transformers do not inherently understand the order or position of the input data, so positional encodings are necessary.</p>\n<p><strong>Facilitating Self-Attention Mechanism</strong>: The transformer architecture relies heavily on the self-attention mechanism, which computes the response at a position in a sequence (in this case, a sequence of patches) by attending to all positions and computing a weighted sum of their features. Flattened and projected patches are conducive to this mechanism.</p>\n<p>In summary, the use of linear projections of flattened patches in ViT is a strategic design choice that leverages the strengths of transformer architecture while making it suitable for processing visual data. This method allows the model to handle high-dimensional image data efficiently, capture local features, and utilize the self-attention mechanism effectively.</p>",
    "contentMarkdown": "*   The ViT model uses linear projections of flattened patches at the input for several reasons:\n    \n    1.  **Reduction of Dimensionality**: Images are inherently high-dimensional data. Flattening and projecting the patches into a lower-dimensional space makes the computation more manageable and efficient. This process is analogous to reducing the resolution of an image while retaining essential features.\n        \n    2.  **Uniform Data Representation**: By flattening and projecting, the vision transformer treats the image patches similarly to how tokens (words) are treated in a language model. This uniformity allows the use of transformer architecture, originally designed for NLP tasks, in processing visual data.\n        \n    3.  **Capturing Local Features**: Each patch represents local features of the image. By projecting these patches, the model can capture and process these local features effectively. This is akin to how convolutional neural networks (CNNs) operate, but with a different approach.\n        \n    4.  **Scalability and Flexibility**: The approach allows the model to be scalable to different image sizes and resolutions. It also offers flexibility in terms of the size of the patches and the depth of the network.\n        \n    5.  **Enabling Positional Encoding**: Flattening and projecting the patches allow for the addition of positional encodings. In transformers, positional encodings are crucial as they provide the model with information about the relative or absolute position of the patches in the image. Unlike CNNs, transformers do not inherently understand the order or position of the input data, so positional encodings are necessary.\n        \n    6.  **Facilitating Self-Attention Mechanism**: The transformer architecture relies heavily on the self-attention mechanism, which computes the response at a position in a sequence (in this case, a sequence of patches) by attending to all positions and computing a weighted sum of their features. Flattened and projected patches are conducive to this mechanism.\n        \n*   In summary, the use of linear projections of flattened patches in ViT is a strategic design choice that leverages the strengths of transformer architecture while making it suitable for processing visual data. This method allows the model to handle high-dimensional image data efficiently, capture local features, and utilize the self-attention mechanism effectively.\n    \n\nThe ViT model uses linear projections of flattened patches at the input for several reasons:\n\n1.  **Reduction of Dimensionality**: Images are inherently high-dimensional data. Flattening and projecting the patches into a lower-dimensional space makes the computation more manageable and efficient. This process is analogous to reducing the resolution of an image while retaining essential features.\n    \n2.  **Uniform Data Representation**: By flattening and projecting, the vision transformer treats the image patches similarly to how tokens (words) are treated in a language model. This uniformity allows the use of transformer architecture, originally designed for NLP tasks, in processing visual data.\n    \n3.  **Capturing Local Features**: Each patch represents local features of the image. By projecting these patches, the model can capture and process these local features effectively. This is akin to how convolutional neural networks (CNNs) operate, but with a different approach.\n    \n4.  **Scalability and Flexibility**: The approach allows the model to be scalable to different image sizes and resolutions. It also offers flexibility in terms of the size of the patches and the depth of the network.\n    \n5.  **Enabling Positional Encoding**: Flattening and projecting the patches allow for the addition of positional encodings. In transformers, positional encodings are crucial as they provide the model with information about the relative or absolute position of the patches in the image. Unlike CNNs, transformers do not inherently understand the order or position of the input data, so positional encodings are necessary.\n    \n6.  **Facilitating Self-Attention Mechanism**: The transformer architecture relies heavily on the self-attention mechanism, which computes the response at a position in a sequence (in this case, a sequence of patches) by attending to all positions and computing a weighted sum of their features. Flattened and projected patches are conducive to this mechanism.\n    \n\n**Reduction of Dimensionality**: Images are inherently high-dimensional data. Flattening and projecting the patches into a lower-dimensional space makes the computation more manageable and efficient. This process is analogous to reducing the resolution of an image while retaining essential features.\n\n**Uniform Data Representation**: By flattening and projecting, the vision transformer treats the image patches similarly to how tokens (words) are treated in a language model. This uniformity allows the use of transformer architecture, originally designed for NLP tasks, in processing visual data.\n\n**Capturing Local Features**: Each patch represents local features of the image. By projecting these patches, the model can capture and process these local features effectively. This is akin to how convolutional neural networks (CNNs) operate, but with a different approach.\n\n**Scalability and Flexibility**: The approach allows the model to be scalable to different image sizes and resolutions. It also offers flexibility in terms of the size of the patches and the depth of the network.\n\n**Enabling Positional Encoding**: Flattening and projecting the patches allow for the addition of positional encodings. In transformers, positional encodings are crucial as they provide the model with information about the relative or absolute position of the patches in the image. Unlike CNNs, transformers do not inherently understand the order or position of the input data, so positional encodings are necessary.\n\n**Facilitating Self-Attention Mechanism**: The transformer architecture relies heavily on the self-attention mechanism, which computes the response at a position in a sequence (in this case, a sequence of patches) by attending to all positions and computing a weighted sum of their features. Flattened and projected patches are conducive to this mechanism.\n\nIn summary, the use of linear projections of flattened patches in ViT is a strategic design choice that leverages the strengths of transformer architecture while making it suitable for processing visual data. This method allows the model to handle high-dimensional image data efficiently, capture local features, and utilize the self-attention mechanism effectively.",
    "contentLength": 7346,
    "wordCount": 949,
    "hasCode": false,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/vit/#why-does-vit-use-linear-projections-of-flattened-patches-at-the-input?"
  },
  {
    "id": "ai-vit-how-are-linear-projections-of-flattened-patches-at-4",
    "articleSlug": "vit",
    "articleTitle": "Vision Transformer (ViT)",
    "category": "Vision",
    "chapter": "FAQs",
    "title": "How are Linear Projections of Flattened Patches at the Input Calculated in ViT? What are the Inputs and Outputs?",
    "order": 4,
    "orderInChapter": 2,
    "contentHtml": "<ul>\n  <li>\n    <p>In ViT, the linear projections of flattened patches at the input are performed using a learnable <strong>fully connected (linear) layer</strong>. This is the very first step in transforming an image into a sequence of embeddings that can be processed by a transformer. Let’s break down the steps, inputs, and outputs:</p>\n\n    <ol>\n      <li>\n        <p><strong>Input Image Processing</strong>:</p>\n\n        <ul>\n          <li><strong>Input</strong>: The input is a raw image of size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi><mo>&amp;#x00D7;</mo><mi>W</mi><mo>&amp;#x00D7;</mo><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-185\" style=\"width: 5.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.638em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.64em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-186\"><span class=\"mi\" id=\"MathJax-Span-187\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-188\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-189\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-190\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-191\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">H \\times W \\times C</script> (height, width, channels).</li>\n          <li><strong>Patching</strong>: The image is divided into non-overlapping patches of size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mo>&amp;#x00D7;</mo><mi>P</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-192\" style=\"width: 2.659em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.19em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.19em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-193\"><span class=\"mi\" id=\"MathJax-Span-194\" style=\"font-family: STIXGeneral-Italic;\">P</span><span class=\"mo\" id=\"MathJax-Span-195\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-196\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">P</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi><mo>×</mo><mi>P</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">P \\times P</script>. For example, if <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mo>=</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-197\" style=\"width: 3.336em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.763em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.71em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-198\"><span class=\"mi\" id=\"MathJax-Span-199\" style=\"font-family: STIXGeneral-Italic;\">P</span><span class=\"mo\" id=\"MathJax-Span-200\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-201\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi><mo>=</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">P = 16</script>, each patch is <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-35-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-202\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-203\"><span class=\"mn\" id=\"MathJax-Span-204\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-205\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-206\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-35\">16 \\times 16</script> pixels.</li>\n          <li><strong>Flattening</strong>: Each patch is flattened into a 1D vector. If a patch is <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-207\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-208\"><span class=\"mn\" id=\"MathJax-Span-209\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-210\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-211\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-36\">16 \\times 16</script> pixels with 3 color channels (RGB), each flattened patch has <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-37-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn><mo>&amp;#x00D7;</mo><mn>3</mn><mo>=</mo><mn>768</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-212\" style=\"width: 8.909em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.398em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.35em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-213\"><span class=\"mn\" id=\"MathJax-Span-214\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span><span class=\"mo\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span><span class=\"mo\" id=\"MathJax-Span-219\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-220\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">768</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn><mo>×</mo><mn>3</mn><mo>=</mo><mn>768</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-37\">16 \\times 16 \\times 3 = 768</script> elements.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Linear Projection via Fully Connected Layer</strong>:</p>\n\n        <ul>\n          <li><strong>Flattened Patches</strong>: The flattened patch vectors from the previous step are the inputs to the projection stage.</li>\n          <li><strong>Fully Connected Layer</strong>: This stage is implemented as a standard <strong>Linear (fully connected) layer without any non-linearity</strong>, with weight matrix <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>D</mi><mo>&amp;#x00D7;</mo><mo stretchy=&quot;false&quot;>(</mo><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-221\" style=\"width: 6.826em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1005.68em, 2.451em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-222\"><span class=\"mi\" id=\"MathJax-Span-223\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-224\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-225\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.492em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-226\"><span class=\"mrow\" id=\"MathJax-Span-227\"><span class=\"mi\" id=\"MathJax-Span-228\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-229\"><span class=\"mrow\" id=\"MathJax-Span-230\"><span class=\"mi\" id=\"MathJax-Span-231\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">D</span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mo\" id=\"MathJax-Span-233\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-234\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-235\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">P</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.268em; left: 0.419em;\"><span class=\"mn\" id=\"MathJax-Span-236\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-237\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-238\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>W</mi><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>D</mi><mo>×</mo><mo stretchy=\"false\">(</mo><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi><mo stretchy=\"false\">)</mo></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-38\">W \\in \\mathbb{R}^{D \\times (P^2 C)}</script> and bias vector <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>b</mi><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mi>D</mi></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-239\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1003.08em, 2.451em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-240\"><span class=\"mi\" id=\"MathJax-Span-241\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mo\" id=\"MathJax-Span-242\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-243\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-244\"><span class=\"mrow\" id=\"MathJax-Span-245\"><span class=\"mi\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-247\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">D</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>b</mi><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mi>D</mi></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">b \\in \\mathbb{R}^D</script>, where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-40-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-248\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-249\"><span class=\"mi\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-40\">D</script> is the embedding dimension. This projection is a Linear layer without a non-linearity (just an affine transform).</li>\n          <li>\n            <p><strong>Calculation</strong>: For each patch vector <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-41-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>p</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-251\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.89em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-252\"><span class=\"msubsup\" id=\"MathJax-Span-253\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-255\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>x</mi><mi>p</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-41\">x_p</script>, the embedding is computed as:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-42-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>z</mi><mi>p</mi></msub><mo>=</mo><mi>W</mi><msub><mi>x</mi><mi>p</mi></msub><mo>+</mo><mi>b</mi></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-256\" style=\"width: 6.669em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.47em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-257\"><span class=\"msubsup\" id=\"MathJax-Span-258\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-259\" style=\"font-family: STIXGeneral-Italic;\">z</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-260\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-261\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-262\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-263\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-264\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-265\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-266\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-267\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">b</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>z</mi><mi>p</mi></msub><mo>=</mo><mi>W</mi><msub><mi>x</mi><mi>p</mi></msub><mo>+</mo><mi>b</mi></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-42\">z_p = W x_p + b</script>\n\n            <p>This transforms each <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-43-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-268\" style=\"width: 2.086em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1001.72em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-269\"><span class=\"msubsup\" id=\"MathJax-Span-270\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-271\" style=\"font-family: STIXGeneral-Italic;\">P</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.628em;\"><span class=\"mn\" id=\"MathJax-Span-272\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-273\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-43\">P^2 C</script>-dimensional flattened patch into a <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-44-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-274\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-275\"><span class=\"mi\" id=\"MathJax-Span-276\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-44\">D</script>-dimensional patch embedding.</p>\n          </li>\n          <li><strong>Efficiency Note</strong>: Some implementations replace the explicit flattening and linear layer with a <code class=\"language-plaintext highlighter-rouge\">Conv2D</code> operation having <code class=\"language-plaintext highlighter-rouge\">kernel size = patch size</code> and <code class=\"language-plaintext highlighter-rouge\">stride = patch size</code>, which is mathematically equivalent to the linear projection, but more efficient on GPUs.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Addition of Positional Encodings</strong>:</p>\n\n        <ul>\n          <li><strong>Positional Embeddings</strong>: Learnable positional embeddings are added to each patch embedding to retain spatial information about where the patch came from in the original image.</li>\n          <li><strong>Final Patch Representation</strong>: Each patch embedding is summed with its positional embedding to form the final patch representation.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Sequence Formation for Transformer</strong>:</p>\n\n        <ul>\n          <li><strong>Sequence of Patch Representations</strong>: The sequence of final patch representations, each of size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-45-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-277\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-278\"><span class=\"mi\" id=\"MathJax-Span-279\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-45\">D</script>, is fed into the transformer encoder for further processing.</li>\n        </ul>\n      </li>\n    </ol>\n  </li>\n  <li>\n    <p>In summary:</p>\n\n    <ul>\n      <li><strong>Inputs</strong>: A raw image, split into patches and flattened.</li>\n      <li><strong>Process</strong>: Each flattened patch is projected into a <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-46-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-280\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-281\"><span class=\"mi\" id=\"MathJax-Span-282\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-46\">D</script>-dimensional embedding using a fully connected linear layer (or equivalent <code class=\"language-plaintext highlighter-rouge\">Conv2D</code>), followed by the addition of positional encodings.</li>\n      <li><strong>Outputs</strong>: A sequence of patch embeddings with positional information, ready for transformer processing.</li>\n    </ul>\n  </li>\n  <li>\n    <p>This process adapts the transformer’s text-oriented architecture to handle images by representing the image as a sequence of learned embeddings, much like word embeddings in NLP.</p>\n  </li>\n</ul>\n<p>In ViT, the linear projections of flattened patches at the input are performed using a learnable <strong>fully connected (linear) layer</strong>. This is the very first step in transforming an image into a sequence of embeddings that can be processed by a transformer. Let’s break down the steps, inputs, and outputs:</p>\n<ol>\n      <li>\n        <p><strong>Input Image Processing</strong>:</p>\n\n        <ul>\n          <li><strong>Input</strong>: The input is a raw image of size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi><mo>&amp;#x00D7;</mo><mi>W</mi><mo>&amp;#x00D7;</mo><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-185\" style=\"width: 5.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.638em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.64em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-186\"><span class=\"mi\" id=\"MathJax-Span-187\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-188\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-189\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-190\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-191\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">H \\times W \\times C</script> (height, width, channels).</li>\n          <li><strong>Patching</strong>: The image is divided into non-overlapping patches of size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mo>&amp;#x00D7;</mo><mi>P</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-192\" style=\"width: 2.659em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.19em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.19em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-193\"><span class=\"mi\" id=\"MathJax-Span-194\" style=\"font-family: STIXGeneral-Italic;\">P</span><span class=\"mo\" id=\"MathJax-Span-195\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-196\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">P</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi><mo>×</mo><mi>P</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">P \\times P</script>. For example, if <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mo>=</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-197\" style=\"width: 3.336em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.763em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.71em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-198\"><span class=\"mi\" id=\"MathJax-Span-199\" style=\"font-family: STIXGeneral-Italic;\">P</span><span class=\"mo\" id=\"MathJax-Span-200\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-201\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi><mo>=</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">P = 16</script>, each patch is <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-35-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-202\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-203\"><span class=\"mn\" id=\"MathJax-Span-204\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-205\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-206\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-35\">16 \\times 16</script> pixels.</li>\n          <li><strong>Flattening</strong>: Each patch is flattened into a 1D vector. If a patch is <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-207\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-208\"><span class=\"mn\" id=\"MathJax-Span-209\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-210\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-211\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-36\">16 \\times 16</script> pixels with 3 color channels (RGB), each flattened patch has <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-37-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn><mo>&amp;#x00D7;</mo><mn>3</mn><mo>=</mo><mn>768</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-212\" style=\"width: 8.909em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.398em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.35em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-213\"><span class=\"mn\" id=\"MathJax-Span-214\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span><span class=\"mo\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span><span class=\"mo\" id=\"MathJax-Span-219\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-220\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">768</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn><mo>×</mo><mn>3</mn><mo>=</mo><mn>768</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-37\">16 \\times 16 \\times 3 = 768</script> elements.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Linear Projection via Fully Connected Layer</strong>:</p>\n\n        <ul>\n          <li><strong>Flattened Patches</strong>: The flattened patch vectors from the previous step are the inputs to the projection stage.</li>\n          <li><strong>Fully Connected Layer</strong>: This stage is implemented as a standard <strong>Linear (fully connected) layer without any non-linearity</strong>, with weight matrix <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>D</mi><mo>&amp;#x00D7;</mo><mo stretchy=&quot;false&quot;>(</mo><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-221\" style=\"width: 6.826em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1005.68em, 2.451em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-222\"><span class=\"mi\" id=\"MathJax-Span-223\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-224\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-225\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.492em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-226\"><span class=\"mrow\" id=\"MathJax-Span-227\"><span class=\"mi\" id=\"MathJax-Span-228\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-229\"><span class=\"mrow\" id=\"MathJax-Span-230\"><span class=\"mi\" id=\"MathJax-Span-231\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">D</span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mo\" id=\"MathJax-Span-233\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-234\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-235\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">P</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.268em; left: 0.419em;\"><span class=\"mn\" id=\"MathJax-Span-236\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-237\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-238\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>W</mi><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>D</mi><mo>×</mo><mo stretchy=\"false\">(</mo><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi><mo stretchy=\"false\">)</mo></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-38\">W \\in \\mathbb{R}^{D \\times (P^2 C)}</script> and bias vector <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>b</mi><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mi>D</mi></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-239\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1003.08em, 2.451em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-240\"><span class=\"mi\" id=\"MathJax-Span-241\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mo\" id=\"MathJax-Span-242\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-243\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-244\"><span class=\"mrow\" id=\"MathJax-Span-245\"><span class=\"mi\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-247\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">D</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>b</mi><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mi>D</mi></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">b \\in \\mathbb{R}^D</script>, where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-40-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-248\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-249\"><span class=\"mi\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-40\">D</script> is the embedding dimension. This projection is a Linear layer without a non-linearity (just an affine transform).</li>\n          <li>\n            <p><strong>Calculation</strong>: For each patch vector <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-41-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>p</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-251\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.89em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-252\"><span class=\"msubsup\" id=\"MathJax-Span-253\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-255\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>x</mi><mi>p</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-41\">x_p</script>, the embedding is computed as:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-42-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>z</mi><mi>p</mi></msub><mo>=</mo><mi>W</mi><msub><mi>x</mi><mi>p</mi></msub><mo>+</mo><mi>b</mi></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-256\" style=\"width: 6.669em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.47em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-257\"><span class=\"msubsup\" id=\"MathJax-Span-258\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-259\" style=\"font-family: STIXGeneral-Italic;\">z</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-260\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-261\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-262\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-263\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-264\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-265\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-266\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-267\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">b</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>z</mi><mi>p</mi></msub><mo>=</mo><mi>W</mi><msub><mi>x</mi><mi>p</mi></msub><mo>+</mo><mi>b</mi></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-42\">z_p = W x_p + b</script>\n\n            <p>This transforms each <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-43-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-268\" style=\"width: 2.086em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1001.72em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-269\"><span class=\"msubsup\" id=\"MathJax-Span-270\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-271\" style=\"font-family: STIXGeneral-Italic;\">P</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.628em;\"><span class=\"mn\" id=\"MathJax-Span-272\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-273\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-43\">P^2 C</script>-dimensional flattened patch into a <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-44-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-274\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-275\"><span class=\"mi\" id=\"MathJax-Span-276\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-44\">D</script>-dimensional patch embedding.</p>\n          </li>\n          <li><strong>Efficiency Note</strong>: Some implementations replace the explicit flattening and linear layer with a <code class=\"language-plaintext highlighter-rouge\">Conv2D</code> operation having <code class=\"language-plaintext highlighter-rouge\">kernel size = patch size</code> and <code class=\"language-plaintext highlighter-rouge\">stride = patch size</code>, which is mathematically equivalent to the linear projection, but more efficient on GPUs.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Addition of Positional Encodings</strong>:</p>\n\n        <ul>\n          <li><strong>Positional Embeddings</strong>: Learnable positional embeddings are added to each patch embedding to retain spatial information about where the patch came from in the original image.</li>\n          <li><strong>Final Patch Representation</strong>: Each patch embedding is summed with its positional embedding to form the final patch representation.</li>\n        </ul>\n      </li>\n      <li>\n        <p><strong>Sequence Formation for Transformer</strong>:</p>\n\n        <ul>\n          <li><strong>Sequence of Patch Representations</strong>: The sequence of final patch representations, each of size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-45-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-277\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-278\"><span class=\"mi\" id=\"MathJax-Span-279\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-45\">D</script>, is fed into the transformer encoder for further processing.</li>\n        </ul>\n      </li>\n    </ol>\n<p><strong>Input Image Processing</strong>:</p>\n<ul>\n          <li><strong>Input</strong>: The input is a raw image of size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>H</mi><mo>&amp;#x00D7;</mo><mi>W</mi><mo>&amp;#x00D7;</mo><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-185\" style=\"width: 5.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.638em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.64em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-186\"><span class=\"mi\" id=\"MathJax-Span-187\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-188\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-189\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-190\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-191\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">H \\times W \\times C</script> (height, width, channels).</li>\n          <li><strong>Patching</strong>: The image is divided into non-overlapping patches of size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mo>&amp;#x00D7;</mo><mi>P</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-192\" style=\"width: 2.659em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.19em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.19em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-193\"><span class=\"mi\" id=\"MathJax-Span-194\" style=\"font-family: STIXGeneral-Italic;\">P</span><span class=\"mo\" id=\"MathJax-Span-195\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-196\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">P</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi><mo>×</mo><mi>P</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">P \\times P</script>. For example, if <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mo>=</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-197\" style=\"width: 3.336em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.763em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.71em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-198\"><span class=\"mi\" id=\"MathJax-Span-199\" style=\"font-family: STIXGeneral-Italic;\">P</span><span class=\"mo\" id=\"MathJax-Span-200\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-201\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi><mo>=</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">P = 16</script>, each patch is <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-35-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-202\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-203\"><span class=\"mn\" id=\"MathJax-Span-204\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-205\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-206\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-35\">16 \\times 16</script> pixels.</li>\n          <li><strong>Flattening</strong>: Each patch is flattened into a 1D vector. If a patch is <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-207\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-208\"><span class=\"mn\" id=\"MathJax-Span-209\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-210\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-211\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-36\">16 \\times 16</script> pixels with 3 color channels (RGB), each flattened patch has <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-37-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn><mo>&amp;#x00D7;</mo><mn>3</mn><mo>=</mo><mn>768</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-212\" style=\"width: 8.909em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.398em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.35em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-213\"><span class=\"mn\" id=\"MathJax-Span-214\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span><span class=\"mo\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span><span class=\"mo\" id=\"MathJax-Span-219\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-220\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">768</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn><mo>×</mo><mn>3</mn><mo>=</mo><mn>768</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-37\">16 \\times 16 \\times 3 = 768</script> elements.</li>\n        </ul>\n<p><strong>Linear Projection via Fully Connected Layer</strong>:</p>\n<ul>\n          <li><strong>Flattened Patches</strong>: The flattened patch vectors from the previous step are the inputs to the projection stage.</li>\n          <li><strong>Fully Connected Layer</strong>: This stage is implemented as a standard <strong>Linear (fully connected) layer without any non-linearity</strong>, with weight matrix <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>D</mi><mo>&amp;#x00D7;</mo><mo stretchy=&quot;false&quot;>(</mo><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-221\" style=\"width: 6.826em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1005.68em, 2.451em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-222\"><span class=\"mi\" id=\"MathJax-Span-223\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-224\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-225\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.492em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-226\"><span class=\"mrow\" id=\"MathJax-Span-227\"><span class=\"mi\" id=\"MathJax-Span-228\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-229\"><span class=\"mrow\" id=\"MathJax-Span-230\"><span class=\"mi\" id=\"MathJax-Span-231\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">D</span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"mo\" id=\"MathJax-Span-233\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-234\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-235\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">P</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.268em; left: 0.419em;\"><span class=\"mn\" id=\"MathJax-Span-236\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-237\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-238\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">)</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>W</mi><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>D</mi><mo>×</mo><mo stretchy=\"false\">(</mo><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi><mo stretchy=\"false\">)</mo></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-38\">W \\in \\mathbb{R}^{D \\times (P^2 C)}</script> and bias vector <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>b</mi><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mi>D</mi></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-239\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1003.08em, 2.451em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-240\"><span class=\"mi\" id=\"MathJax-Span-241\" style=\"font-family: STIXGeneral-Italic;\">b</span><span class=\"mo\" id=\"MathJax-Span-242\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-243\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-244\"><span class=\"mrow\" id=\"MathJax-Span-245\"><span class=\"mi\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-247\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">D</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>b</mi><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mi>D</mi></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">b \\in \\mathbb{R}^D</script>, where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-40-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-248\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-249\"><span class=\"mi\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-40\">D</script> is the embedding dimension. This projection is a Linear layer without a non-linearity (just an affine transform).</li>\n          <li>\n            <p><strong>Calculation</strong>: For each patch vector <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-41-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>p</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-251\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.89em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-252\"><span class=\"msubsup\" id=\"MathJax-Span-253\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-255\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>x</mi><mi>p</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-41\">x_p</script>, the embedding is computed as:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-42-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>z</mi><mi>p</mi></msub><mo>=</mo><mi>W</mi><msub><mi>x</mi><mi>p</mi></msub><mo>+</mo><mi>b</mi></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-256\" style=\"width: 6.669em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.47em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-257\"><span class=\"msubsup\" id=\"MathJax-Span-258\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-259\" style=\"font-family: STIXGeneral-Italic;\">z</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"mi\" id=\"MathJax-Span-260\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-261\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-262\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"msubsup\" id=\"MathJax-Span-263\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-264\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-265\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-266\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-267\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">b</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>z</mi><mi>p</mi></msub><mo>=</mo><mi>W</mi><msub><mi>x</mi><mi>p</mi></msub><mo>+</mo><mi>b</mi></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-42\">z_p = W x_p + b</script>\n\n            <p>This transforms each <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-43-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-268\" style=\"width: 2.086em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1001.72em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-269\"><span class=\"msubsup\" id=\"MathJax-Span-270\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-271\" style=\"font-family: STIXGeneral-Italic;\">P</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.628em;\"><span class=\"mn\" id=\"MathJax-Span-272\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-273\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-43\">P^2 C</script>-dimensional flattened patch into a <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-44-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-274\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-275\"><span class=\"mi\" id=\"MathJax-Span-276\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-44\">D</script>-dimensional patch embedding.</p>\n          </li>\n          <li><strong>Efficiency Note</strong>: Some implementations replace the explicit flattening and linear layer with a <code class=\"language-plaintext highlighter-rouge\">Conv2D</code> operation having <code class=\"language-plaintext highlighter-rouge\">kernel size = patch size</code> and <code class=\"language-plaintext highlighter-rouge\">stride = patch size</code>, which is mathematically equivalent to the linear projection, but more efficient on GPUs.</li>\n        </ul>\n<p><strong>Calculation</strong>: For each patch vector <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-41-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>p</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-251\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.89em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-252\"><span class=\"msubsup\" id=\"MathJax-Span-253\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-255\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>x</mi><mi>p</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-41\">x_p</script>, the embedding is computed as:</p>\n<p>This transforms each <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-43-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-268\" style=\"width: 2.086em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1001.72em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-269\"><span class=\"msubsup\" id=\"MathJax-Span-270\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-271\" style=\"font-family: STIXGeneral-Italic;\">P</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.628em;\"><span class=\"mn\" id=\"MathJax-Span-272\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-273\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>P</mi><mn>2</mn></msup><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-43\">P^2 C</script>-dimensional flattened patch into a <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-44-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-274\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-275\"><span class=\"mi\" id=\"MathJax-Span-276\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-44\">D</script>-dimensional patch embedding.</p>\n<p><strong>Addition of Positional Encodings</strong>:</p>\n<ul>\n          <li><strong>Positional Embeddings</strong>: Learnable positional embeddings are added to each patch embedding to retain spatial information about where the patch came from in the original image.</li>\n          <li><strong>Final Patch Representation</strong>: Each patch embedding is summed with its positional embedding to form the final patch representation.</li>\n        </ul>\n<p><strong>Sequence Formation for Transformer</strong>:</p>\n<ul>\n          <li><strong>Sequence of Patch Representations</strong>: The sequence of final patch representations, each of size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-45-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-277\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-278\"><span class=\"mi\" id=\"MathJax-Span-279\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-45\">D</script>, is fed into the transformer encoder for further processing.</li>\n        </ul>\n<p>In summary:</p>\n<ul>\n      <li><strong>Inputs</strong>: A raw image, split into patches and flattened.</li>\n      <li><strong>Process</strong>: Each flattened patch is projected into a <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-46-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-280\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.73em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-281\"><span class=\"mi\" id=\"MathJax-Span-282\" style=\"font-family: STIXGeneral-Italic;\">D</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>D</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-46\">D</script>-dimensional embedding using a fully connected linear layer (or equivalent <code class=\"language-plaintext highlighter-rouge\">Conv2D</code>), followed by the addition of positional encodings.</li>\n      <li><strong>Outputs</strong>: A sequence of patch embeddings with positional information, ready for transformer processing.</li>\n    </ul>\n<p>This process adapts the transformer’s text-oriented architecture to handle images by representing the image as a sequence of learned embeddings, much like word embeddings in NLP.</p>",
    "contentMarkdown": "*   In ViT, the linear projections of flattened patches at the input are performed using a learnable **fully connected (linear) layer**. This is the very first step in transforming an image into a sequence of embeddings that can be processed by a transformer. Let’s break down the steps, inputs, and outputs:\n    \n    1.  **Input Image Processing**:\n        \n        *   **Input**: The input is a raw image of size H×W×CH×W×CH \\\\times W \\\\times C (height, width, channels).\n        *   **Patching**: The image is divided into non-overlapping patches of size P×PP×PP \\\\times P. For example, if P\\=16P\\=16P = 16, each patch is 16×1616×1616 \\\\times 16 pixels.\n        *   **Flattening**: Each patch is flattened into a 1D vector. If a patch is 16×1616×1616 \\\\times 16 pixels with 3 color channels (RGB), each flattened patch has 16×16×3\\=76816×16×3\\=76816 \\\\times 16 \\\\times 3 = 768 elements.\n    2.  **Linear Projection via Fully Connected Layer**:\n        \n        *   **Flattened Patches**: The flattened patch vectors from the previous step are the inputs to the projection stage.\n        *   **Fully Connected Layer**: This stage is implemented as a standard **Linear (fully connected) layer without any non-linearity**, with weight matrix W∈ℝD×(P2C)W∈RD×(P2C)W \\\\in \\\\mathbb{R}^{D \\\\times (P^2 C)} and bias vector b∈ℝDb∈RDb \\\\in \\\\mathbb{R}^D, where DDD is the embedding dimension. This projection is a Linear layer without a non-linearity (just an affine transform).\n        *   **Calculation**: For each patch vector xpxpx\\_p, the embedding is computed as:\n            \n            zp\\=Wxp+bzp\\=Wxp+b\n            \n            z\\_p = W x\\_p + b\n            \n            This transforms each P2CP2CP^2 C\\-dimensional flattened patch into a DDD\\-dimensional patch embedding.\n            \n        *   **Efficiency Note**: Some implementations replace the explicit flattening and linear layer with a `Conv2D` operation having `kernel size = patch size` and `stride = patch size`, which is mathematically equivalent to the linear projection, but more efficient on GPUs.\n    3.  **Addition of Positional Encodings**:\n        \n        *   **Positional Embeddings**: Learnable positional embeddings are added to each patch embedding to retain spatial information about where the patch came from in the original image.\n        *   **Final Patch Representation**: Each patch embedding is summed with its positional embedding to form the final patch representation.\n    4.  **Sequence Formation for Transformer**:\n        \n        *   **Sequence of Patch Representations**: The sequence of final patch representations, each of size DDD, is fed into the transformer encoder for further processing.\n*   In summary:\n    \n    *   **Inputs**: A raw image, split into patches and flattened.\n    *   **Process**: Each flattened patch is projected into a DDD\\-dimensional embedding using a fully connected linear layer (or equivalent `Conv2D`), followed by the addition of positional encodings.\n    *   **Outputs**: A sequence of patch embeddings with positional information, ready for transformer processing.\n*   This process adapts the transformer’s text-oriented architecture to handle images by representing the image as a sequence of learned embeddings, much like word embeddings in NLP.\n    \n\nIn ViT, the linear projections of flattened patches at the input are performed using a learnable **fully connected (linear) layer**. This is the very first step in transforming an image into a sequence of embeddings that can be processed by a transformer. Let’s break down the steps, inputs, and outputs:\n\n1.  **Input Image Processing**:\n    \n    *   **Input**: The input is a raw image of size H×W×CH×W×CH \\\\times W \\\\times C (height, width, channels).\n    *   **Patching**: The image is divided into non-overlapping patches of size P×PP×PP \\\\times P. For example, if P\\=16P\\=16P = 16, each patch is 16×1616×1616 \\\\times 16 pixels.\n    *   **Flattening**: Each patch is flattened into a 1D vector. If a patch is 16×1616×1616 \\\\times 16 pixels with 3 color channels (RGB), each flattened patch has 16×16×3\\=76816×16×3\\=76816 \\\\times 16 \\\\times 3 = 768 elements.\n2.  **Linear Projection via Fully Connected Layer**:\n    \n    *   **Flattened Patches**: The flattened patch vectors from the previous step are the inputs to the projection stage.\n    *   **Fully Connected Layer**: This stage is implemented as a standard **Linear (fully connected) layer without any non-linearity**, with weight matrix W∈ℝD×(P2C)W∈RD×(P2C)W \\\\in \\\\mathbb{R}^{D \\\\times (P^2 C)} and bias vector b∈ℝDb∈RDb \\\\in \\\\mathbb{R}^D, where DDD is the embedding dimension. This projection is a Linear layer without a non-linearity (just an affine transform).\n    *   **Calculation**: For each patch vector xpxpx\\_p, the embedding is computed as:\n        \n        zp\\=Wxp+bzp\\=Wxp+b\n        \n        z\\_p = W x\\_p + b\n        \n        This transforms each P2CP2CP^2 C\\-dimensional flattened patch into a DDD\\-dimensional patch embedding.\n        \n    *   **Efficiency Note**: Some implementations replace the explicit flattening and linear layer with a `Conv2D` operation having `kernel size = patch size` and `stride = patch size`, which is mathematically equivalent to the linear projection, but more efficient on GPUs.\n3.  **Addition of Positional Encodings**:\n    \n    *   **Positional Embeddings**: Learnable positional embeddings are added to each patch embedding to retain spatial information about where the patch came from in the original image.\n    *   **Final Patch Representation**: Each patch embedding is summed with its positional embedding to form the final patch representation.\n4.  **Sequence Formation for Transformer**:\n    \n    *   **Sequence of Patch Representations**: The sequence of final patch representations, each of size DDD, is fed into the transformer encoder for further processing.\n\n**Input Image Processing**:\n\n*   **Input**: The input is a raw image of size H×W×CH×W×CH \\\\times W \\\\times C (height, width, channels).\n*   **Patching**: The image is divided into non-overlapping patches of size P×PP×PP \\\\times P. For example, if P\\=16P\\=16P = 16, each patch is 16×1616×1616 \\\\times 16 pixels.\n*   **Flattening**: Each patch is flattened into a 1D vector. If a patch is 16×1616×1616 \\\\times 16 pixels with 3 color channels (RGB), each flattened patch has 16×16×3\\=76816×16×3\\=76816 \\\\times 16 \\\\times 3 = 768 elements.\n\n**Linear Projection via Fully Connected Layer**:\n\n*   **Flattened Patches**: The flattened patch vectors from the previous step are the inputs to the projection stage.\n*   **Fully Connected Layer**: This stage is implemented as a standard **Linear (fully connected) layer without any non-linearity**, with weight matrix W∈ℝD×(P2C)W∈RD×(P2C)W \\\\in \\\\mathbb{R}^{D \\\\times (P^2 C)} and bias vector b∈ℝDb∈RDb \\\\in \\\\mathbb{R}^D, where DDD is the embedding dimension. This projection is a Linear layer without a non-linearity (just an affine transform).\n*   **Calculation**: For each patch vector xpxpx\\_p, the embedding is computed as:\n    \n    zp\\=Wxp+bzp\\=Wxp+b\n    \n    z\\_p = W x\\_p + b\n    \n    This transforms each P2CP2CP^2 C\\-dimensional flattened patch into a DDD\\-dimensional patch embedding.\n    \n*   **Efficiency Note**: Some implementations replace the explicit flattening and linear layer with a `Conv2D` operation having `kernel size = patch size` and `stride = patch size`, which is mathematically equivalent to the linear projection, but more efficient on GPUs.\n\n**Calculation**: For each patch vector xpxpx\\_p, the embedding is computed as:\n\nThis transforms each P2CP2CP^2 C\\-dimensional flattened patch into a DDD\\-dimensional patch embedding.\n\n**Addition of Positional Encodings**:\n\n*   **Positional Embeddings**: Learnable positional embeddings are added to each patch embedding to retain spatial information about where the patch came from in the original image.\n*   **Final Patch Representation**: Each patch embedding is summed with its positional embedding to form the final patch representation.\n\n**Sequence Formation for Transformer**:\n\n*   **Sequence of Patch Representations**: The sequence of final patch representations, each of size DDD, is fed into the transformer encoder for further processing.\n\nIn summary:\n\n*   **Inputs**: A raw image, split into patches and flattened.\n*   **Process**: Each flattened patch is projected into a DDD\\-dimensional embedding using a fully connected linear layer (or equivalent `Conv2D`), followed by the addition of positional encodings.\n*   **Outputs**: A sequence of patch embeddings with positional information, ready for transformer processing.\n\nThis process adapts the transformer’s text-oriented architecture to handle images by representing the image as a sequence of learned embeddings, much like word embeddings in NLP.",
    "contentLength": 99440,
    "wordCount": 1213,
    "hasCode": true,
    "hasMath": true,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/vit/#how-are-linear-projections-of-flattened-patches-at-the-input-calculated-in-vit?-what-are-the-inputs-and-outputs?"
  },
  {
    "id": "ai-vit-why-does-vit-rely-on-1616161616-times-16-pixels-fo-5",
    "articleSlug": "vit",
    "articleTitle": "Vision Transformer (ViT)",
    "category": "Vision",
    "chapter": "FAQs",
    "title": "Why Does ViT Rely on 16×1616×1616 \\times 16 Pixels for Its Input Patches?",
    "order": 5,
    "orderInChapter": 3,
    "contentHtml": "<ul>\n  <li>\n    <p>ViT often uses <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-48-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-288\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-289\"><span class=\"mn\" id=\"MathJax-Span-290\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-291\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-292\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-48\">16 \\times 16</script> pixel patches for its input, but this choice is not a strict requirement; it’s more of a practical and empirical decision. Let’s explore why <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-49-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-293\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-294\"><span class=\"mn\" id=\"MathJax-Span-295\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-296\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-297\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-49\">16 \\times 16</script> is commonly used and whether other patch sizes could work:</p>\n\n    <ol>\n      <li>\n        <p><strong>Balance Between Granularity and Computational Efficiency</strong>: A <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-50-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-298\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-299\"><span class=\"mn\" id=\"MathJax-Span-300\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-301\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-302\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-50\">16 \\times 16</script> patch size is a compromise between capturing sufficient detail in each patch and keeping the number of patches (and thus the sequence length for the transformer) manageable. Smaller patches would provide more detailed information but would increase the sequence length and computational cost. Larger patches would reduce the sequence length but might miss finer details in the image.</p>\n      </li>\n      <li>\n        <p><strong>Empirical Performance</strong>: The choice of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-51-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-303\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-304\"><span class=\"mn\" id=\"MathJax-Span-305\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-306\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-307\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-51\">16 \\times 16</script> has been empirically found to work well for a range of tasks and datasets in many studies and applications. This practical experience has led to its common adoption.</p>\n      </li>\n      <li>\n        <p><strong>Comparison with Convolutional Networks</strong>: The patch size somewhat mirrors the receptive field of filters in traditional convolutional neural networks (CNNs). In CNNs, filters capture local patterns, and their effective receptive field often aligns with the size of these patches in ViTs.</p>\n      </li>\n      <li>\n        <p><strong>Hardware and Memory Constraints</strong>: The patch size also needs to be chosen considering the hardware and memory constraints. Larger models with smaller patches might not be feasible for training and inference on available hardware.</p>\n      </li>\n      <li>\n        <p><strong>Other Patch Sizes</strong>: ViTs can certainly work with other patch sizes. The choice of patch size is a hyperparameter that can be tuned based on the specific requirements of the task, the nature of the dataset, and the available computational resources. For instance, for higher resolution images or tasks requiring finer details, smaller patches might be more suitable. Conversely, for tasks where global features are more important, larger patches could be used.</p>\n      </li>\n    </ol>\n  </li>\n  <li>\n    <p>In summary, while <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-52-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-308\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-309\"><span class=\"mn\" id=\"MathJax-Span-310\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-311\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-312\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-52\">16 \\times 16</script> pixels is a common choice for input patches in ViTs due to a balance between detail capture and computational efficiency, it is not a fixed requirement. Other patch sizes can be used, and the optimal choice depends on the specific task, dataset characteristics, and available computational resources. Experimentation and empirical validation are key in determining the most suitable patch size for a given application.</p>\n  </li>\n</ul>\n<p>ViT often uses <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-48-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-288\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-289\"><span class=\"mn\" id=\"MathJax-Span-290\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-291\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-292\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-48\">16 \\times 16</script> pixel patches for its input, but this choice is not a strict requirement; it’s more of a practical and empirical decision. Let’s explore why <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-49-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-293\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-294\"><span class=\"mn\" id=\"MathJax-Span-295\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-296\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-297\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-49\">16 \\times 16</script> is commonly used and whether other patch sizes could work:</p>\n<ol>\n      <li>\n        <p><strong>Balance Between Granularity and Computational Efficiency</strong>: A <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-50-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-298\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-299\"><span class=\"mn\" id=\"MathJax-Span-300\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-301\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-302\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-50\">16 \\times 16</script> patch size is a compromise between capturing sufficient detail in each patch and keeping the number of patches (and thus the sequence length for the transformer) manageable. Smaller patches would provide more detailed information but would increase the sequence length and computational cost. Larger patches would reduce the sequence length but might miss finer details in the image.</p>\n      </li>\n      <li>\n        <p><strong>Empirical Performance</strong>: The choice of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-51-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-303\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-304\"><span class=\"mn\" id=\"MathJax-Span-305\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-306\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-307\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-51\">16 \\times 16</script> has been empirically found to work well for a range of tasks and datasets in many studies and applications. This practical experience has led to its common adoption.</p>\n      </li>\n      <li>\n        <p><strong>Comparison with Convolutional Networks</strong>: The patch size somewhat mirrors the receptive field of filters in traditional convolutional neural networks (CNNs). In CNNs, filters capture local patterns, and their effective receptive field often aligns with the size of these patches in ViTs.</p>\n      </li>\n      <li>\n        <p><strong>Hardware and Memory Constraints</strong>: The patch size also needs to be chosen considering the hardware and memory constraints. Larger models with smaller patches might not be feasible for training and inference on available hardware.</p>\n      </li>\n      <li>\n        <p><strong>Other Patch Sizes</strong>: ViTs can certainly work with other patch sizes. The choice of patch size is a hyperparameter that can be tuned based on the specific requirements of the task, the nature of the dataset, and the available computational resources. For instance, for higher resolution images or tasks requiring finer details, smaller patches might be more suitable. Conversely, for tasks where global features are more important, larger patches could be used.</p>\n      </li>\n    </ol>\n<p><strong>Balance Between Granularity and Computational Efficiency</strong>: A <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-50-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-298\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-299\"><span class=\"mn\" id=\"MathJax-Span-300\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-301\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-302\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-50\">16 \\times 16</script> patch size is a compromise between capturing sufficient detail in each patch and keeping the number of patches (and thus the sequence length for the transformer) manageable. Smaller patches would provide more detailed information but would increase the sequence length and computational cost. Larger patches would reduce the sequence length but might miss finer details in the image.</p>\n<p><strong>Empirical Performance</strong>: The choice of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-51-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-303\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-304\"><span class=\"mn\" id=\"MathJax-Span-305\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-306\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-307\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-51\">16 \\times 16</script> has been empirically found to work well for a range of tasks and datasets in many studies and applications. This practical experience has led to its common adoption.</p>\n<p><strong>Comparison with Convolutional Networks</strong>: The patch size somewhat mirrors the receptive field of filters in traditional convolutional neural networks (CNNs). In CNNs, filters capture local patterns, and their effective receptive field often aligns with the size of these patches in ViTs.</p>\n<p><strong>Hardware and Memory Constraints</strong>: The patch size also needs to be chosen considering the hardware and memory constraints. Larger models with smaller patches might not be feasible for training and inference on available hardware.</p>\n<p><strong>Other Patch Sizes</strong>: ViTs can certainly work with other patch sizes. The choice of patch size is a hyperparameter that can be tuned based on the specific requirements of the task, the nature of the dataset, and the available computational resources. For instance, for higher resolution images or tasks requiring finer details, smaller patches might be more suitable. Conversely, for tasks where global features are more important, larger patches could be used.</p>\n<p>In summary, while <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-52-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>16</mn><mo>&amp;#x00D7;</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-308\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.02em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-309\"><span class=\"mn\" id=\"MathJax-Span-310\" style=\"font-family: STIXGeneral-Regular;\">16</span><span class=\"mo\" id=\"MathJax-Span-311\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-312\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>16</mn><mo>×</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-52\">16 \\times 16</script> pixels is a common choice for input patches in ViTs due to a balance between detail capture and computational efficiency, it is not a fixed requirement. Other patch sizes can be used, and the optimal choice depends on the specific task, dataset characteristics, and available computational resources. Experimentation and empirical validation are key in determining the most suitable patch size for a given application.</p>",
    "contentMarkdown": "*   ViT often uses 16×1616×1616 \\\\times 16 pixel patches for its input, but this choice is not a strict requirement; it’s more of a practical and empirical decision. Let’s explore why 16×1616×1616 \\\\times 16 is commonly used and whether other patch sizes could work:\n    \n    1.  **Balance Between Granularity and Computational Efficiency**: A 16×1616×1616 \\\\times 16 patch size is a compromise between capturing sufficient detail in each patch and keeping the number of patches (and thus the sequence length for the transformer) manageable. Smaller patches would provide more detailed information but would increase the sequence length and computational cost. Larger patches would reduce the sequence length but might miss finer details in the image.\n        \n    2.  **Empirical Performance**: The choice of 16×1616×1616 \\\\times 16 has been empirically found to work well for a range of tasks and datasets in many studies and applications. This practical experience has led to its common adoption.\n        \n    3.  **Comparison with Convolutional Networks**: The patch size somewhat mirrors the receptive field of filters in traditional convolutional neural networks (CNNs). In CNNs, filters capture local patterns, and their effective receptive field often aligns with the size of these patches in ViTs.\n        \n    4.  **Hardware and Memory Constraints**: The patch size also needs to be chosen considering the hardware and memory constraints. Larger models with smaller patches might not be feasible for training and inference on available hardware.\n        \n    5.  **Other Patch Sizes**: ViTs can certainly work with other patch sizes. The choice of patch size is a hyperparameter that can be tuned based on the specific requirements of the task, the nature of the dataset, and the available computational resources. For instance, for higher resolution images or tasks requiring finer details, smaller patches might be more suitable. Conversely, for tasks where global features are more important, larger patches could be used.\n        \n*   In summary, while 16×1616×1616 \\\\times 16 pixels is a common choice for input patches in ViTs due to a balance between detail capture and computational efficiency, it is not a fixed requirement. Other patch sizes can be used, and the optimal choice depends on the specific task, dataset characteristics, and available computational resources. Experimentation and empirical validation are key in determining the most suitable patch size for a given application.\n    \n\nViT often uses 16×1616×1616 \\\\times 16 pixel patches for its input, but this choice is not a strict requirement; it’s more of a practical and empirical decision. Let’s explore why 16×1616×1616 \\\\times 16 is commonly used and whether other patch sizes could work:\n\n1.  **Balance Between Granularity and Computational Efficiency**: A 16×1616×1616 \\\\times 16 patch size is a compromise between capturing sufficient detail in each patch and keeping the number of patches (and thus the sequence length for the transformer) manageable. Smaller patches would provide more detailed information but would increase the sequence length and computational cost. Larger patches would reduce the sequence length but might miss finer details in the image.\n    \n2.  **Empirical Performance**: The choice of 16×1616×1616 \\\\times 16 has been empirically found to work well for a range of tasks and datasets in many studies and applications. This practical experience has led to its common adoption.\n    \n3.  **Comparison with Convolutional Networks**: The patch size somewhat mirrors the receptive field of filters in traditional convolutional neural networks (CNNs). In CNNs, filters capture local patterns, and their effective receptive field often aligns with the size of these patches in ViTs.\n    \n4.  **Hardware and Memory Constraints**: The patch size also needs to be chosen considering the hardware and memory constraints. Larger models with smaller patches might not be feasible for training and inference on available hardware.\n    \n5.  **Other Patch Sizes**: ViTs can certainly work with other patch sizes. The choice of patch size is a hyperparameter that can be tuned based on the specific requirements of the task, the nature of the dataset, and the available computational resources. For instance, for higher resolution images or tasks requiring finer details, smaller patches might be more suitable. Conversely, for tasks where global features are more important, larger patches could be used.\n    \n\n**Balance Between Granularity and Computational Efficiency**: A 16×1616×1616 \\\\times 16 patch size is a compromise between capturing sufficient detail in each patch and keeping the number of patches (and thus the sequence length for the transformer) manageable. Smaller patches would provide more detailed information but would increase the sequence length and computational cost. Larger patches would reduce the sequence length but might miss finer details in the image.\n\n**Empirical Performance**: The choice of 16×1616×1616 \\\\times 16 has been empirically found to work well for a range of tasks and datasets in many studies and applications. This practical experience has led to its common adoption.\n\n**Comparison with Convolutional Networks**: The patch size somewhat mirrors the receptive field of filters in traditional convolutional neural networks (CNNs). In CNNs, filters capture local patterns, and their effective receptive field often aligns with the size of these patches in ViTs.\n\n**Hardware and Memory Constraints**: The patch size also needs to be chosen considering the hardware and memory constraints. Larger models with smaller patches might not be feasible for training and inference on available hardware.\n\n**Other Patch Sizes**: ViTs can certainly work with other patch sizes. The choice of patch size is a hyperparameter that can be tuned based on the specific requirements of the task, the nature of the dataset, and the available computational resources. For instance, for higher resolution images or tasks requiring finer details, smaller patches might be more suitable. Conversely, for tasks where global features are more important, larger patches could be used.\n\nIn summary, while 16×1616×1616 \\\\times 16 pixels is a common choice for input patches in ViTs due to a balance between detail capture and computational efficiency, it is not a fixed requirement. Other patch sizes can be used, and the optimal choice depends on the specific task, dataset characteristics, and available computational resources. Experimentation and empirical validation are key in determining the most suitable patch size for a given application.",
    "contentLength": 24621,
    "wordCount": 991,
    "hasCode": false,
    "hasMath": true,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/vit/#why-does-vit-rely-on-16×1616×1616-\\times-16-pixels-for-its-input-patches?"
  },
  {
    "id": "ai-vit-why-does-vit-not-use-a-tokenizer-at-the-input-akin-6",
    "articleSlug": "vit",
    "articleTitle": "Vision Transformer (ViT)",
    "category": "Vision",
    "chapter": "FAQs",
    "title": "Why Does ViT Not Use a Tokenizer at the Input (akin to Transformers for Text Processing Tasks)?",
    "order": 6,
    "orderInChapter": 4,
    "contentHtml": "<ul>\n  <li>\n    <p>In ViTs, the concept of tokenization is applied differently compared to how it’s used in traditional text-based transformers. ViTs do not use a tokenizer in the same sense as NLP models, and here’s why:</p>\n\n    <ol>\n      <li>\n        <p><strong>Nature of Input Data</strong>: In NLP, tokenization is used to convert text into a series of tokens (words or subwords), which are then mapped to embeddings. This is necessary because text data is discrete and symbolic. In contrast, images are continuous and high-dimensional. The concept of ‘words’ or ‘characters’ does not directly apply to images.</p>\n      </li>\n      <li>\n        <p><strong>Image Patching as a Form of Tokenization</strong>: In ViTs, the closest analog to tokenization is the division of an image into fixed-size patches. Each patch is treated as a ‘token’. These patches are then flattened and linearly projected into embeddings. This process can be thought of as a form of tokenization where each ‘token’ represents a part of the image rather than a word or character.</p>\n      </li>\n      <li>\n        <p><strong>Absence of Vocabulary</strong>: In text processing, tokenization is followed by mapping tokens to a vocabulary of known words or subwords. For images, there is no predefined vocabulary. Each patch is unique and is represented by its pixel values, which are then projected into a latent space.</p>\n      </li>\n      <li>\n        <p><strong>Direct Processing of Raw Input</strong>: Unlike text, where tokenization is a necessary preprocessing step to handle the symbolic nature of language, ViTs can process raw image data directly (after patching and embedding). This direct processing of visual information is more analogous to how convolutional neural networks (CNNs) handle images, although the mechanisms are different.</p>\n      </li>\n    </ol>\n  </li>\n  <li>\n    <p>In summary, while ViTs don’t use a tokenizer in the traditional NLP sense, the process of dividing an image into patches and linearly projecting these patches serves a similar purpose. It converts the raw image data into a format that can be processed by the transformer architecture, ensuring that spatial information is retained and managed efficiently. The key difference lies in the nature of the input data and how it’s represented and processed within the model.</p>\n  </li>\n</ul>\n<p>In ViTs, the concept of tokenization is applied differently compared to how it’s used in traditional text-based transformers. ViTs do not use a tokenizer in the same sense as NLP models, and here’s why:</p>\n<ol>\n      <li>\n        <p><strong>Nature of Input Data</strong>: In NLP, tokenization is used to convert text into a series of tokens (words or subwords), which are then mapped to embeddings. This is necessary because text data is discrete and symbolic. In contrast, images are continuous and high-dimensional. The concept of ‘words’ or ‘characters’ does not directly apply to images.</p>\n      </li>\n      <li>\n        <p><strong>Image Patching as a Form of Tokenization</strong>: In ViTs, the closest analog to tokenization is the division of an image into fixed-size patches. Each patch is treated as a ‘token’. These patches are then flattened and linearly projected into embeddings. This process can be thought of as a form of tokenization where each ‘token’ represents a part of the image rather than a word or character.</p>\n      </li>\n      <li>\n        <p><strong>Absence of Vocabulary</strong>: In text processing, tokenization is followed by mapping tokens to a vocabulary of known words or subwords. For images, there is no predefined vocabulary. Each patch is unique and is represented by its pixel values, which are then projected into a latent space.</p>\n      </li>\n      <li>\n        <p><strong>Direct Processing of Raw Input</strong>: Unlike text, where tokenization is a necessary preprocessing step to handle the symbolic nature of language, ViTs can process raw image data directly (after patching and embedding). This direct processing of visual information is more analogous to how convolutional neural networks (CNNs) handle images, although the mechanisms are different.</p>\n      </li>\n    </ol>\n<p><strong>Nature of Input Data</strong>: In NLP, tokenization is used to convert text into a series of tokens (words or subwords), which are then mapped to embeddings. This is necessary because text data is discrete and symbolic. In contrast, images are continuous and high-dimensional. The concept of ‘words’ or ‘characters’ does not directly apply to images.</p>\n<p><strong>Image Patching as a Form of Tokenization</strong>: In ViTs, the closest analog to tokenization is the division of an image into fixed-size patches. Each patch is treated as a ‘token’. These patches are then flattened and linearly projected into embeddings. This process can be thought of as a form of tokenization where each ‘token’ represents a part of the image rather than a word or character.</p>\n<p><strong>Absence of Vocabulary</strong>: In text processing, tokenization is followed by mapping tokens to a vocabulary of known words or subwords. For images, there is no predefined vocabulary. Each patch is unique and is represented by its pixel values, which are then projected into a latent space.</p>\n<p><strong>Direct Processing of Raw Input</strong>: Unlike text, where tokenization is a necessary preprocessing step to handle the symbolic nature of language, ViTs can process raw image data directly (after patching and embedding). This direct processing of visual information is more analogous to how convolutional neural networks (CNNs) handle images, although the mechanisms are different.</p>\n<p>In summary, while ViTs don’t use a tokenizer in the traditional NLP sense, the process of dividing an image into patches and linearly projecting these patches serves a similar purpose. It converts the raw image data into a format that can be processed by the transformer architecture, ensuring that spatial information is retained and managed efficiently. The key difference lies in the nature of the input data and how it’s represented and processed within the model.</p>",
    "contentMarkdown": "*   In ViTs, the concept of tokenization is applied differently compared to how it’s used in traditional text-based transformers. ViTs do not use a tokenizer in the same sense as NLP models, and here’s why:\n    \n    1.  **Nature of Input Data**: In NLP, tokenization is used to convert text into a series of tokens (words or subwords), which are then mapped to embeddings. This is necessary because text data is discrete and symbolic. In contrast, images are continuous and high-dimensional. The concept of ‘words’ or ‘characters’ does not directly apply to images.\n        \n    2.  **Image Patching as a Form of Tokenization**: In ViTs, the closest analog to tokenization is the division of an image into fixed-size patches. Each patch is treated as a ‘token’. These patches are then flattened and linearly projected into embeddings. This process can be thought of as a form of tokenization where each ‘token’ represents a part of the image rather than a word or character.\n        \n    3.  **Absence of Vocabulary**: In text processing, tokenization is followed by mapping tokens to a vocabulary of known words or subwords. For images, there is no predefined vocabulary. Each patch is unique and is represented by its pixel values, which are then projected into a latent space.\n        \n    4.  **Direct Processing of Raw Input**: Unlike text, where tokenization is a necessary preprocessing step to handle the symbolic nature of language, ViTs can process raw image data directly (after patching and embedding). This direct processing of visual information is more analogous to how convolutional neural networks (CNNs) handle images, although the mechanisms are different.\n        \n*   In summary, while ViTs don’t use a tokenizer in the traditional NLP sense, the process of dividing an image into patches and linearly projecting these patches serves a similar purpose. It converts the raw image data into a format that can be processed by the transformer architecture, ensuring that spatial information is retained and managed efficiently. The key difference lies in the nature of the input data and how it’s represented and processed within the model.\n    \n\nIn ViTs, the concept of tokenization is applied differently compared to how it’s used in traditional text-based transformers. ViTs do not use a tokenizer in the same sense as NLP models, and here’s why:\n\n1.  **Nature of Input Data**: In NLP, tokenization is used to convert text into a series of tokens (words or subwords), which are then mapped to embeddings. This is necessary because text data is discrete and symbolic. In contrast, images are continuous and high-dimensional. The concept of ‘words’ or ‘characters’ does not directly apply to images.\n    \n2.  **Image Patching as a Form of Tokenization**: In ViTs, the closest analog to tokenization is the division of an image into fixed-size patches. Each patch is treated as a ‘token’. These patches are then flattened and linearly projected into embeddings. This process can be thought of as a form of tokenization where each ‘token’ represents a part of the image rather than a word or character.\n    \n3.  **Absence of Vocabulary**: In text processing, tokenization is followed by mapping tokens to a vocabulary of known words or subwords. For images, there is no predefined vocabulary. Each patch is unique and is represented by its pixel values, which are then projected into a latent space.\n    \n4.  **Direct Processing of Raw Input**: Unlike text, where tokenization is a necessary preprocessing step to handle the symbolic nature of language, ViTs can process raw image data directly (after patching and embedding). This direct processing of visual information is more analogous to how convolutional neural networks (CNNs) handle images, although the mechanisms are different.\n    \n\n**Nature of Input Data**: In NLP, tokenization is used to convert text into a series of tokens (words or subwords), which are then mapped to embeddings. This is necessary because text data is discrete and symbolic. In contrast, images are continuous and high-dimensional. The concept of ‘words’ or ‘characters’ does not directly apply to images.\n\n**Image Patching as a Form of Tokenization**: In ViTs, the closest analog to tokenization is the division of an image into fixed-size patches. Each patch is treated as a ‘token’. These patches are then flattened and linearly projected into embeddings. This process can be thought of as a form of tokenization where each ‘token’ represents a part of the image rather than a word or character.\n\n**Absence of Vocabulary**: In text processing, tokenization is followed by mapping tokens to a vocabulary of known words or subwords. For images, there is no predefined vocabulary. Each patch is unique and is represented by its pixel values, which are then projected into a latent space.\n\n**Direct Processing of Raw Input**: Unlike text, where tokenization is a necessary preprocessing step to handle the symbolic nature of language, ViTs can process raw image data directly (after patching and embedding). This direct processing of visual information is more analogous to how convolutional neural networks (CNNs) handle images, although the mechanisms are different.\n\nIn summary, while ViTs don’t use a tokenizer in the traditional NLP sense, the process of dividing an image into patches and linearly projecting these patches serves a similar purpose. It converts the raw image data into a format that can be processed by the transformer architecture, ensuring that spatial information is retained and managed efficiently. The key difference lies in the nature of the input data and how it’s represented and processed within the model.",
    "contentLength": 6158,
    "wordCount": 893,
    "hasCode": false,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/vit/#why-does-vit-not-use-a-tokenizer-at-the-input-(akin-to-transformers-for-text-processing-tasks)?"
  },
  {
    "id": "ai-vit-what-are-tokens-when-embedding-an-image-using-an-e-7",
    "articleSlug": "vit",
    "articleTitle": "Vision Transformer (ViT)",
    "category": "Vision",
    "chapter": "FAQs",
    "title": "What are “tokens” When Embedding an Image Using an Encoder? How are They Different Compared to Word/sub-word Tokens in NLP?",
    "order": 7,
    "orderInChapter": 5,
    "contentHtml": "<ul>\n  <li>When embedding an image using an encoder in the context of machine learning and neural networks, there are indeed “tokens,” although they might not be tokens in the traditional sense as understood in natural language processing (NLP).</li>\n  <li>In NLP, tokens usually refer to words or subwords. However, in the context of image processing, an encoder, especially in models like ViT, converts an image into a series of numerical representations, which can be analogously thought of as “tokens.”</li>\n  <li>\n    <p>Here’s a simplified breakdown of the process:</p>\n\n    <ol>\n      <li>\n        <p><strong>Image Segmentation</strong>: The image is divided into patches. Each patch can be seen as a visual “word.” This is analogous to tokenization in NLP, where a sentence is broken down into words or subwords.</p>\n      </li>\n      <li>\n        <p><strong>Flattening and Linear Projection</strong>: Each patch is then flattened (turned into a 1D array) and passed through a linear projection to obtain a fixed-size vector. These vectors are the equivalent of word embeddings in NLP.</p>\n      </li>\n      <li>\n        <p><strong>Sequence of Embeddings</strong>: The sequence of these vectors (one for each patch) is what the Transformer encoder processes. Each vector represents the “token” corresponding to a part of the image.</p>\n      </li>\n      <li>\n        <p><strong>Positional Encoding</strong>: Since Transformers don’t have a sense of order, positional encodings are added to these embeddings to provide information about the location of each patch in the image.</p>\n      </li>\n      <li>\n        <p><strong>Transformer Encoder</strong>: The sequence of patch embeddings, now with positional information, is fed into the Transformer encoder. The encoder processes these embeddings (tokens) through its layers, enabling the model to understand and encode complex relationships and features within the image.</p>\n      </li>\n    </ol>\n  </li>\n  <li>In summary, while the term “tokens” originates from text processing, its use in image processing with encoders like ViT is an analogy to how images are broken down into manageable, meaningful segments for the model to process, similar to how text is tokenized into words or subwords.</li>\n</ul>\n<p>Here’s a simplified breakdown of the process:</p>\n<ol>\n      <li>\n        <p><strong>Image Segmentation</strong>: The image is divided into patches. Each patch can be seen as a visual “word.” This is analogous to tokenization in NLP, where a sentence is broken down into words or subwords.</p>\n      </li>\n      <li>\n        <p><strong>Flattening and Linear Projection</strong>: Each patch is then flattened (turned into a 1D array) and passed through a linear projection to obtain a fixed-size vector. These vectors are the equivalent of word embeddings in NLP.</p>\n      </li>\n      <li>\n        <p><strong>Sequence of Embeddings</strong>: The sequence of these vectors (one for each patch) is what the Transformer encoder processes. Each vector represents the “token” corresponding to a part of the image.</p>\n      </li>\n      <li>\n        <p><strong>Positional Encoding</strong>: Since Transformers don’t have a sense of order, positional encodings are added to these embeddings to provide information about the location of each patch in the image.</p>\n      </li>\n      <li>\n        <p><strong>Transformer Encoder</strong>: The sequence of patch embeddings, now with positional information, is fed into the Transformer encoder. The encoder processes these embeddings (tokens) through its layers, enabling the model to understand and encode complex relationships and features within the image.</p>\n      </li>\n    </ol>\n<p><strong>Image Segmentation</strong>: The image is divided into patches. Each patch can be seen as a visual “word.” This is analogous to tokenization in NLP, where a sentence is broken down into words or subwords.</p>\n<p><strong>Flattening and Linear Projection</strong>: Each patch is then flattened (turned into a 1D array) and passed through a linear projection to obtain a fixed-size vector. These vectors are the equivalent of word embeddings in NLP.</p>\n<p><strong>Sequence of Embeddings</strong>: The sequence of these vectors (one for each patch) is what the Transformer encoder processes. Each vector represents the “token” corresponding to a part of the image.</p>\n<p><strong>Positional Encoding</strong>: Since Transformers don’t have a sense of order, positional encodings are added to these embeddings to provide information about the location of each patch in the image.</p>\n<p><strong>Transformer Encoder</strong>: The sequence of patch embeddings, now with positional information, is fed into the Transformer encoder. The encoder processes these embeddings (tokens) through its layers, enabling the model to understand and encode complex relationships and features within the image.</p>",
    "contentMarkdown": "*   When embedding an image using an encoder in the context of machine learning and neural networks, there are indeed “tokens,” although they might not be tokens in the traditional sense as understood in natural language processing (NLP).\n*   In NLP, tokens usually refer to words or subwords. However, in the context of image processing, an encoder, especially in models like ViT, converts an image into a series of numerical representations, which can be analogously thought of as “tokens.”\n*   Here’s a simplified breakdown of the process:\n    \n    1.  **Image Segmentation**: The image is divided into patches. Each patch can be seen as a visual “word.” This is analogous to tokenization in NLP, where a sentence is broken down into words or subwords.\n        \n    2.  **Flattening and Linear Projection**: Each patch is then flattened (turned into a 1D array) and passed through a linear projection to obtain a fixed-size vector. These vectors are the equivalent of word embeddings in NLP.\n        \n    3.  **Sequence of Embeddings**: The sequence of these vectors (one for each patch) is what the Transformer encoder processes. Each vector represents the “token” corresponding to a part of the image.\n        \n    4.  **Positional Encoding**: Since Transformers don’t have a sense of order, positional encodings are added to these embeddings to provide information about the location of each patch in the image.\n        \n    5.  **Transformer Encoder**: The sequence of patch embeddings, now with positional information, is fed into the Transformer encoder. The encoder processes these embeddings (tokens) through its layers, enabling the model to understand and encode complex relationships and features within the image.\n        \n*   In summary, while the term “tokens” originates from text processing, its use in image processing with encoders like ViT is an analogy to how images are broken down into manageable, meaningful segments for the model to process, similar to how text is tokenized into words or subwords.\n\nHere’s a simplified breakdown of the process:\n\n1.  **Image Segmentation**: The image is divided into patches. Each patch can be seen as a visual “word.” This is analogous to tokenization in NLP, where a sentence is broken down into words or subwords.\n    \n2.  **Flattening and Linear Projection**: Each patch is then flattened (turned into a 1D array) and passed through a linear projection to obtain a fixed-size vector. These vectors are the equivalent of word embeddings in NLP.\n    \n3.  **Sequence of Embeddings**: The sequence of these vectors (one for each patch) is what the Transformer encoder processes. Each vector represents the “token” corresponding to a part of the image.\n    \n4.  **Positional Encoding**: Since Transformers don’t have a sense of order, positional encodings are added to these embeddings to provide information about the location of each patch in the image.\n    \n5.  **Transformer Encoder**: The sequence of patch embeddings, now with positional information, is fed into the Transformer encoder. The encoder processes these embeddings (tokens) through its layers, enabling the model to understand and encode complex relationships and features within the image.\n    \n\n**Image Segmentation**: The image is divided into patches. Each patch can be seen as a visual “word.” This is analogous to tokenization in NLP, where a sentence is broken down into words or subwords.\n\n**Flattening and Linear Projection**: Each patch is then flattened (turned into a 1D array) and passed through a linear projection to obtain a fixed-size vector. These vectors are the equivalent of word embeddings in NLP.\n\n**Sequence of Embeddings**: The sequence of these vectors (one for each patch) is what the Transformer encoder processes. Each vector represents the “token” corresponding to a part of the image.\n\n**Positional Encoding**: Since Transformers don’t have a sense of order, positional encodings are added to these embeddings to provide information about the location of each patch in the image.\n\n**Transformer Encoder**: The sequence of patch embeddings, now with positional information, is fed into the Transformer encoder. The encoder processes these embeddings (tokens) through its layers, enabling the model to understand and encode complex relationships and features within the image.",
    "contentLength": 4897,
    "wordCount": 656,
    "hasCode": false,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/vit/#what-are-“tokens”-when-embedding-an-image-using-an-encoder?-how-are-they-different-compared-to-word/sub-word-tokens-in-nlp?"
  }
]