<!DOCTYPE html><html lang="en"><head><style type="text/css" id="nanobarcss">.nanobar{width:100%;height:4px;z-index:9999;top:0}.bar{width:0;height:100%;transition:height .3s;background:#000}</style><style>#back-to-top{background:#fff;-webkit-border-radius:50%;-moz-border-radius:50%;border-radius:50%;bottom:20px;-webkit-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);-moz-box-shadow:0 2px 5px 0 rgba(0,0,0,.26);box-shadow:0 2px 5px 0 rgba(0,0,0,.26);color:#333;cursor:pointer;display:block;height:56px;opacity:1;outline:0;position:fixed;right:20px;-webkit-tap-highlight-color:transparent;-webkit-touch-callout:none;-webkit-transition:bottom .2s,opacity .2s;-o-transition:bottom .2s,opacity .2s;-moz-transition:bottom .2s,opacity .2s;transition:bottom .2s,opacity .2s;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:56px;z-index:1}#back-to-top svg{display:block;fill:currentColor;height:24px;margin:16px auto 0;width:24px}#back-to-top.hidden{bottom:-56px;opacity:0}</style>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Aman's AI Journal • Primers • Fine-Tuning and Evaluating BERT</title>
  <meta name="viewport" content="width=device-width">
  <meta name="description" content="Aman's AI Journal | Course notes and learning material for Artificial Intelligence and Deep Learning Stanford classes.">
  <link rel="canonical" href="https://aman.ai/primers/ai/fine-tune-and-eval-BERT/">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/css/main.css">

  <!-- Google fonts -->
  <!-- <link href='https://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'>-->

  <!-- RSS feed -->
  <link rel="alternate" type="application/atom+xml" title="Aman’s AI Journal" href="/feed.xml">  
  
  <link href="https://aman.ai/favicon.jpg" rel="shortcut icon">

  <!-- Google ads -->
  <script src="https://pagead2.googlesyndication.com/pagead/managed/js/adsense/m202512100101/show_ads_impl.js"></script><script async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5905744527956213" crossorigin="anonymous" data-checked-head="true"></script>
<meta http-equiv="origin-trial" content="AlK2UR5SkAlj8jjdEc9p3F3xuFYlF6LYjAML3EOqw1g26eCwWPjdmecULvBH5MVPoqKYrOfPhYVL71xAXI1IBQoAAAB8eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="Amm8/NmvvQfhwCib6I7ZsmUxiSCfOxWxHayJwyU1r3gRIItzr7bNQid6O8ZYaE1GSQTa69WwhPC9flq/oYkRBwsAAACCeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="A9nrunKdU5m96PSN1XsSGr3qOP0lvPFUB2AiAylCDlN5DTl17uDFkpQuHj1AFtgWLxpLaiBZuhrtb2WOu7ofHwEAAACKeyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiQUlQcm9tcHRBUElNdWx0aW1vZGFsSW5wdXQiLCJleHBpcnkiOjE3NzQzMTA0MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A93bovR+QVXNx2/38qDbmeYYf1wdte9EO37K9eMq3r+541qo0byhYU899BhPB7Cv9QqD7wIbR1B6OAc9kEfYCA4AAACQeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiQUlQcm9tcHRBUElNdWx0aW1vZGFsSW5wdXQiLCJleHBpcnkiOjE3NzQzMTA0MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A1S5fojrAunSDrFbD8OfGmFHdRFZymSM/1ss3G+NEttCLfHkXvlcF6LGLH8Mo5PakLO1sCASXU1/gQf6XGuTBgwAAACQeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXRhZ3NlcnZpY2VzLmNvbTo0NDMiLCJmZWF0dXJlIjoiQUlQcm9tcHRBUElNdWx0aW1vZGFsSW5wdXQiLCJleHBpcnkiOjE3NzQzMTA0MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><script async="" src="https://fundingchoicesmessages.google.com/i/ca-pub-5905744527956213?href=https%3A%2F%2Faman.ai%2Fprimers%2Fai%2Ffine-tune-and-eval-BERT&amp;ers=2"></script><script async="" src="https://fundingchoicesmessages.google.com/f/AGSKWxXVChC_QYnHHVtf2i9CQyfZvHZHxZ2OzFUnswRioQGxRI_ljXiMN1sKCS-O8B7Z67oZtyJpX_-ZyBzJsA7YI6_K9KG58qNV--rm6U79p0NJZZ8Nmg1R1BkwBvNRtcbsWmjRB5DbKQ==?fccs=W1siQUtzUm9sOGJGZDNweUZmTGNmeFhEZ2d3THlKSGRoR0c2Q0M4SkxobkI4bTV0c0NtY0xpR2R2bmZvQ2ZLRlExSFl5bk02aGRIMXI2R1lsQ2lGZWZiZlhNTlNUV3c3OHhYWXdPeGtXa1BaVEp2NllNUVhpQW1FMHFKanY1OEpLbkd6Z05CVFVfeWVCWlVuWFBSSWxsc2Z5eFg2Ung3UkxObUdBPT0iXSxudWxsLG51bGwsbnVsbCxudWxsLG51bGwsWzE3NjY5MjI1NzUsNDQwMDAwMDBdLG51bGwsbnVsbCxudWxsLFtudWxsLFs3XV0sImh0dHBzOi8vYW1hbi5haS9wcmltZXJzL2FpL2ZpbmUtdHVuZS1hbmQtZXZhbC1CRVJULyIsbnVsbCxbWzgsInNDaE5INU9zYWswIl0sWzksImVuLVVTIl0sWzE5LCIyIl0sWzE3LCJbMF0iXSxbMjQsIiJdLFsyNSwiW1s5NTM0MDI1Myw5NTM0MDI1NV1dIl0sWzI5LCJmYWxzZSJdXV0"></script><script async="" src="https://fundingchoicesmessages.google.com/f/AGSKWxX1OD_TgDggbOGYVb9SYO1mNnVdHsER3H7hWKL4kIn7kx3YTwWO1pHzk4a-xJmyXfM5CZAB2Xf3kOqRU3Ch_tc1migBP5W9gBPSpV5IOeFWJLbWE_gmZat3qEIq2sia5D2G__hseQ==?fccs=W1siQUtzUm9sOGJGZDNweUZmTGNmeFhEZ2d3THlKSGRoR0c2Q0M4SkxobkI4bTV0c0NtY0xpR2R2bmZvQ2ZLRlExSFl5bk02aGRIMXI2R1lsQ2lGZWZiZlhNTlNUV3c3OHhYWXdPeGtXa1BaVEp2NllNUVhpQW1FMHFKanY1OEpLbkd6Z05CVFVfeWVCWlVuWFBSSWxsc2Z5eFg2Ung3UkxObUdBPT0iXSxudWxsLG51bGwsbnVsbCxudWxsLG51bGwsWzE3NjY5MjI1NzUsMTY4MDAwMDAwXSxudWxsLG51bGwsbnVsbCxbbnVsbCxbNyw5XSxudWxsLDIsbnVsbCwiZW4iXSwiaHR0cHM6Ly9hbWFuLmFpL3ByaW1lcnMvYWkvZmluZS10dW5lLWFuZC1ldmFsLUJFUlQvIixudWxsLFtbOCwic0NoTkg1T3NhazAiXSxbOSwiZW4tVVMiXSxbMTksIjIiXSxbMTcsIlswXSJdLFsyNCwiIl0sWzI1LCJbWzk1MzQwMjUzLDk1MzQwMjU1XV0iXSxbMjksImZhbHNlIl1dXQ"></script><script async="" src="https://fundingchoicesmessages.google.com/f/AGSKWxX7S8pjugw5IzAf-1rllqn_da7UDAXyBVcPrDhrwxeO34DNPe9A1owUYZoxQNy8s3PyLQq6e6Jb9_ever6GDC0YpB98b9enKJtMjtUXoQ7h1GXLaBgptdHwndKV0vvVwbbRlwRi2Q==?fccs=W1siQUtzUm9sOGJGZDNweUZmTGNmeFhEZ2d3THlKSGRoR0c2Q0M4SkxobkI4bTV0c0NtY0xpR2R2bmZvQ2ZLRlExSFl5bk02aGRIMXI2R1lsQ2lGZWZiZlhNTlNUV3c3OHhYWXdPeGtXa1BaVEp2NllNUVhpQW1FMHFKanY1OEpLbkd6Z05CVFVfeWVCWlVuWFBSSWxsc2Z5eFg2Ung3UkxObUdBPT0iXSxudWxsLG51bGwsbnVsbCxudWxsLG51bGwsWzE3NjY5MjI1NzYsMzcwMDAwMDBdLG51bGwsbnVsbCxudWxsLFtudWxsLFs3LDksNl0sbnVsbCwyLG51bGwsImVuIixudWxsLG51bGwsbnVsbCxudWxsLG51bGwsMV0sImh0dHBzOi8vYW1hbi5haS9wcmltZXJzL2FpL2ZpbmUtdHVuZS1hbmQtZXZhbC1CRVJULyIsbnVsbCxbWzgsInNDaE5INU9zYWswIl0sWzksImVuLVVTIl0sWzE5LCIyIl0sWzE3LCJbMF0iXSxbMjQsIiJdLFsyNSwiW1s5NTM0MDI1Myw5NTM0MDI1NV1dIl0sWzI5LCJmYWxzZSJdXV0"></script></head>


    <body><div id="MathJax_Message" style="display: none;"></div>

      <script src="https://unpkg.com/vanilla-back-to-top@7.2.1/dist/vanilla-back-to-top.min.js"></script>
      <script>addBackToTop({
        backgroundColor: '#fff',
        innerHTML: 'Back to Top',
        textColor: '#333'
      })</script><div id="back-to-top" class="hidden">Back to Top</div>
      <style>
        #back-to-top {
          border: 1px solid #ccc;
          border-radius: 0;
          font-family: sans-serif;
          font-size: 14px;
          width: 100px;
          text-align: center;
          line-height: 30px;
          height: 30px;
        }
      </style>   

    <header class="site-header">

  <a class="site-title" href="../">Distilled AI</a>

  <a class="site-link" href="https://aman.ai">Back to aman.ai</a>

  <!-- Html Elements for Search -->
  <div id="search-container">
  <input class="site-search-box" type="text" autocomplete="off" id="search-input" placeholder="search...">
  <div id="results-container"></div>
  </div>

  <!-- Script pointing to aman-script.js -->
  <script src="https://aman.ai/js/aman-search.min.js" type="text/javascript"></script>

  <!-- Configuration -->
  <script>
  document.getElementById('search-input').value='';
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('results-container'),
    exclude: ["cs231a"],
    searchResultTemplate: '<div class="site-search-results"><a href="{url}">{title}</a></div>',
    noResultsText: '<div class="site-search-results"><p>No results found</p></div>',
    json: 'https://aman.ai/search.json',
    limit: 5,
    fuzzy: false,
  })
  </script>    

</header>     

    <div class="page-content">
      <div class="wrap">
      <div class="post">

  <header class="post-header">
    <h1>Primers • Fine-Tuning and Evaluating BERT</h1>
  </header>

  <article class="post-content">
  <ul id="markdown-toc">
  <li><a href="#overview" id="markdown-toc-overview">Overview</a></li>
  <li><a href="#setup" id="markdown-toc-setup">Setup</a>    <ul>
      <li><a href="#install-transformers" id="markdown-toc-install-transformers">Install Transformers</a></li>
      <li><a href="#helper-functions" id="markdown-toc-helper-functions">Helper Functions</a></li>
    </ul>
  </li>
  <li><a href="#retrieve-dataset" id="markdown-toc-retrieve-dataset">Retrieve Dataset</a>    <ul>
      <li><a href="#download-dataset-files" id="markdown-toc-download-dataset-files">Download Dataset Files</a></li>
    </ul>
  </li>
  <li><a href="#inspect-dataset" id="markdown-toc-inspect-dataset">Inspect Dataset</a>    <ul>
      <li><a href="#inspect-training-samples" id="markdown-toc-inspect-training-samples">Inspect Training Samples</a></li>
    </ul>
  </li>
  <li><a href="#smart-batching" id="markdown-toc-smart-batching">Smart Batching</a>    <ul>
      <li><a href="#load-tokenizer" id="markdown-toc-load-tokenizer">Load Tokenizer</a></li>
      <li><a href="#tokenize-without-padding" id="markdown-toc-tokenize-without-padding">Tokenize Without Padding</a>        <ul>
          <li><a href="#peak-gpu-memory-use" id="markdown-toc-peak-gpu-memory-use">Peak GPU Memory Use</a></li>
          <li><a href="#tokenize-but-dont-pad" id="markdown-toc-tokenize-but-dont-pad">Tokenize, but Don’t Pad</a></li>
        </ul>
      </li>
      <li><a href="#sort-by-length" id="markdown-toc-sort-by-length">Sort by Length</a></li>
      <li><a href="#random-batch-selection" id="markdown-toc-random-batch-selection">Random Batch Selection</a></li>
      <li><a href="#add-padding" id="markdown-toc-add-padding">Add Padding</a></li>
      <li><a href="#old-approach---fixed-padding" id="markdown-toc-old-approach---fixed-padding">Old Approach - Fixed Padding</a></li>
    </ul>
  </li>
  <li><a href="#fine-tune-bert" id="markdown-toc-fine-tune-bert">Fine-Tune BERT</a>    <ul>
      <li><a href="#load-pre-trained-model" id="markdown-toc-load-pre-trained-model">Load Pre-Trained Model</a></li>
      <li><a href="#optimizer--learning-rate-scheduler" id="markdown-toc-optimizer--learning-rate-scheduler">Optimizer &amp; Learning Rate Scheduler</a></li>
      <li><a href="#training-loop" id="markdown-toc-training-loop">Training Loop</a></li>
    </ul>
  </li>
  <li><a href="#collate-function" id="markdown-toc-collate-function"><code class="language-plaintext Highlighter-rouge">collate</code> Function</a></li>
  <li><a href="#evaluate-on-test-set" id="markdown-toc-evaluate-on-test-set">Evaluate on Test Set</a>    <ul>
      <li><a href="#make_smart_batches" id="markdown-toc-make_smart_batches"><code class="language-plaintext Highlighter-rouge">make_smart_batches()</code></a></li>
      <li><a href="#load-test-dataset--smart-batch" id="markdown-toc-load-test-dataset--smart-batch">Load Test Dataset &amp; Smart Batch</a></li>
      <li><a href="#evaluate" id="markdown-toc-evaluate">Evaluate</a></li>
    </ul>
  </li>
  <li><a href="#appendix" id="markdown-toc-appendix">Appendix</a>    <ul>
      <li><a href="#smart-batching-with-batch_encode_plus-and-dataloader" id="markdown-toc-smart-batching-with-batch_encode_plus-and-dataloader">Smart Batching with <code class="language-plaintext Highlighter-rouge">batch_encode_plus</code> and <code class="language-plaintext Highlighter-rouge">DataLoader</code></a></li>
      <li><a href="#impact-of-pad-tokens-on-accuracy" id="markdown-toc-impact-of-pad-tokens-on-accuracy">Impact of <code class="language-plaintext Highlighter-rouge">[PAD]</code> Tokens on Accuracy</a></li>
      <li><a href="#out-of-memory-oom-errors" id="markdown-toc-out-of-memory-oom-errors">Out of Memory (OOM) Errors</a></li>
    </ul>
  </li>
  <li><a href="#further-reading" id="markdown-toc-further-reading">Further Reading</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
  <li><a href="#citation" id="markdown-toc-citation">Citation</a></li>
</ul>

<h2 id="overview">Overview</h2>

<ul>
  <li>In this article, let’s go over how to fine-tune and evaluate BERT while dramatically increase BERT’s training time by creating batches of samples with different sequence lengths.</li>
</ul>

<h2 id="setup">Setup</h2>

<h3 id="install-transformers">Install Transformers</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code0"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code0"><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span>
</code></pre></div></div>

<h3 id="helper-functions">Helper Functions</h3>

<ul>
  <li>In many of our (long-running) <code class="language-plaintext highlighter-rouge">for</code>-loops, we should print periodic progress updates. Typically people pick the update interval manually, but yoy may defined a helper function to make that choice as follows:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code1"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code1"><span class="k">def</span> <span class="nf">good_update_interval</span><span class="p">(</span><span class="n">total_iters</span><span class="p">,</span> <span class="n">num_desired_updates</span><span class="p">):</span>
    <span class="s">'''
    This function will try to pick an intelligent progress update interval 
    based on the magnitude of the total iterations.

    Parameters:
      `total_iters` - The number of iterations in the for-loop.
      `num_desired_updates` - How many times we want to see an update over the 
                              course of the for-loop.
    '''</span>
    <span class="c1"># Divide the total iterations by the desired number of updates. Most likely
</span>    <span class="c1"># this will be some ugly number.
</span>    <span class="n">exact_interval</span> <span class="o">=</span> <span class="n">total_iters</span> <span class="o">/</span> <span class="n">num_desired_updates</span>

    <span class="c1"># The `round` function has the ability to round down a number to, e.g., the
</span>    <span class="c1"># nearest thousandth: round(exact_interval, -3)
</span>    <span class="c1">#
</span>    <span class="c1"># To determine the magnitude to round to, find the magnitude of the total,
</span>    <span class="c1"># and then go one magnitude below that.
</span>
    <span class="c1"># Get the order of magnitude of the total.
</span>    <span class="n">order_of_mag</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">total_iters</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># Our update interval should be rounded to an order of magnitude smaller. 
</span>    <span class="n">round_mag</span> <span class="o">=</span> <span class="n">order_of_mag</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># Round down and cast to an int.
</span>    <span class="n">update_interval</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">exact_interval</span><span class="p">,</span> <span class="o">-</span><span class="n">round_mag</span><span class="p">))</span>

    <span class="c1"># Don't allow the interval to be zero!
</span>    <span class="k">if</span> <span class="n">update_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">update_interval</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">update_interval</span>
</code></pre></div></div>

<ul>
  <li>Helper function for formatting elapsed times as <code class="language-plaintext highlighter-rouge">hh:mm:ss</code>:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code2"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code2"><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">datetime</span>

<span class="k">def</span> <span class="nf">format_time</span><span class="p">(</span><span class="n">elapsed</span><span class="p">):</span>
    <span class="s">'''
    Takes a time in seconds and returns a string hh:mm:ss
    '''</span>
    <span class="c1"># Round to the nearest second.
</span>    <span class="n">elapsed_rounded</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">((</span><span class="n">elapsed</span><span class="p">)))</span>
    
    <span class="c1"># Format as hh:mm:ss
</span>    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="p">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="n">elapsed_rounded</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="retrieve-dataset">Retrieve Dataset</h2>

<h3 id="download-dataset-files">Download Dataset Files</h3>

<ul>
  <li>
    <p>I’m sure there are many ways to retrieve this dataset–I’m using the TensorFlow Datasets library here as one easy way to do it.</p>
  </li>
  <li>
    <p>Check out the documentation <a href="https://www.tensorflow.org/datasets/catalog/imdb_reviews">here</a></p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code3"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code3">
<span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="n">tfds</span>

<span class="c1"># Download the train and test portions of the dataset.
</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">tfds</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"imdb_reviews/plain_text"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">"train"</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">tfds</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"imdb_reviews/plain_text"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">"test"</span><span class="p">)</span>

<span class="n">INFO</span><span class="p">:</span><span class="n">absl</span><span class="p">:</span><span class="n">Overwrite</span> <span class="n">dataset</span> <span class="n">info</span> <span class="k">from</span> <span class="n">restored</span> <span class="n">data</span> <span class="n">version</span><span class="p">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">absl</span><span class="p">:</span><span class="n">Reusing</span> <span class="n">dataset</span> <span class="n">imdb_reviews</span> <span class="p">(</span><span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="n">tensorflow_datasets</span><span class="o">/</span><span class="n">imdb_reviews</span><span class="o">/</span><span class="n">plain_text</span><span class="o">/</span><span class="mf">1.0</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">absl</span><span class="p">:</span><span class="n">Constructing</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span> <span class="k">for</span> <span class="n">split</span> <span class="n">train</span><span class="p">,</span> <span class="k">from</span> <span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="n">tensorflow_datasets</span><span class="o">/</span><span class="n">imdb_reviews</span><span class="o">/</span><span class="n">plain_text</span><span class="o">/</span><span class="mf">1.0</span><span class="p">.</span><span class="mi">0</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">absl</span><span class="p">:</span><span class="n">Overwrite</span> <span class="n">dataset</span> <span class="n">info</span> <span class="k">from</span> <span class="n">restored</span> <span class="n">data</span> <span class="n">version</span><span class="p">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">absl</span><span class="p">:</span><span class="n">Reusing</span> <span class="n">dataset</span> <span class="n">imdb_reviews</span> <span class="p">(</span><span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="n">tensorflow_datasets</span><span class="o">/</span><span class="n">imdb_reviews</span><span class="o">/</span><span class="n">plain_text</span><span class="o">/</span><span class="mf">1.0</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">absl</span><span class="p">:</span><span class="n">Constructing</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span> <span class="k">for</span> <span class="n">split</span> <span class="n">test</span><span class="p">,</span> <span class="k">from</span> <span class="o">/</span><span class="n">root</span><span class="o">/</span><span class="n">tensorflow_datasets</span><span class="o">/</span><span class="n">imdb_reviews</span><span class="o">/</span><span class="n">plain_text</span><span class="o">/</span><span class="mf">1.0</span><span class="p">.</span><span class="mi">0</span>
<span class="n">Let</span><span class="err">’</span><span class="n">s</span> <span class="n">examine</span> <span class="n">the</span> <span class="n">contents</span> <span class="ow">and</span> <span class="n">datatypes</span> <span class="n">contained</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">dataset</span><span class="p">.</span>
</code></pre></div></div>

<ul>
  <li>Each sample has a label and text field.</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code4"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code4">train_data
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code5"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code5">&lt;DatasetV1Adapter shapes: {label: (), text: ()}, types: {label: tf.int64, text: tf.string}&gt;
</code></pre></div></div>

<ul>
  <li>Let’s pull the data out of TensorFlow’s icy grip, so we just have plain Python types :)</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code6"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code6"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">train_text</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Loop over the training set...
</span><span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">train_data</span><span class="p">.</span><span class="n">as_numpy_iterator</span><span class="p">():</span>

    <span class="c1"># The text is a `bytes` object, decode to string.
</span>    <span class="n">train_text</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s">'text'</span><span class="p">].</span><span class="n">decode</span><span class="p">())</span>

    <span class="c1"># Cast the label from `np.int64` to `int`
</span>    <span class="n">train_labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s">'label'</span><span class="p">]))</span>

<span class="n">test_text</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Loop over the test set...
</span><span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">.</span><span class="n">as_numpy_iterator</span><span class="p">():</span>

    <span class="c1"># The text is a `bytes` object, decode to string.
</span>    <span class="n">test_text</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s">'text'</span><span class="p">].</span><span class="n">decode</span><span class="p">())</span>

    <span class="c1"># Cast the label from `np.int64` to `int`
</span>    <span class="n">test_labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">ex</span><span class="p">[</span><span class="s">'label'</span><span class="p">]))</span>

<span class="c1"># Print some stats.
</span><span class="k">print</span><span class="p">(</span><span class="s">'{:,} Training Samples'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'{:,} Test Samples'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Labels:'</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">train_labels</span><span class="p">))</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code7"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code7">25,000 Training Samples
25,000 Test Samples
Labels: [0 1]
</code></pre></div></div>

<h2 id="inspect-dataset">Inspect Dataset</h2>

<h3 id="inspect-training-samples">Inspect Training Samples</h3>

<ul>
  <li>Lets print out a handful of samples at random.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code8"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code8"><span class="kn">import</span> <span class="nn">textwrap</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Wrap text to 80 characters.
</span><span class="n">wrapper</span> <span class="o">=</span> <span class="n">textwrap</span><span class="p">.</span><span class="n">TextWrapper</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span> 

<span class="c1"># Randomly choose some examples.
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    
    <span class="c1"># Choose a random sample by index.
</span>    <span class="n">j</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_text</span><span class="p">)))</span>
    
    <span class="c1"># Print out the label and the text. 
</span>    <span class="k">print</span><span class="p">(</span><span class="s">'==== Label: {:} ===='</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">train_labels</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
    <span class="k">print</span><span class="p">(</span><span class="n">wrapper</span><span class="p">.</span><span class="n">fill</span><span class="p">(</span><span class="n">train_text</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">''</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code9"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code9">==== Label: 0 ====
Somewhere, on this site, someone wrote that to get the best version of the works
of Jane Austen, one should simply read them. I agree with that. However, we love
adaptations of great literature and the current writers' strike brings to mind
that without good writers, it's hard for actors to bring their roles to life.
The current version of Jane Austen's PERSUASION shows us what happens when you
don't have a good foundation in a well-written adaptation. This version does not
compare to the 1995 version with Amanda Root and Ciaran Hinds, which was well
acted and kept the essence of the era and the constraints on the characters
(with the exception of the bizarre parade &amp; kissing in the street scene in
Bath). The 2007 version shows a twitty Anne who seems angst-ridden. The other
characters were not very developed which is a crime, considering how Austen
could paint such wonderful characters with some carefully chosen
understatements. The sequence of events that made sense in the novel were
completely tossed about, and Mrs. Smith, Anne's bedridden and impoverished
schoolmate is walking around in Bath - - twittering away, as many of the
characters seemed to do. The strength of character and the intelligence of
Captain Wentworth, which caused Anne to love him in the first place, didn't seem
to be written into the Rupert Penry-Jones' Wentworth. Ciaran Hinds had more
substance and was able to convey so much more with a look, than P-J was able to
do with his poses. All in all, the 2007 version was a disappointment. It seemed
to reduce the novel into a hand- wringing, costumed melodrama of debatable
worth. If they wanted to bring our modern emotional extravagances into Austen's
work, they should have done what they do with adaptations of Shakespeare: adapt
it to the present. At least "Bride &amp; Prejudice" was taken out of the historical
&amp; locational settings and was fun to watch, as was "Clueless". This wasn't
PERSUASION, but they didn't know what else to call it.

==== Label: 0 ====
It's difficult to put into words the almost seething hatred I have of this film.
But I'll try:&lt;br /&gt;&lt;br /&gt;Every other word was an expletive, the sex scenes were
uncomfortable, drugs were rampant and stereotyping was beyond the norm, if not
offensive to Italian-Americans.&lt;br /&gt;&lt;br /&gt;I'm not saying the acting was
terrible, because Leguizamo, Sorvino, Brody, Espisito et. al, performed well.
But...almost every character in the film I despised. Not since The Bonfire of
the Vanities have I disliked every character on screen.

==== Label: 0 ====
Take one look at the cover of this movie, and you know right away that you are
not about to watch a landmark film. This is cheese filmmaking in every respect,
but it does have its moments. Despite the look of utter trash that the movie
gives, the story is actually interesting at some points, although it is
undeniably pulled along mainly by the cheerleading squads' shower scenes and sex
scenes with numerous personality-free boyfriends. The acting is awful and the
director did little more than point and shoot, which is why the extensive amount
of nudity was needed to keep the audience's attention.&lt;br /&gt;&lt;br /&gt;In The Nutty
Professor, a hopelessly geeky professor discovers a potion that can turn him
into a cool and stylish womanizer, whereas in The Invisible Maniac, a mentally
damaged professor discovers a potion that can make him invisible, allowing him
to spy on (and kill, for some reason) his students. Boring fodder. Don't expect
any kind of mental stimulation from this, and prepare yourself for shrill and
enormously overdone maniacal laughter which gets real annoying real quick...
</code></pre></div></div>

<ul>
  <li>Let’s also check out the classes and their balance.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code10"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code10"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s">'darkgrid'</span><span class="p">)</span>

<span class="c1"># Increase the plot size and font size.
</span><span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Plot the number of tokens of each length.
</span><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>

<span class="c1"># Add labels
</span><span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Class Distribution'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Category'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'# of Training Samples'</span><span class="p">)</span>

<span class="c1"># Add thousands separators to the y-axis labels.
</span><span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="n">ax</span><span class="p">.</span><span class="n">yaxis</span><span class="p">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">mpl</span><span class="p">.</span><span class="n">ticker</span><span class="p">.</span><span class="n">StrMethodFormatter</span><span class="p">(</span><span class="s">'{x:,.0f}'</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<ul>
  <li>The plot below shows the class balance in IMDB’s movie reviews:</li>
</ul>

<p><img src="/primers/ai/assets/fine-tune-and-eval-BERT/imdb_reviews_class_distribution.png" alt=""></p>

<h2 id="smart-batching">Smart Batching</h2>

<ul>
  <li>
    <p>In this section, we will prepare our training set into these smart batches.</p>
  </li>
  <li>
    <p>Note that we’ve also defined a <code class="language-plaintext highlighter-rouge">make_smart_batches</code> function towards the end which performs all of these steps. We’ll use that function to prepare the test set, and you could use that function in your own applications for both the training and test sets.</p>
  </li>
</ul>

<h3 id="load-tokenizer">Load Tokenizer</h3>

<ul>
  <li>We’ll use the uncased version of BERT-base.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code11"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code11"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span>

<span class="c1"># Load the BERT tokenizer.
</span><span class="k">print</span><span class="p">(</span><span class="s">'Loading BERT tokenizer...'</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">'bert-base-uncased'</span><span class="p">,</span> <span class="n">do_lower_case</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code12"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code12">Loading BERT tokenizer...
</code></pre></div></div>

<h3 id="tokenize-without-padding">Tokenize Without Padding</h3>

<h4 id="peak-gpu-memory-use">Peak GPU Memory Use</h4>

<ul>
  <li>
    <p>Even when applying smart batching, we may still want to truncate our inputs to a certain maximum length. BERT requires a lot of GPU memory, and it’s quite possible for the GPU to not be able to process a batch with too many samples in it and / or too long of sequences.</p>
  </li>
  <li>
    <p>Smart batching means most of our batches will naturally have shorter sequence lengths and not require too much memory. However, all it takes is one batch that’s too long to fit on the GPU, and our <strong>training will fail</strong>!</p>
  </li>
  <li>
    <p>In other words, we still have to be concerned with our “peak” memory usage, and it still likely makes sense to truncate to something lower than 512, even with smart batching.</p>
  </li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code13"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code13">max_len = 400
</code></pre></div></div>

<h4 id="tokenize-but-dont-pad">Tokenize, but Don’t Pad</h4>

<ul>
  <li>
    <p>We’re going to start by tokenizing all of the samples and mapping the tokens to their IDs.</p>
  </li>
  <li>
    <p>We’re also going to truncate the sequences to our chosen <code class="language-plaintext highlighter-rouge">max_len</code>, and we’re going to add the special tokens.</p>
  </li>
  <li>
    <p>But we are not padding yet! We don’t know what lengths to pad the sequences too until after we’ve grouped them into batches.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code14"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code14"><span class="n">full_input_ids</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Tokenize all training examples
</span><span class="k">print</span><span class="p">(</span><span class="s">'Tokenizing {:,} training samples...'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_text</span><span class="p">)))</span>

<span class="c1"># Choose an interval on which to print progress updates.
</span><span class="n">update_interval</span> <span class="o">=</span> <span class="n">good_update_interval</span><span class="p">(</span><span class="n">total_iters</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_text</span><span class="p">),</span> <span class="n">num_desired_updates</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># For each training example...
</span><span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">train_text</span><span class="p">:</span>
    
    <span class="c1"># Report progress.
</span>    <span class="k">if</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">full_input_ids</span><span class="p">)</span> <span class="o">%</span> <span class="n">update_interval</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'  Tokenized {:,} samples.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">full_input_ids</span><span class="p">)))</span>

    <span class="c1"># Tokenize the sentence.
</span>    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>           <span class="c1"># Movie review text
</span>                                 <span class="n">add_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="c1"># Do add specials.
</span>                                 <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span>  <span class="c1"># Do truncate to `max_len`
</span>                                 <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>     <span class="c1"># Do truncate!
</span>                                 <span class="n">padding</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>       <span class="c1"># Don't pad!
</span>                                 
    <span class="c1"># Add the tokenized result to our list.
</span>    <span class="n">full_input_ids</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
    
<span class="k">print</span><span class="p">(</span><span class="s">'DONE.'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'{:&gt;10,} samples'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">full_input_ids</span><span class="p">)))</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code15"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code15">Tokenizing 25,000 training samples...
Tokenized 0 samples.
Tokenized 2,000 samples.
Tokenized 4,000 samples.
Tokenized 6,000 samples.
Tokenized 8,000 samples.
Tokenized 10,000 samples.
Tokenized 12,000 samples.
Tokenized 14,000 samples.
Tokenized 16,000 samples.
Tokenized 18,000 samples.
Tokenized 20,000 samples.
Tokenized 22,000 samples.
Tokenized 24,000 samples.
DONE.
25,000 samples
</code></pre></div></div>

<h3 id="sort-by-length">Sort by Length</h3>

<ul>
  <li>
    <p>Before we sort the samples by length, let’s look at the lengths of the samples in their original, unsorted order.</p>
  </li>
  <li>
    <p>The below plot simply confirms that the sample lengths do vary significantly, and that they are unsorted.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code16"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code16"><span class="c1"># Get all of the lengths.
</span><span class="n">unsorted_lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">full_input_ids</span><span class="p">]</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="c1"># Use plot styling from seaborn.
</span><span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s">'darkgrid'</span><span class="p">)</span>

<span class="c1"># Increase the plot size and font size.
</span><span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">unsorted_lengths</span><span class="p">)),</span> <span class="n">unsorted_lengths</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">"|"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Sample Number'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Sequence Length'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Samples BEFORE Sorting'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<ul>
  <li>The following plot shows samples before sorting:</li>
</ul>

<p><img src="/primers/ai/assets/fine-tune-and-eval-BERT/samples_before_sorting.png" alt=""></p>

<ul>
  <li>Now we’ll sort the examples by length so that we can create batches with equal (or at least similar) lengths.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code17"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code17"><span class="c1"># Sort the two lists together by the length of the input sequence.
</span><span class="n">train_samples</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">full_input_ids</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">train_samples</code> is now a list of tuples of (input_ids, label):</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code18"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code18"><span class="n">train_samples</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code19"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code19">([101, 2023, 3185, 2003, 6659, 2021, 2009, 2038, 2070, 2204, 3896, 1012, 102],
 0)
</code></pre></div></div>

<ul>
  <li>Now let’s check out the shortest/longest sample:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code20"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code20">print('Shortest sample:', len(train_samples[0][0]))
print('Longest sample:', len(train_samples[-1][0]))
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code21"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code21"><span class="n">Shortest</span> <span class="n">sample</span><span class="p">:</span> <span class="mi">13</span>
<span class="n">Longest</span> <span class="n">sample</span><span class="p">:</span> <span class="mi">400</span>
</code></pre></div></div>

<ul>
  <li>Let’s generate the same plot again, now that the samples are sorted by length.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code22"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code22"><span class="c1"># Get the new list of lengths after sorting.
</span><span class="n">sorted_lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">train_samples</span><span class="p">]</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="c1"># Use plot styling from seaborn.
</span><span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s">'darkgrid'</span><span class="p">)</span>

<span class="c1"># Increase the plot size and font size.
</span><span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sorted_lengths</span><span class="p">)),</span> <span class="n">sorted_lengths</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Sample Number'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Sequence Length'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Samples after Sorting'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<ul>
  <li>The following plot shows samples after sorting:</li>
</ul>

<p><img src="/primers/ai/assets/fine-tune-and-eval-BERT/samples_after_sorting.png" alt=""></p>

<h3 id="random-batch-selection">Random Batch Selection</h3>

<ul>
  <li>Choose our batch size.</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code23"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code23">batch_size = 16
</code></pre></div></div>

<ul>
  <li>
    <p>Now we’re ready to select our batches.</p>
  </li>
  <li>
    <p>The strategy used here comes from Michaël Benesty’s <a href="https://gist.github.com/pommedeterresautee/1a334b665710bec9bb65965f662c94c8">code</a> (also, blog post is <a href="https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e">here</a>), in his <code class="language-plaintext highlighter-rouge">build_batches</code> function.</p>
  </li>
  <li>
    <p>Rather than dividing the batches up in order, we will still add a degree of <strong>randomness</strong> to our selection.</p>
  </li>
  <li>
    <p>Here’s the process:</p>

    <ul>
      <li>Pick a random starting point in the (sorted!) list of samples.</li>
      <li>Grab a contiguous batch of samples starting from that point.</li>
      <li>Delete those samples from the list, and repeat until all of the samples have been grabbed.</li>
    </ul>
  </li>
  <li>
    <p>This will result in some <strong>fragmentation</strong> of the list, which means it won’t be quite as efficient as if we just sliced up the batches in sorted order.</p>
  </li>
  <li>
    <p>The benefit is that our path through the training set can still have a degree of randomness. Also, given the distribution of lengths that we saw in the previous section (lots of samples with similar lengths), the fragmentation problem should be pretty minor!</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code24"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code24"><span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># List of batches that we'll construct.
</span><span class="n">batch_ordered_sentences</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">batch_ordered_labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Creating training batches of size {:}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">batch_size</span><span class="p">))</span>

<span class="c1"># Loop over all of the input samples...    
</span><span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_samples</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    
    <span class="c1"># Report progress.
</span>    <span class="k">if</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_ordered_sentences</span><span class="p">)</span> <span class="o">%</span> <span class="mi">500</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'  Selected {:,} batches.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_ordered_sentences</span><span class="p">)))</span>

    <span class="c1"># `to_take` is our actual batch size. It will be `batch_size` until 
</span>    <span class="c1"># we get to the last batch, which may be smaller. 
</span>    <span class="n">to_take</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_samples</span><span class="p">))</span>

    <span class="c1"># Pick a random index in the list of remaining samples to start
</span>    <span class="c1"># our batch at.
</span>    <span class="n">select</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_samples</span><span class="p">)</span> <span class="o">-</span> <span class="n">to_take</span><span class="p">)</span>

    <span class="c1"># Select a contiguous batch of samples starting at `select`.
</span>    <span class="n">batch</span> <span class="o">=</span> <span class="n">train_samples</span><span class="p">[</span><span class="n">select</span><span class="p">:(</span><span class="n">select</span> <span class="o">+</span> <span class="n">to_take</span><span class="p">)]</span>

    <span class="c1"># Each sample is a tuple--split them apart to create a separate list of 
</span>    <span class="c1"># sequences and a list of labels for this batch.
</span>    <span class="n">batch_ordered_sentences</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
    <span class="n">batch_ordered_labels</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>

    <span class="c1"># Remove these samples from the list.
</span>    <span class="k">del</span> <span class="n">train_samples</span><span class="p">[</span><span class="n">select</span><span class="p">:</span><span class="n">select</span> <span class="o">+</span> <span class="n">to_take</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">  DONE - {:,} batches.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_ordered_sentences</span><span class="p">)))</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code25"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code25">Creating training batches of size 16
Selected 0 batches.
Selected 500 batches.
Selected 1,000 batches.
Selected 1,500 batches.

DONE - 1,563 batches.
</code></pre></div></div>

<h3 id="add-padding">Add Padding</h3>

<ul>
  <li>
    <p>We’ve created our batches, but many of them will contain sequences of different lengths. In order to leverage the GPUs parallel processing of batches, all of the sequences within a batch need to be the same length.</p>
  </li>
  <li>
    <p>This means we need to do some padding!</p>
  </li>
  <li>
    <p>We’ll also create our <strong>attention masks</strong> here, and cast everything to <strong>PyTorch tensors</strong> in preparation for our fine-tuning step.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code26"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code26"><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">py_inputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">py_attn_masks</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">py_labels</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># For each batch...
</span><span class="k">for</span> <span class="p">(</span><span class="n">batch_inputs</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batch_ordered_sentences</span><span class="p">,</span> <span class="n">batch_ordered_labels</span><span class="p">):</span>

    <span class="c1"># New version of the batch, this time with padded sequences and now with
</span>    <span class="c1"># attention masks defined.
</span>    <span class="n">batch_padded_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">batch_attn_masks</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># First, find the longest sample in the batch. 
</span>    <span class="c1"># Note that the sequences do currently include the special tokens!
</span>    <span class="n">max_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sen</span><span class="p">)</span> <span class="k">for</span> <span class="n">sen</span> <span class="ow">in</span> <span class="n">batch_inputs</span><span class="p">])</span>

    <span class="c1">#print('Max size:', max_size)
</span>
    <span class="c1"># For each input in this batch...
</span>    <span class="k">for</span> <span class="n">sen</span> <span class="ow">in</span> <span class="n">batch_inputs</span><span class="p">:</span>
        
        <span class="c1"># How many pad tokens do we need to add?
</span>        <span class="n">num_pads</span> <span class="o">=</span> <span class="n">max_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sen</span><span class="p">)</span>

        <span class="c1"># Add `num_pads` padding tokens to the end of the sequence.
</span>        <span class="n">padded_input</span> <span class="o">=</span> <span class="n">sen</span> <span class="o">+</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span><span class="p">]</span><span class="o">*</span><span class="n">num_pads</span>

        <span class="c1"># Define the attention mask--it's just a `1` for every real token
</span>        <span class="c1"># and a `0` for every padding token.
</span>        <span class="n">attn_mask</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">sen</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_pads</span>

        <span class="c1"># Add the padded results to the batch.
</span>        <span class="n">batch_padded_inputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">padded_input</span><span class="p">)</span>
        <span class="n">batch_attn_masks</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">)</span>

    <span class="c1"># Our batch has been padded, so we need to save this updated batch.
</span>    <span class="c1"># We also need the inputs to be PyTorch tensors, so we'll do that here.
</span>    <span class="n">py_inputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">batch_padded_inputs</span><span class="p">))</span>
    <span class="n">py_attn_masks</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">batch_attn_masks</span><span class="p">))</span>
    <span class="n">py_labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">batch_labels</span><span class="p">))</span>
</code></pre></div></div>

<ul>
  <li>Now that our data is ready, we can calculate the total number of tokens in the training data after using smart batching.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code27"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code27"><span class="c1"># Get the new list of lengths after sorting.
</span><span class="n">padded_lengths</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># For each batch...
</span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">py_inputs</span><span class="p">:</span>
    
    <span class="c1"># For each sample...
</span>    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
    
        <span class="c1"># Record its length.
</span>        <span class="n">padded_lengths</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>

<span class="c1"># Sum up the lengths to the get the total number of tokens after smart batching.
</span><span class="n">smart_token_count</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">padded_lengths</span><span class="p">)</span>

<span class="c1"># To get the total number of tokens in the dataset using fixed padding, it's
# as simple as the number of samples times our `max_len` parameter (that we
# would pad everything to).
</span><span class="n">fixed_token_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_text</span><span class="p">)</span> <span class="o">*</span> <span class="n">max_len</span>

<span class="c1"># Calculate the percentage reduction.
</span><span class="n">prcnt_reduced</span> <span class="o">=</span> <span class="p">(</span><span class="n">fixed_token_count</span> <span class="o">-</span> <span class="n">smart_token_count</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">fixed_token_count</span><span class="p">)</span> 

<span class="k">print</span><span class="p">(</span><span class="s">'Total tokens:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'   Fixed Padding: {:,}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">fixed_token_count</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'  Smart Batching: {:,}  ({:.1%} less)'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">smart_token_count</span><span class="p">,</span> <span class="n">prcnt_reduced</span><span class="p">))</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code28"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code28">Total tokens:
Fixed Padding: 10,000,000
Smart Batching: 6,381,424  (36.2% less)
</code></pre></div></div>

<ul>
  <li>We’ll see at the end that this reduction in token count corresponds well to the reduction in training time!</li>
</ul>

<h3 id="old-approach---fixed-padding">Old Approach - Fixed Padding</h3>

<ul>
  <li>To see how BERT does on the benchmark without smart batching, you can run the following code instead of the above sections: <a href="#tokenize-without-padding">Tokenize Without Padding</a>, <a href="#sort-by-length">Sort by length</a>, <a href="#random-batch-selection">Random Batch Selection</a> and <a href="#add-padding">Add Padding</a>.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code29"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code29"><span class="n">use_fixed_padding</span> <span class="o">=</span> <span class="bp">False</span>

<span class="k">if</span> <span class="n">use_fixed_padding</span><span class="p">:</span>

    <span class="c1"># Specify batch_size and truncation length.    
</span>    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">max_len</span> <span class="o">=</span> <span class="mi">400</span>   

    <span class="c1"># Tokenize all training examples
</span>    <span class="k">print</span><span class="p">(</span><span class="s">'Tokenizing {:,} training samples...'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_text</span><span class="p">)))</span>

    <span class="c1"># Tokenize all of the sentences and map the tokens to thier word IDs.
</span>    <span class="n">batches_input_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">batches_attention_masks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">batches_labels</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">update_interval</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="mi">150</span> 

    <span class="c1"># For every sentence...
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_text</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>

        <span class="c1"># Report progress.
</span>        <span class="k">if</span> <span class="p">((</span><span class="n">i</span> <span class="o">%</span> <span class="n">update_interval</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'  Tokenized {:,} samples.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

        <span class="c1"># `encode_plus` will:
</span>        <span class="c1">#   (1) Tokenize the sentence.
</span>        <span class="c1">#   (2) Prepend the `[CLS]` token to the start.
</span>        <span class="c1">#   (3) Append the `[SEP]` token to the end.
</span>        <span class="c1">#   (4) Map tokens to their IDs.
</span>        <span class="c1">#   (5) Pad or truncate the sentence to `max_length`
</span>        <span class="c1">#   (6) Create attention masks for `[PAD]` tokens.
</span>        <span class="n">encoded_dict</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_encode_plus</span><span class="p">(</span>
                            <span class="n">train_text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> <span class="c1"># Batch of sentences to encode.
</span>                            <span class="n">add_special_tokens</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>  <span class="c1"># Add '[CLS]' and '[SEP]'
</span>                            <span class="n">max_length</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span>           <span class="c1"># Pad &amp; truncate all sentences.
</span>                            <span class="n">padding</span> <span class="o">=</span> <span class="s">'max_length'</span><span class="p">,</span>     <span class="c1"># Pad all to the `max_length` parameter.
</span>                            <span class="n">truncation</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
                            <span class="n">return_attention_mask</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>   <span class="c1"># Construct attn. masks.
</span>                            <span class="n">return_tensors</span> <span class="o">=</span> <span class="s">'pt'</span><span class="p">,</span>     <span class="c1"># Return pytorch tensors.
</span>                    <span class="p">)</span>
        
        <span class="c1"># Add the encoded sentence to the list.    
</span>        <span class="n">batches_input_ids</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoded_dict</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">])</span>
        
        <span class="c1"># And its attention mask (simply differentiates padding from non-padding).
</span>        <span class="n">batches_attention_masks</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoded_dict</span><span class="p">[</span><span class="s">'attention_mask'</span><span class="p">])</span>

        <span class="c1"># Add the labels for the batch
</span>        <span class="n">batches_labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_labels</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]))</span>
    
    <span class="c1"># Rename the final variable to match the rest of the code in this Notebook.
</span>    <span class="n">py_inputs</span> <span class="o">=</span> <span class="n">batches_input_ids</span>
    <span class="n">py_attn_masks</span> <span class="o">=</span> <span class="n">batches_attention_masks</span>
    <span class="n">py_labels</span> <span class="o">=</span> <span class="n">batches_labels</span>
</code></pre></div></div>

<h2 id="fine-tune-bert">Fine-Tune BERT</h2>

<h3 id="load-pre-trained-model">Load Pre-Trained Model</h3>

<ul>
  <li>
    <p>We’ll use BERT-base-uncased for this example.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">transformers</code> defines these <code class="language-plaintext highlighter-rouge">Auto</code> classes which will automatically select the correct class for the pre-trained model that you specified.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code30"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code30"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoConfig</span>

<span class="c1"># Load the Config object, with an output configured for classification.
</span><span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name_or_path</span><span class="o">=</span><span class="s">'bert-base-uncased'</span><span class="p">,</span>
                                    <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Config type:'</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="p">)),</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code31"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code31">HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…

Config type: &lt;class 'transformers.configuration_bert.BertConfig'&gt; 
</code></pre></div></div>

<ul>
  <li>Now let’s load the pre-trained model using the config:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code32"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code32"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="c1"># Load the pre-trained model for classification, passing in the `config` from
# above.
</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">pretrained_model_name_or_path</span><span class="o">=</span><span class="s">'bert-base-uncased'</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Model type:'</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)))</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code33"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code33">HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…

WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:transformers.modeling_utils:Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Model type: &lt;class 'transformers.modeling_bert.BertForSequenceClassification'&gt;
</code></pre></div></div>

<ul>
  <li>
    <p>Connect to the GPU and load our model onto it.</p>
  </li>
  <li>
    <p>It’s worth taking note of which GPU you’re given. The Tesla P100 is much faster, for example, than the Tesla K80.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code34"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code34"><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Loading model to GPU...'</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'  GPU:'</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

<span class="n">desc</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'    DONE.'</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code35"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code35">Loading model to GPU...
  GPU: Tesla K80
    DONE.
</code></pre></div></div>

<h3 id="optimizer--learning-rate-scheduler">Optimizer &amp; Learning Rate Scheduler</h3>

<ul>
  <li>Set up our optimizer and learning rate scheduler for training.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code36"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code36"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span>

<span class="c1"># Note: AdamW is a class from the huggingface library (as opposed to pytorch) 
# The 'W' likely stands for 'Weight Decay fix"
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span>
                  <span class="n">lr</span> <span class="o">=</span> <span class="mf">5e-5</span><span class="p">,</span> <span class="c1"># This is the value Michael used.
</span>                  <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-8</span> <span class="c1"># args.adam_epsilon  - default is 1e-8.
</span>                <span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code37"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code37"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">get_linear_schedule_with_warmup</span>

<span class="c1"># Number of training epochs. We choose to train for one epoch simply because the training
# time is long. More epochs may improve the model's accuracy.
</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Total number of training steps is [number of batches] x [number of epochs]. 
# Note that it's the number of *batches*, not *samples*!
</span><span class="n">total_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">)</span> <span class="o">*</span> <span class="n">epochs</span>

<span class="c1"># Create the learning rate scheduler.
</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> 
                                            <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Default value in run_glue.py
</span>                                            <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">total_steps</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="training-loop">Training Loop</h3>

<ul>
  <li>
    <p>In previous examples, we’ve made use of the PyTorch <code class="language-plaintext highlighter-rouge">Dataset</code> and <code class="language-plaintext highlighter-rouge">DataLoader</code> classes, but because of the smart batching we’re not using them in this Notebook. However, check out the section below on how to use the <a href="#collate-function"><code class="language-plaintext highlighter-rouge">collate</code> function</a> with a standard <code class="language-plaintext highlighter-rouge">DataLoader</code> pipeline. However, check out the section below on how to use the <a href="#collate-function"><code class="language-plaintext highlighter-rouge">collate</code> function</a> with a standard <code class="language-plaintext highlighter-rouge">DataLoader</code> pipeline.</p>
  </li>
  <li>
    <p>Note: If you have modified the code here to run for more than one epoch, you’ll need the <code class="language-plaintext highlighter-rouge">make_smart_batches</code> function defined in the <a href="#make-smart-batches">make_smart_batches</a> section.</p>
  </li>
  <li>
    <p>We’re ready to kick off the training!</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code38"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code38"><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># This training code is based on the `run_glue.py` script here:
# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128
</span>
<span class="c1"># Set the seed value all over the place to make this reproducible.
</span><span class="n">seed_val</span> <span class="o">=</span> <span class="mi">321</span>

<span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed_val</span><span class="p">)</span>

<span class="c1"># We'll store a number of quantities such as training and validation loss, 
# validation accuracy, and timings.
</span><span class="n">training_stats</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Update every `update_interval` batches.
</span><span class="n">update_interval</span> <span class="o">=</span> <span class="n">good_update_interval</span><span class="p">(</span><span class="n">total_iters</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">),</span> <span class="n">num_desired_updates</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Measure the total training time for the whole run.
</span><span class="n">total_t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># For each epoch...
</span><span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    
    <span class="c1"># ========================================
</span>    <span class="c1">#               Training
</span>    <span class="c1"># ========================================
</span>    
    <span class="c1"># Perform one full pass over the training set.
</span>
    <span class="k">print</span><span class="p">(</span><span class="s">""</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'======== Epoch {:} / {:} ========'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch_i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">))</span>
    
    <span class="c1"># At the start of each epoch (except for the first) we need to re-randomize
</span>    <span class="c1"># our training data.
</span>    <span class="k">if</span> <span class="n">epoch_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Use our `make_smart_batches` function (from 6.1.) to re-shuffle the 
</span>        <span class="c1"># dataset into new batches.
</span>        <span class="p">(</span><span class="n">py_inputs</span><span class="p">,</span> <span class="n">py_attn_masks</span><span class="p">,</span> <span class="n">py_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">make_smart_batches</span><span class="p">(</span><span class="n">train_text</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">'Training on {:,} batches...'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">)))</span>

    <span class="c1"># Measure how long the training epoch takes.
</span>    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

    <span class="c1"># Reset the total loss for this epoch.
</span>    <span class="n">total_train_loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Put the model into training mode. Don't be misled--the call to 
</span>    <span class="c1"># `train` just changes the *mode*, it doesn't *perform* the training.
</span>    <span class="c1"># `dropout` and `batchnorm` layers behave differently during training
</span>    <span class="c1"># vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)
</span>    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># For each batch of training data...
</span>    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">)):</span>

        <span class="c1"># Progress update every, e.g., 100 batches.
</span>        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">update_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Calculate elapsed time in minutes.
</span>            <span class="n">elapsed</span> <span class="o">=</span> <span class="n">format_time</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span>
            
            <span class="c1"># Calculate the time remaining based on our progress.
</span>            <span class="n">steps_per_sec</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span> <span class="o">/</span> <span class="n">step</span>
            <span class="n">remaining_sec</span> <span class="o">=</span> <span class="n">steps_per_sec</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">)</span> <span class="o">-</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">remaining</span> <span class="o">=</span> <span class="n">format_time</span><span class="p">(</span><span class="n">remaining_sec</span><span class="p">)</span>

            <span class="c1"># Report progress.
</span>            <span class="k">print</span><span class="p">(</span><span class="s">'  Batch {:&gt;7,}  of  {:&gt;7,}.    Elapsed: {:}.  Remaining: {:}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">),</span> <span class="n">elapsed</span><span class="p">,</span> <span class="n">remaining</span><span class="p">))</span>

        <span class="c1"># Copy the current training batch to the GPU using the `to` method.
</span>        <span class="n">b_input_ids</span> <span class="o">=</span> <span class="n">py_inputs</span><span class="p">[</span><span class="n">step</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">b_input_mask</span> <span class="o">=</span> <span class="n">py_attn_masks</span><span class="p">[</span><span class="n">step</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">b_labels</span> <span class="o">=</span> <span class="n">py_labels</span><span class="p">[</span><span class="n">step</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Always clear any previously calculated gradients before performing a
</span>        <span class="c1"># backward pass.
</span>        <span class="n">model</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>        

        <span class="c1"># Perform a forward pass (evaluate the model on this training batch).
</span>        <span class="c1"># The call returns the loss (because we provided labels) and the 
</span>        <span class="c1"># "logits"--the model outputs prior to activation.
</span>        <span class="n">loss</span><span class="p">,</span> <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> 
                             <span class="n">token_type_ids</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                             <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span><span class="p">,</span> 
                             <span class="n">labels</span><span class="o">=</span><span class="n">b_labels</span><span class="p">)</span>

        <span class="c1"># Accumulate the training loss over all of the batches so that we can
</span>        <span class="c1"># calculate the average loss at the end. `loss` is a Tensor containing a
</span>        <span class="c1"># single value; the `.item()` function just returns the Python value 
</span>        <span class="c1"># from the tensor.
</span>        <span class="n">total_train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># Perform a backward pass to calculate the gradients.
</span>        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Clip the norm of the gradients to 1.0.
</span>        <span class="c1"># This is to help prevent the "exploding gradients" problem.
</span>        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.0</span><span class="p">)</span>

        <span class="c1"># Update parameters and take a step using the computed gradient.
</span>        <span class="c1"># The optimizer dictates the "update rule"--how the parameters are
</span>        <span class="c1"># modified based on their gradients, the learning rate, etc.
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Update the learning rate.
</span>        <span class="n">scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Calculate the average loss over all of the batches.
</span>    <span class="n">avg_train_loss</span> <span class="o">=</span> <span class="n">total_train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">)</span>            
    
    <span class="c1"># Measure how long this epoch took.
</span>    <span class="n">training_time</span> <span class="o">=</span> <span class="n">format_time</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">""</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"  Average training loss: {0:.2f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">avg_train_loss</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"  Training epcoh took: {:}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">training_time</span><span class="p">))</span>
        
    <span class="c1"># Record all statistics from this epoch.
</span>    <span class="n">training_stats</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s">'epoch'</span><span class="p">:</span> <span class="n">epoch_i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s">'Training Loss'</span><span class="p">:</span> <span class="n">avg_train_loss</span><span class="p">,</span>
            <span class="s">'Training Time'</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">""</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Training complete!"</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Total training took {:} (h:mm:ss)"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">format_time</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">total_t0</span><span class="p">)))</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code39"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code39">======== Epoch 1 / 1 ========
Training on 1,563 batches...
  Batch     200  of    1,563.    Elapsed: 0:04:33.  Remaining: 0:30:58
  Batch     400  of    1,563.    Elapsed: 0:08:52.  Remaining: 0:25:47
  Batch     600  of    1,563.    Elapsed: 0:13:15.  Remaining: 0:21:16
  Batch     800  of    1,563.    Elapsed: 0:17:47.  Remaining: 0:16:58
  Batch   1,000  of    1,563.    Elapsed: 0:22:22.  Remaining: 0:12:36
  Batch   1,200  of    1,563.    Elapsed: 0:27:04.  Remaining: 0:08:11
  Batch   1,400  of    1,563.    Elapsed: 0:31:19.  Remaining: 0:03:39

  Average training loss: 0.25
  Training epcoh took: 0:35:06

Training complete!
Total training took 0:35:06 (h:mm:ss)
</code></pre></div></div>

<h2 id="collate-function"><code class="language-plaintext Highlighter-rouge">collate</code> Function</h2>

<ul>
  <li>The <code class="language-plaintext highlighter-rouge">collate_fn</code> argument to the <code class="language-plaintext highlighter-rouge">DataLoader</code> class receives a list of tuples if your <code class="language-plaintext highlighter-rouge">__getitem__</code> function from a Dataset subclass returns a tuple, or just a normal list if your Dataset subclass returns only one element. Its main objective is to create your batch without spending much time implementing it manually. Try to see it as a glue that you specify the way examples stick together in a batch. If you don’t use it, PyTorch only put <code class="language-plaintext highlighter-rouge">batch_size</code> examples together as you would using torch.stack (not exactly it, but it is simple like that).</li>
  <li>Suppose for example, you want to create batches of a list of varying dimension tensors. The below code pads sequences with 0 until the maximum sequence size of the batch, that is why we need the <code class="language-plaintext highlighter-rouge">collate_fn</code>, because a standard batching algorithm (simply using <code class="language-plaintext highlighter-rouge">torch.stack</code>) won’t work in this case, and we need to manually pad different sequences with variable length to the same size before creating the batch.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code40"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code40"><span class="k">def</span> <span class="nf">collate_fn</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="s">"""
       data: is a list of tuples with (example, label, length)
             where 'example' is a tensor of arbitrary shape
             and label/length are scalars
    """</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">)</span>
    <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
    <span class="n">n_ftrs</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">n_ftrs</span><span class="p">))</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
        <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">features</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">))])</span>

    <span class="k">return</span> <span class="n">features</span><span class="p">.</span><span class="nb">float</span><span class="p">(),</span> <span class="n">labels</span><span class="p">.</span><span class="nb">long</span><span class="p">(),</span> <span class="n">lengths</span><span class="p">.</span><span class="nb">long</span><span class="p">()</span>
</code></pre></div></div>

<ul>
  <li>The function above is fed to the collate_fn param in the DataLoader, as this example:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code41"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code41"><span class="n">DataLoader</span><span class="p">(</span><span class="n">toy_dataset</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>
    <p>With this <code class="language-plaintext highlighter-rouge">collate_fn</code> function, you always gonna have a tensor where all your examples have the same size. So, when you feed your <code class="language-plaintext highlighter-rouge">forward()</code> function with this data, you need to use the length to get the original data back, to not use those meaningless zeros in your computation.</p>
  </li>
  <li>
    <p>For more, check out the <a href="https://pytorch.org/docs/stable/data.html#dataloader-collate-fn">PyTorch documentation</a>.</p>
  </li>
</ul>

<h2 id="evaluate-on-test-set">Evaluate on Test Set</h2>

<h3 id="make_smart_batches"><code class="language-plaintext Highlighter-rouge">make_smart_batches()</code></h3>

<ul>
  <li>This function combines all of the steps from the “Smart Batching” section into a single (re-usable) function. You can use this in your own Notebook for applying smart batching to both your training and test sets.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code42"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code42"><span class="k">def</span> <span class="nf">make_smart_batches</span><span class="p">(</span><span class="n">text_samples</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="s">'''
    This function combines all of the required steps to prepare batches.
    '''</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'Creating Smart Batches from {:,} examples with batch size {:,}...</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text_samples</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">))</span>

    <span class="c1"># =========================
</span>    <span class="c1">#   Tokenize &amp; Truncate
</span>    <span class="c1"># =========================
</span>
    <span class="n">full_input_ids</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Tokenize all training examples
</span>    <span class="k">print</span><span class="p">(</span><span class="s">'Tokenizing {:,} samples...'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)))</span>

    <span class="c1"># Choose an interval on which to print progress updates.
</span>    <span class="n">update_interval</span> <span class="o">=</span> <span class="n">good_update_interval</span><span class="p">(</span><span class="n">total_iters</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="n">num_desired_updates</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="c1"># For each training example...
</span>    <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">text_samples</span><span class="p">:</span>
        
        <span class="c1"># Report progress.
</span>        <span class="k">if</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">full_input_ids</span><span class="p">)</span> <span class="o">%</span> <span class="n">update_interval</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'  Tokenized {:,} samples.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">full_input_ids</span><span class="p">)))</span>

        <span class="c1"># Tokenize the sample.
</span>        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>              <span class="c1"># Text to encode.
</span>                                    <span class="n">add_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="c1"># Do add specials.
</span>                                    <span class="n">max_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span>      <span class="c1"># Do Truncate!
</span>                                    <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>         <span class="c1"># Do Truncate!
</span>                                    <span class="n">padding</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>           <span class="c1"># DO NOT pad.
</span>                                    
        <span class="c1"># Add the tokenized result to our list.
</span>        <span class="n">full_input_ids</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        
    <span class="k">print</span><span class="p">(</span><span class="s">'DONE.'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'{:&gt;10,} samples</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">full_input_ids</span><span class="p">)))</span>

    <span class="c1"># =========================
</span>    <span class="c1">#      Select Batches
</span>    <span class="c1"># =========================    
</span>
    <span class="c1"># Sort the two lists together by the length of the input sequence.
</span>    <span class="n">samples</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">full_input_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'{:&gt;10,} samples after sorting</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)))</span>

    <span class="kn">import</span> <span class="nn">random</span>

    <span class="c1"># List of batches that we'll construct.
</span>    <span class="n">batch_ordered_sentences</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">batch_ordered_labels</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'Creating batches of size {:}...'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">batch_size</span><span class="p">))</span>

    <span class="c1"># Choose an interval on which to print progress updates.
</span>    <span class="n">update_interval</span> <span class="o">=</span> <span class="n">good_update_interval</span><span class="p">(</span><span class="n">total_iters</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">num_desired_updates</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="c1"># Loop over all of the input samples...    
</span>    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        
        <span class="c1"># Report progress.
</span>        <span class="k">if</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_ordered_sentences</span><span class="p">)</span> <span class="o">%</span> <span class="n">update_interval</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> \
            <span class="ow">and</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_ordered_sentences</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'  Selected {:,} batches.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_ordered_sentences</span><span class="p">)))</span>

        <span class="c1"># `to_take` is our actual batch size. It will be `batch_size` until 
</span>        <span class="c1"># we get to the last batch, which may be smaller. 
</span>        <span class="n">to_take</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">))</span>

        <span class="c1"># Pick a random index in the list of remaining samples to start
</span>        <span class="c1"># our batch at.
</span>        <span class="n">select</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="o">-</span> <span class="n">to_take</span><span class="p">)</span>

        <span class="c1"># Select a contiguous batch of samples starting at `select`.
</span>        <span class="c1">#print("Selecting batch from {:} to {:}".format(select, select+to_take))
</span>        <span class="n">batch</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="n">select</span><span class="p">:(</span><span class="n">select</span> <span class="o">+</span> <span class="n">to_take</span><span class="p">)]</span>

        <span class="c1">#print("Batch length:", len(batch))
</span>
        <span class="c1"># Each sample is a tuple--split them apart to create a separate list of 
</span>        <span class="c1"># sequences and a list of labels for this batch.
</span>        <span class="n">batch_ordered_sentences</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
        <span class="n">batch_ordered_labels</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>

        <span class="c1"># Remove these samples from the list.
</span>        <span class="k">del</span> <span class="n">samples</span><span class="p">[</span><span class="n">select</span><span class="p">:</span><span class="n">select</span> <span class="o">+</span> <span class="n">to_take</span><span class="p">]</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">  DONE - Selected {:,} batches.</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_ordered_sentences</span><span class="p">)))</span>

    <span class="c1"># =========================
</span>    <span class="c1">#        Add Padding
</span>    <span class="c1"># =========================    
</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Padding out sequences within each batch...'</span><span class="p">)</span>

    <span class="n">py_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">py_attn_masks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">py_labels</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># For each batch...
</span>    <span class="k">for</span> <span class="p">(</span><span class="n">batch_inputs</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batch_ordered_sentences</span><span class="p">,</span> <span class="n">batch_ordered_labels</span><span class="p">):</span>

        <span class="c1"># New version of the batch, this time with padded sequences and now with
</span>        <span class="c1"># attention masks defined.
</span>        <span class="n">batch_padded_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">batch_attn_masks</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># First, find the longest sample in the batch. 
</span>        <span class="c1"># Note that the sequences do currently include the special tokens!
</span>        <span class="n">max_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sen</span><span class="p">)</span> <span class="k">for</span> <span class="n">sen</span> <span class="ow">in</span> <span class="n">batch_inputs</span><span class="p">])</span>

        <span class="c1"># For each input in this batch...
</span>        <span class="k">for</span> <span class="n">sen</span> <span class="ow">in</span> <span class="n">batch_inputs</span><span class="p">:</span>
            
            <span class="c1"># How many pad tokens do we need to add?
</span>            <span class="n">num_pads</span> <span class="o">=</span> <span class="n">max_size</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sen</span><span class="p">)</span>

            <span class="c1"># Add `num_pads` padding tokens to the end of the sequence.
</span>            <span class="n">padded_input</span> <span class="o">=</span> <span class="n">sen</span> <span class="o">+</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span><span class="p">]</span><span class="o">*</span><span class="n">num_pads</span>

            <span class="c1"># Define the attention mask--it's just a `1` for every real token
</span>            <span class="c1"># and a `0` for every padding token.
</span>            <span class="n">attn_mask</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">sen</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_pads</span>

            <span class="c1"># Add the padded results to the batch.
</span>            <span class="n">batch_padded_inputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">padded_input</span><span class="p">)</span>
            <span class="n">batch_attn_masks</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">)</span>

        <span class="c1"># Our batch has been padded, so we need to save this updated batch.
</span>        <span class="c1"># We also need the inputs to be PyTorch tensors, so we'll do that here.
</span>        <span class="c1"># Todo - Michael's code specified "dtype=torch.long"
</span>        <span class="n">py_inputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">batch_padded_inputs</span><span class="p">))</span>
        <span class="n">py_attn_masks</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">batch_attn_masks</span><span class="p">))</span>
        <span class="n">py_labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">batch_labels</span><span class="p">))</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">'  DONE.'</span><span class="p">)</span>

    <span class="c1"># Return the smart-batched dataset!
</span>    <span class="k">return</span> <span class="p">(</span><span class="n">py_inputs</span><span class="p">,</span> <span class="n">py_attn_masks</span><span class="p">,</span> <span class="n">py_labels</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="load-test-dataset--smart-batch">Load Test Dataset &amp; Smart Batch</h3>

<ul>
  <li>Load the test dataset. This file has more columns, and contains rows for different languages (we’ll only select the French test samples).</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code43"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code43"><span class="c1"># Use our new function to completely prepare our dataset.
</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">,</span> <span class="n">py_attn_masks</span><span class="p">,</span> <span class="n">py_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">make_smart_batches</span><span class="p">(</span><span class="n">test_text</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code44"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code44">Creating Smart Batches from 25,000 examples with batch size 16...

Tokenizing 25,000 samples...
  Tokenized 0 samples.
  Tokenized 2,000 samples.
  Tokenized 4,000 samples.
  Tokenized 6,000 samples.
  Tokenized 8,000 samples.
  Tokenized 10,000 samples.
  Tokenized 12,000 samples.
  Tokenized 14,000 samples.
  Tokenized 16,000 samples.
  Tokenized 18,000 samples.
  Tokenized 20,000 samples.
  Tokenized 22,000 samples.
  Tokenized 24,000 samples.
DONE.
    25,000 samples

    25,000 samples after sorting

Creating batches of size 16...

  DONE - Selected 1,563 batches.

Padding out sequences within each batch...
  DONE.
</code></pre></div></div>

<h3 id="evaluate">Evaluate</h3>

<ul>
  <li>With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code45"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code45"><span class="c1"># Prediction on test set
</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Predicting labels for {:,} test sentences...'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)))</span>

<span class="c1"># Tracking variables 
</span><span class="n">predictions</span> <span class="p">,</span> <span class="n">true_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="c1"># Choose an interval on which to print progress updates.
</span><span class="n">update_interval</span> <span class="o">=</span> <span class="n">good_update_interval</span><span class="p">(</span><span class="n">total_iters</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">),</span> <span class="n">num_desired_updates</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Measure elapsed time.
</span><span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Put model in evaluation mode
</span><span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

<span class="c1"># For each batch of training data...
</span><span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">)):</span>

    <span class="c1"># Progress update every 100 batches.
</span>    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">update_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Calculate elapsed time in minutes.
</span>        <span class="n">elapsed</span> <span class="o">=</span> <span class="n">format_time</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span>
        
        <span class="c1"># Calculate the time remaining based on our progress.
</span>        <span class="n">steps_per_sec</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span> <span class="o">/</span> <span class="n">step</span>
        <span class="n">remaining_sec</span> <span class="o">=</span> <span class="n">steps_per_sec</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">)</span> <span class="o">-</span> <span class="n">step</span><span class="p">)</span>
        <span class="n">remaining</span> <span class="o">=</span> <span class="n">format_time</span><span class="p">(</span><span class="n">remaining_sec</span><span class="p">)</span>

        <span class="c1"># Report progress.
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'  Batch {:&gt;7,}  of  {:&gt;7,}.    Elapsed: {:}.  Remaining: {:}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">py_inputs</span><span class="p">),</span> <span class="n">elapsed</span><span class="p">,</span> <span class="n">remaining</span><span class="p">))</span>

    <span class="c1"># Copy the batch to the GPU.
</span>    <span class="n">b_input_ids</span> <span class="o">=</span> <span class="n">py_inputs</span><span class="p">[</span><span class="n">step</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">b_input_mask</span> <span class="o">=</span> <span class="n">py_attn_masks</span><span class="p">[</span><span class="n">step</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">b_labels</span> <span class="o">=</span> <span class="n">py_labels</span><span class="p">[</span><span class="n">step</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  
    <span class="c1"># Telling the model not to compute or store gradients, saving memory and 
</span>    <span class="c1"># speeding up prediction
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># Forward pass, calculate logit predictions
</span>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b_input_ids</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                        <span class="n">attention_mask</span><span class="o">=</span><span class="n">b_input_mask</span><span class="p">)</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Move logits and labels to CPU
</span>    <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">label_ids</span> <span class="o">=</span> <span class="n">b_labels</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">).</span><span class="n">numpy</span><span class="p">()</span>
  
    <span class="c1"># Store predictions and true labels
</span>    <span class="n">predictions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    <span class="n">true_labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_ids</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'    DONE.'</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code46"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code46">Predicting labels for 25,000 test sentences...
  Batch     200  of    1,563.    Elapsed: 0:01:32.  Remaining: 0:10:27
  Batch     400  of    1,563.    Elapsed: 0:03:03.  Remaining: 0:08:53
  Batch     600  of    1,563.    Elapsed: 0:04:35.  Remaining: 0:07:21
  Batch     800  of    1,563.    Elapsed: 0:06:05.  Remaining: 0:05:48
  Batch   1,000  of    1,563.    Elapsed: 0:07:37.  Remaining: 0:04:17
  Batch   1,200  of    1,563.    Elapsed: 0:09:08.  Remaining: 0:02:46
  Batch   1,400  of    1,563.    Elapsed: 0:10:44.  Remaining: 0:01:15
    DONE.
</code></pre></div></div>

<ul>
  <li>Now we can calculate the test set accuracy!</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code47"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code47"><span class="c1"># Combine the results across the batches.
</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">true_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Choose the label with the highest score as our prediction.
</span><span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">flatten</span><span class="p">()</span>

<span class="c1"># Calculate simple flat accuracy -- number correct over total number.
</span><span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">true_labels</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy: {:.3f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</code></pre></div></div>

<ul>
  <li>which outputs:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code48"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code48">Accuracy: 0.935
</code></pre></div></div>

<ul>
  <li>Here are our results from running a single training epoch on a Tesla K80, comparing fixed-padding to smart batching.</li>
</ul>

<p><img src="/primers/ai/assets/fine-tune-and-eval-BERT/res.jpg" alt=""></p>

<ul>
  <li>The fixed padding approach took 51.7% longer to train the model than Smart Batching!</li>
</ul>

<h2 id="appendix">Appendix</h2>

<h3 id="smart-batching-with-batch_encode_plus-and-dataloader">Smart Batching with <code class="language-plaintext Highlighter-rouge">batch_encode_plus</code> and <code class="language-plaintext Highlighter-rouge">DataLoader</code></h3>

<ul>
  <li>
    <p>This section discusses how “smart batching” might be implemented in a more formal way with the PyTorch <code class="language-plaintext highlighter-rouge">DataLoader</code> class and using the features currently available in huggingface <code class="language-plaintext highlighter-rouge">transformers</code>.</p>
  </li>
  <li>
    <p>In <code class="language-plaintext highlighter-rouge">transformers</code>, the <code class="language-plaintext highlighter-rouge">batch_encode_plus</code> function does have support for “Dynamic Padding”–it can automatically pad all of the samples in a batch out to match the longest sequence length in the batch.</p>
  </li>
  <li>
    <p>Check out the explanation given in this Warning in the source code, in <a href="https://github.com/huggingface/transformers/blob/master/src/transformers/tokenization_utils_base.py#L1458">tokenization_utils_base.py</a>:</p>
  </li>
</ul>

<blockquote>
  <p>“The pad_to_max_length argument is deprecated and will be removed in a future version, use padding=True or padding=’longest’ to pad to the longest sequence in the batch, or use padding=’max_length’ to pad to a max length. In this case, you can give a specific length with max_length (e.g. max_length=45) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).”</p>
</blockquote>

<ul>
  <li>So the call would look like this:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code49"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code49"><span class="c1"># Encode a batch of sentences with dynamic padding.
</span><span class="n">encoded_dict</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_encode_plus</span><span class="p">(</span>
                    <span class="n">train_text</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">],</span> <span class="c1"># Batch of sentences to encode.
</span>                    <span class="n">add_special_tokens</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>  <span class="c1"># Add '[CLS]' and '[SEP]'
</span>                    <span class="n">padding</span> <span class="o">=</span> <span class="s">'longest'</span><span class="p">,</span>        <span class="c1"># Pad to longest in batch.
</span>                    <span class="n">truncation</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>          <span class="c1"># Truncate sentences to `max_length`.
</span>                    <span class="n">max_length</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span>           
                    <span class="n">return_attention_mask</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="c1"># Construct attn. masks.
</span>                    <span class="n">return_tensors</span> <span class="o">=</span> <span class="s">'pt'</span><span class="p">,</span>        <span class="c1"># Return pytorch tensors.
</span>            <span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>
    <p>However, if you do this, you need wait to actually encode your text until the random training samples for the batch have been selected! i.e., you can’t pre-tokenize all of your sentences the way we have been.</p>
  </li>
  <li>
    <p>The “correct” approach would be to implement a custom DataLoader class which:</p>

    <ol>
      <li>Stores the original training sample strings, sorted by string length.</li>
      <li>Selects a contiguous batch of samples starting at a random point in the list.</li>
      <li>Calls <code class="language-plaintext highlighter-rouge">batch_encode_plus</code> to encode the samples with dynamic padding, then returns the training batch.</li>
    </ol>
  </li>
</ul>

<h3 id="impact-of-pad-tokens-on-accuracy">Impact of <code class="language-plaintext Highlighter-rouge">[PAD]</code> Tokens on Accuracy</h3>

<ul>
  <li>
    <p>The difference in accuracy (0.93 for fixed-padding and 0.935 for smart batching) is interesting. It makes me curious to look at the attention mask implementation more–perhaps the <code class="language-plaintext highlighter-rouge">[PAD]</code> tokens are still having some small influence on the results.</p>
  </li>
  <li>
    <p>Maybe the Attention scores are calculated for all tokens, including the <code class="language-plaintext highlighter-rouge">[PAD]</code> tokens, and then the scores are multiplied against the mask, to zero out the scores for the <code class="language-plaintext highlighter-rouge">[PAD]</code> tokens? Because the SoftMax makes all of the attention scores sum to 1.0, that would mean the presence of <code class="language-plaintext highlighter-rouge">[PAD]</code> tokens would cause the scores for the real words to be lower…</p>
  </li>
</ul>

<h3 id="out-of-memory-oom-errors">Out of Memory (OOM) Errors</h3>

<ul>
  <li>OOM errors can happen due to bugs in your code or using the wrong version of PyTorch/CUDA. Some OOMs come from sub-optimal code in do_sample, such as storing extra tensors (e.g., storing the entire set of logits rather than just the sampled token index) or failing to wrap your sampling code with <code class="language-plaintext highlighter-rouge">torch.inference_mode()</code>.</li>
  <li>
    <p>Another way to save memory in <code class="language-plaintext highlighter-rouge">do_sample()</code> is to avoid saving the full outputs object from the model. That is, instead of:</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code50"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code50">  <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
  <span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> 
</code></pre></div>    </div>

    <ul>
      <li>maybe just do</li>
    </ul>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code51"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code51">  <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">).</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
</code></pre></div>    </div>

    <ul>
      <li>so you aren’t saving the full model outputs variable (including the full logits output tensor, which can add up to a few hundred MB of memory).</li>
    </ul>
  </li>
</ul>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><a href="https://stackoverflow.com/questions/65279115/how-to-use-collate-fn-with-dataloaders">How to use ‘collate_fn’ with dataloaders?</a></li>
  <li><a href="https://discuss.pytorch.org/t/how-to-use-collate-fn/27181">How to use collate_fn()</a></li>
  <li><a href="https://python.plainenglish.io/understanding-collate-fn-in-pytorch-f9d1742647d3">Understand collate_fn in PyTorch</a></li>
</ul>

<h2 id="references">References</h2>

<ul>
  <li><a href="https://wandb.ai/pommedeterresautee/speed_training/reports/Divide-HuggingFace-Transformers-training-times-by-2-or-more-with-dynamic-padding-and-uniform-length-batching--VmlldzoxMDgzOTI">Weights and Biases: Train HuggingFace Models Twice As Fast</a></li>
  <li><a href="https://mccormickml.com/2020/07/29/smart-batching-tutorial/#s1-setup">Smart Batching Tutorial - Speed Up BERT Training</a></li>
</ul>

<h2 id="citation">Citation</h2>

<p>If you found our work useful, please cite it as:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><div><button class="btn-copy" data-clipboard-action="copy" data-clipboard-target="#code52"><img src="https://aman.ai/images/copy.png" style="margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;"></button></div><code id="code52">@article{Chadha2020DistilledFineTuneAndEvalBERT,
  title   = {Fine-Tuning and Evaluating BERT},
  author  = {Chadha, Aman},
  journal = {Distilled AI},
  year    = {2020},
  note    = {\url{https://aman.ai}}
}
</code></pre></div></div>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">
   <div align="center" class="wrap">
      <div align="center" class="footer-col-1 column">
         <ul>
            <li>
               
               <span class="icon github">
                  <a href="https://github.com/amanchadha">
                     <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                        <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                           c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                           c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                           c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                           C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                           c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                           c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                           c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                           c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"></path>
                     </svg>
                  </a>
               </span>
               <!-- <span class="username">amanchadha</span> -->
                | 
               <a href="https://citations.amanchadha.com/">
                  <svg version="1.1" class="mail-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                     <image id="image0" width="16" height="16" x="0" y="0" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABJoAAAVjBAMAAABzrVjQAAAABGdBTUEAALGPC/xhBQAAACBjSFJN
                        AAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAElBMVEX///+xsLCxsLCxsLCx
                        sLD///+bxiTSAAAABHRSTlMAAKP3FWDuDwAAAAFiS0dEAIgFHUgAAAAJcEhZcwAACxMAAAsTAQCa
                        nBgAAAAHdElNRQfkBwQDMic2f+cwAAA03klEQVR42u2dW3IdOZJEu81mAcMqbOCacQMy0wImVNr/
                        msZKKpVeuHkzEA8PIPx8douAh+MkkmKR1H/+QwghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQ
                        QgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIeQQ/vt2KOMzyeH/GtiE7rgP/3u+TQPdcRukgU3o
                        jtsgb+fbNNAlt+GtgU3ojtsgDWxCd9yGT2/n2zTQJbfhrYFN6I7bIA1sGuiS2/DWwCZ0x214a2DT
                        QJfcBelgE7rkNrw1sAndcRukgU0DXXIXvsl0tE3oktvwb+MH2zTQJXdBOtiELrkL32U62KaBbrkL
                        P3R+rE1/oEvugnSwCV1yF/76sfRTbRrolrvwU+un2oQuuQvSwaaBbrkLP9d+qE3okrvwS+1n2jTQ
                        LTdBOtj0J7rlLvxa/JE2oUvugnSwaaBbbsJvMh1pE7rlLvze/IE2DXTLTZAWNqFbbsKnSfXn2TTQ
                        NTdh1v1xNg10y02QFjahW+7CtPzTbBrolpswb/80m9AtN0Fa2DTQNTfhSf2H2YRuuQmPFja9o2vu
                        gTzr/yibBrrmJjw9gKNsQrfcBGlh00DX3IPnMh1lE7rmJlycwEE2DXTNPZAeNqFrbsLVEZxj00d0
                        zT24PINjbBromnsgPWxC19yE60M4xaaBrrkHL07hFJvQNfdAetg00D334NUxHGITuuYeSA+b0DU3
                        oYdNA11zE3rYhG65Cy1sGuiWu9DCJnTJbehg00CX3IYGNg10x31oYBO64kacb9NAV9yI821CN9yJ
                        420a6IY7cbxN6IJbcbpNA11wKw63ib8YPJXDbULX24yzbRroeptxtk3odrtxtE0D3W43jrYJXW47
                        TrbpHV1uOw62aaC77cfBNqGrbci5Ng10tQ051yZ0sx051qaBbrYjx9qELrYlp9qE7rUnh9o00L32
                        5FCb0LU25UybBrrWppxpE7rVrhxp00C32pUjbUKX2pYTbfqILrUtB9o00J325UCb0JW2YEz/1/Ns
                        GqpWyBIy5v/zcTahi27Bk2f2OJuGqhWyhDSx6Q900R2QtyY2oYtuwVsTm4aqFbKEdLEJXXQLnj+2
                        Z9k0VK2QJS6aPssmdNEdkC42DVUtZImrqk+yaahaIUtIF5vQRXfgr8sn9yCbhqoWssR12QfZhC66
                        A//qMq7/7+1tGqpayBIv2j7HJnTRHfhuy3jx/29u01DVQlaQV3WfYtNQ1UKWeNn3KTahi+7Aj66M
                        l39iY5uGqhayxOvCD7EJXXQHPnSxaahqISvIjcbPsAnddAfuPL9H2PSObroBv4gy7vyhLW0aqlrI
                        Erc6P8EmdNEdeHSxaahqISvIvdIPsAnddAduPsL72zRUtZAV5Gbr+9uEbroDd5/h7W1CF92BSe1j
                        +gd3t2moaiEryO3ed7cJ3XQH7j/Fm9s0VLWQFeR+8ZvbhG66AZ8Uj/HeNg1VL2QFTfN724RuugFP
                        BBmaP7yHTeimO/Ck+jH9wzvbNFS1kBVE1f3ONqGbbsBTPYbuj9e3aah6ISsoy9/YJnTTDXhux1D+
                        +eo2DVUvZAVt+9vaxF8MHs+FHEP7AbVtQjfdgCs3hvojKts0VL2QFfT972oTuukGXKox9B9S16ah
                        6oWssHAAm9qEbroBK4/znjYNVS9kAVk5gS1tGqpeyApLR7ClTeimG/DKi7H0URVtGqpeyAJ/rZ3B
                        jjahq27A4hO9oU1D1QtZ4KUVb3+ufVw9m9BVN8BwBJvZNNBVn49YTuDyg6vZNG71QQy8kOnlx29k
                        E7rqBpgPYBubBrrq8xHzATxfoZhN6Kob4HAAm9g00FWfj1wewLttjVo2oas+H3E5gC1sekd3fT7X
                        BzBurvLMyUo23Z2FLCPXJ3B7nQ1sQlfdAK8TqG/TQFd9Pg+vE5DyNqGr/p1fAn5E57EiL05gWFeq
                        Y9P9UVLYIqTLTN95v71SeZvQVd+tfaDDLSOOR1Dcpo/oru+XPtAJF3l5Bua1qthU5oReulQqrYbX
                        Y5kXq2ITuur7ldfKe58bj4m5pyI2DXTXVx1N+dO+W7XZhnm1Ijahq/6C6DJ/ROf1Hm6Yl6thk2aO
                        MPZM7TidZp7KNqGr/nzjR8yK5r7JnWmGYr3CNqGr/qx+yxVK7jfeMC9YwSbNFMi2N9bJ/Rzq2oSu
                        2iBThfBu8w3zigVs0gyBLHtfnW7ON8xLFrAJ3bVNpgL5X3JzkGHuDG+TZoYQPlknQA/wCrk5xzCv
                        CbcJ/4vB7TOgJ3AacCjWLGoTumoHmQo8EVfI3TGGeVG0TZoJQjhjigtuy3SATft0vatOMUOUtAl9
                        Ck4yFf5RQMWEw7ws2CZ01+dM4jDhUCxb0SZNfnDVm+oUdRoFbUJ/x5mYJ1g8i5oTaiYoaBO4avOX
                        LevrFDZAPZvQ9XvPAx5ngqjyD/PKSJu2qtr5NFJQfgegJn85m9DlnzeRcUJN/HI2gasW8wDlRjJO
                        OMxr42zSZI/gxJlsE2rSy3QFmE3o4h8hU4GH+gnRhh/mxWE27Vb1HmP9gP7rH8PcH8omTfIITp3L
                        MqEmu0xXQNkErlrMAxQdzDLhMC8PskkTPIJzJzNMqIku0xVANoGrFvMAZUczTDjM62NsQncdOZvm
                        TMKQ6OTzDSA2oQtf6vo24OG+EH4s8wohNm3Z9T7jrT4uw7wDwiZN6jpd7zPf6uOiyT3vEGETumsx
                        T1B8wMda7GHuEGCTJnQIp08oCbHnewBswladcDWhR1xNPcwl5tv0EVt1wtUEvpwkI/V8k3SboEWb
                        ytaAHDDlaOYtptuE7NlWdtTBlJlPE1qmK2TbBKzZ3LYG2HiynllzNvNtsm2CtezQdtTJuJKUeV5j
                        sk2wkj3aVgEaTwyRNYcz3yfXJvwvOrK0reIjZj5L5GHuMdcmTMOvWwhAczR+pEWe95hqE6Zhv7pV
                        IKYTU2LN8cx3SrUJUbBn3WFn40Ve4nmRmTYh+r1VQgzbTac5n/lWmTbl1/sb0SOuHo4Lkhh4vlei
                        Tent+vetI3u6zAOaN5lnkyZrFGKeovDE5uE0eeeb5dmUW+2c2Aktp1NhOE1ema6QZlNytYoK4kgd
                        7kPqEc2rTLMptVlVBXFojqfAbJq48+2ybMos9imRA07ZazbNGcl0hSybkr1RNBCJ5nzws2nSzvdL
                        simv1uDGlaTNln1I8y5zbNLkrN24ko87jaY5JZmukGNTvjkTlv6N+sQDMiDmoNqw8x1TbErqNKVy
                        JTmj5R/TvMwUmxDuRFUeeELLiDmmOut8ywybUhp9TdR41yQM5vUK15yTTFfIsAlkz635w/kYP5lX
                        1GFuM8Gmd4w99+YPR3NE4ME0UeebxtsUX+c9YqZ7zT6DaU5KpivE2wTTJ6r0wDNaQcwJV5LOdw23
                        KbrM/NK1xM7l+I/saY5qXme4TUiDfuQRMh2+AcegQ7GtTFeItkmTcJfWK1Ug5nhrQef7RtsENegH
                        nP/V1TIdeOYcin1lukKwTViFXk6fg+aUkGNpcs43jrUpsEclD//hCrQg5myrOec7x9qEdug7/rNV
                        qME35lDsLNMVQm3SxAvGX5ECPYg52XLM+dahNqEVCus98Jg0AGPOC420KarEBcQ8jImYoR7A85oX
                        GmkTWqEfcPcj7pyMB5qUcr55oE1og37E3Y8CXbiHHIrNZbpCnE2abNGIeRojW8ykObH57nE2oQ2K
                        bT7woG6CDTlvNMymgP4qNa9lh5E0RybTFcJsQgsUXT24DjEn+p1h3j/KJk2yeAKqB/ch5kS2jPP9
                        g2zC/2Lw6Oq1eM8UEHGYKw2yCe3PndFz8Z4pIOIwVxpjkyZXAhF2oCsRcyJTxPn2MTah9fmFCDvg
                        nfgnHIrdZbpCiE2aWBnE6KGk/lCaY5PpCiE2oe25NXk2mrPCTKVJON89wibv3ur1vsKf5afSnNt8
                        9wCbNKFS8O99Ce+x3ANqDm7eaYBNaHnia48/rPUDTQo439zfJu/S7MQJAi1GzIkMAeeb+9uEdud3
                        4gTBNuOdbyj2lukK7jZpIuUg5pmceHcezDuf5ujmpbrbhHbn7uAANKeFGEyTb763t03ejRUsfZ3i
                        g2nObr63s02aQFnEGqKh+GSaw5PpCs42oc1J6DzpuACTaeLJdAVfm7zrqth5oXrEnGg53nxrX5vQ
                        4kyJdgTXj5gD/cQwb+1qkyZOGs6Vm3h3ns03neb45q262oQWRzE3Bs153QGXbt6qp03vaHEUc4Mo
                        Pdsw7+xokyZMIr6NGyk9m+YA5zs72oTW5gkZkoQcWPpwmnAyXcHPJu+iShaeeWDpw2nCyXQFP5vQ
                        1qQUbsZ5ODEH+oFh3tjNJk2UVJI0uYnzcGIOtHiE843dbEJLk9J37ollT6fJNt/Yyya0NDl9557Y
                        HVDZ5rU62eRdkh9imCoC5/E8o2kOcV6rk01oZ7Rj4yg83jDv62OTJkcyiaIgqhJzoLVo8319bEIr
                        c0GiKO5HljyfJppMV3Cxybuhom37UHc+zTHKdAUXm9DGJLXtQ935hmJbma7gYRNamKy2889s+VjD
                        k823dbDJuZ6yZQPOLHdATbL5tg42oYXJKtuLsgMO87Z2mzQZ8nEs2wvnCf2CaU5y3qvdJrQvK1ND
                        0RzaDTDB5r2abXLuxhtZGioU58Ywwea9Wm2q9YvB706NpeqEw7yr1Sa0La8AyJLcmZjzfGOYdzXa
                        pAkAAWFLbmlizrOSa76r0Sa0LC9B2OJ5apkjanLJdAWbTc69BIDx5QVFR9ScpkxXsNmEdiWxak+K
                        jjgUm8p0BZNNmu1BgHy5xndEMedZOM75phabvH+fegCfUMK4HdvqwQbHmm9qsQmtSmbTrmiOLXFG
                        Taz5pgabfDuJwa1pX3yH9EqlOdB5sQab0KasDw3Hd0ivVMNc7LpNmr1hiG6mLHy7Q6SaF7tuE1oU
                        w9BwNOf2GkSqebHLNvkWEoWoZkrDtzyvITWp5nuu2uTbRxheRXtTckjNmc73XLUJrUly0d6UHHKY
                        91y0SbMxkgfUmaT+xBxHH2q+56JNaEvugnXG5+Be4vUFf00oma6wZpNrGZGgrckpEBBKpius2YSW
                        JLtnfypOORRbynSFJZve0ZJk9+xPxSmHYkuZrrBik2ZXMGhpnlJxSs25ynSFFZvQiuT37I/m5BaP
                        NjTTfMsFm1yLCAYtTU6JYo6jzjTfcsEmtCEa0NLktCjmNF8Y5i31Nmn2hIN25jmeU4o5jfpk51vq
                        bUILogLtTE6NYk7zhWHeUm3TR7QgKtDO+BzdK/7KjyTTFbQ2eZaQANqZpCLzI8l0Ba1NaD0gNUeg
                        ObqkMTWRZLqC0ibXDhJAO3NBvTE1hyvTFZQ2oe3A1BxCvTGHYkeZrqCzSbNfCdDKXFBvTM3pynQF
                        nU1oOUA1h6A5u7WzjUw031FlE9oNPWhlnM5u7WwjE8131NjkOX8SaGWS2hRzGm2i+Y4am9BqLIBW
                        5gLP3xgq5jR/M8w7KmzSbFYFtDJXOI4p5jDaA57vqLAJbcYKaGOS+hRzmL8Z5h3v26TZqwxoY65w
                        HFPMYbQnPN/xtk2areqANiar0fRAMl3htk1oL4AtB6E5vJQ5NYFkusJdmzxHTwRtTFal6YFkusJd
                        m9BaIFuOotqcQ7GhTFe4aZNmo0qghbmk2pyaQ5bpCjdtQlsBbTmKanMOxYYyXeGeTZp9SoEWxu30
                        MubU5JHpCrds2uAXg0e2HIXm9F7wyM4j0xVu2YR2Yh20MG6n9wIxh1HmmW94xybHqbNBC+N2ei8Q
                        cxhlnvmGd2xCK2EALcw1fnOKOctbkk2aTaqB9uUavznFnEV50PMNb9iENsIC2pdr/OYUc5a3HJve
                        0UZYQPvid3zXiDmLMs58w5c2+U2MAO2L3/FdI+YsyjjzDV/ahPbBBtoXv+O7RsxZlHHmG76yyW9g
                        CGhf/I7vGjFnUcaZb/jKJrQORtC+vMBtTjFHeUuwSbNBRdC6vKDWoEOxn0xXeGET2oYKJQdSa9Ch
                        2E+mK1zbhJbBjLyVxm9QjzTDXOylTZrlayJvpfErODvNvNhLm9Au2JG30mjO75rsNPNir2zymxWG
                        vJXGr+HsNPNir2xCq+CAvJVGc37XZKeZF3thk9+oOOStNm6DeoQZ5mIvbEKb4IG81cZtUI8ww1zs
                        c5vQIrggrxoE4zaoR5hhLvapTZql60KbatiE9sCH6jZpDvCS2ja5jYmFNpWwCa2BE7Spgk1uU6JB
                        60KbfH/DJxa0Lq+oNOdQ7KexCe2AH2hbaNM57znaVMAmtAKOoG2hTZpVq4O2hTahDfAEbYvnCUbP
                        qcly2yavAUuAtqW7TV7z1QBtS3eb0Ofvi9ytkjZF2OQ1XhFoE9Qm9PE7U90mr75r2qRZcQdoE9Im
                        9Ol7Q5uANmkW3ALahLNJs94e0CacTeiz96e8TZojvKCgTU6TlQJtS1+b0CcfAdqWtjY5DVYLtC1t
                        bUIffAhoW7ra9D/ogw8BbctL6ow5FPu9tOm/6F5DekYPkTMlbfIcTjt2IWhTCrSJNvlBm2iTH7SJ
                        NvnRxKZ32pRBE5t8xsxOMq/1eJvKf4mANm1Ucw+bPmUnkekKtAmNy5iSnWS+IW1CQ5v2qZk2xSSZ
                        b0ib4NCmDJxscik6kjJD0ibaRJvch6NNyYXPN6RNcMoMSZtoE21yH+4K9ByvoE0Z0KbkGWnTATZ5
                        zJkeRKYr0CY4tGmXlp8PXgfatEvLtCkoyLxU2gSHNu3SMm0KCjIvlTbBoU27tOxXdek5JT3IfEfa
                        BIc2bdLyFjY5fDFc0guf70ib8NCmBNxs8uk6jioT0ibaRJvch2tu0yO98HmntAmPfcL8wueddrCp
                        +qfhVQakTbSJNrkPR5uSC5fpCrQJT5UBaZNh9DJUmY820SbalNTyJja9F5mPNp1gk+YUadMqbjYV
                        /zScNmVAm3LHo020iTbdw8+mD+hRLqFNGfjZJOYskdCmDGhT7nS0iTbRpnv42VT703DalAFtok11
                        Wu5iEyKHTFdoYpOYwxSeE5FjXihtwkObdmiZNsXlmBfaxCaXf7+t6JyCyDHftIlNpT8Np00btEyb
                        AnPMN6VNeGhTCo42uVUegNEmSI55n7QJD21KgTbRJj8cbar8iZPNJoHkmO9Km/DQphRoE23y493R
                        Jr/S3bHZhMkxr7O0TbaaaVNgjnmdtAkPbdqg5rDWS40pmBzzbWkTHtpUv+YmNn3A5JDpCqVtcv0S
                        gZjTRGGyCZRj3iZtwkObcvC0qe6rzmKTgHLM96VNeGhTDrSJNtXoObT4MlOicszLpE14aFP9nlvY
                        5DoTbdKAniZgSkHlmG9Mm/DQpiRcbXKt3hGDTbAc8y5pEx7DSK45aFNvm3wnok0q0NO4DymuOY63
                        STNgQ5twZct0hVY2iTlPCLQpCdpEm/z409Wmoq+6Kk/H8Ta1+DScNpVvesoDPY7vjM45aJMOMecJ
                        QHOItAlU9fk2eU9Dm5Sgx3EdUYBB5nvTJjjLIyKDyHSF6jb94WuTmAP5Q5vyoE1ps9AmLehxJrzT
                        pjTOt6nMKA1s0oy43AIU2pQHbUqbhDapQc/zO7SpftnH2+QfhDapEXMgZzRnSJus0KasOTrYtNj2
                        U9DzOM33AZtEpivQJjSL84GTyHSF+jad/qp7LzMFbapxDvnjRUxBmxZAz+MyXkSSFjZphqRNSUXL
                        dIWGNok5kSt1ZqBNC3xCD+Qw3Qd0FJmusIFNZ3/itGYTPIpMV+hok5gTObJkU8wEPWxaKpw2hUaZ
                        J+hoU6lXXaEBaFOhw1hjJf9f+J5lusIONh39iVOh/LRpiUJfI9Cc4L8UyCLTFbawaalywHFkjVYg
                        i0xX6GmTmCMhR4tK38Smgz9xWrGpQpZ5gz1tqvOqqxS+i03v3jY90BN9YyG7RGXpYpNmTuyJaFnI
                        XqLleYF72OT8q3kjj0THymNSIoxMV9jDpmM/cVqwSUqEmafoapOYI7mwYFONMPP+NrFpoXXYoWjQ
                        5w78Oj5tameT1Ch5HmMTm0591ZV6CmjTOuiJ/kZzfvEPQR+b9L2faVOVNDJdoa9NYs5kp9Yz0Mem
                        M191tR6BRjZpRj3XpjIVy3SFxjaJOVP6TLGRG9l04qtObVOdODJdobNNj+1Gio3TySbNrJZGEikW
                        mDaZ2G2iQnlkusI+NgW86sScyYTWpui4rWx6P80mbdzoPK1s0j7KBc7nmmrut7LptFed9ukoFWje
                        XG+boJeT0iYpFWieZiebtA9zcZuUUaVUv/M0O9l02KuunPi0yQpuGM3Z5XjfzCblARQ5JJ9hiiWa
                        97aVTf4/pBn1a9puUM/6Zjad9KrTHF1SzG42KY9gvZZqo6SkpE12QKMUDNnNpohXnZhDxU+Sk7Gd
                        TZqB77LBIPUyyXSFzWwK+Fsd5lswVQklJ1M7m4551akSJmXqZ5Nm4mKHtTyGFAw1z7SbTYdcTu8V
                        badNLtSeQrJCNbRJM3K581oaomSqeWXb2XTE5VRT9Y42fQyw6ZE8Q03TO9qkmdnWTYkREqN1tOmA
                        V13RZC1t0gxtKyeKosFa2vRHgE2pl5Pm1KrmkukKG9oU8qoTc6qQ/Jmxmtqkmfo2NeOX7VWmK+xo
                        0+aXk+LQ8kIpg51kk2bs26Slr5hJXatMV9jSpq0vJ8WZZUXSJ6NNr6iXPbnVrjZp5jYW5I3i6xuP
                        wq3Oy9rTpo0vp/tHJtmltrVJM3it4ysm92qp8642tWnby+n+iUl6p31t0kxe6QBLqW3odF7VrjZt
                        ejndPzDJr7SxTe8RNok51gsKif07jW3SjF7mDO+HluKVzvNta1PMq07MsZwyIxrtbJNm9iKneD+y
                        VG90HnBfm2Iup9DfNVdE6me0tkkzvLWm5MCBIZwKnSfc2KaYyynwWiguU3ObNNNbe0qNu0Gf85Z2
                        tmmzywnv8wua26QZH64Ten/fOmW6wtY2BV1OYs414f5RhWzvG/FMmzTzK4iIit3dvU2ZrrC3TUGX
                        U8CB3j8pgZXZ3iZNAeauDNz/7a+f9ihz3tDmNu1yOeF2VkCbNA3gdLqfUjbpcp5zd5uiLicxB/sB
                        xTEhq6RNYZeTmJN9ByRxZJXzoNvbFHU5OR6sYlNok7Qp7nJyO1lFQNmmyXnS/W2K+Q5xP500Z4Qt
                        kjb9TZRNLoerOaIHtkfapG0hWyfNP1olG/U4z3qCTXGXk/kL06rf0YmukTapa8jVSbOX7FTjPOwR
                        NsVdTjaddL89GF0ibfqHkF/6bNZJ9w99CrpE2rRShJakTOgKadN3Am1aPGelTIJukDatNZGikzYQ
                        ukBlZJmucIpNcV8Rf97dFfE7+EObvhNpk/bq0JzLyvox0Ka1LhaQ+0l0f5fTrl6jwXngc2wK+Uc1
                        V058ZW10d1+gTT8SbNO9Mw8VNRbatNpGjE+rCdDN6dPLdIWTbIr9e91ljV+IWDMT2vQzCTZ9nv/H
                        Fs1J/Aa6toUZZLrCWTaZznRRAfueYpgY1d4881k2perkBrq0lfJkusJhNiW961wR89BO0KbfQLtB
                        m06ySVNJDdCNLVUn0xWOs2k7ncQ8MaK5eerzbNrtXYeu6zu0aQbaDxViHtcN2mRtBQ66rMXeZLrC
                        iTbtpJOYh8XUNs99pE0bvevQTf0IbXoCWpK7hP4jQVpo0zPQmpgOBQRt8mgGCLqm5c5kusKpNu2h
                        k5jHRFU2T36sTVvohO5ovTGZrnCuTRvoBPxN89bCZLrCwTbV10nMI8L6mkc/2abyOqH7MdQl0xWO
                        tqm4TmKeD9fWY7rC2TbV1gldjqWs+QqH21RaJ3Q3v0GbXlFXJ0FX8xu06SVldUIX8zu0ybekRIp9
                        sUlZ1HyBDjbV1EnQrfzOsIZvYVNJndCdTKBN3j1lIeaZkC09Sd/Epno6iXmkAG6nf/LxXWwq97ZD
                        12Hr6MnH97GpmE7oNkwVPfv7aCObSr3tBF2GqaFn6TvZVOl6Qjcx565NH558fC+b6lxP6CKeYEzf
                        zKb43wN9D0HX8ARj+nY21XjdiXmKGAZtiqksFHQFT7Gl72hTAZ/QBZiakacf3dMmtE+CHt/Uy+Pp
                        R3e1aenf1mlg051X3fMP7mvTG/DzcfTgFwzLo9DaJtgLDz32FZbwzW16gwgl6JktfVyFp01/c9uD
                        Ty6vR0HPaynj6kNp0zdeOvD1j/1xvE3jMvvj6kNp00+8Pv3rru+BnvIFVyPK5UfSJiUNbLq4pl/8
                        oA1tUuIgU3mb3laT0yYlDjIJeoblKV99GG3SMXrYNNfp5UfRJh1dbJoMeiM2bdLhYRN6hqVR5c6H
                        0CYdDjLtYtMCtEkHbbqCNqnweNHRJvIVD5sEPUQctEkFbbqENqnweNEJeog4aJMK2nQJbVJBmy6h
                        TRoGbbqENmlwsQk9RCC0SQNtuoY2afCQiTaRr9Cma2iTBtp0DW1SMGjTNbRJAW16AW1SQJteQJsU
                        0KYX0CYFLjLRJvIF2vQC2qSANv3nNv9FRy0PbaJNbgzaRJvcoE20yQ8nmwQ9hwHa5AZtok1+0Cba
                        5IePTLSJ/A1tok1+0Cba5IeTTTt/iYA2uUGbaJMftIk2uTG8bHqgJ1mHNnnhZpOgJ1mHNnlBm2iT
                        H7SJNvnhZtPGn4bTJi9oE23yw88mQY+yDG3ygjbRJj/cZKJNxPNfKEePsgxt8oI20SY/HG0S9Cyr
                        0CYvaBNt8sPRpm1fdbTJC9pEm/zwtEnQwyxCm7zwtOmTPQ4E2uSFp027vupokxeuNgl6mjVokxe0
                        iTb54WrTpq862uSFr02CHmcJ2uQFbaJNfvjatOerjjZ54WyToOdZgTZ5QZtokx/ONm35qqNNXnjb
                        JOiBFqBNXnjbtOPlRJu8ePe26YGeSA9t8mLwVUeb3HC3acNXHW3ywt8mQY+khjZ54W/TfpcTbfIi
                        wCZBz6SFNnkRYNN2lxNt8iLCpg/ooZTQJjcCbBL0TEpokxsBNu32qqNNbkTYJOihdNAmNyJs2uxy
                        ok1uhNgk6KlU0CY3Qmza63KiTW4MXk60yY0Ym7a6nGiTG0E2CXouBbTJjSCbdrqcaJMfQTYJeq77
                        0CY/gmza6HKiTX5E2STowW5Dm/yIsmmfy4k2+THaX060yY8wm7a5nGiTH3E2CXq0m9AmP+Js2uVy
                        ok2OxNkk6NHuQZscibNpk8uJNjkSaNMev4+eNjkyAnUS9HB3oE2ORNq0xbuONjkSapOgp7sBbfIk
                        0qYdLifa5EmoTYKe7jW0yZP35pcTbfJkNL+caJMnsTbV14k2uRJrU/l3HW1yJdgmQc/3Atrkysfe
                        lxNtcmX0vpxokyvRNhX/lfS0yZdom2q/62iTL+E2CXrCK2iTL6P15USbfIm3SdAjXkCbnAm3qbJO
                        tMmZeJsKv+tokzPvnS8n2uTMSLicHughn0GbnMmwqey7jjZ5k2GToId8Am3yJsOmqpcTbfJmNNaJ
                        NnnzR4pNgh5zCm1yJ8WmmpcTbXJn9NWJNrmTZJOg55xAm/zJsani5USb/EmyqaBOtMmfkWSToAf9
                        DdrkT5ZN9S4n2hRAlk3ldKJNAXzMsknQk/4CbQpgdL2caFMEaTYV04k2RZBnk6BH/QnaFMFoejnR
                        pggSbRL0rD9Cm0LIs6mUTrQphMTLqdK7jjaFkGmToIf9Dm2KIdGmQj8QRZtiyLyc6rzraFMMqTYJ
                        etpv0KYgMm0qcznRpiBSL6cqOtGmIHJtEvS4X6FNUaTaVORyok1RdLycaFMUuTbV+KITbQoj16YS
                        7zraFEby5SToed9oUyDJNlW4nGhTHMk2CXpe2hRJ9uUk6IFpUyTJNuHfdbQpkGybBD0wbQpkdLuc
                        aFMk3S4n2hRJ+uX0ATsvbYok3Sbwu442hZJuk0DHpU2hNLucaFMsvS4n2hTLe6vLiTaFkfOPGpTS
                        iTYF8CfIo68IbnDa5AvUI/jlRJu8GGiJ/kVgHdAmB+qI9BVYEbTJRjWRviCoNmjTOiVN+sID1Aht
                        WqOuSV8AtUKbFkC78hrBFEOblAy0KPfAlEObNGyi0mfU5USbbvMRbYgKSEW06R5oOdQIoiXadAO0
                        GUsgiqJNr0BbsYoAuqJNlwy0EwYe+XXRpudgv7HETn5jtOkZaBfsSHpntGnKQJvgQnpttGkC2gIv
                        JLs42vQrqG/njiC7O9r0MwMtgCuS3B5t+pGzXPqcfjnRpu8c51L65USbvnGgS5+zLyfa9JUzXcq+
                        nGjT35zq0ufky4k2He1S8uVEm452iTblgj7tcDLLbG4T+qgTkMQ6W9s00CedQmKhjW3q4VLq5dTX
                        JvQh55HXaVebBvqIE5G0VpvahD7gXNJqbWkT+nSzeWQV29Cm3X94QI9kVdvPJvTRIsjqtptNJ32f
                        7n0kqd1mNg30uYJIqreXTehDhfHI6beTTQN9pjgkp+FGNjWWKetV18em7PP79DTJANgkKR23sSnv
                        4B638iQr9elWKCtNbEo6u4cmU65OKTX3sClBpoWHP9Umyei5hU1FT2qk6pRRdAebyp5Sqk4ZTTew
                        KfCEpG4096x3ON6muO8Y8PhrUqZOCWWfbtOofTZh8WhTAEGnJW4BE23yC/2Us22Kkck1YqJO8X0f
                        bVOETN5fVI7I+IRHeOEn2/TufyDinzJPp4Dwv3CwTbscR5pN8a+6c2366H0Wj6CgI82mqAn+5Vib
                        vGWSuKhpOgXO8JVTbdrqHLJsCn/VHWrT+0YuJf6EX3TtZ9o0tjqDvHedBM9xpE2uhyMZiZNsin4w
                        TrTJU6a/ciJnveuCxzjQJk+ZHjuGvkBipzjPJsfHPOdb87+SY1PwVXueTX7VPzJjjxydYoc4zia3
                        3jMvpr/J0UlCZzjNpk1qD41Om5wYXq0jwqfoFDrBWTZ5ySRbp8eNdpZNOzy/8fFpU6XT2H4A2HQn
                        2TTqP7wpE9CmMkch0BkSbIoc8BybfH4/KnoK2lSDI2TKeNcFpj/GJo9jEPQQbyE/aEObtJwiU8K7
                        LnDMU2yq3bIGj+fimrjsh9jk0PEDPcM3wnWKi36GTQ4HgB7hB6JtkrDkR9h0lkzhl5OEJT/CprNk
                        itcpLPgJNtnLR0/wK7QJxnkyReskUbEPsOlAmYLfdRIVe3+bzMWjB5gSalPYyNvbZJbpgZ5gDm3a
                        sXVBD/AE81OCGHp3m6ylR/VqhzalY/2mpqhaPaBNmzWe/ROYKkagTkGR97bJWjg6/zW0aau+0fFf
                        YH1WLpCYxFvbZKw7qNIy89GmxLKDGvUkzKaga3lnm0oW6orxeaFNaVWj49/iPcomCYm7sU0V6yw2
                        JG26yyjYZrUpadNdbG2i0yeNmVzAtjbZHlpBx0+akzbdo2CXMQTpJBFZd7XJ1jE6vQraFI3tewdC
                        mgzD9uDQpte8m5pEp1cSYlNICXva1OlqegvSKSLonjbV6zGUEWGTBATd0iZbu+j0C9CmQN6rtRiN
                        7fGhTVfYPmtCp18iQqeAmDva9F7tkUyANpVsFh1+kUGbChYr6PSr+NsUUMWGNlV7IHMwPUO0KaTW
                        gAazeKdNAZgaRIeHDZ5TxnY2jWKP4yaT06YpxfrbZnTaNMH0gAo6PXD2lDp2s6nYw7jR8LTpN0yP
                        p397O01Pm37D1B46PHj8hEL2ssn0cAo6PXh+2uTZJjq8B7SpSJmCDu+B6XGiTX5dosP74GqTeKfb
                        yiZLc6V/xeV9TA8UbfJq0r05ELSpQpHo8F6YHina9J1SxW3ZQvQjtpFNpqcSHb5IDbTpG5baBB2+
                        SA+06R9Mz6SAw3vyTpvslKoNiemxin3Ietjk3dq+TdCmL5ieSGz0UlXQpr8xtYaNXqsL2sTPwf3K
                        oE180f2Ml03ezexiU6XO8NAmE8NSmSCT16uDNlWqrAK0CdYeMngQgzaByhNg8DCcbHLuZg+bKj1/
                        NTA9X7SJNv2E7Xd/trbJ9CA6F1YF2gRp7oHLHYnpCaNNq+BiFy6lsU2mx9C5rzr4XE6+mXawqdLT
                        VwjalF8bLHU4LpeTb6QNbLK1hkpdvZeuNpnaElTq6sXQJtr0Ex6Xk2+i+jbZOgOFzoE2qTHZJKDQ
                        G1QTUVB9mwqVVQ7apMT2/GEyp0GblNCmsHIa2mTq6pBfKBfUDm1CdlUQ8+Xk21B1m2x1+XZVENqU
                        WBckciq0Ka8tSORUrJeTuKYpbpOtLN+qamK9nFzD0KbNoU1ZXSESZ2N73mgTbXKsqJNNxgcPkDgf
                        2nQXm00CSLxbR51sshUlgMTbleQahTZtD226xyhUVF1sLblGoU3bQ5vuYZPpr/zAGGhTfE1dPm2i
                        TfcYtCm+J9cktOkAaFNwSd49laZMS7TpAEaVlmjTAdCm2I4+d/q0yfQrVV2D0KYToE2RFdEm2uRX
                        UTebBm16gfX3qyfHhUKbAhtqZ5PhHneNQZuOoEhNdW0yykSbaJNLQV84/tej/MSgTdcYbZLkuFho
                        U1Q/tIk2+fXT0ab1m9w1RVmbjDLRJtrkUU9ES/Wp0RNtOoNRoqeqNv1Jm1TQppB2mtq0/F81XVPQ
                        pkMo0VNVm95pk44SPVW1ySqTpKYtwOrj5xqCNh3CoE3PoU1KaJN/N7SJNvl109em1dvcNQNtOgXa
                        9JSPtEkLbfKuprNNgzY9w2xTZtga0Kan0CY1tMm5mdY2LT6BrhFo0zEs9SSuEWjTMdCmJ9CmBd5p
                        0xyzTB1tWnoExTUCbToG2vQE2rQAbXoCbcpqTVwT0KZzoE1TBm1agTZNoU1L4HuiTefwEd4TbTqH
                        ldp8E9Cmc6BNUz7SphVo0xS7TLSJNn2DNi1Bm6bQpqzenH9zMW06CH1N4huANh0EbfJphTat9Sa+
                        ASraNGjTGrRpAm1ahDZNoE2L6Gt6+AagTQehL845AG06CNrkUgptWizOOQBtOgja5FIKbVoszjlA
                        RZscZKJNtxDnALTpIGjTBNq0CG2aQJsWoU0TPGzy7mkL1DY9nAPQpoNQ2+QdgDYdBG2aQJsWoU0T
                        aNMitGkCbVpEa5N7SbTpIGjTBNq0CG2a4GFTyy9f0qYJtGkRrU3uAWjTQdCmCbRpEdo0gTYtQpsm
                        0KZFlDaJe4BjbfKvqj60aQJtWoQ2TaBNiyhtergHoE0HobTJPwBtOgjaNMHFpo5/qaNNE2jTIjqb
                        xD8AbToI2jSBNi1Cmyb42PRIy1uGj+jH7VybJC1vGXQFBQSgTQdBm8yl0Ka14iL6Odemhp+G0yZr
                        KbRpsTgJCECbDgJeD206CHg9B9skaYGrQJuspdCmfxnwdmjTOdCmGU42/ZUWuAgqm0ISVLRJ1Up2
                        YYWhTeZWaNNabyEJTrZJ0hLXQNNbTDe06Rzw3dCmc9B0E5PgZJu6feKEr4Y2nQO+Gtp0DopmJCZB
                        RZv+9LIpqLOiaB7CoGYq2uT1xXDa9JSgCEfb1OtVR5vm0KYVFDZJUATadAy0aY6bTVGtlaRAL7Tp
                        GBS9REUoadNw0ykvM54CtdCmY7jfikRFONymsN7qoSgtrBXadAqK0sIyHG5To1cdbbIXQ5u+cb8T
                        CctQ0ia/LxE0etVV6IQ2ncL9TuIynG5Tn1ddhUpo0yGM241IXIiaNt2vBtldKWiTQzW0SV1ZYIjj
                        beryqrvdx6fAELTpEG73IYEhatrk9nMGwe3V4f7zF5mipk2ef6nrcTnRpgtok5LbNklkigY2hfZX
                        hRptFLXpnTbpuN1GaIqiNg3PyykzOIj7f20JjdHBJslMjuF2X7Fd0KYjuN1XbIyiNrl+Gt7gVVek
                        ihY2SWp0BEWaoE0nMIo0UdWm2/3cIjU6gNttBefoYZOkZs+nSg+06QSq9FDVJt9PnA5/1d1+9KKD
                        NLFJcsMnc9emyG+U+0ITm86+nMo8U2Vtuvu80ab7NoUH6WKT5KavWVV4krI2eX4z7+GX012bJDxJ
                        WZu8P3GKrxJGnQeKNu0PbXrNcNYpOX69oiQ+Sh+bEsrEUOhxqmuT96fhx15ON8cP/9LlW2WbvD9x
                        OvVyGoXGb2TToZfTe6HpC9t096G7zYfsCVIodDW1siml0KotpQxf2Ca+6u7wsdLsrWyS9BHKlJQz
                        emWbBi8nt45y0vSySdJniKbWc1TZJv9X3XmXU63HqJlNSa2mMWo9RaVteufl9IJiD1Fpm+4+eW0v
                        p7sFZU1d2qY//G0663KqNnRpmwI+cTrrcqo2c22bBi8nj3rSAvWzSQBzBFFu4to2Rbzqzrmcyl1N
                        HW0SxCDIcvISFbfp7uOn4oGYBNeN5EXqaNMh77qC0xa3KeRVd8a7ruDV1NOmIy6nirNWt+nuE9ju
                        crr73wlSR61uU9Dl9MAM48h7waupq03bv+tGyUHL23S7Nh2CmcaNmnOWt8n9B8iPuJxqXk31bYp6
                        1e2tU82raQObbj+GSpKLxnSSnKuvTTvrVHXE+jaFver2fddVvZp2sCnsctpWp6pXU2+b0tv2oe7T
                        soFNca+6PXW6/XTlT7eDTXGX05bvusLDNbdpQ51ujyb52XawKfBVt59O9x8tQLgtbLrfoB7BjbVE
                        6cG2sCn0ckK0ntEEIh1t2kqnUXuqPWy6X+IKD+BkYT1A8u1hU+zltM9n4vdHEki+TWxSPJQH61R+
                        Itq0j06KEgSTcBObgl91W+ikeaJAEXexSVPloTophhFQxF1sCr+cyuu0wyzb2DSa66SZRFAht7Ep
                        6mdXNtFpj0G2sSn+VVdZp6EZQ2Ax97FJVegiD/CMPrPjcu5jU8blVPS/2e0i00426To9SCfd4MgJ
                        NrIp5XIqqJPyKUJG3ckmZa2roMe0TS3IrLSpuE7aoaFhd7Ip51WHPpGf2UqmvWzSVruMoCddnRgc
                        fCub0i4n9Kl8Q/34gPPuZZO63XXQoy6N+wAH3sumvMupgk4ftZEFnXgzm9RPqwEBz7rhA7CZTZmX
                        E/h09HEf6MPZzqbRRKeFOQV9NvvZFPHvkBc8oQWZ8O+5DW3KfdeBzmiboL+wn00rj60FyR9xk5i/
                        s59N2ZfT588fcucbKxk/oU/lCxvatNS2jczx6id8zoY25V9Oie+RsZbvA/pMvrKjTYuN7+BT6XCv
                        2dGm5K8S5B3ZcjT0gXxjS5sQ77r4QxtFcynY06b14sv6dPdfVp0g6OP4lz1tQl1OcT4ZEgn6ML6z
                        qU0JP0ee6ZMljqDP4gc2tQn3rgs4wHJyL7OrTcB3ne8ZGj5fKifTvjYNsE4+52gOIehz+IltbSqg
                        k1UohwkEfQo/s69N6HfdPzwW0797bC7oM/iFjW1C/r3uJ/T//d5rZ/QR/MrGNpV4131Dbqd23BR9
                        AL+xs01F3nX3jzd3NwBb21RPp3/466eUI2aTB7r939nbpqBz2gJBlz9hb5sa6yTo6mdsblPZd11L
                        mba3qalOgq59zvY2DfTBUqbvbG9TS53QnT9jf5savuvQjT/lAJva6YTu+zkn2NRMJ3TbFxxh00Af
                        MGX6yhE2ddIJXfUlZ9jURyd00dccYhPox38p08+cYlOLz8T/stcUyzE2NdCpxu9ouuIcm47XSdAF
                        v+Ygmw7XSdD13uAkm6w/6FgaQbd7h5NsqvNTLE1lOsumc7/sJOhm73GWTafqhK71LofZdKZO6FJv
                        c5pNJ+qErvQ+x9l0nk7oQhWcZ9NhOgm6Tg0H2nTUlzEF3aWKI206R6cHukkdZ9p0ik7oGrUcatMZ
                        OqFLVHOqTQd8Li7oCvUca9P2Ogm6wAXOtWlzndDtLXGwTTt/8iTo6tY42qZtdRJ0cYucbdOmbzt0
                        a8scbtOOOgm6s3VOt2m/tx26Lwvn27SXToJuy0QDm3Z626GrMtLBpm2uJ0H3ZKWHTXtcT+iS7DSx
                        aQOdPqArcqCLTdXfdoKux4U+NpX+UWB0N040sqnu607QxXjRyqaarztBl+JHM5sKXk/oRjzpZlO1
                        6wndhi/9bKrkE7oJbzraVOV19wHdgzstbSrhk6A7CKCpTfDXnaDnD6GtTVCfHujZg2hsE8wn9Nhx
                        tLYJ8fmToEeOpLlN2b95FT1tMO1test74Ql60HBo098kfHuBoGfMgDb9w6BKdmjTd4KEEvRcedCm
                        n3AX6gN6olRo02/4qYSeJB3aNIXvtyVo03N4J2mhTS/gjaSANt2DHt3hvk2EEEIIIYQQQgghhBBC
                        CCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCH/8P/T2g3wTNSy
                        bgAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMC0wNy0wNFQwMzo1MDozOSswMzowMFesjGwAAAAldEVY
                        dGRhdGU6bW9kaWZ5ADIwMjAtMDctMDRUMDM6NTA6MzkrMDM6MDAm8TTQAAAAAElFTkSuQmCC"></image>
                  </svg>
               </a>
               | 
               
               <span class="icon twitter">
                  <a href="https://twitter.com/i_amanchadha">
                     <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                        <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                           c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                           c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                           c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                           C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                           c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                           c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"></path>
                     </svg>
                  </a>
               </span>
               <!-- <span class="username">i_amanchadha</span> -->
                | 
               <a href="mailto:hi@aman.ai">
                  <svg version="1.1" class="mail-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                     <image id="image0" width="16" height="16" x="0" y="0" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAW4AAAFuBAMAAABTjO+8AAAABGdBTUEAALGPC/xhBQAAACBjSFJN
                        AAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAALVBMVEWxsLDGxcW4t7esq6u+
                        vr7Z2NiqqamxsLCvrq7Ozc2ysrK1tbWenZ2dnZ3////zevNgAAAAAXRSTlMAQObYZgAAAAFiS0dE
                        Dm+9ME8AAAAJcEhZcwAACxMAAAsTAQCanBgAAAAHdElNRQfkBwQDLRvUSpUpAAALt0lEQVR42u2d
                        PW8jyRGGR7Lk3XXEyNqQwAVKBewtiHMkwAfQoQ4L3B02ImCs98KVuFZzFfECm3Am4A7YDXmR/sQF
                        /gHO7+94R6Somarq7qr+mGra/YZifzzsfmc4XdNdappcOvjixZcX2VrPpj+az1r8QxtDqp/MRmfa
                        IDI93WKbxUgbRaS3D9zmUhtFolfmUUttGL6OOtjm+kIbh61Jl3t/nPLK9LXUBuLpAGDvi1NWkHs/
                        nPKtwVprQ/l1QGDvg1NWFLf5URvLp28NrbUCy+sfzJB6MUqD/SoeRagkk/M0nkOqFA+Rx2+H5zY3
                        8dzfK2CncIrGcBtztYfuvtdtJPdHJe7ZXtrEmPdx2MdK2OZ6P+1tzEUU9+/VuMdR3E/UuM/+L7lP
                        9pR7um3lry+G0iQp93lUKxL9rnJX7spduSt35a7clbtyV+7KXbkrd+Wu3JW7clfuyl25K3flrtyV
                        u3JX7spduSt35a7c+809Men0rnJX7spduSt35a7clVuiOzXuZQz2QyMK3POLcOzjHd/w3DEnBaa7
                        xgH3z1+nE2h6xx3u8McmFNYN4U55dIkOd6hTpkaZO8wp3QaUuEOO93ZdosUdchC86xI1bvmvT7+6
                        GrfUKX2X6HFLndJ3iSK3zCnoWJoet8Qp+EyxHrfEKSemIG6+U4jDi5rcXKdQJ881ublOwS5R5uad
                        SiePuOpyc5xC5yfQ5eakIaFcos7td4rlILQ2t88ptiwW2tw+p9AuKYDb7RTrcXl9bpdT7LlO9Lld
                        TrG5pAhuu1McSRVK4LY5xZURpwRu8y+6ht0lhXDTOSOcqTfK4KaSi7jzJpXBTTnF5RLE/eeEiRXO
                        BNzYKX8wEu6JSad3NPeC5RSLS+ZTNe6XNBFwynPLMOtxnx3SxXtOsbjkjer7tE9k8a5TLC5ZKL8H
                        pHvpOMWSg22kzH1EV9g55XhFfv6m0X7vSieP3CXL+97+sS63JVnn2jXcm9yFytxkctSHAadza82a
                        ArgtTtnQ3FEfbRMAanPTcB/aT55Rn8xvC+E+WFF03YI9bWvpc9MuXjb4lUir3Ztafe7mlKjzgWZ4
                        XMkVwA1fkd0D0j9Ky8bDnVF4vw9l5FvKP51IRQnclJPPmu8cLimEm3jse0fYft1ppQhuYsl+iROW
                        9lYUZXDjZc0NujX0V3CFcCOnzBv4TcYlcjeHPu6/91sphRvmDUbcoHgx3E8qd+Wu3JW7cv9Pcpf6
                        ezn1cLdBwQK54ZoHcy9K5EZrTMxtXhbIPTV+7h5jGdx4DUxxz0vjfrZicZuvCuM+NTzuzpqnBG4q
                        JktzP64xC+C2RDYp7sc1fQHcd4bPvYuh6HPTkXsb90PMSp2bflNi5X6IEapzr4TcW6dYuH/9Tzr9
                        28Vt+zdydu6NUyzcv5l0eufgPrBVsnNvdl0rc08CuHsvUXS47f8pz8XdOkWV+8heycXdvp1S5Z4E
                        cn+uq8n9yVHJzT2/UOQ+dFVyc5srRe63Edxmosa9cFZC3H+iyw3P3dfio4f7jN7Zps09e+LjZp2D
                        GZr7hhFn45w7Gph7MeLEB0+K437DimsyztUN8BzbUbufisFNVQXcGUV0PmJyExsQNLnbfYw8brxV
                        RZF7E2hlceOAnCL3uYAbhbb0uLfhYSY3DCW+DOaQ6hQCiriRU4YacNjvWMgNw1uR/9+WKzjPu4Af
                        m/vA1kJWWUeLzY1CLmM5hViwz3UANwxxhSR/EQrOcWdDoIAbBosYh6oj5RgpAbdj1vII9rfsfCbh
                        hgGMzE6B89tLryDiPnK1lFzO60nEjQJ0Sz6FWK+cJDJuuJszo1Pg3IJkYULuQ3drCQWuJZicTciN
                        gnRnPAqxfgL9zMDnUm7olJh0hg7Beb2CBcTc8KhgHqeA0VncRnOjPcwzP4VYn7x9yLlhWAKPRbTg
                        nN7gInJu1OqVl0MoNDKjJNwogPUmMfdzRvsh3JzxiBAMSC6oQiHcqOWbJqFQWI8clSBuFMBK6RSe
                        C8O4YQAroVPgXM7pYmHcKBqzaBIJueQ8KTcKYDGc8jNMxUsJOtAWYArlRnvhRh6g1+1AXvtKoSyJ
                        toKh3CiQNG+c2q4C5u4hR4HfcXJutD/LGTLcrRXdKw3oPntwKZwb7YdzDeUdAwXPoeNLhnOjMIHD
                        KV3bjqyl0DWztrcYwY2cYh3Knm3tt0zoEldgKYYb7XYaWwqe9ErZbplw/pyXQgw37okuBn8CR/Qo
                        QJcsXV1HcaPdfOTMop9A+jEMus4dVIrjRjue1kShE1iIdAq6yi8ycqOgEuFJIucO8RiGrhVPx5Hc
                        aK8Wcgq5nwIv7aDjfGGCWG6062kJCtD7V2agFHTJ4sLTbyw3ChkAp1gyM4EgALpOZr5uo7nRwfVL
                        56e0UybOT/NwoxHtVrHv+euWglc3IyQTz40c3LmDOfb8uUoxFiEJuNEd4/FeYHOJuxQnPJCA2+4U
                        +/7hVkuLl1iL7BTc6Bdxmw3IsX+41fbOE+KSRNzIKZv7wcTNvbnzoLq80EASbrxXb9bYzyL0nYJ+
                        lzguScWNwgef72ToieP6G8Ip6Npg7mxJxI0W4jf4xMoaz8CPREKQQbnxNqi/wT+0q7g7+Ef4ddn7
                        cVJxk2mlep5oC5Fn4uCXG5b7mQdpfF/Kc63ydxEl47ak0YMD6Z6WsQK3E2l3uTmnRbCjJSG3y7zn
                        nGmRvO1PyO0wb/embJ+WtaCvlNz0UVQDbspUXrh7iXazJOW2Hdcb9UpZMjXL9oQk5bY4BT7gTclS
                        S1FPabnJ46joAY8MTQj3PCXmJpxCLAOIox7S/SCJuYklDrUMOEGlpP2k5j6GQORiETlFvE04NTcc
                        SctiET12S984J+ZGPDNLQbjMkb5xTsttWWhGlRyCG43irbUoWsbP2L0k50YsrtoobHLL7CU9N5z7
                        9wlLZ+SGI+j5LRHNTkZuMQf8jZL8ZibknojnXV4jAzfjFRUUCiAuh+cOYgj4rqm5V6Ai77k0rFZC
                        btHL9Ueh5971sNzB/Qd+31TccL75kZDAmmm4Q0etIaIu6+G4Ud9jNjZ7M0gO7jtQSXZWMKh2Cm60
                        nUuEjUOG42G4Ub/nMu6g752A+xRUkZ89Dmghnlu4cZPSs4l4xqK5j+V9YuG0qtm5p6BC2BZ2cSux
                        3Ik2gqNZG+XlFvdnE+swRjrukyQuCWgpjjvhwRLh4Zoo7qQHeWRjEMXNOdjEl6i1GO7EB9VEB/Yi
                        uJMfDJSMQwR3+oOYghbDub1HaQPEn8FwbtBHkoPG/OPiwdx5DnazWw3l9hzLD9aEOYuh3KD9ZIkL
                        uCkoArnzJYpgthzGnTMxB28mw7hXmVzSypn2JI47b+IZVush3LkT/XBmM4T7LqNL7scFgFPjEsCd
                        Pz0Rowc59xCJw+CMpuD2txkv/9iIuW0J6tLKm1RNyg2DmF+xMOQ6hVyR3L72UsmXqFHIPVz6RE9P
                        Mm4YnsqZrnLqnFkZN2grWVYISnCM+mEJETcMYo5ycrt7k3DDwEPq/DhQrtmVcJ8M6BLfOAm4QQAv
                        cVYfSo4e+dxDu6QVmOFOqJPP/dzaRj7Zx4rNDYJ3GbKEUbL2yuWG33w2CDaa5V0wj8v9yVI/t2zj
                        xeQGgbuBXEL1fCHifkv+dRCBmX4v4abrDiRyzFjcIDyVKTelTYdU7yzuiZ5LWoGQ4SWXm6o3qMC4
                        LXncIDw1QP5sqCNMwOBe4W87tMDy/pLDDerkz/pNCYzd2s+t75JWiMLLfQe/qY7grPu4/1mCS1qB
                        8Tv1cIP5UcP2HGH3cI/1uN1H2N3cw/yvCZtOQ7mzBQN5ch1hd3Kf63K7jrC7uIf73zU2nYZwK7uk
                        lfUIu4v7XJu6sR5hd3FffV2CJmLuslW5K3flLk+Vu3JX7vJUuSt35S5P+8p9vafcc2/y1DJ1RWb8
                        Kl8fmo/aCEE6sy/1i9bal9S4UDXu3Nelqn2B/Z02RIBmjT1pY8HahC5PtDHE2mxf8mXeLU4PkeKn
                        8U0Nir2LFL9eabMIdN0JcB//5cW+6JcN8X8B85vetwnigQ8AAAAldEVYdGRhdGU6Y3JlYXRlADIw
                        MjAtMDctMDRUMDM6NDU6MjcrMDM6MDDsnuMrAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDIwLTA3LTA0
                        VDAzOjQ1OjI3KzAzOjAwncNblwAAAABJRU5ErkJggg=="></image>
                  </svg>
               </a>
               | 
               <a id="theme-toggle" onclick="modeSwitcher()" style="cursor: pointer;">
                  <svg version="1.1" class="mail-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                     <image id="image0" width="16" height="16" x="0" y="0" xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAMAAAAM7l6QAAAABGdBTUEAALGPC/xhBQAAACBjSFJN
                        AAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAACYVBMVEU/PzpEREBBQT1CQj4/
                        PztAQDtHR0NJSUU+PjpISERDQz9AQDw5OTRFRUE8PDhCQj1CQj89PTlKSkY+PjlNTUlLS0hEREBD
                        Qz9aWleHh4WtrazBwcHCwsLCwsLCwsLAwMCurq2IiIZgYFxXV1Sbm5rFxcXCwsKgoKBkZGFERECX
                        l5bExMSPj45LS0empqWpqahUVFCnp6axsbFTU09CQj6lpaSpqahISESRkZCNjYtUVFG/v7/FxcW7
                        u7vExMVhYV6ampmTk5FXV1S3t7eenp1VVVHCwsOYmJd3d3XIyMjCwsJdXVqEhIKrq6uGhoSnp6aX
                        l5aAgH6srKzAwMBdXVq8vLzCwsOZmZhNTUm3t7bDw8PCwsKYmJexsbCYmJawsK/CwsJOTkq2trXD
                        w8K9vb1bW1jBwcK9vb2pqaiXl5aCgoCvr66AgH6jo6OGhoNYWFXAwMB9fXvIyMjGxsZeXluamplM
                        TEi5ubmcnJteXlrCwsLGxsaTk5FDQz+dnZzJycljY2CJiYe+vr5bW1hUVFCcnJuVlZRGRkKmpqW4
                        uLd8fHl/f33AwMCioqFFRUFQUEyurq6wsLCFhYNkZGBSUk9SUk9hYV6JiYenp6bHx8inp6ZKSkZP
                        T0unp6bExMS6urm0tLSzs7O4uLjExMSioqGMjIrExMTKysuVlZRFRUFiYl6hoaDExMTIyMicnJtr
                        a2hhYV6Li4qxsbDDw8O+vr2zs7KHh4VlZWPHx8fGxsbCwsLJycnIyMjDw8PKysvExMTKysrMzMzL
                        y8vFxcXJycrFxcbGxsfHx8jIyMnExMX///9/oPL/AAAAuHRSTlMAAAAAAAAAAAAAAAAAAAAAAAAA
                        AAAAAQEYUJzK4+3kzJxYGSKE5+qSIgJe7GoGlqYMprcLAZapAl1uH/H70vMkhWYP1ZoW7G5G/fMb
                        UbpinWtbrMsd1OVuBtfn7m3IbMnlBNTozhzz1Z5sVq5Yt2YW7zf48iCTD9CiH/DzZwWv9Ctp0QsQ
                        rnABqNFKO82sAg22uF0fBwUfV7T7uw0Lp/PYycnV8qtu7/JxASeZ7vGgLh5hqebTrWUhilEqqgAA
                        AAFiS0dEyvO0NuYAAAAJcEhZcwAACxMAAAsTAQCanBgAAAAHdElNRQfkCBYKLR1KuANWAAACD0lE
                        QVQoz23TZXvUQBAA4CG7R09K4ZANFtwKFHcvTrHi0BZ3d5dCKe4uxd1d7jbZJCQFwr9ik1wud83N
                        hyRP3uzOk5lZIE6IUK95i5atWktSm7bt2ncQQHTfg3MVUMdOnRNJ6kRS7tK1GxZSXEhIqH53SWE0
                        HUzp0TMPe6txUS9Vo1nB1N59wi6HivrqNBByv/7Y5gGRgTmU+6DBAufwkF85kCczhoZFwMOGa0Ed
                        MVKjbNRogOgYOahG8dhxJpXHx2DCxOBiY1I0f/IUykqmwjQllwpig+kJWjsDZiYCWop4yQpm6TQ5
                        G+bkVhKaW8LYPJhfR9UFUafcaOEik5ZBebbqFa4SlLf4Ny2vw/oS5CqJRpbavCxr5wpPScPlK0y6
                        ElZlNNJI5bUjtHoNY2th3R9f1/tKCjbINLkRNtWmdy5t5KsY2/yXWltg6zbNqxXylcS376Bs5y7A
                        u+V0JX2N7dlrUmUfArz/gL384KFMDR8+olBWeTQOJH7M4N2vOp6PPIzi6hN8gIyTSASCTp3mz9qZ
                        s43jYQEhAZoI587zPqkXLtrDRPClyzy9aV25eu1602Y3bt66fYen0+/WhNw5x/fuq8we/wcPHz1+
                        8tSyW2w8q8HeKcGR5y8s/gHTTPOffVdevnodyzhE+M3bd7Lp1JeZ1vsPH53/KEwx/xX06fOXqq+S
                        VPbt+4+fQjx1BP8DniGUSqIRNGsAAAAldEVYdGRhdGU6Y3JlYXRlADIwMjAtMDgtMjJUMTA6NDU6
                        MjkrMDM6MDBYVnojAAAAJXRFWHRkYXRlOm1vZGlmeQAyMDIwLTA4LTIyVDEwOjQ1OjI5KzAzOjAw
                        KQvCnwAAAABJRU5ErkJggg=="></image>
                  </svg>
               </a>
            </li>
         </ul>
      </div>
      <div align="center" class="footer-col-1 column">
         <a href="https://www.amanchadha.com/">www.amanchadha.com</a>
      </div>
      <!-- <div class="footer-col-2 column">
         </div>
         
         <div class="footer-col-3 column">
         
         </div> -->
   </div>
   <!-- add permalinks to headers in kramdown -->
   <!-- <script>
      var headings = document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]");
      
      for (var i = 0; i < headings.length; i++) {
          headings[i].innerHTML =
              '<a href="#' + headings[i].id + '">' +
                  headings[i].innerText +
              '</a>';
      }
   </script>   -->

   <!-- add title case to section headings -->
   <script src="https://aman.ai/js/ap-style-title-case.js" type="text/javascript"></script>   
   <script>
      var headings = document.querySelectorAll("h1, h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]");
      
      for (var i = 0; i < headings.length; i++) {
          headings[i].innerHTML = titleCase(headings[i].innerHTML);
      }
      
      var toc = document.querySelectorAll("a[id^='markdown-toc-']");
      
      for (var i = 0; i < toc.length; i++) {
          toc[i].innerHTML = titleCase(toc[i].innerHTML);
      }      
   </script>        
</footer>

    <script src="https://aman.ai/js/nanobar.min.js"></script>
    <script>
    var options = {
      classname: 'my-class',
        id: 'my-id'
    };
    var nanobar = new Nanobar( options );
    nanobar.go(100);
    </script><div class="nanobar my-class" id="my-id" style="position: fixed;"><div class="bar"></div></div>     

    <!-- Scroll bar -->
    <div class="progress-bar"></div>
    <!-- Script used to generate --scroll variable with current scroll percentage value -->
    <script>
    var element = document.documentElement,
      body = document.body,
      scrollTop = 'scrollTop',
      scrollHeight = 'scrollHeight',
      progress = document.querySelector('.progress-bar'),
      scroll;

    document.addEventListener('scroll', function() {
      scroll = (element[scrollTop]||body[scrollTop]) / ((element[scrollHeight]||body[scrollHeight]) - element.clientHeight) * 100;
      progress.style.setProperty('--scroll', scroll + '%');
    });
    </script>    
    <!-- theme switcher -->
    <script src="https://aman.ai/js/mode-switcher.js"></script>
    <!-- mathjax -->
<!--     <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" id=""></script>
    <!-- make mathjax responsive -->
    <script type="text/x-mathjax-config;executed=true">
      MathJax.Hub.Config({
       "HTML-CSS": { linebreaks: { automatic: true } },
       "SVG": { linebreaks: { automatic: true } },
      });
    </script>
    <!-- Copy button -->
    <script src="https://aman.ai/js/clipboard.min.js"></script>
    <script src="https://aman.ai/js/copy.js"></script>      
    

<ins class="adsbygoogle adsbygoogle-noablate" data-adsbygoogle-status="done" style="display: none !important;" data-ad-status="unfilled"><div id="aswift_0_host" style="border: none; height: 0px; width: 0px; margin: 0px; padding: 0px; position: relative; visibility: visible; background-color: transparent; display: inline-block;"><iframe id="aswift_0" name="aswift_0" style="left:0;position:absolute;top:0;border:0;width:undefinedpx;height:undefinedpx;min-height:auto;max-height:none;min-width:auto;max-width:none;" sandbox="allow-forms allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-top-navigation-by-user-activation" frameborder="0" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" allow="attribution-reporting; run-ad-auction" src="https://googleads.g.doubleclick.net/pagead/ads?client=ca-pub-5905744527956213&amp;output=html&amp;adk=1812271804&amp;adf=3025194257&amp;lmt=1766895470&amp;plaf=1%3A2%2C2%3A2%2C7%3A2&amp;plat=1%3A128%2C2%3A128%2C3%3A128%2C4%3A128%2C8%3A128%2C9%3A32776%2C16%3A8388608%2C17%3A32%2C24%3A32%2C25%3A32%2C30%3A1048576%2C32%3A32%2C41%3A32%2C42%3A32&amp;format=0x0&amp;url=https%3A%2F%2Faman.ai%2Fprimers%2Fai%2Ffine-tune-and-eval-BERT%2F&amp;pra=5&amp;wgl=1&amp;asro=0&amp;aiapm=0.1542&amp;aiapmd=0.1423&amp;aiapmi=0.16&amp;aiapmid=1&amp;aiact=0.5423&amp;aiactd=0.7&amp;aicct=0.7&amp;aicctd=0.5799&amp;ailct=0.5849&amp;ailctd=0.65&amp;aimart=4&amp;aimartd=4&amp;aieuf=1&amp;aicrs=1&amp;uach=WyIiLCIiLCIiLCIiLCIiLG51bGwsMCxudWxsLCIiLG51bGwsMF0.&amp;abgtt=6&amp;dt=1766922574517&amp;bpp=1&amp;bdt=60&amp;idt=8&amp;shv=r20251211&amp;mjsv=m202512100101&amp;ptt=9&amp;saldr=aa&amp;abxe=1&amp;cookie_enabled=1&amp;eoidce=1&amp;nras=1&amp;correlator=8643357009592&amp;frm=20&amp;pv=2&amp;u_tz=330&amp;u_his=50&amp;u_h=600&amp;u_w=800&amp;u_ah=600&amp;u_aw=800&amp;u_cd=24&amp;u_sd=1&amp;dmc=8&amp;adx=-12245933&amp;ady=-12245933&amp;biw=800&amp;bih=600&amp;scr_x=0&amp;scr_y=0&amp;eid=31095904%2C31096041%2C95376241%2C95376582%2C95378749%2C95377244%2C95340253%2C95340255&amp;oid=2&amp;pvsid=5636339972861827&amp;tmod=112874479&amp;uas=0&amp;nvt=1&amp;fsapi=1&amp;fc=1920&amp;brdim=22%2C22%2C22%2C22%2C800%2C0%2C756%2C556%2C800%2C600&amp;vis=1&amp;rsz=%7C%7Cs%7C&amp;abl=NS&amp;fu=33792&amp;bc=31&amp;bz=0.95&amp;psd=W251bGwsW251bGwsbnVsbCxudWxsLCJkZXByZWNhdGVkX2thbm9uIl1d&amp;ifi=1&amp;uci=a!1&amp;fsb=1&amp;dtd=11" data-google-container-id="a!1" tabindex="0" title="Advertisement" aria-label="Advertisement" data-load-complete="true"></iframe></div></ins><iframe name="googlefcPresent" style="display: none; width: 0px; height: 0px; border: none; z-index: -1000; left: -1000px; top: -1000px;"></iframe><iframe name="__tcfapiLocator" src="about:blank" style="display: none; width: 0px; height: 0px; border: none; z-index: -1000; left: -1000px; top: -1000px;"></iframe><iframe name="googlefcInactive" src="about:blank" style="display: none; width: 0px; height: 0px; border: none; z-index: -1000; left: -1000px; top: -1000px;"></iframe><iframe name="googlefcLoaded" src="about:blank" style="display: none; width: 0px; height: 0px; border: none; z-index: -1000; left: -1000px; top: -1000px;"></iframe><iframe src="https://www.google.com/recaptcha/api2/aframe" width="0" height="0" style="display: none;"></iframe></body><iframe id="google_esf" name="google_esf" src="https://googleads.g.doubleclick.net/pagead/html/r20251211/r20190131/zrt_lookup.html" style="display: none;"></iframe></html>