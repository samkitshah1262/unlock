[
  {
    "id": "ai-prompt-engineering-zero-shot-cot-1",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Prompt Engineering",
    "articleSlug": "prompt-engineering",
    "chapter": "Chain-of-Thought (CoT) Prompting",
    "title": "Zero-shot CoT",
    "subtitle": "Chain-of-Thought (CoT) Prompting",
    "contentHtml": "<ul>\n  <li>Zero-shot CoT was introduced by <a href=\"https://arxiv.org/abs/2205.11916\">Kojima et al. (2022)</a>, which involves appending “Let’s think step by step” to the prompt, and helps in improving model performance, as illustrated in the figure below <a href=\"https://arxiv.org/abs/2205.11916\">(source)</a>.</li>\n</ul>\n<p><img src=\"/primers/ai/assets/prompt/zero-cot.png\" alt=\"\"></p>\n<ul>\n  <li>\n    <p>Let’s look at an example below:</p>\n  </li>\n  <li>\n    <p><em>Prompt:</em></p>\n  </li>\n</ul>\n<p>Let’s look at an example below:</p>\n<p><em>Prompt:</em></p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code8\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code8\">I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code8\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code8\">I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n</code></pre>\n<ul>\n  <li><em>Output:</em></li>\n</ul>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code9\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code9\">11 apples\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code9\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code9\">11 apples\n</code></pre>\n<ul>\n  <li>\n    <p>The answer is incorrect! Now Let’s try with the special prompt.</p>\n  </li>\n  <li>\n    <p><em>Prompt:</em></p>\n  </li>\n</ul>\n<p>The answer is incorrect! Now Let’s try with the special prompt.</p>\n<p><em>Prompt:</em></p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code10\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code10\">I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n\nLet's think step by step.\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code10\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code10\">I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n\nLet's think step by step.\n</code></pre>\n<ul>\n  <li><em>Output:</em></li>\n</ul>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code11\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code11\">First, you started with 10 apples.\nYou gave away 2 apples to the neighbor and 2 to the repairman, so you had 6 apples left.\nThen you bought 5 more apples, so now you had 11 apples.\nFinally, you ate 1 apple, so you would remain with 10 apples.\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code11\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code11\">First, you started with 10 apples.\nYou gave away 2 apples to the neighbor and 2 to the repairman, so you had 6 apples left.\nThen you bought 5 more apples, so now you had 11 apples.\nFinally, you ate 1 apple, so you would remain with 10 apples.\n</code></pre>\n<p>It’s impressive that this simple prompt is effective at this task. This is particularly useful where you don’t have too many examples to use in the prompt.</p>\n<ul>\n  <li>Chain-of-Thought (CoT) prompting generates a sequence of short sentences known as reasoning chains along with an explanation and prediction pair. This method does not require additional training or fine-tuning.</li>\n  <li>These describe step-by-step reasoning logic leading to the final answer with more benefits seen for complex reasoning tasks and larger models.</li>\n  <li>We will look at the two basic CoT Prompting techniques and describe them below.</li>\n</ul>",
    "contentMarkdown": "*   Zero-shot CoT was introduced by [Kojima et al. (2022)](https://arxiv.org/abs/2205.11916), which involves appending “Let’s think step by step” to the prompt, and helps in improving model performance, as illustrated in the figure below [(source)](https://arxiv.org/abs/2205.11916).\n\n![](/primers/ai/assets/prompt/zero-cot.png)\n\n*   Let’s look at an example below:\n    \n*   _Prompt:_\n    \n\nLet’s look at an example below:\n\n_Prompt:_\n\n![](https://aman.ai/images/copy.png)\n\n`I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?`\n\n![](https://aman.ai/images/copy.png)\n\n`I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?`\n\n*   _Output:_\n\n![](https://aman.ai/images/copy.png)\n\n`11 apples`\n\n![](https://aman.ai/images/copy.png)\n\n`11 apples`\n\n*   The answer is incorrect! Now Let’s try with the special prompt.\n    \n*   _Prompt:_\n    \n\nThe answer is incorrect! Now Let’s try with the special prompt.\n\n_Prompt:_\n\n![](https://aman.ai/images/copy.png)\n\n`I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?  Let's think step by step.`\n\n![](https://aman.ai/images/copy.png)\n\n`I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?  Let's think step by step.`\n\n*   _Output:_\n\n![](https://aman.ai/images/copy.png)\n\n`First, you started with 10 apples. You gave away 2 apples to the neighbor and 2 to the repairman, so you had 6 apples left. Then you bought 5 more apples, so now you had 11 apples. Finally, you ate 1 apple, so you would remain with 10 apples.`\n\n![](https://aman.ai/images/copy.png)\n\n`First, you started with 10 apples. You gave away 2 apples to the neighbor and 2 to the repairman, so you had 6 apples left. Then you bought 5 more apples, so now you had 11 apples. Finally, you ate 1 apple, so you would remain with 10 apples.`\n\nIt’s impressive that this simple prompt is effective at this task. This is particularly useful where you don’t have too many examples to use in the prompt.\n\n*   Chain-of-Thought (CoT) prompting generates a sequence of short sentences known as reasoning chains along with an explanation and prediction pair. This method does not require additional training or fine-tuning.\n*   These describe step-by-step reasoning logic leading to the final answer with more benefits seen for complex reasoning tasks and larger models.\n*   We will look at the two basic CoT Prompting techniques and describe them below.",
    "order": 1,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 3,
    "tags": [
      "algorithmsarchitecture",
      "fine-tuning"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 451,
      "contentLength": 5453
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/prompt-engineering/#zero-shot-cot",
    "scrapedAt": "2025-12-28T11:46:09.795Z"
  },
  {
    "id": "ai-prompt-engineering-few-shot-cot-2",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Prompt Engineering",
    "articleSlug": "prompt-engineering",
    "chapter": "Chain-of-Thought (CoT) Prompting",
    "title": "Few-shot CoT",
    "subtitle": "Chain-of-Thought (CoT) Prompting",
    "contentHtml": "<ul>\n  <li>Few-shot CoT allows the model to view a few demonstration of high-quality reasoning chains.</li>\n  <li>Let’s look at the example <a href=\"https://github.com/openai/grade-school-math\">below</a>:</li>\n</ul>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code12\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code12\"><span class=\"n\">Question</span><span class=\"p\">:</span> <span class=\"n\">Tom</span> <span class=\"ow\">and</span> <span class=\"n\">Elizabeth</span> <span class=\"n\">have</span> <span class=\"n\">a</span> <span class=\"n\">competition</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">a</span> <span class=\"n\">hill</span><span class=\"p\">.</span> <span class=\"n\">Elizabeth</span> <span class=\"n\">takes</span> <span class=\"mi\">30</span> <span class=\"n\">minutes</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">the</span> <span class=\"n\">hill</span><span class=\"p\">.</span> <span class=\"n\">Tom</span> <span class=\"n\">takes</span> <span class=\"n\">four</span> <span class=\"n\">times</span> <span class=\"k\">as</span> <span class=\"nb\">long</span> <span class=\"k\">as</span> <span class=\"n\">Elizabeth</span> <span class=\"n\">does</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">the</span> <span class=\"n\">hill</span><span class=\"p\">.</span> <span class=\"n\">How</span> <span class=\"n\">many</span> <span class=\"n\">hours</span> <span class=\"n\">does</span> <span class=\"n\">it</span> <span class=\"n\">take</span> <span class=\"n\">Tom</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">up</span> <span class=\"n\">the</span> <span class=\"n\">hill</span><span class=\"err\">?</span>\n<span class=\"n\">Answer</span><span class=\"p\">:</span> <span class=\"n\">It</span> <span class=\"n\">takes</span> <span class=\"n\">Tom</span> <span class=\"mi\">30</span><span class=\"o\">*</span><span class=\"mi\">4</span> <span class=\"o\">=</span> <span class=\"o\">&lt;&lt;</span><span class=\"mi\">30</span><span class=\"o\">*</span><span class=\"mi\">4</span><span class=\"o\">=</span><span class=\"mi\">120</span><span class=\"o\">&gt;&gt;</span><span class=\"mi\">120</span> <span class=\"n\">minutes</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">the</span> <span class=\"n\">hill</span><span class=\"p\">.</span>\n<span class=\"n\">It</span> <span class=\"n\">takes</span> <span class=\"n\">Tom</span> <span class=\"mi\">120</span><span class=\"o\">/</span><span class=\"mi\">60</span> <span class=\"o\">=</span> <span class=\"o\">&lt;&lt;</span><span class=\"mi\">120</span><span class=\"o\">/</span><span class=\"mi\">60</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"o\">&gt;&gt;</span><span class=\"mi\">2</span> <span class=\"n\">hours</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">the</span> <span class=\"n\">hill</span><span class=\"p\">.</span>\n<span class=\"n\">So</span> <span class=\"n\">the</span> <span class=\"n\">answer</span> <span class=\"ow\">is</span> <span class=\"mf\">2.</span>\n<span class=\"o\">===</span>\n<span class=\"n\">Question</span><span class=\"p\">:</span> <span class=\"n\">Jack</span> <span class=\"ow\">is</span> <span class=\"n\">a</span> <span class=\"n\">soccer</span> <span class=\"n\">player</span><span class=\"p\">.</span> <span class=\"n\">He</span> <span class=\"n\">needs</span> <span class=\"n\">to</span> <span class=\"n\">buy</span> <span class=\"n\">two</span> <span class=\"n\">pairs</span> <span class=\"n\">of</span> <span class=\"n\">socks</span> <span class=\"ow\">and</span> <span class=\"n\">a</span> <span class=\"n\">pair</span> <span class=\"n\">of</span> <span class=\"n\">soccer</span> <span class=\"n\">shoes</span><span class=\"p\">.</span> <span class=\"n\">Each</span> <span class=\"n\">pair</span> <span class=\"n\">of</span> <span class=\"n\">socks</span> <span class=\"n\">cost</span> <span class=\"err\">$</span><span class=\"mf\">9.50</span><span class=\"p\">,</span> <span class=\"ow\">and</span> <span class=\"n\">the</span> <span class=\"n\">shoes</span> <span class=\"n\">cost</span> <span class=\"err\">$</span><span class=\"mf\">92.</span> <span class=\"n\">Jack</span> <span class=\"n\">has</span> <span class=\"err\">$</span><span class=\"mf\">40.</span> <span class=\"n\">How</span> <span class=\"n\">much</span> <span class=\"n\">more</span> <span class=\"n\">money</span> <span class=\"n\">does</span> <span class=\"n\">Jack</span> <span class=\"n\">need</span><span class=\"err\">?</span>\n<span class=\"n\">Answer</span><span class=\"p\">:</span> <span class=\"n\">The</span> <span class=\"n\">total</span> <span class=\"n\">cost</span> <span class=\"n\">of</span> <span class=\"n\">two</span> <span class=\"n\">pairs</span> <span class=\"n\">of</span> <span class=\"n\">socks</span> <span class=\"ow\">is</span> <span class=\"err\">$</span><span class=\"mf\">9.50</span> <span class=\"n\">x</span> <span class=\"mi\">2</span> <span class=\"o\">=</span> <span class=\"err\">$</span><span class=\"o\">&lt;&lt;</span><span class=\"mf\">9.5</span><span class=\"o\">*</span><span class=\"mi\">2</span><span class=\"o\">=</span><span class=\"mi\">19</span><span class=\"o\">&gt;&gt;</span><span class=\"mf\">19.</span>\n<span class=\"n\">The</span> <span class=\"n\">total</span> <span class=\"n\">cost</span> <span class=\"n\">of</span> <span class=\"n\">the</span> <span class=\"n\">socks</span> <span class=\"ow\">and</span> <span class=\"n\">the</span> <span class=\"n\">shoes</span> <span class=\"ow\">is</span> <span class=\"err\">$</span><span class=\"mi\">19</span> <span class=\"o\">+</span> <span class=\"err\">$</span><span class=\"mi\">92</span> <span class=\"o\">=</span> <span class=\"err\">$</span><span class=\"o\">&lt;&lt;</span><span class=\"mi\">19</span><span class=\"o\">+</span><span class=\"mi\">92</span><span class=\"o\">=</span><span class=\"mi\">111</span><span class=\"o\">&gt;&gt;</span><span class=\"mf\">111.</span>\n<span class=\"n\">Jack</span> <span class=\"n\">need</span> <span class=\"err\">$</span><span class=\"mi\">111</span> <span class=\"o\">-</span> <span class=\"err\">$</span><span class=\"mi\">40</span> <span class=\"o\">=</span> <span class=\"err\">$</span><span class=\"o\">&lt;&lt;</span><span class=\"mi\">111</span><span class=\"o\">-</span><span class=\"mi\">40</span><span class=\"o\">=</span><span class=\"mi\">71</span><span class=\"o\">&gt;&gt;</span><span class=\"mi\">71</span> <span class=\"n\">more</span><span class=\"p\">.</span>\n<span class=\"n\">So</span> <span class=\"n\">the</span> <span class=\"n\">answer</span> <span class=\"ow\">is</span> <span class=\"mf\">71.</span>\n<span class=\"o\">===</span>\n<span class=\"n\">Question</span><span class=\"p\">:</span> <span class=\"n\">Marty</span> <span class=\"n\">has</span> <span class=\"mi\">100</span> <span class=\"n\">centimeters</span> <span class=\"n\">of</span> <span class=\"n\">ribbon</span> <span class=\"n\">that</span> <span class=\"n\">he</span> <span class=\"n\">must</span> <span class=\"n\">cut</span> <span class=\"n\">into</span> <span class=\"mi\">4</span> <span class=\"n\">equal</span> <span class=\"n\">parts</span><span class=\"p\">.</span> <span class=\"n\">Each</span> <span class=\"n\">of</span> <span class=\"n\">the</span> <span class=\"n\">cut</span> <span class=\"n\">parts</span> <span class=\"n\">must</span> <span class=\"n\">be</span> <span class=\"n\">divided</span> <span class=\"n\">into</span> <span class=\"mi\">5</span> <span class=\"n\">equal</span> <span class=\"n\">parts</span><span class=\"p\">.</span> <span class=\"n\">How</span> <span class=\"nb\">long</span> <span class=\"n\">will</span> <span class=\"n\">each</span> <span class=\"n\">final</span> <span class=\"n\">cut</span> <span class=\"n\">be</span><span class=\"err\">?</span>\n<span class=\"n\">Answer</span><span class=\"p\">:</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code12\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code12\"><span class=\"n\">Question</span><span class=\"p\">:</span> <span class=\"n\">Tom</span> <span class=\"ow\">and</span> <span class=\"n\">Elizabeth</span> <span class=\"n\">have</span> <span class=\"n\">a</span> <span class=\"n\">competition</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">a</span> <span class=\"n\">hill</span><span class=\"p\">.</span> <span class=\"n\">Elizabeth</span> <span class=\"n\">takes</span> <span class=\"mi\">30</span> <span class=\"n\">minutes</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">the</span> <span class=\"n\">hill</span><span class=\"p\">.</span> <span class=\"n\">Tom</span> <span class=\"n\">takes</span> <span class=\"n\">four</span> <span class=\"n\">times</span> <span class=\"k\">as</span> <span class=\"nb\">long</span> <span class=\"k\">as</span> <span class=\"n\">Elizabeth</span> <span class=\"n\">does</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">the</span> <span class=\"n\">hill</span><span class=\"p\">.</span> <span class=\"n\">How</span> <span class=\"n\">many</span> <span class=\"n\">hours</span> <span class=\"n\">does</span> <span class=\"n\">it</span> <span class=\"n\">take</span> <span class=\"n\">Tom</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">up</span> <span class=\"n\">the</span> <span class=\"n\">hill</span><span class=\"err\">?</span>\n<span class=\"n\">Answer</span><span class=\"p\">:</span> <span class=\"n\">It</span> <span class=\"n\">takes</span> <span class=\"n\">Tom</span> <span class=\"mi\">30</span><span class=\"o\">*</span><span class=\"mi\">4</span> <span class=\"o\">=</span> <span class=\"o\">&lt;&lt;</span><span class=\"mi\">30</span><span class=\"o\">*</span><span class=\"mi\">4</span><span class=\"o\">=</span><span class=\"mi\">120</span><span class=\"o\">&gt;&gt;</span><span class=\"mi\">120</span> <span class=\"n\">minutes</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">the</span> <span class=\"n\">hill</span><span class=\"p\">.</span>\n<span class=\"n\">It</span> <span class=\"n\">takes</span> <span class=\"n\">Tom</span> <span class=\"mi\">120</span><span class=\"o\">/</span><span class=\"mi\">60</span> <span class=\"o\">=</span> <span class=\"o\">&lt;&lt;</span><span class=\"mi\">120</span><span class=\"o\">/</span><span class=\"mi\">60</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"o\">&gt;&gt;</span><span class=\"mi\">2</span> <span class=\"n\">hours</span> <span class=\"n\">to</span> <span class=\"n\">climb</span> <span class=\"n\">the</span> <span class=\"n\">hill</span><span class=\"p\">.</span>\n<span class=\"n\">So</span> <span class=\"n\">the</span> <span class=\"n\">answer</span> <span class=\"ow\">is</span> <span class=\"mf\">2.</span>\n<span class=\"o\">===</span>\n<span class=\"n\">Question</span><span class=\"p\">:</span> <span class=\"n\">Jack</span> <span class=\"ow\">is</span> <span class=\"n\">a</span> <span class=\"n\">soccer</span> <span class=\"n\">player</span><span class=\"p\">.</span> <span class=\"n\">He</span> <span class=\"n\">needs</span> <span class=\"n\">to</span> <span class=\"n\">buy</span> <span class=\"n\">two</span> <span class=\"n\">pairs</span> <span class=\"n\">of</span> <span class=\"n\">socks</span> <span class=\"ow\">and</span> <span class=\"n\">a</span> <span class=\"n\">pair</span> <span class=\"n\">of</span> <span class=\"n\">soccer</span> <span class=\"n\">shoes</span><span class=\"p\">.</span> <span class=\"n\">Each</span> <span class=\"n\">pair</span> <span class=\"n\">of</span> <span class=\"n\">socks</span> <span class=\"n\">cost</span> <span class=\"err\">$</span><span class=\"mf\">9.50</span><span class=\"p\">,</span> <span class=\"ow\">and</span> <span class=\"n\">the</span> <span class=\"n\">shoes</span> <span class=\"n\">cost</span> <span class=\"err\">$</span><span class=\"mf\">92.</span> <span class=\"n\">Jack</span> <span class=\"n\">has</span> <span class=\"err\">$</span><span class=\"mf\">40.</span> <span class=\"n\">How</span> <span class=\"n\">much</span> <span class=\"n\">more</span> <span class=\"n\">money</span> <span class=\"n\">does</span> <span class=\"n\">Jack</span> <span class=\"n\">need</span><span class=\"err\">?</span>\n<span class=\"n\">Answer</span><span class=\"p\">:</span> <span class=\"n\">The</span> <span class=\"n\">total</span> <span class=\"n\">cost</span> <span class=\"n\">of</span> <span class=\"n\">two</span> <span class=\"n\">pairs</span> <span class=\"n\">of</span> <span class=\"n\">socks</span> <span class=\"ow\">is</span> <span class=\"err\">$</span><span class=\"mf\">9.50</span> <span class=\"n\">x</span> <span class=\"mi\">2</span> <span class=\"o\">=</span> <span class=\"err\">$</span><span class=\"o\">&lt;&lt;</span><span class=\"mf\">9.5</span><span class=\"o\">*</span><span class=\"mi\">2</span><span class=\"o\">=</span><span class=\"mi\">19</span><span class=\"o\">&gt;&gt;</span><span class=\"mf\">19.</span>\n<span class=\"n\">The</span> <span class=\"n\">total</span> <span class=\"n\">cost</span> <span class=\"n\">of</span> <span class=\"n\">the</span> <span class=\"n\">socks</span> <span class=\"ow\">and</span> <span class=\"n\">the</span> <span class=\"n\">shoes</span> <span class=\"ow\">is</span> <span class=\"err\">$</span><span class=\"mi\">19</span> <span class=\"o\">+</span> <span class=\"err\">$</span><span class=\"mi\">92</span> <span class=\"o\">=</span> <span class=\"err\">$</span><span class=\"o\">&lt;&lt;</span><span class=\"mi\">19</span><span class=\"o\">+</span><span class=\"mi\">92</span><span class=\"o\">=</span><span class=\"mi\">111</span><span class=\"o\">&gt;&gt;</span><span class=\"mf\">111.</span>\n<span class=\"n\">Jack</span> <span class=\"n\">need</span> <span class=\"err\">$</span><span class=\"mi\">111</span> <span class=\"o\">-</span> <span class=\"err\">$</span><span class=\"mi\">40</span> <span class=\"o\">=</span> <span class=\"err\">$</span><span class=\"o\">&lt;&lt;</span><span class=\"mi\">111</span><span class=\"o\">-</span><span class=\"mi\">40</span><span class=\"o\">=</span><span class=\"mi\">71</span><span class=\"o\">&gt;&gt;</span><span class=\"mi\">71</span> <span class=\"n\">more</span><span class=\"p\">.</span>\n<span class=\"n\">So</span> <span class=\"n\">the</span> <span class=\"n\">answer</span> <span class=\"ow\">is</span> <span class=\"mf\">71.</span>\n<span class=\"o\">===</span>\n<span class=\"n\">Question</span><span class=\"p\">:</span> <span class=\"n\">Marty</span> <span class=\"n\">has</span> <span class=\"mi\">100</span> <span class=\"n\">centimeters</span> <span class=\"n\">of</span> <span class=\"n\">ribbon</span> <span class=\"n\">that</span> <span class=\"n\">he</span> <span class=\"n\">must</span> <span class=\"n\">cut</span> <span class=\"n\">into</span> <span class=\"mi\">4</span> <span class=\"n\">equal</span> <span class=\"n\">parts</span><span class=\"p\">.</span> <span class=\"n\">Each</span> <span class=\"n\">of</span> <span class=\"n\">the</span> <span class=\"n\">cut</span> <span class=\"n\">parts</span> <span class=\"n\">must</span> <span class=\"n\">be</span> <span class=\"n\">divided</span> <span class=\"n\">into</span> <span class=\"mi\">5</span> <span class=\"n\">equal</span> <span class=\"n\">parts</span><span class=\"p\">.</span> <span class=\"n\">How</span> <span class=\"nb\">long</span> <span class=\"n\">will</span> <span class=\"n\">each</span> <span class=\"n\">final</span> <span class=\"n\">cut</span> <span class=\"n\">be</span><span class=\"err\">?</span>\n<span class=\"n\">Answer</span><span class=\"p\">:</span>\n</code></pre>",
    "contentMarkdown": "*   Few-shot CoT allows the model to view a few demonstration of high-quality reasoning chains.\n*   Let’s look at the example [below](https://github.com/openai/grade-school-math):\n\n![](https://aman.ai/images/copy.png)\n\n`Question: Tom and Elizabeth have a competition to climb a hill. Elizabeth takes 30 minutes to climb the hill. Tom takes four times as long as Elizabeth does to climb the hill. How many hours does it take Tom to climb up the hill? Answer: It takes Tom 30*4 = <<30*4=120>>120 minutes to climb the hill. It takes Tom 120/60 = <<120/60=2>>2 hours to climb the hill. So the answer is 2. === Question: Jack is a soccer player. He needs to buy two pairs of socks and a pair of soccer shoes. Each pair of socks cost $9.50, and the shoes cost $92. Jack has $40. How much more money does Jack need? Answer: The total cost of two pairs of socks is $9.50 x 2 = $<<9.5*2=19>>19. The total cost of the socks and the shoes is $19 + $92 = $<<19+92=111>>111. Jack need $111 - $40 = $<<111-40=71>>71 more. So the answer is 71. === Question: Marty has 100 centimeters of ribbon that he must cut into 4 equal parts. Each of the cut parts must be divided into 5 equal parts. How long will each final cut be? Answer:`\n\n![](https://aman.ai/images/copy.png)\n\n`Question: Tom and Elizabeth have a competition to climb a hill. Elizabeth takes 30 minutes to climb the hill. Tom takes four times as long as Elizabeth does to climb the hill. How many hours does it take Tom to climb up the hill? Answer: It takes Tom 30*4 = <<30*4=120>>120 minutes to climb the hill. It takes Tom 120/60 = <<120/60=2>>2 hours to climb the hill. So the answer is 2. === Question: Jack is a soccer player. He needs to buy two pairs of socks and a pair of soccer shoes. Each pair of socks cost $9.50, and the shoes cost $92. Jack has $40. How much more money does Jack need? Answer: The total cost of two pairs of socks is $9.50 x 2 = $<<9.5*2=19>>19. The total cost of the socks and the shoes is $19 + $92 = $<<19+92=111>>111. Jack need $111 - $40 = $<<111-40=71>>71 more. So the answer is 71. === Question: Marty has 100 centimeters of ribbon that he must cut into 4 equal parts. Each of the cut parts must be divided into 5 equal parts. How long will each final cut be? Answer:`",
    "order": 2,
    "orderInChapter": 2,
    "difficulty": 3,
    "estimatedMinutes": 3,
    "tags": [
      "algorithmsarchitecture"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 410,
      "contentLength": 15239
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/prompt-engineering/#few-shot-cot",
    "scrapedAt": "2025-12-28T11:46:09.795Z"
  },
  {
    "id": "ai-prompt-engineering-what-is-the-difference-between-tree-of-thought-pro-3",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Prompt Engineering",
    "articleSlug": "prompt-engineering",
    "chapter": "Tree-of-Thoughts (ToT) Prompting",
    "title": "What is the Difference Between Tree-of-Thought Prompting and Chain-of-Thought Prompting? Which is Better and Why?",
    "subtitle": "Tree-of-Thoughts (ToT) Prompting",
    "contentHtml": "<ul>\n  <li>“Chain of Thought” prompting and “Tree of Thought” prompting are methods used to enhance the performance of large language models like GPT-3 or GPT-4, particularly on complex tasks that require multi-step reasoning or problem-solving.</li>\n  <li><strong>Chain of Thought Prompting</strong>\n    <ul>\n      <li><strong>Principle:</strong> In Chain of Thought prompting, the user writes out the intermediate steps or reasoning process that might lead to the answer. This approach helps the model to “think aloud” or follow a logical progression of steps to reach a conclusion.</li>\n      <li><strong>Usage:</strong> It’s particularly useful for complex problems like math word problems, where simply stating the problem doesn’t provide enough guidance for the model. By including a chain of reasoning, the model is encouraged to follow a similar step-by-step approach.</li>\n      <li><strong>Example:</strong> For a math problem, the prompt would include both the problem and a sequential, detailed explanation of how to solve it, guiding the model through the reasoning process.</li>\n    </ul>\n  </li>\n  <li><strong>Tree of Thought Prompting</strong>\n    <ul>\n      <li><strong>Principle:</strong> Tree of Thought prompting is a more sophisticated approach where multiple lines of reasoning are considered in parallel. It’s like creating a decision tree where each branch represents a different path of thought or a different aspect of the problem.</li>\n      <li><strong>Usage:</strong> This method is useful for problems where there might be multiple valid approaches or when the problem’s domain involves dealing with branching possibilities and outcomes.</li>\n      <li><strong>Example:</strong> In a complex scenario with multiple variables or possible outcomes, the prompt would include an exploration of these different paths, like considering different possible causes for a phenomenon in a scientific problem.</li>\n    </ul>\n  </li>\n  <li><strong>Comparison and Effectiveness</strong>\n    <ul>\n      <li><strong>Complexity:</strong> Tree of Thought is inherently more complex as it involves considering multiple lines of reasoning simultaneously. It’s more comprehensive but also more challenging to structure effectively.</li>\n      <li><strong>Applicability:</strong> Chain of Thought is generally more straightforward and can be applied to a wide range of problems, especially where a linear, step-by-step approach is beneficial. Tree of Thought is more suited to scenarios with branching possibilities, where multiple factors or outcomes must be considered.</li>\n      <li><strong>Efficiency:</strong> For simpler problems, Chain of Thought is usually more efficient, as it’s more direct. For more complex, multi-faceted problems, Tree of Thought may provide a more thorough exploration of the problem space.</li>\n      <li><strong>Which is Better?:</strong> The choice between them depends on the nature of the task. For most straightforward problem-solving tasks, Chain of Thought is sufficient and easier to manage. Tree of Thought is better suited for complex, multi-dimensional problems where different hypotheses or scenarios need to be evaluated.</li>\n    </ul>\n  </li>\n  <li>In summary, both methods aim to improve the reasoning capabilities of language models by guiding them through a more structured thought process. The choice of which to use should be based on the specific requirements of the problem at hand.</li>\n</ul>\n<ul>\n      <li><strong>Principle:</strong> In Chain of Thought prompting, the user writes out the intermediate steps or reasoning process that might lead to the answer. This approach helps the model to “think aloud” or follow a logical progression of steps to reach a conclusion.</li>\n      <li><strong>Usage:</strong> It’s particularly useful for complex problems like math word problems, where simply stating the problem doesn’t provide enough guidance for the model. By including a chain of reasoning, the model is encouraged to follow a similar step-by-step approach.</li>\n      <li><strong>Example:</strong> For a math problem, the prompt would include both the problem and a sequential, detailed explanation of how to solve it, guiding the model through the reasoning process.</li>\n    </ul>\n<ul>\n      <li><strong>Principle:</strong> Tree of Thought prompting is a more sophisticated approach where multiple lines of reasoning are considered in parallel. It’s like creating a decision tree where each branch represents a different path of thought or a different aspect of the problem.</li>\n      <li><strong>Usage:</strong> This method is useful for problems where there might be multiple valid approaches or when the problem’s domain involves dealing with branching possibilities and outcomes.</li>\n      <li><strong>Example:</strong> In a complex scenario with multiple variables or possible outcomes, the prompt would include an exploration of these different paths, like considering different possible causes for a phenomenon in a scientific problem.</li>\n    </ul>\n<ul>\n      <li><strong>Complexity:</strong> Tree of Thought is inherently more complex as it involves considering multiple lines of reasoning simultaneously. It’s more comprehensive but also more challenging to structure effectively.</li>\n      <li><strong>Applicability:</strong> Chain of Thought is generally more straightforward and can be applied to a wide range of problems, especially where a linear, step-by-step approach is beneficial. Tree of Thought is more suited to scenarios with branching possibilities, where multiple factors or outcomes must be considered.</li>\n      <li><strong>Efficiency:</strong> For simpler problems, Chain of Thought is usually more efficient, as it’s more direct. For more complex, multi-faceted problems, Tree of Thought may provide a more thorough exploration of the problem space.</li>\n      <li><strong>Which is Better?:</strong> The choice between them depends on the nature of the task. For most straightforward problem-solving tasks, Chain of Thought is sufficient and easier to manage. Tree of Thought is better suited for complex, multi-dimensional problems where different hypotheses or scenarios need to be evaluated.</li>\n    </ul>",
    "contentMarkdown": "*   “Chain of Thought” prompting and “Tree of Thought” prompting are methods used to enhance the performance of large language models like GPT-3 or GPT-4, particularly on complex tasks that require multi-step reasoning or problem-solving.\n*   **Chain of Thought Prompting**\n    *   **Principle:** In Chain of Thought prompting, the user writes out the intermediate steps or reasoning process that might lead to the answer. This approach helps the model to “think aloud” or follow a logical progression of steps to reach a conclusion.\n    *   **Usage:** It’s particularly useful for complex problems like math word problems, where simply stating the problem doesn’t provide enough guidance for the model. By including a chain of reasoning, the model is encouraged to follow a similar step-by-step approach.\n    *   **Example:** For a math problem, the prompt would include both the problem and a sequential, detailed explanation of how to solve it, guiding the model through the reasoning process.\n*   **Tree of Thought Prompting**\n    *   **Principle:** Tree of Thought prompting is a more sophisticated approach where multiple lines of reasoning are considered in parallel. It’s like creating a decision tree where each branch represents a different path of thought or a different aspect of the problem.\n    *   **Usage:** This method is useful for problems where there might be multiple valid approaches or when the problem’s domain involves dealing with branching possibilities and outcomes.\n    *   **Example:** In a complex scenario with multiple variables or possible outcomes, the prompt would include an exploration of these different paths, like considering different possible causes for a phenomenon in a scientific problem.\n*   **Comparison and Effectiveness**\n    *   **Complexity:** Tree of Thought is inherently more complex as it involves considering multiple lines of reasoning simultaneously. It’s more comprehensive but also more challenging to structure effectively.\n    *   **Applicability:** Chain of Thought is generally more straightforward and can be applied to a wide range of problems, especially where a linear, step-by-step approach is beneficial. Tree of Thought is more suited to scenarios with branching possibilities, where multiple factors or outcomes must be considered.\n    *   **Efficiency:** For simpler problems, Chain of Thought is usually more efficient, as it’s more direct. For more complex, multi-faceted problems, Tree of Thought may provide a more thorough exploration of the problem space.\n    *   **Which is Better?:** The choice between them depends on the nature of the task. For most straightforward problem-solving tasks, Chain of Thought is sufficient and easier to manage. Tree of Thought is better suited for complex, multi-dimensional problems where different hypotheses or scenarios need to be evaluated.\n*   In summary, both methods aim to improve the reasoning capabilities of language models by guiding them through a more structured thought process. The choice of which to use should be based on the specific requirements of the problem at hand.\n\n*   **Principle:** In Chain of Thought prompting, the user writes out the intermediate steps or reasoning process that might lead to the answer. This approach helps the model to “think aloud” or follow a logical progression of steps to reach a conclusion.\n*   **Usage:** It’s particularly useful for complex problems like math word problems, where simply stating the problem doesn’t provide enough guidance for the model. By including a chain of reasoning, the model is encouraged to follow a similar step-by-step approach.\n*   **Example:** For a math problem, the prompt would include both the problem and a sequential, detailed explanation of how to solve it, guiding the model through the reasoning process.\n\n*   **Principle:** Tree of Thought prompting is a more sophisticated approach where multiple lines of reasoning are considered in parallel. It’s like creating a decision tree where each branch represents a different path of thought or a different aspect of the problem.\n*   **Usage:** This method is useful for problems where there might be multiple valid approaches or when the problem’s domain involves dealing with branching possibilities and outcomes.\n*   **Example:** In a complex scenario with multiple variables or possible outcomes, the prompt would include an exploration of these different paths, like considering different possible causes for a phenomenon in a scientific problem.\n\n*   **Complexity:** Tree of Thought is inherently more complex as it involves considering multiple lines of reasoning simultaneously. It’s more comprehensive but also more challenging to structure effectively.\n*   **Applicability:** Chain of Thought is generally more straightforward and can be applied to a wide range of problems, especially where a linear, step-by-step approach is beneficial. Tree of Thought is more suited to scenarios with branching possibilities, where multiple factors or outcomes must be considered.\n*   **Efficiency:** For simpler problems, Chain of Thought is usually more efficient, as it’s more direct. For more complex, multi-faceted problems, Tree of Thought may provide a more thorough exploration of the problem space.\n*   **Which is Better?:** The choice between them depends on the nature of the task. For most straightforward problem-solving tasks, Chain of Thought is sufficient and easier to manage. Tree of Thought is better suited for complex, multi-dimensional problems where different hypotheses or scenarios need to be evaluated.",
    "order": 3,
    "orderInChapter": 1,
    "difficulty": 2,
    "estimatedMinutes": 5,
    "tags": [
      "algorithmsarchitecture",
      "gpt"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 832,
      "contentLength": 6217
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/prompt-engineering/#what-is-the-difference-between-tree-of-thought-prompting-and-chain-of-thought-prompting?-which-is-better-and-why?",
    "scrapedAt": "2025-12-28T11:46:09.795Z"
  },
  {
    "id": "ai-prompt-engineering-what-is-the-difference-between-tree-of-thought-pro-4",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Prompt Engineering",
    "articleSlug": "prompt-engineering",
    "chapter": "Graph-of-Thought (GoT) Prompting",
    "title": "What is the Difference Between Tree-of-Thought Prompting and Graph-of-Thought Prompting? Which is Better and Why?",
    "subtitle": "Graph-of-Thought (GoT) Prompting",
    "contentHtml": "<ol>\n  <li><strong>Disadvantages of CoT</strong>: CoT prompting fails to solve problems that benefit from planning, strategic lookahead, backtracking, and exploration of numerous solutions in parallel.</li>\n  <li><strong>Structural Approach</strong>:\n    <ul>\n      <li><strong>Tree-of-Thought (ToT)</strong> prompting structures the reasoning process as a tree where each node represents a “thought” or a simpler sub-problem derived from a more complex problem. Put simply, ToT prompting breaks a complex problem into a series of simpler problems (or “thoughts”). The solution process involves branching out into these simpler problems, allowing for strategic planning, lookahead, and backtracking. The LLM generates many thoughts and continually evaluates its progress toward a final solution via natural language (i.e., via prompting). By leveraging the model’s self-evaluation of progress towards a solution, we can power the exploration process with widely-used search algorithms (e.g., breadth-first search or depth-first search), allowing for lookahead/backtracking when solving a problem.</li>\n      <li><strong>Graph-of-Thought (GoT)</strong> prompting, on the other hand, generalizes research on ToT prompting to graph-based strategies for reasoning. GoT thus uses a graph structure instead of a tree. This means that the paths of thought are not strictly linear or hierarchical. Thoughts can be revisited, reused, or even form recursive loops. This approach recognizes that the reasoning process may require revisiting earlier stages or combining thoughts in non-linear ways.</li>\n    </ul>\n  </li>\n  <li><strong>Flexibility and Complexity</strong>:\n    <ul>\n      <li><strong>ToT</strong> is somewhat linear in its progression, even though it allows for branching. This makes it suitable for problems where a structured breakdown into sub-problems can lead logically from one step to another until a solution is reached.</li>\n      <li><strong>GoT</strong> provides greater flexibility as it can accommodate more complex relationships between thoughts, allowing for more dynamic and interconnected reasoning. This is particularly useful in scenarios where the problem-solving process is not straightforward and may benefit from revisiting and re-evaluating previous thoughts. GoT thus makes no assumption that the path of thoughts used to generate a solution is linear. We can re-use thoughts or even recurse through a sequence of several thoughts when deriving a solution.\n     - <strong>Which is better and why?</strong> Choosing between ToT and GoT prompting depends on the nature of the problem at hand:</li>\n      <li><strong>For problems that are well-suited to linear or hierarchical breakdowns</strong>, where each sub-problem distinctly leads to the next, ToT prompting might be more effective and efficient. It simplifies the problem-solving process by maintaining a clear structure and path.</li>\n      <li><strong>For more complex problems where the solution might require revisiting earlier ideas or combining insights in a non-linear fashion</strong>, GoT prompting could be superior. It allows for a more robust exploration of potential solutions by leveraging the flexibility and interconnectedness of thoughts in a graph.</li>\n      <li>Note that ultimately, <strong>neither method is inherently “better”</strong> as their effectiveness is context-dependent. The choice between them should be guided by the specific requirements and nature of the problem being addressed. Additionally, the criticism of both methods regarding their practicality due to the potential for a high number of inference steps indicates that there are still challenges to overcome in deploying these techniques efficiently.</li>\n      <li>On a related note, these tree/graph-based prompting techniques have been criticized for their lack of practicality. Solving a reasoning problem with ToT/GoT prompting could potentially require a massive number of inference steps from the LLM!</li>\n    </ul>\n  </li>\n</ol>\n<ul>\n      <li><strong>Tree-of-Thought (ToT)</strong> prompting structures the reasoning process as a tree where each node represents a “thought” or a simpler sub-problem derived from a more complex problem. Put simply, ToT prompting breaks a complex problem into a series of simpler problems (or “thoughts”). The solution process involves branching out into these simpler problems, allowing for strategic planning, lookahead, and backtracking. The LLM generates many thoughts and continually evaluates its progress toward a final solution via natural language (i.e., via prompting). By leveraging the model’s self-evaluation of progress towards a solution, we can power the exploration process with widely-used search algorithms (e.g., breadth-first search or depth-first search), allowing for lookahead/backtracking when solving a problem.</li>\n      <li><strong>Graph-of-Thought (GoT)</strong> prompting, on the other hand, generalizes research on ToT prompting to graph-based strategies for reasoning. GoT thus uses a graph structure instead of a tree. This means that the paths of thought are not strictly linear or hierarchical. Thoughts can be revisited, reused, or even form recursive loops. This approach recognizes that the reasoning process may require revisiting earlier stages or combining thoughts in non-linear ways.</li>\n    </ul>\n<ul>\n      <li><strong>ToT</strong> is somewhat linear in its progression, even though it allows for branching. This makes it suitable for problems where a structured breakdown into sub-problems can lead logically from one step to another until a solution is reached.</li>\n      <li><strong>GoT</strong> provides greater flexibility as it can accommodate more complex relationships between thoughts, allowing for more dynamic and interconnected reasoning. This is particularly useful in scenarios where the problem-solving process is not straightforward and may benefit from revisiting and re-evaluating previous thoughts. GoT thus makes no assumption that the path of thoughts used to generate a solution is linear. We can re-use thoughts or even recurse through a sequence of several thoughts when deriving a solution.\n     - <strong>Which is better and why?</strong> Choosing between ToT and GoT prompting depends on the nature of the problem at hand:</li>\n      <li><strong>For problems that are well-suited to linear or hierarchical breakdowns</strong>, where each sub-problem distinctly leads to the next, ToT prompting might be more effective and efficient. It simplifies the problem-solving process by maintaining a clear structure and path.</li>\n      <li><strong>For more complex problems where the solution might require revisiting earlier ideas or combining insights in a non-linear fashion</strong>, GoT prompting could be superior. It allows for a more robust exploration of potential solutions by leveraging the flexibility and interconnectedness of thoughts in a graph.</li>\n      <li>Note that ultimately, <strong>neither method is inherently “better”</strong> as their effectiveness is context-dependent. The choice between them should be guided by the specific requirements and nature of the problem being addressed. Additionally, the criticism of both methods regarding their practicality due to the potential for a high number of inference steps indicates that there are still challenges to overcome in deploying these techniques efficiently.</li>\n      <li>On a related note, these tree/graph-based prompting techniques have been criticized for their lack of practicality. Solving a reasoning problem with ToT/GoT prompting could potentially require a massive number of inference steps from the LLM!</li>\n    </ul>",
    "contentMarkdown": "1.  **Disadvantages of CoT**: CoT prompting fails to solve problems that benefit from planning, strategic lookahead, backtracking, and exploration of numerous solutions in parallel.\n2.  **Structural Approach**:\n    *   **Tree-of-Thought (ToT)** prompting structures the reasoning process as a tree where each node represents a “thought” or a simpler sub-problem derived from a more complex problem. Put simply, ToT prompting breaks a complex problem into a series of simpler problems (or “thoughts”). The solution process involves branching out into these simpler problems, allowing for strategic planning, lookahead, and backtracking. The LLM generates many thoughts and continually evaluates its progress toward a final solution via natural language (i.e., via prompting). By leveraging the model’s self-evaluation of progress towards a solution, we can power the exploration process with widely-used search algorithms (e.g., breadth-first search or depth-first search), allowing for lookahead/backtracking when solving a problem.\n    *   **Graph-of-Thought (GoT)** prompting, on the other hand, generalizes research on ToT prompting to graph-based strategies for reasoning. GoT thus uses a graph structure instead of a tree. This means that the paths of thought are not strictly linear or hierarchical. Thoughts can be revisited, reused, or even form recursive loops. This approach recognizes that the reasoning process may require revisiting earlier stages or combining thoughts in non-linear ways.\n3.  **Flexibility and Complexity**:\n    *   **ToT** is somewhat linear in its progression, even though it allows for branching. This makes it suitable for problems where a structured breakdown into sub-problems can lead logically from one step to another until a solution is reached.\n    *   **GoT** provides greater flexibility as it can accommodate more complex relationships between thoughts, allowing for more dynamic and interconnected reasoning. This is particularly useful in scenarios where the problem-solving process is not straightforward and may benefit from revisiting and re-evaluating previous thoughts. GoT thus makes no assumption that the path of thoughts used to generate a solution is linear. We can re-use thoughts or even recurse through a sequence of several thoughts when deriving a solution. - **Which is better and why?** Choosing between ToT and GoT prompting depends on the nature of the problem at hand:\n    *   **For problems that are well-suited to linear or hierarchical breakdowns**, where each sub-problem distinctly leads to the next, ToT prompting might be more effective and efficient. It simplifies the problem-solving process by maintaining a clear structure and path.\n    *   **For more complex problems where the solution might require revisiting earlier ideas or combining insights in a non-linear fashion**, GoT prompting could be superior. It allows for a more robust exploration of potential solutions by leveraging the flexibility and interconnectedness of thoughts in a graph.\n    *   Note that ultimately, **neither method is inherently “better”** as their effectiveness is context-dependent. The choice between them should be guided by the specific requirements and nature of the problem being addressed. Additionally, the criticism of both methods regarding their practicality due to the potential for a high number of inference steps indicates that there are still challenges to overcome in deploying these techniques efficiently.\n    *   On a related note, these tree/graph-based prompting techniques have been criticized for their lack of practicality. Solving a reasoning problem with ToT/GoT prompting could potentially require a massive number of inference steps from the LLM!\n\n*   **Tree-of-Thought (ToT)** prompting structures the reasoning process as a tree where each node represents a “thought” or a simpler sub-problem derived from a more complex problem. Put simply, ToT prompting breaks a complex problem into a series of simpler problems (or “thoughts”). The solution process involves branching out into these simpler problems, allowing for strategic planning, lookahead, and backtracking. The LLM generates many thoughts and continually evaluates its progress toward a final solution via natural language (i.e., via prompting). By leveraging the model’s self-evaluation of progress towards a solution, we can power the exploration process with widely-used search algorithms (e.g., breadth-first search or depth-first search), allowing for lookahead/backtracking when solving a problem.\n*   **Graph-of-Thought (GoT)** prompting, on the other hand, generalizes research on ToT prompting to graph-based strategies for reasoning. GoT thus uses a graph structure instead of a tree. This means that the paths of thought are not strictly linear or hierarchical. Thoughts can be revisited, reused, or even form recursive loops. This approach recognizes that the reasoning process may require revisiting earlier stages or combining thoughts in non-linear ways.\n\n*   **ToT** is somewhat linear in its progression, even though it allows for branching. This makes it suitable for problems where a structured breakdown into sub-problems can lead logically from one step to another until a solution is reached.\n*   **GoT** provides greater flexibility as it can accommodate more complex relationships between thoughts, allowing for more dynamic and interconnected reasoning. This is particularly useful in scenarios where the problem-solving process is not straightforward and may benefit from revisiting and re-evaluating previous thoughts. GoT thus makes no assumption that the path of thoughts used to generate a solution is linear. We can re-use thoughts or even recurse through a sequence of several thoughts when deriving a solution. - **Which is better and why?** Choosing between ToT and GoT prompting depends on the nature of the problem at hand:\n*   **For problems that are well-suited to linear or hierarchical breakdowns**, where each sub-problem distinctly leads to the next, ToT prompting might be more effective and efficient. It simplifies the problem-solving process by maintaining a clear structure and path.\n*   **For more complex problems where the solution might require revisiting earlier ideas or combining insights in a non-linear fashion**, GoT prompting could be superior. It allows for a more robust exploration of potential solutions by leveraging the flexibility and interconnectedness of thoughts in a graph.\n*   Note that ultimately, **neither method is inherently “better”** as their effectiveness is context-dependent. The choice between them should be guided by the specific requirements and nature of the problem being addressed. Additionally, the criticism of both methods regarding their practicality due to the potential for a high number of inference steps indicates that there are still challenges to overcome in deploying these techniques efficiently.\n*   On a related note, these tree/graph-based prompting techniques have been criticized for their lack of practicality. Solving a reasoning problem with ToT/GoT prompting could potentially require a massive number of inference steps from the LLM!",
    "order": 4,
    "orderInChapter": 1,
    "difficulty": 2,
    "estimatedMinutes": 6,
    "tags": [
      "algorithmsarchitecture",
      "llm"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 1041,
      "contentLength": 7699
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/prompt-engineering/#what-is-the-difference-between-tree-of-thought-prompting-and-graph-of-thought-prompting?-which-is-better-and-why?",
    "scrapedAt": "2025-12-28T11:46:09.796Z"
  },
  {
    "id": "ai-prompt-engineering-how-does-react-work-5",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Prompt Engineering",
    "articleSlug": "prompt-engineering",
    "chapter": "ReAct Prompting",
    "title": "How Does ReAct Work?",
    "subtitle": "ReAct Prompting",
    "contentHtml": "<ul>\n  <li>\n    <p>ReAct is inspired by the synergies between “acting” and “reasoning” which allow humans to learn new tasks and make decisions or reasoning.</p>\n  </li>\n  <li>\n    <p>Chain-of-thought (CoT) prompting has shown the capabilities of LLMs to carry out reasoning traces to generate answers to questions involving arithmetic and commonsense reasoning, among other tasks <a href=\"https://arxiv.org/abs/2201.11903\">(Wei et al., 2022)</a>. But it’s lack of access to the external world or inability to update its knowledge can lead to issues like fact hallucination and error propagation.</p>\n  </li>\n  <li>\n    <p>ReAct is a general paradigm that combines reasoning and acting with LLMs. ReAct prompts LLMs to generate verbal reasoning traces and actions for a task. This allows the system to perform dynamic reasoning to create, maintain, and adjust plans for acting while also enabling interaction to external environments (e.g., Wikipedia) to incorporate additional information into the reasoning. The figure below (<a href=\"https://arxiv.org/abs/2210.03629\">source</a>) shows an example of ReAct and the different steps involved to perform question answering.</p>\n  </li>\n</ul>\n<p>ReAct is inspired by the synergies between “acting” and “reasoning” which allow humans to learn new tasks and make decisions or reasoning.</p>\n<p>Chain-of-thought (CoT) prompting has shown the capabilities of LLMs to carry out reasoning traces to generate answers to questions involving arithmetic and commonsense reasoning, among other tasks <a href=\"https://arxiv.org/abs/2201.11903\">(Wei et al., 2022)</a>. But it’s lack of access to the external world or inability to update its knowledge can lead to issues like fact hallucination and error propagation.</p>\n<p>ReAct is a general paradigm that combines reasoning and acting with LLMs. ReAct prompts LLMs to generate verbal reasoning traces and actions for a task. This allows the system to perform dynamic reasoning to create, maintain, and adjust plans for acting while also enabling interaction to external environments (e.g., Wikipedia) to incorporate additional information into the reasoning. The figure below (<a href=\"https://arxiv.org/abs/2210.03629\">source</a>) shows an example of ReAct and the different steps involved to perform question answering.</p>\n<p><img src=\"/primers/ai/assets/prompt/react.png\" alt=\"\"></p>\n<ul>\n  <li>In the example above, we pass a prompt like the following question from <a href=\"https://hotpotqa.github.io/\">HotpotQA</a>:</li>\n</ul>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code19\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code19\">Aside from the Apple Remote, what other devices can control the program Apple Remote was originally designed to interact with?\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code19\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code19\">Aside from the Apple Remote, what other devices can control the program Apple Remote was originally designed to interact with?\n</code></pre>\n<ul>\n  <li>Note that in-context examples are also added to the prompt but we exclude that here for simplicity. We can see that the model generates <em>task solving trajectories</em> (Thought, Act). Obs corresponds to observation from the environment that’s being interacted with (e.g., Search engine). In essence, ReAct can retrieve information to support reasoning, while reasoning helps to target what to retrieve next.</li>\n</ul>",
    "contentMarkdown": "*   ReAct is inspired by the synergies between “acting” and “reasoning” which allow humans to learn new tasks and make decisions or reasoning.\n    \n*   Chain-of-thought (CoT) prompting has shown the capabilities of LLMs to carry out reasoning traces to generate answers to questions involving arithmetic and commonsense reasoning, among other tasks [(Wei et al., 2022)](https://arxiv.org/abs/2201.11903). But it’s lack of access to the external world or inability to update its knowledge can lead to issues like fact hallucination and error propagation.\n    \n*   ReAct is a general paradigm that combines reasoning and acting with LLMs. ReAct prompts LLMs to generate verbal reasoning traces and actions for a task. This allows the system to perform dynamic reasoning to create, maintain, and adjust plans for acting while also enabling interaction to external environments (e.g., Wikipedia) to incorporate additional information into the reasoning. The figure below ([source](https://arxiv.org/abs/2210.03629)) shows an example of ReAct and the different steps involved to perform question answering.\n    \n\nReAct is inspired by the synergies between “acting” and “reasoning” which allow humans to learn new tasks and make decisions or reasoning.\n\nChain-of-thought (CoT) prompting has shown the capabilities of LLMs to carry out reasoning traces to generate answers to questions involving arithmetic and commonsense reasoning, among other tasks [(Wei et al., 2022)](https://arxiv.org/abs/2201.11903). But it’s lack of access to the external world or inability to update its knowledge can lead to issues like fact hallucination and error propagation.\n\nReAct is a general paradigm that combines reasoning and acting with LLMs. ReAct prompts LLMs to generate verbal reasoning traces and actions for a task. This allows the system to perform dynamic reasoning to create, maintain, and adjust plans for acting while also enabling interaction to external environments (e.g., Wikipedia) to incorporate additional information into the reasoning. The figure below ([source](https://arxiv.org/abs/2210.03629)) shows an example of ReAct and the different steps involved to perform question answering.\n\n![](/primers/ai/assets/prompt/react.png)\n\n*   In the example above, we pass a prompt like the following question from [HotpotQA](https://hotpotqa.github.io/):\n\n![](https://aman.ai/images/copy.png)\n\n`Aside from the Apple Remote, what other devices can control the program Apple Remote was originally designed to interact with?`\n\n![](https://aman.ai/images/copy.png)\n\n`Aside from the Apple Remote, what other devices can control the program Apple Remote was originally designed to interact with?`\n\n*   Note that in-context examples are also added to the prompt but we exclude that here for simplicity. We can see that the model generates _task solving trajectories_ (Thought, Act). Obs corresponds to observation from the environment that’s being interacted with (e.g., Search engine). In essence, ReAct can retrieve information to support reasoning, while reasoning helps to target what to retrieve next.",
    "order": 5,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 3,
    "tags": [
      "algorithmsarchitecture",
      "llm"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 429,
      "contentLength": 3871
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/prompt-engineering/#how-does-react-work?",
    "scrapedAt": "2025-12-28T11:46:09.796Z"
  },
  {
    "id": "ai-prompt-engineering-react-prompting-6",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Prompt Engineering",
    "articleSlug": "prompt-engineering",
    "chapter": "ReAct Prompting",
    "title": "ReAct Prompting",
    "subtitle": "ReAct Prompting",
    "contentHtml": "<ul>\n  <li>\n    <p>To demonstrate how ReAct prompting works, let’s follow an example from the paper.</p>\n  </li>\n  <li>\n    <p>The first step is to select cases from a training set (e.g., HotPotQA) and compose ReAct-format trajectories. These are used as few-shot exemplars in the prompts. The trajectories consist of multiple thought-action-observation steps as shown in the figure above. The free-form thoughts are used to achieve different tasks such as decomposing questions, extracting information, performing commonsense/arithmetic reasoning, guide search formulation, and synthesizing final answer.</p>\n  </li>\n  <li>\n    <p>Here is an example of what the ReAct prompt exemplars look like (obtained from the paper and shortened to one example for simplicity):</p>\n  </li>\n</ul>\n<p>To demonstrate how ReAct prompting works, let’s follow an example from the paper.</p>\n<p>The first step is to select cases from a training set (e.g., HotPotQA) and compose ReAct-format trajectories. These are used as few-shot exemplars in the prompts. The trajectories consist of multiple thought-action-observation steps as shown in the figure above. The free-form thoughts are used to achieve different tasks such as decomposing questions, extracting information, performing commonsense/arithmetic reasoning, guide search formulation, and synthesizing final answer.</p>\n<p>Here is an example of what the ReAct prompt exemplars look like (obtained from the paper and shortened to one example for simplicity):</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code20\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code20\">Question What is the elevation range for the area that the eastern sector of the\nColorado orogeny extends into?\nThought 1 I need to search Colorado orogeny, find the area that the eastern sector\nof the Colorado orogeny extends into, then find the elevation range of the\narea.\nAction 1 Search[Colorado orogeny]\nObservation 1 The Colorado orogeny was an episode of mountain building (an orogeny) in\nColorado and surrounding areas.\nThought 2 It does not mention the eastern sector. So I need to look up eastern\nsector.\nAction 2 Lookup[eastern sector]\nObservation 2 (Result 1 / 1) The eastern sector extends into the High Plains and is called\nthe Central Plains orogeny.\nThought 3 The eastern sector of Colorado orogeny extends into the High Plains. So I\nneed to search High Plains and find its elevation range.\nAction 3 Search[High Plains]\nObservation 3 High Plains refers to one of two distinct land regions\nThought 4 I need to instead search High Plains (United States).\nAction 4 Search[High Plains (United States)]\nObservation 4 The High Plains are a subregion of the Great Plains. From east to west, the\nHigh Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130\nm).[3]\nThought 5 High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer\nis 1,800 to 7,000 ft.\nAction 5 Finish[1,800 to 7,000 ft]\n...\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code20\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code20\">Question What is the elevation range for the area that the eastern sector of the\nColorado orogeny extends into?\nThought 1 I need to search Colorado orogeny, find the area that the eastern sector\nof the Colorado orogeny extends into, then find the elevation range of the\narea.\nAction 1 Search[Colorado orogeny]\nObservation 1 The Colorado orogeny was an episode of mountain building (an orogeny) in\nColorado and surrounding areas.\nThought 2 It does not mention the eastern sector. So I need to look up eastern\nsector.\nAction 2 Lookup[eastern sector]\nObservation 2 (Result 1 / 1) The eastern sector extends into the High Plains and is called\nthe Central Plains orogeny.\nThought 3 The eastern sector of Colorado orogeny extends into the High Plains. So I\nneed to search High Plains and find its elevation range.\nAction 3 Search[High Plains]\nObservation 3 High Plains refers to one of two distinct land regions\nThought 4 I need to instead search High Plains (United States).\nAction 4 Search[High Plains (United States)]\nObservation 4 The High Plains are a subregion of the Great Plains. From east to west, the\nHigh Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130\nm).[3]\nThought 5 High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer\nis 1,800 to 7,000 ft.\nAction 5 Finish[1,800 to 7,000 ft]\n...\n</code></pre>\n<ul>\n  <li>Note that different prompts setups are used for different types of tasks. For tasks where reasoning is of primary importance (e.g., HotpotQA), multiple thought-action-observation steps are used for the task-solving trajectory. For decision making tasks involving lots of action steps, thoughts are used sparsely.</li>\n</ul>",
    "contentMarkdown": "*   To demonstrate how ReAct prompting works, let’s follow an example from the paper.\n    \n*   The first step is to select cases from a training set (e.g., HotPotQA) and compose ReAct-format trajectories. These are used as few-shot exemplars in the prompts. The trajectories consist of multiple thought-action-observation steps as shown in the figure above. The free-form thoughts are used to achieve different tasks such as decomposing questions, extracting information, performing commonsense/arithmetic reasoning, guide search formulation, and synthesizing final answer.\n    \n*   Here is an example of what the ReAct prompt exemplars look like (obtained from the paper and shortened to one example for simplicity):\n    \n\nTo demonstrate how ReAct prompting works, let’s follow an example from the paper.\n\nThe first step is to select cases from a training set (e.g., HotPotQA) and compose ReAct-format trajectories. These are used as few-shot exemplars in the prompts. The trajectories consist of multiple thought-action-observation steps as shown in the figure above. The free-form thoughts are used to achieve different tasks such as decomposing questions, extracting information, performing commonsense/arithmetic reasoning, guide search formulation, and synthesizing final answer.\n\nHere is an example of what the ReAct prompt exemplars look like (obtained from the paper and shortened to one example for simplicity):\n\n![](https://aman.ai/images/copy.png)\n\n`Question What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into? Thought 1 I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area. Action 1 Search[Colorado orogeny] Observation 1 The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas. Thought 2 It does not mention the eastern sector. So I need to look up eastern sector. Action 2 Lookup[eastern sector] Observation 2 (Result 1 / 1) The eastern sector extends into the High Plains and is called the Central Plains orogeny. Thought 3 The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range. Action 3 Search[High Plains] Observation 3 High Plains refers to one of two distinct land regions Thought 4 I need to instead search High Plains (United States). Action 4 Search[High Plains (United States)] Observation 4 The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130 m).[3] Thought 5 High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft. Action 5 Finish[1,800 to 7,000 ft] ...`\n\n![](https://aman.ai/images/copy.png)\n\n`Question What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into? Thought 1 I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area. Action 1 Search[Colorado orogeny] Observation 1 The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas. Thought 2 It does not mention the eastern sector. So I need to look up eastern sector. Action 2 Lookup[eastern sector] Observation 2 (Result 1 / 1) The eastern sector extends into the High Plains and is called the Central Plains orogeny. Thought 3 The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range. Action 3 Search[High Plains] Observation 3 High Plains refers to one of two distinct land regions Thought 4 I need to instead search High Plains (United States). Action 4 Search[High Plains (United States)] Observation 4 The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130 m).[3] Thought 5 High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft. Action 5 Finish[1,800 to 7,000 ft] ...`\n\n*   Note that different prompts setups are used for different types of tasks. For tasks where reasoning is of primary importance (e.g., HotpotQA), multiple thought-action-observation steps are used for the task-solving trajectory. For decision making tasks involving lots of action steps, thoughts are used sparsely.",
    "order": 6,
    "orderInChapter": 2,
    "difficulty": 3,
    "estimatedMinutes": 4,
    "tags": [
      "algorithmsarchitecture"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 710,
      "contentLength": 5163
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/prompt-engineering/#react-prompting",
    "scrapedAt": "2025-12-28T11:46:09.796Z"
  },
  {
    "id": "ai-prompt-engineering-results-on-knowledge-intensive-tasks-7",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Prompt Engineering",
    "articleSlug": "prompt-engineering",
    "chapter": "ReAct Prompting",
    "title": "Results on Knowledge-Intensive Tasks",
    "subtitle": "ReAct Prompting",
    "contentHtml": "<ul>\n  <li>The paper first evaluates ReAct on knowledge-intensive reasoning tasks such as question answering (HotPotQA) and fact verification (<a href=\"https://fever.ai/resources.html\">Fever</a>), as shown in the figure below (<a href=\"https://arxiv.org/abs/2210.03629\">source</a>). PaLM-540B is used as the base model for prompting.</li>\n</ul>\n<p><img src=\"/primers/ai/assets/prompt/table1.png\" alt=\"\"></p>\n<ul>\n  <li>\n    <p>The prompting results on HotPotQA and Fever using different prompting methods show that ReAct generally performs better than Act (involves acting only) on both tasks.</p>\n  </li>\n  <li>\n    <p>We can also observe that ReAct outperforms CoT on Fever and lags behind CoT on HotpotQA. A detailed error analysis is provided in the paper. In summary:</p>\n\n    <ul>\n      <li>CoT suffers from fact hallucination</li>\n      <li>ReAct’s structural constraint reduces its flexibility in formulating reasoning steps</li>\n      <li>ReAct depends a lot on the information it’s retrieving; non-informative search results derails the model reasoning and leads to difficulty in recovering and reformulating thoughts</li>\n    </ul>\n  </li>\n  <li>\n    <p>Prompting methods that combine and support switching between ReAct and CoT+Self-Consistency generally outperform all the other prompting methods.</p>\n  </li>\n</ul>\n<p>The prompting results on HotPotQA and Fever using different prompting methods show that ReAct generally performs better than Act (involves acting only) on both tasks.</p>\n<p>We can also observe that ReAct outperforms CoT on Fever and lags behind CoT on HotpotQA. A detailed error analysis is provided in the paper. In summary:</p>\n<ul>\n      <li>CoT suffers from fact hallucination</li>\n      <li>ReAct’s structural constraint reduces its flexibility in formulating reasoning steps</li>\n      <li>ReAct depends a lot on the information it’s retrieving; non-informative search results derails the model reasoning and leads to difficulty in recovering and reformulating thoughts</li>\n    </ul>\n<p>Prompting methods that combine and support switching between ReAct and CoT+Self-Consistency generally outperform all the other prompting methods.</p>",
    "contentMarkdown": "*   The paper first evaluates ReAct on knowledge-intensive reasoning tasks such as question answering (HotPotQA) and fact verification ([Fever](https://fever.ai/resources.html)), as shown in the figure below ([source](https://arxiv.org/abs/2210.03629)). PaLM-540B is used as the base model for prompting.\n\n![](/primers/ai/assets/prompt/table1.png)\n\n*   The prompting results on HotPotQA and Fever using different prompting methods show that ReAct generally performs better than Act (involves acting only) on both tasks.\n    \n*   We can also observe that ReAct outperforms CoT on Fever and lags behind CoT on HotpotQA. A detailed error analysis is provided in the paper. In summary:\n    \n    *   CoT suffers from fact hallucination\n    *   ReAct’s structural constraint reduces its flexibility in formulating reasoning steps\n    *   ReAct depends a lot on the information it’s retrieving; non-informative search results derails the model reasoning and leads to difficulty in recovering and reformulating thoughts\n*   Prompting methods that combine and support switching between ReAct and CoT+Self-Consistency generally outperform all the other prompting methods.\n    \n\nThe prompting results on HotPotQA and Fever using different prompting methods show that ReAct generally performs better than Act (involves acting only) on both tasks.\n\nWe can also observe that ReAct outperforms CoT on Fever and lags behind CoT on HotpotQA. A detailed error analysis is provided in the paper. In summary:\n\n*   CoT suffers from fact hallucination\n*   ReAct’s structural constraint reduces its flexibility in formulating reasoning steps\n*   ReAct depends a lot on the information it’s retrieving; non-informative search results derails the model reasoning and leads to difficulty in recovering and reformulating thoughts\n\nPrompting methods that combine and support switching between ReAct and CoT+Self-Consistency generally outperform all the other prompting methods.",
    "order": 7,
    "orderInChapter": 3,
    "difficulty": 2,
    "estimatedMinutes": 2,
    "tags": [
      "algorithmsarchitecture"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 265,
      "contentLength": 2176
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/prompt-engineering/#results-on-knowledge-intensive-tasks",
    "scrapedAt": "2025-12-28T11:46:09.796Z"
  },
  {
    "id": "ai-prompt-engineering-results-on-decision-making-tasks-8",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Prompt Engineering",
    "articleSlug": "prompt-engineering",
    "chapter": "ReAct Prompting",
    "title": "Results on Decision Making Tasks",
    "subtitle": "ReAct Prompting",
    "contentHtml": "<ul>\n  <li>\n    <p>The paper also reports results demonstrating ReAct’s performance on decision making tasks. ReAct is evaluated on two benchmarks called <a href=\"https://alfworld.github.io/\">ALFWorld</a> (text-based game) and <a href=\"https://webshop-pnlp.github.io/\">WebShop</a> (online shopping website environment). Both involve complex environments that require reasoning to act and explore effectively.</p>\n  </li>\n  <li>\n    <p>Note that the ReAct prompts are designed differently for these tasks while still keeping the same core idea of combining reasoning and acting. Below is an example (<a href=\"https://arxiv.org/abs/2210.03629\">source</a>) for an ALFWorld problem involving ReAct prompting.</p>\n  </li>\n</ul>\n<p>The paper also reports results demonstrating ReAct’s performance on decision making tasks. ReAct is evaluated on two benchmarks called <a href=\"https://alfworld.github.io/\">ALFWorld</a> (text-based game) and <a href=\"https://webshop-pnlp.github.io/\">WebShop</a> (online shopping website environment). Both involve complex environments that require reasoning to act and explore effectively.</p>\n<p>Note that the ReAct prompts are designed differently for these tasks while still keeping the same core idea of combining reasoning and acting. Below is an example (<a href=\"https://arxiv.org/abs/2210.03629\">source</a>) for an ALFWorld problem involving ReAct prompting.</p>\n<p><img src=\"/primers/ai/assets/prompt/alfworld.png\" alt=\"\"></p>\n<ul>\n  <li>ReAct outperforms Act on both ALFWorld and Webshop. Act, without any thoughts, fails to correctly decompose goals into subgoals. Reasoning seems to be advantageous in ReAct for these types of tasks but current prompting-based methods are still far from the performance of expert humans on these tasks.</li>\n</ul>",
    "contentMarkdown": "*   The paper also reports results demonstrating ReAct’s performance on decision making tasks. ReAct is evaluated on two benchmarks called [ALFWorld](https://alfworld.github.io/) (text-based game) and [WebShop](https://webshop-pnlp.github.io/) (online shopping website environment). Both involve complex environments that require reasoning to act and explore effectively.\n    \n*   Note that the ReAct prompts are designed differently for these tasks while still keeping the same core idea of combining reasoning and acting. Below is an example ([source](https://arxiv.org/abs/2210.03629)) for an ALFWorld problem involving ReAct prompting.\n    \n\nThe paper also reports results demonstrating ReAct’s performance on decision making tasks. ReAct is evaluated on two benchmarks called [ALFWorld](https://alfworld.github.io/) (text-based game) and [WebShop](https://webshop-pnlp.github.io/) (online shopping website environment). Both involve complex environments that require reasoning to act and explore effectively.\n\nNote that the ReAct prompts are designed differently for these tasks while still keeping the same core idea of combining reasoning and acting. Below is an example ([source](https://arxiv.org/abs/2210.03629)) for an ALFWorld problem involving ReAct prompting.\n\n![](/primers/ai/assets/prompt/alfworld.png)\n\n*   ReAct outperforms Act on both ALFWorld and Webshop. Act, without any thoughts, fails to correctly decompose goals into subgoals. Reasoning seems to be advantageous in ReAct for these types of tasks but current prompting-based methods are still far from the performance of expert humans on these tasks.",
    "order": 8,
    "orderInChapter": 4,
    "difficulty": 2,
    "estimatedMinutes": 2,
    "tags": [
      "algorithmsarchitecture",
      "nlp"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 201,
      "contentLength": 1785
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/prompt-engineering/#results-on-decision-making-tasks",
    "scrapedAt": "2025-12-28T11:46:09.796Z"
  },
  {
    "id": "ai-prompt-engineering-react-usage-with-langchain-9",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Prompt Engineering",
    "articleSlug": "prompt-engineering",
    "chapter": "ReAct Prompting",
    "title": "ReAct Usage with LangChain",
    "subtitle": "ReAct Prompting",
    "contentHtml": "<ul>\n  <li>\n    <p>Below is a high-level example of how the ReAct prompting approach works in practice. We will be using OpenAI for the LLM and <a href=\"https://python.langchain.com/en/latest/index.html\">LangChain</a> as it already has built-in functionality that leverages the ReAct framework to build agents that perform tasks by combining the power of LLMs and different tools.</p>\n  </li>\n  <li>\n    <p>First, let’s install and import the necessary libraries:</p>\n  </li>\n</ul>\n<p>Below is a high-level example of how the ReAct prompting approach works in practice. We will be using OpenAI for the LLM and <a href=\"https://python.langchain.com/en/latest/index.html\">LangChain</a> as it already has built-in functionality that leverages the ReAct framework to build agents that perform tasks by combining the power of LLMs and different tools.</p>\n<p>First, let’s install and import the necessary libraries:</p>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code21\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code21\"><span class=\"o\">%%</span><span class=\"n\">capture</span>\n<span class=\"c1\"># update or install the necessary libraries\n</span><span class=\"err\">!</span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"o\">--</span><span class=\"n\">upgrade</span> <span class=\"n\">openai</span>\n<span class=\"err\">!</span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"o\">--</span><span class=\"n\">upgrade</span> <span class=\"n\">langchain</span>\n<span class=\"err\">!</span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"o\">--</span><span class=\"n\">upgrade</span> <span class=\"n\">python</span><span class=\"o\">-</span><span class=\"n\">dotenv</span>\n<span class=\"err\">!</span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">google</span><span class=\"o\">-</span><span class=\"n\">search</span><span class=\"o\">-</span><span class=\"n\">results</span>\n\n<span class=\"c1\"># import libraries\n</span><span class=\"kn\">import</span> <span class=\"nn\">openai</span>\n<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">from</span> <span class=\"nn\">langchain.llms</span> <span class=\"kn\">import</span> <span class=\"n\">OpenAI</span>\n<span class=\"kn\">from</span> <span class=\"nn\">langchain.agents</span> <span class=\"kn\">import</span> <span class=\"n\">load_tools</span>\n<span class=\"kn\">from</span> <span class=\"nn\">langchain.agents</span> <span class=\"kn\">import</span> <span class=\"n\">initialize_agent</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dotenv</span> <span class=\"kn\">import</span> <span class=\"n\">load_dotenv</span>\n<span class=\"n\">load_dotenv</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># load API keys; you will need to obtain these if you haven't yet\n</span><span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">environ</span><span class=\"p\">[</span><span class=\"s\">\"OPENAI_API_KEY\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">getenv</span><span class=\"p\">(</span><span class=\"s\">\"OPENAI_API_KEY\"</span><span class=\"p\">)</span>\n<span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">environ</span><span class=\"p\">[</span><span class=\"s\">\"SERPER_API_KEY\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">getenv</span><span class=\"p\">(</span><span class=\"s\">\"SERPER_API_KEY\"</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code21\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code21\"><span class=\"o\">%%</span><span class=\"n\">capture</span>\n<span class=\"c1\"># update or install the necessary libraries\n</span><span class=\"err\">!</span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"o\">--</span><span class=\"n\">upgrade</span> <span class=\"n\">openai</span>\n<span class=\"err\">!</span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"o\">--</span><span class=\"n\">upgrade</span> <span class=\"n\">langchain</span>\n<span class=\"err\">!</span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"o\">--</span><span class=\"n\">upgrade</span> <span class=\"n\">python</span><span class=\"o\">-</span><span class=\"n\">dotenv</span>\n<span class=\"err\">!</span><span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"n\">google</span><span class=\"o\">-</span><span class=\"n\">search</span><span class=\"o\">-</span><span class=\"n\">results</span>\n\n<span class=\"c1\"># import libraries\n</span><span class=\"kn\">import</span> <span class=\"nn\">openai</span>\n<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n<span class=\"kn\">from</span> <span class=\"nn\">langchain.llms</span> <span class=\"kn\">import</span> <span class=\"n\">OpenAI</span>\n<span class=\"kn\">from</span> <span class=\"nn\">langchain.agents</span> <span class=\"kn\">import</span> <span class=\"n\">load_tools</span>\n<span class=\"kn\">from</span> <span class=\"nn\">langchain.agents</span> <span class=\"kn\">import</span> <span class=\"n\">initialize_agent</span>\n<span class=\"kn\">from</span> <span class=\"nn\">dotenv</span> <span class=\"kn\">import</span> <span class=\"n\">load_dotenv</span>\n<span class=\"n\">load_dotenv</span><span class=\"p\">()</span>\n\n<span class=\"c1\"># load API keys; you will need to obtain these if you haven't yet\n</span><span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">environ</span><span class=\"p\">[</span><span class=\"s\">\"OPENAI_API_KEY\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">getenv</span><span class=\"p\">(</span><span class=\"s\">\"OPENAI_API_KEY\"</span><span class=\"p\">)</span>\n<span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">environ</span><span class=\"p\">[</span><span class=\"s\">\"SERPER_API_KEY\"</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"p\">.</span><span class=\"n\">getenv</span><span class=\"p\">(</span><span class=\"s\">\"SERPER_API_KEY\"</span><span class=\"p\">)</span>\n</code></pre>\n<ul>\n  <li>Now we can configure the LLM, the tools we will use, and the agent that allows us to leverage the ReAct framework together with the LLM and tools. Note that we are using a search API for searching external information and LLM as a math tool.</li>\n</ul>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code22\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code22\"><span class=\"n\">llm</span> <span class=\"o\">=</span> <span class=\"n\">OpenAI</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s\">\"text-davinci-003\"</span> <span class=\"p\">,</span><span class=\"n\">temperature</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">tools</span> <span class=\"o\">=</span> <span class=\"n\">load_tools</span><span class=\"p\">([</span><span class=\"s\">\"google-serper\"</span><span class=\"p\">,</span> <span class=\"s\">\"llm-math\"</span><span class=\"p\">],</span> <span class=\"n\">llm</span><span class=\"o\">=</span><span class=\"n\">llm</span><span class=\"p\">)</span>\n<span class=\"n\">agent</span> <span class=\"o\">=</span> <span class=\"n\">initialize_agent</span><span class=\"p\">(</span><span class=\"n\">tools</span><span class=\"p\">,</span> <span class=\"n\">llm</span><span class=\"p\">,</span> <span class=\"n\">agent</span><span class=\"o\">=</span><span class=\"s\">\"zero-shot-react-description\"</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code22\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code22\"><span class=\"n\">llm</span> <span class=\"o\">=</span> <span class=\"n\">OpenAI</span><span class=\"p\">(</span><span class=\"n\">model_name</span><span class=\"o\">=</span><span class=\"s\">\"text-davinci-003\"</span> <span class=\"p\">,</span><span class=\"n\">temperature</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">tools</span> <span class=\"o\">=</span> <span class=\"n\">load_tools</span><span class=\"p\">([</span><span class=\"s\">\"google-serper\"</span><span class=\"p\">,</span> <span class=\"s\">\"llm-math\"</span><span class=\"p\">],</span> <span class=\"n\">llm</span><span class=\"o\">=</span><span class=\"n\">llm</span><span class=\"p\">)</span>\n<span class=\"n\">agent</span> <span class=\"o\">=</span> <span class=\"n\">initialize_agent</span><span class=\"p\">(</span><span class=\"n\">tools</span><span class=\"p\">,</span> <span class=\"n\">llm</span><span class=\"p\">,</span> <span class=\"n\">agent</span><span class=\"o\">=</span><span class=\"s\">\"zero-shot-react-description\"</span><span class=\"p\">,</span> <span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n</code></pre>\n<ul>\n  <li>Once that’s configured, we can now run the agent with the desired query/prompt. Notice that here we are not expected to provide few-shot exemplars as explained in the paper.</li>\n</ul>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code23\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code23\"><span class=\"n\">agent</span><span class=\"p\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"s\">\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\"</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code23\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code23\"><span class=\"n\">agent</span><span class=\"p\">.</span><span class=\"n\">run</span><span class=\"p\">(</span><span class=\"s\">\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\"</span><span class=\"p\">)</span>\n</code></pre>\n<ul>\n  <li>The chain execution looks as follows:</li>\n</ul>\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code24\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code24\"><span class=\"pi\">&gt;</span> <span class=\"err\">Entering</span> <span class=\"err\">new</span> <span class=\"err\">AgentExecutor</span> <span class=\"err\">chain...</span>\n <span class=\"s\">I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power.</span>\n<span class=\"na\">Action</span><span class=\"pi\">:</span> <span class=\"s\">Search</span>\n<span class=\"na\">Action Input</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">Olivia</span><span class=\"nv\"> </span><span class=\"s\">Wilde</span><span class=\"nv\"> </span><span class=\"s\">boyfriend\"</span>\n<span class=\"na\">Observation</span><span class=\"pi\">:</span> <span class=\"s\">Olivia Wilde started dating Harry Styles after ending her years-long engagement to Jason Sudeikis — see their relationship timeline.</span>\n<span class=\"na\">Thought</span><span class=\"pi\">:</span> <span class=\"s\">I need to find out Harry Styles' age.</span>\n<span class=\"na\">Action</span><span class=\"pi\">:</span> <span class=\"s\">Search</span>\n<span class=\"na\">Action Input</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">Harry</span><span class=\"nv\"> </span><span class=\"s\">Styles</span><span class=\"nv\"> </span><span class=\"s\">age\"</span>\n<span class=\"na\">Observation</span><span class=\"pi\">:</span> <span class=\"s\">29 years</span>\n<span class=\"na\">Thought</span><span class=\"pi\">:</span> <span class=\"s\">I need to calculate 29 raised to the 0.23 power.</span>\n<span class=\"na\">Action</span><span class=\"pi\">:</span> <span class=\"s\">Calculator</span>\n<span class=\"na\">Action Input</span><span class=\"pi\">:</span> <span class=\"s\">29^0.23</span>\n<span class=\"na\">Observation</span><span class=\"pi\">:</span> <span class=\"na\">Answer</span><span class=\"pi\">:</span> <span class=\"m\">2.169459462491557</span>\n\n<span class=\"na\">Thought</span><span class=\"pi\">:</span> <span class=\"s\">I now know the final answer.</span>\n<span class=\"na\">Final Answer</span><span class=\"pi\">:</span> <span class=\"s\">Harry Styles, Olivia Wilde's boyfriend, is 29 years old and his age raised to the 0.23 power is 2.169459462491557.</span>\n\n<span class=\"pi\">&gt;</span> <span class=\"err\">Finished</span> <span class=\"err\">chain.</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code24\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code24\"><span class=\"pi\">&gt;</span> <span class=\"err\">Entering</span> <span class=\"err\">new</span> <span class=\"err\">AgentExecutor</span> <span class=\"err\">chain...</span>\n <span class=\"s\">I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power.</span>\n<span class=\"na\">Action</span><span class=\"pi\">:</span> <span class=\"s\">Search</span>\n<span class=\"na\">Action Input</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">Olivia</span><span class=\"nv\"> </span><span class=\"s\">Wilde</span><span class=\"nv\"> </span><span class=\"s\">boyfriend\"</span>\n<span class=\"na\">Observation</span><span class=\"pi\">:</span> <span class=\"s\">Olivia Wilde started dating Harry Styles after ending her years-long engagement to Jason Sudeikis — see their relationship timeline.</span>\n<span class=\"na\">Thought</span><span class=\"pi\">:</span> <span class=\"s\">I need to find out Harry Styles' age.</span>\n<span class=\"na\">Action</span><span class=\"pi\">:</span> <span class=\"s\">Search</span>\n<span class=\"na\">Action Input</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">Harry</span><span class=\"nv\"> </span><span class=\"s\">Styles</span><span class=\"nv\"> </span><span class=\"s\">age\"</span>\n<span class=\"na\">Observation</span><span class=\"pi\">:</span> <span class=\"s\">29 years</span>\n<span class=\"na\">Thought</span><span class=\"pi\">:</span> <span class=\"s\">I need to calculate 29 raised to the 0.23 power.</span>\n<span class=\"na\">Action</span><span class=\"pi\">:</span> <span class=\"s\">Calculator</span>\n<span class=\"na\">Action Input</span><span class=\"pi\">:</span> <span class=\"s\">29^0.23</span>\n<span class=\"na\">Observation</span><span class=\"pi\">:</span> <span class=\"na\">Answer</span><span class=\"pi\">:</span> <span class=\"m\">2.169459462491557</span>\n\n<span class=\"na\">Thought</span><span class=\"pi\">:</span> <span class=\"s\">I now know the final answer.</span>\n<span class=\"na\">Final Answer</span><span class=\"pi\">:</span> <span class=\"s\">Harry Styles, Olivia Wilde's boyfriend, is 29 years old and his age raised to the 0.23 power is 2.169459462491557.</span>\n\n<span class=\"pi\">&gt;</span> <span class=\"err\">Finished</span> <span class=\"err\">chain.</span>\n</code></pre>\n<ul>\n  <li>The output we get is as follows:</li>\n</ul>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code25\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code25\">\"Harry Styles, Olivia Wilde's boyfriend, is 29 years old and his age raised to the 0.23 power is 2.169459462491557.\"\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code25\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code25\">\"Harry Styles, Olivia Wilde's boyfriend, is 29 years old and his age raised to the 0.23 power is 2.169459462491557.\"\n</code></pre>\n<ul>\n  <li>We adapted the example from the <a href=\"https://python.langchain.com/docs/modules/agents/agent_types/react\">LangChain documentation</a>, so credit goes to them. We encourage the learner to explore different combination of tools and tasks.</li>\n</ul>",
    "contentMarkdown": "*   Below is a high-level example of how the ReAct prompting approach works in practice. We will be using OpenAI for the LLM and [LangChain](https://python.langchain.com/en/latest/index.html) as it already has built-in functionality that leverages the ReAct framework to build agents that perform tasks by combining the power of LLMs and different tools.\n    \n*   First, let’s install and import the necessary libraries:\n    \n\nBelow is a high-level example of how the ReAct prompting approach works in practice. We will be using OpenAI for the LLM and [LangChain](https://python.langchain.com/en/latest/index.html) as it already has built-in functionality that leverages the ReAct framework to build agents that perform tasks by combining the power of LLMs and different tools.\n\nFirst, let’s install and import the necessary libraries:\n\n![](https://aman.ai/images/copy.png)\n\n`%%capture # update or install the necessary libraries !pip install --upgrade openai !pip install --upgrade langchain !pip install --upgrade python-dotenv !pip install google-search-results  # import libraries import openai import os from langchain.llms import OpenAI from langchain.agents import load_tools from langchain.agents import initialize_agent from dotenv import load_dotenv load_dotenv()  # load API keys; you will need to obtain these if you haven't yet os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") os.environ[\"SERPER_API_KEY\"] = os.getenv(\"SERPER_API_KEY\")`\n\n![](https://aman.ai/images/copy.png)\n\n`%%capture # update or install the necessary libraries !pip install --upgrade openai !pip install --upgrade langchain !pip install --upgrade python-dotenv !pip install google-search-results  # import libraries import openai import os from langchain.llms import OpenAI from langchain.agents import load_tools from langchain.agents import initialize_agent from dotenv import load_dotenv load_dotenv()  # load API keys; you will need to obtain these if you haven't yet os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") os.environ[\"SERPER_API_KEY\"] = os.getenv(\"SERPER_API_KEY\")`\n\n*   Now we can configure the LLM, the tools we will use, and the agent that allows us to leverage the ReAct framework together with the LLM and tools. Note that we are using a search API for searching external information and LLM as a math tool.\n\n![](https://aman.ai/images/copy.png)\n\n`llm = OpenAI(model_name=\"text-davinci-003\" ,temperature=0) tools = load_tools([\"google-serper\", \"llm-math\"], llm=llm) agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)`\n\n![](https://aman.ai/images/copy.png)\n\n`llm = OpenAI(model_name=\"text-davinci-003\" ,temperature=0) tools = load_tools([\"google-serper\", \"llm-math\"], llm=llm) agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)`\n\n*   Once that’s configured, we can now run the agent with the desired query/prompt. Notice that here we are not expected to provide few-shot exemplars as explained in the paper.\n\n![](https://aman.ai/images/copy.png)\n\n`agent.run(\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\")`\n\n![](https://aman.ai/images/copy.png)\n\n`agent.run(\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\")`\n\n*   The chain execution looks as follows:\n\n![](https://aman.ai/images/copy.png)\n\n`> Entering new AgentExecutor chain...  I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power. Action: Search Action Input: \"Olivia Wilde boyfriend\" Observation: Olivia Wilde started dating Harry Styles after ending her years-long engagement to Jason Sudeikis — see their relationship timeline. Thought: I need to find out Harry Styles' age. Action: Search Action Input: \"Harry Styles age\" Observation: 29 years Thought: I need to calculate 29 raised to the 0.23 power. Action: Calculator Action Input: 29^0.23 Observation: Answer: 2.169459462491557  Thought: I now know the final answer. Final Answer: Harry Styles, Olivia Wilde's boyfriend, is 29 years old and his age raised to the 0.23 power is 2.169459462491557.  > Finished chain.`\n\n![](https://aman.ai/images/copy.png)\n\n`> Entering new AgentExecutor chain...  I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power. Action: Search Action Input: \"Olivia Wilde boyfriend\" Observation: Olivia Wilde started dating Harry Styles after ending her years-long engagement to Jason Sudeikis — see their relationship timeline. Thought: I need to find out Harry Styles' age. Action: Search Action Input: \"Harry Styles age\" Observation: 29 years Thought: I need to calculate 29 raised to the 0.23 power. Action: Calculator Action Input: 29^0.23 Observation: Answer: 2.169459462491557  Thought: I now know the final answer. Final Answer: Harry Styles, Olivia Wilde's boyfriend, is 29 years old and his age raised to the 0.23 power is 2.169459462491557.  > Finished chain.`\n\n*   The output we get is as follows:\n\n![](https://aman.ai/images/copy.png)\n\n`\"Harry Styles, Olivia Wilde's boyfriend, is 29 years old and his age raised to the 0.23 power is 2.169459462491557.\"`\n\n![](https://aman.ai/images/copy.png)\n\n`\"Harry Styles, Olivia Wilde's boyfriend, is 29 years old and his age raised to the 0.23 power is 2.169459462491557.\"`\n\n*   We adapted the example from the [LangChain documentation](https://python.langchain.com/docs/modules/agents/agent_types/react), so credit goes to them. We encourage the learner to explore different combination of tools and tasks.",
    "order": 9,
    "orderInChapter": 5,
    "difficulty": 3,
    "estimatedMinutes": 4,
    "tags": [
      "algorithmsarchitecture",
      "llm"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 720,
      "contentLength": 17394
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/prompt-engineering/#react-usage-with-langchain",
    "scrapedAt": "2025-12-28T11:46:09.796Z"
  },
  {
    "id": "ai-prompt-engineering-the-needle-in-a-haystack-test-10",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Prompt Engineering",
    "articleSlug": "prompt-engineering",
    "chapter": "Retrieval Augmented Generation (RAG)",
    "title": "The “Needle in a Haystack” Test",
    "subtitle": "Retrieval Augmented Generation (RAG)",
    "contentHtml": "<ul>\n  <li>To understand the in-context retrieval ability of long-context LLMs over various parts of their prompt, a simple ‘needle in a haystack’ analysis could be conducted. This method involves embedding specific, targeted information (the ‘needle’) within a larger, more complex body of text (the ‘haystack’). The purpose is to test the LLM’s ability to identify and utilize this specific piece of information amidst a deluge of other data.</li>\n  <li>In practical terms, the analysis could involve inserting a unique fact or data point into a lengthy, seemingly unrelated text. The LLM would then be tasked with tasks or queries that require it to recall or apply this embedded information. This setup mimics real-world situations where essential details are often buried within extensive content, and the ability to retrieve such details is crucial.</li>\n  <li>The experiment could be structured to assess various aspects of the LLM’s performance. For instance, the placement of the ‘needle’ could be varied—early, middle, or late in the text—to see if the model’s retrieval ability changes based on information location. Additionally, the complexity of the surrounding ‘haystack’ can be modified to test the LLM’s performance under varying degrees of contextual difficulty. By analyzing how well the LLM performs in these scenarios, insights can be gained into its in-context retrieval capabilities and potential areas for improvement.</li>\n  <li>This can be accomplished using the <a href=\"https://github.com/gkamradt/LLMTest_NeedleInAHaystack\">Needle In A Haystack</a> library. The following plot shows OpenAI’s GPT-4-128K’s (top) and (bottom) performance with varying context length.</li>\n</ul>\n<p><img src=\"../../../primers/ai/assets/RAG/GPT4_haystack.jpg\" alt=\"\"></p>\n<p><img src=\"../../../primers/ai/assets/RAG/Claude_haystack.jpg\" alt=\"\"></p>\n<ul>\n  <li>However, in their <a href=\"https://www.anthropic.com/index/claude-2-1-prompting\">Long context prompting for Claude 2.1</a> blog, Anthropic noted that adding “Here is the most relevant sentence in the context:” to the start of Claude’s response raised the score from 27% to 98% on the original evaluation!</li>\n  <li>The figure below from the blog shows that Claude 2.1’s performance when retrieving an individual sentence across its full 200K token context window. This experiment uses a prompt technique to guide Claude in recalling the most relevant sentence.</li>\n</ul>\n<p><img src=\"../../../primers/ai/assets/RAG/Claude_haystack1.jpg\" alt=\"\"></p>",
    "contentMarkdown": "*   To understand the in-context retrieval ability of long-context LLMs over various parts of their prompt, a simple ‘needle in a haystack’ analysis could be conducted. This method involves embedding specific, targeted information (the ‘needle’) within a larger, more complex body of text (the ‘haystack’). The purpose is to test the LLM’s ability to identify and utilize this specific piece of information amidst a deluge of other data.\n*   In practical terms, the analysis could involve inserting a unique fact or data point into a lengthy, seemingly unrelated text. The LLM would then be tasked with tasks or queries that require it to recall or apply this embedded information. This setup mimics real-world situations where essential details are often buried within extensive content, and the ability to retrieve such details is crucial.\n*   The experiment could be structured to assess various aspects of the LLM’s performance. For instance, the placement of the ‘needle’ could be varied—early, middle, or late in the text—to see if the model’s retrieval ability changes based on information location. Additionally, the complexity of the surrounding ‘haystack’ can be modified to test the LLM’s performance under varying degrees of contextual difficulty. By analyzing how well the LLM performs in these scenarios, insights can be gained into its in-context retrieval capabilities and potential areas for improvement.\n*   This can be accomplished using the [Needle In A Haystack](https://github.com/gkamradt/LLMTest_NeedleInAHaystack) library. The following plot shows OpenAI’s GPT-4-128K’s (top) and (bottom) performance with varying context length.\n\n![](../../../primers/ai/assets/RAG/GPT4_haystack.jpg)\n\n![](../../../primers/ai/assets/RAG/Claude_haystack.jpg)\n\n*   However, in their [Long context prompting for Claude 2.1](https://www.anthropic.com/index/claude-2-1-prompting) blog, Anthropic noted that adding “Here is the most relevant sentence in the context:” to the start of Claude’s response raised the score from 27% to 98% on the original evaluation!\n*   The figure below from the blog shows that Claude 2.1’s performance when retrieving an individual sentence across its full 200K token context window. This experiment uses a prompt technique to guide Claude in recalling the most relevant sentence.\n\n![](../../../primers/ai/assets/RAG/Claude_haystack1.jpg)",
    "order": 10,
    "orderInChapter": 1,
    "difficulty": 2,
    "estimatedMinutes": 2,
    "tags": [
      "algorithmsarchitecture",
      "embedding",
      "gpt",
      "llm"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 327,
      "contentLength": 2518
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/prompt-engineering/#the-“needle-in-a-haystack”-test",
    "scrapedAt": "2025-12-28T11:46:09.796Z"
  },
  {
    "id": "ai-prompt-engineering-anthropics-prompt-generator-11",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Prompt Engineering",
    "articleSlug": "prompt-engineering",
    "chapter": "Resources",
    "title": "Anthropic’s Prompt Generator",
    "subtitle": "Resources",
    "contentHtml": "<ul>\n  <li>Anthropic’s <a href=\"https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator\">Prompt Generator</a> automatically generates high-quality first draft prompt templates tailored to your specific tasks, following prompt engineering best practices.</li>\n  <li>The prompt generator is particularly useful as a tool for solving the “blank page problem” to give you a jumping-off point for further testing and iteration.</li>\n</ul>",
    "contentMarkdown": "*   Anthropic’s [Prompt Generator](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator) automatically generates high-quality first draft prompt templates tailored to your specific tasks, following prompt engineering best practices.\n*   The prompt generator is particularly useful as a tool for solving the “blank page problem” to give you a jumping-off point for further testing and iteration.",
    "order": 11,
    "orderInChapter": 1,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "algorithmsarchitecture"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 48,
      "contentLength": 466
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/prompt-engineering/#anthropic’s-prompt-generator",
    "scrapedAt": "2025-12-28T11:46:09.796Z"
  }
]