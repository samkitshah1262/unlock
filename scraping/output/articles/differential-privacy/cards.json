[
  {
    "id": "ai-differential-privacy-components-1",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Privacy Budget and Definition",
    "title": "Components",
    "subtitle": "Privacy Budget and Definition",
    "contentHtml": "<ul>\n  <li><strong><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-7-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-56\" style=\"width: 0.571em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.467em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.552em, 1000.47em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-57\"><span class=\"mi\" id=\"MathJax-Span-58\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-7\">\\varepsilon</script> (epsilon)</strong>: The <em>privacy loss parameter</em>. Smaller values imply stronger privacy. A typical range is <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-8-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi><mo>&amp;#x2208;</mo><mo stretchy=&quot;false&quot;>[</mo><mn>0.01</mn><mo>,</mo><mn>10</mn><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-59\" style=\"width: 6.669em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1005.42em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-60\"><span class=\"mi\" id=\"MathJax-Span-61\" style=\"font-family: STIXGeneral-Italic;\">ε</span><span class=\"mo\" id=\"MathJax-Span-62\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"mo\" id=\"MathJax-Span-63\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">[</span><span class=\"mn\" id=\"MathJax-Span-64\" style=\"font-family: STIXGeneral-Regular;\">0.01</span><span class=\"mo\" id=\"MathJax-Span-65\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mn\" id=\"MathJax-Span-66\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">10</span><span class=\"mo\" id=\"MathJax-Span-67\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>0.01</mn><mo>,</mo><mn>10</mn><mo stretchy=\"false\">]</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-8\">\\varepsilon \\in [0.01, 10]</script>.</li>\n  <li><strong><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B4;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-68\" style=\"width: 0.726em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.571em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.57em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-69\"><span class=\"mi\" id=\"MathJax-Span-70\" style=\"font-family: STIXGeneral-Italic;\">δ</span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>δ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-9\">\\delta</script></strong>: The probability that the differential privacy guarantee fails. Typically chosen to be smaller than <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mfrac><mn>1</mn><mi>n</mi></mfrac></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-71\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1000.68em, 2.659em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-72\"><span class=\"mfrac\" id=\"MathJax-Span-73\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.424em; left: 50%; margin-left: -0.154em;\"><span class=\"mn\" id=\"MathJax-Span-74\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.544em, 1000.32em, 4.169em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.154em;\"><span class=\"mi\" id=\"MathJax-Span-75\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.47em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.471em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.497em; border-left: 0px solid; width: 0px; height: 1.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mfrac><mn>1</mn><mi>n</mi></mfrac></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-10\">\\frac{1}{n}</script>, where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-76\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-77\"><span class=\"mi\" id=\"MathJax-Span-78\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-11\">n</script> is the dataset size.</li>\n  <li><strong>Adjacent datasets</strong>: Two datasets are adjacent if they differ in exactly one individual’s data.</li>\n  <li><strong>Randomized algorithm <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>M</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-79\" style=\"width: 1.139em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.932em; height: 0px; font-size: 121%;\"><span style=\"position: absolute; clip: rect(1.346em, 1000.93em, 2.327em, -999.997em); top: -2.167em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-80\"><span class=\"mi\" id=\"MathJax-Span-81\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.054em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.172em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>M</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">M</script></strong>: The core of DP is randomness—achieved by injecting carefully calibrated noise (e.g., Laplace or Gaussian)—so that individual records cannot be inferred from outputs.</li>\n</ul>",
    "contentMarkdown": "*   **εε\\\\varepsilon (epsilon)**: The _privacy loss parameter_. Smaller values imply stronger privacy. A typical range is ε∈\\[0.01,10\\]ε∈\\[0.01,10\\]\\\\varepsilon \\\\in \\[0.01, 10\\].\n*   **δδ\\\\delta**: The probability that the differential privacy guarantee fails. Typically chosen to be smaller than 1n1n\\\\frac{1}{n}, where nnn is the dataset size.\n*   **Adjacent datasets**: Two datasets are adjacent if they differ in exactly one individual’s data.\n*   **Randomized algorithm MMM**: The core of DP is randomness—achieved by injecting carefully calibrated noise (e.g., Laplace or Gaussian)—so that individual records cannot be inferred from outputs.",
    "order": 1,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 85,
      "contentLength": 9823
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#components",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-intuition-2",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Privacy Budget and Definition",
    "title": "Intuition",
    "subtitle": "Privacy Budget and Definition",
    "contentHtml": "<ul>\n  <li>This definition ensures that the <strong>presence or absence of a single user’s data</strong> does not significantly influence the output distribution of the algorithm. Even a powerful adversary cannot confidently determine if a specific user contributed data, based on the output alone.</li>\n</ul>",
    "contentMarkdown": "*   This definition ensures that the **presence or absence of a single user’s data** does not significantly influence the output distribution of the algorithm. Even a powerful adversary cannot confidently determine if a specific user contributed data, based on the output alone.",
    "order": 2,
    "orderInChapter": 2,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 42,
      "contentLength": 309
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#intuition",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-tightness-3",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Privacy Budget and Definition",
    "title": "Tightness",
    "subtitle": "Privacy Budget and Definition",
    "contentHtml": "<ul>\n  <li>If <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B4;</mi><mo>=</mo><mn>0</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-82\" style=\"width: 2.711em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.242em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.24em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-83\"><span class=\"mi\" id=\"MathJax-Span-84\" style=\"font-family: STIXGeneral-Italic;\">δ</span><span class=\"mo\" id=\"MathJax-Span-85\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-86\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">0</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>δ</mi><mo>=</mo><mn>0</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">\\delta = 0</script>, we get <strong>pure differential privacy</strong>.</li>\n  <li>If <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-14-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B4;</mi><mo>&amp;gt;</mo><mn>0</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-87\" style=\"width: 2.711em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.242em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.24em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-88\"><span class=\"mi\" id=\"MathJax-Span-89\" style=\"font-family: STIXGeneral-Italic;\">δ</span><span class=\"mo\" id=\"MathJax-Span-90\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">&gt;</span><span class=\"mn\" id=\"MathJax-Span-91\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">0</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>δ</mi><mo>&gt;</mo><mn>0</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-14\">\\delta > 0</script>, the guarantee becomes <strong>approximate differential privacy</strong>, which is more practical for complex models like deep neural networks.</li>\n</ul>",
    "contentMarkdown": "*   If δ\\=0δ\\=0\\\\delta = 0, we get **pure differential privacy**.\n*   If δ\\>0δ\\>0\\\\delta > 0, the guarantee becomes **approximate differential privacy**, which is more practical for complex models like deep neural networks.",
    "order": 3,
    "orderInChapter": 3,
    "difficulty": 3,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai",
      "neural network"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 32,
      "contentLength": 3165
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#tightness",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-privacy-budget-in-practice-4",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Privacy Budget and Definition",
    "title": "Privacy Budget in Practice",
    "subtitle": "Privacy Budget and Definition",
    "contentHtml": "<ul>\n  <li>A typical differential privacy system tracks a user’s <strong>privacy budget</strong>—a measure of how much information about them has been exposed.</li>\n  <li>The budget is often enforced by setting limits on the number of contributions per user and how much noise is injected.</li>\n</ul>",
    "contentMarkdown": "*   A typical differential privacy system tracks a user’s **privacy budget**—a measure of how much information about them has been exposed.\n*   The budget is often enforced by setting limits on the number of contributions per user and how much noise is injected.",
    "order": 4,
    "orderInChapter": 4,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 43,
      "contentLength": 300
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#privacy-budget-in-practice",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-real-world-example-apple-dp-5",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Privacy Budget and Definition",
    "title": "Real-World Example: Apple DP",
    "subtitle": "Privacy Budget and Definition",
    "contentHtml": "<ul>\n  <li>\n    <p>From <a href=\"https://www.apple.com/privacy/docs/Differential_Privacy_Overview.pdf\">Apple’s Differential Privacy Technical Overview</a>, Apple uses carefully bounded <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-15-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-92\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-93\"><span class=\"mi\" id=\"MathJax-Span-94\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-15\">\\varepsilon</script> values and per-day contribution limits to collect aggregate insights without compromising user privacy. Examples include:</p>\n\n    <ul>\n      <li><strong>Emoji suggestions</strong>: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-16-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi><mo>=</mo><mn>4</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-95\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.09em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-96\"><span class=\"mi\" id=\"MathJax-Span-97\" style=\"font-family: STIXGeneral-Italic;\">ε</span><span class=\"mo\" id=\"MathJax-Span-98\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-99\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">4</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi><mo>=</mo><mn>4</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-16\">\\varepsilon = 4</script>, one contribution per day.</li>\n      <li><strong>QuickType</strong>: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi><mo>=</mo><mn>8</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-100\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.09em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-101\"><span class=\"mi\" id=\"MathJax-Span-102\" style=\"font-family: STIXGeneral-Italic;\">ε</span><span class=\"mo\" id=\"MathJax-Span-103\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-104\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">8</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi><mo>=</mo><mn>8</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-17\">\\varepsilon = 8</script>, two donations per day.</li>\n      <li><strong>Safari Auto-play intent detection</strong>: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi><mo>=</mo><mn>8</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-105\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.09em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-106\"><span class=\"mi\" id=\"MathJax-Span-107\" style=\"font-family: STIXGeneral-Italic;\">ε</span><span class=\"mo\" id=\"MathJax-Span-108\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-109\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">8</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi><mo>=</mo><mn>8</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-18\">\\varepsilon = 8</script>, two donations per day.</li>\n      <li><strong>Health Type Usage</strong>: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi><mo>=</mo><mn>2</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-110\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.14em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-111\"><span class=\"mi\" id=\"MathJax-Span-112\" style=\"font-family: STIXGeneral-Italic;\">ε</span><span class=\"mo\" id=\"MathJax-Span-113\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-114\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi><mo>=</mo><mn>2</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-19\">\\varepsilon = 2</script>, one donation per day (only metadata, not raw health info).</li>\n    </ul>\n  </li>\n  <li>\n    <p>These limits and budgets are designed to keep user-specific data unidentifiable—even internally.</p>\n  </li>\n</ul>\n<p>From <a href=\"https://www.apple.com/privacy/docs/Differential_Privacy_Overview.pdf\">Apple’s Differential Privacy Technical Overview</a>, Apple uses carefully bounded <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-15-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-92\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-93\"><span class=\"mi\" id=\"MathJax-Span-94\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-15\">\\varepsilon</script> values and per-day contribution limits to collect aggregate insights without compromising user privacy. Examples include:</p>\n<ul>\n      <li><strong>Emoji suggestions</strong>: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-16-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi><mo>=</mo><mn>4</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-95\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.09em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-96\"><span class=\"mi\" id=\"MathJax-Span-97\" style=\"font-family: STIXGeneral-Italic;\">ε</span><span class=\"mo\" id=\"MathJax-Span-98\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-99\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">4</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi><mo>=</mo><mn>4</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-16\">\\varepsilon = 4</script>, one contribution per day.</li>\n      <li><strong>QuickType</strong>: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi><mo>=</mo><mn>8</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-100\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.09em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-101\"><span class=\"mi\" id=\"MathJax-Span-102\" style=\"font-family: STIXGeneral-Italic;\">ε</span><span class=\"mo\" id=\"MathJax-Span-103\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-104\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">8</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi><mo>=</mo><mn>8</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-17\">\\varepsilon = 8</script>, two donations per day.</li>\n      <li><strong>Safari Auto-play intent detection</strong>: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi><mo>=</mo><mn>8</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-105\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.09em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-106\"><span class=\"mi\" id=\"MathJax-Span-107\" style=\"font-family: STIXGeneral-Italic;\">ε</span><span class=\"mo\" id=\"MathJax-Span-108\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-109\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">8</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi><mo>=</mo><mn>8</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-18\">\\varepsilon = 8</script>, two donations per day.</li>\n      <li><strong>Health Type Usage</strong>: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi><mo>=</mo><mn>2</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-110\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.14em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-111\"><span class=\"mi\" id=\"MathJax-Span-112\" style=\"font-family: STIXGeneral-Italic;\">ε</span><span class=\"mo\" id=\"MathJax-Span-113\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-114\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi><mo>=</mo><mn>2</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-19\">\\varepsilon = 2</script>, one donation per day (only metadata, not raw health info).</li>\n    </ul>\n<p>These limits and budgets are designed to keep user-specific data unidentifiable—even internally.</p>",
    "contentMarkdown": "*   From [Apple’s Differential Privacy Technical Overview](https://www.apple.com/privacy/docs/Differential_Privacy_Overview.pdf), Apple uses carefully bounded εε\\\\varepsilon values and per-day contribution limits to collect aggregate insights without compromising user privacy. Examples include:\n    \n    *   **Emoji suggestions**: ε\\=4ε\\=4\\\\varepsilon = 4, one contribution per day.\n    *   **QuickType**: ε\\=8ε\\=8\\\\varepsilon = 8, two donations per day.\n    *   **Safari Auto-play intent detection**: ε\\=8ε\\=8\\\\varepsilon = 8, two donations per day.\n    *   **Health Type Usage**: ε\\=2ε\\=2\\\\varepsilon = 2, one donation per day (only metadata, not raw health info).\n*   These limits and budgets are designed to keep user-specific data unidentifiable—even internally.\n    \n\nFrom [Apple’s Differential Privacy Technical Overview](https://www.apple.com/privacy/docs/Differential_Privacy_Overview.pdf), Apple uses carefully bounded εε\\\\varepsilon values and per-day contribution limits to collect aggregate insights without compromising user privacy. Examples include:\n\n*   **Emoji suggestions**: ε\\=4ε\\=4\\\\varepsilon = 4, one contribution per day.\n*   **QuickType**: ε\\=8ε\\=8\\\\varepsilon = 8, two donations per day.\n*   **Safari Auto-play intent detection**: ε\\=8ε\\=8\\\\varepsilon = 8, two donations per day.\n*   **Health Type Usage**: ε\\=2ε\\=2\\\\varepsilon = 2, one donation per day (only metadata, not raw health info).\n\nThese limits and budgets are designed to keep user-specific data unidentifiable—even internally.",
    "order": 5,
    "orderInChapter": 5,
    "difficulty": 3,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 174,
      "contentLength": 15713
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#real-world-example:-apple-dp",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-example-visualization-apple-dp-emoji-analysis-6",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Privacy Budget and Definition",
    "title": "Example Visualization (Apple DP Emoji Analysis)",
    "subtitle": "Privacy Budget and Definition",
    "contentHtml": "<ul>\n  <li>Apple uses techniques like Count Mean Sketch to estimate popular emoji in a privacy-preserving way. Here’s an example histogram shared in their technical whitepaper:</li>\n</ul>\n<p><img src=\"/primers/ai/assets/differential-privacy/emoji.jpg\" alt=\"\"></p>\n<ul>\n  <li>This visual illustrates how even noisy, privacy-preserving data collection can yield useful aggregate insights.</li>\n</ul>",
    "contentMarkdown": "*   Apple uses techniques like Count Mean Sketch to estimate popular emoji in a privacy-preserving way. Here’s an example histogram shared in their technical whitepaper:\n\n![](/primers/ai/assets/differential-privacy/emoji.jpg)\n\n*   This visual illustrates how even noisy, privacy-preserving data collection can yield useful aggregate insights.",
    "order": 6,
    "orderInChapter": 6,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 41,
      "contentLength": 397
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#example-visualization-(apple-dp-emoji-analysis)",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-count-mean-sketch-cms-7",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Techniques",
    "title": "Count Mean Sketch (CMS)",
    "subtitle": "Techniques",
    "contentHtml": "<ul>\n  <li>This technique creates a <strong>sketch matrix</strong> to represent user inputs compactly.</li>\n  <li>Data is <strong>hashed</strong> using functions like SHA-256 to discretize inputs into vectors.</li>\n  <li>Each coordinate of the hashed vector is then <strong>flipped with probability</strong>:</li>\n</ul>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-20-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>&amp;#x03B5;</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>/</mo></mrow><mn>2</mn></mrow></msup></mrow></mfrac></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-115\" style=\"width: 4.169em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.44em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(0.628em, 1003.44em, 3.076em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-116\"><span class=\"mfrac\" id=\"MathJax-Span-117\"><span style=\"display: inline-block; position: relative; width: 3.232em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;\"><span class=\"mn\" id=\"MathJax-Span-118\" style=\"font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.076em, 1003.08em, 4.221em, -999.997em); top: -3.279em; left: 50%; margin-left: -1.56em;\"><span class=\"mrow\" id=\"MathJax-Span-119\"><span class=\"mn\" id=\"MathJax-Span-120\" style=\"font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-121\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"msubsup\" id=\"MathJax-Span-122\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-123\" style=\"font-family: STIXGeneral-Italic;\">e</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.32em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-124\"><span class=\"mrow\" id=\"MathJax-Span-125\"><span class=\"mi\" id=\"MathJax-Span-126\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">ε</span><span class=\"texatom\" id=\"MathJax-Span-127\"><span class=\"mrow\" id=\"MathJax-Span-128\"><span class=\"mo\" id=\"MathJax-Span-129\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">/</span></span></span><span class=\"mn\" id=\"MathJax-Span-130\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1003.23em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 3.232em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.997em; border-left: 0px solid; width: 0px; height: 2.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>ε</mi><mrow class=\"MJX-TeXAtom-ORD\"><mo>/</mo></mrow><mn>2</mn></mrow></msup></mrow></mfrac></math></span></span></div>\n<ul>\n  <li>This flipping introduces <strong>uncertainty</strong>, so the server cannot tell whether any specific bit was the result of a user’s actual data or the added noise.</li>\n</ul>\n<h4 id=\"workflow\">Workflow</h4>\n<ul>\n  <li>\n    <p>The workflow for CMS is as follows:</p>\n\n    <ol>\n      <li>User input is hashed and mapped into a vector space.</li>\n      <li>The vector is privatized using random flips.</li>\n      <li>Only <strong>one random row</strong> of the sketch matrix is transmitted to the server to further reduce information leakage.</li>\n      <li>The server <strong>aggregates</strong> noisy vectors from many users and <strong>averages them</strong>, estimating population-level statistics (e.g., the most common emojis or words).</li>\n    </ol>\n  </li>\n  <li>\n    <p>This setup provides good privacy with moderate utility, especially over large user populations.</p>\n  </li>\n</ul>\n<p>The workflow for CMS is as follows:</p>\n<ol>\n      <li>User input is hashed and mapped into a vector space.</li>\n      <li>The vector is privatized using random flips.</li>\n      <li>Only <strong>one random row</strong> of the sketch matrix is transmitted to the server to further reduce information leakage.</li>\n      <li>The server <strong>aggregates</strong> noisy vectors from many users and <strong>averages them</strong>, estimating population-level statistics (e.g., the most common emojis or words).</li>\n    </ol>\n<p>This setup provides good privacy with moderate utility, especially over large user populations.</p>",
    "contentMarkdown": "*   This technique creates a **sketch matrix** to represent user inputs compactly.\n*   Data is **hashed** using functions like SHA-256 to discretize inputs into vectors.\n*   Each coordinate of the hashed vector is then **flipped with probability**:\n\n11+eε/211+eε/2\n\n*   This flipping introduces **uncertainty**, so the server cannot tell whether any specific bit was the result of a user’s actual data or the added noise.\n\n#### Workflow\n\n*   The workflow for CMS is as follows:\n    \n    1.  User input is hashed and mapped into a vector space.\n    2.  The vector is privatized using random flips.\n    3.  Only **one random row** of the sketch matrix is transmitted to the server to further reduce information leakage.\n    4.  The server **aggregates** noisy vectors from many users and **averages them**, estimating population-level statistics (e.g., the most common emojis or words).\n*   This setup provides good privacy with moderate utility, especially over large user populations.\n    \n\nThe workflow for CMS is as follows:\n\n1.  User input is hashed and mapped into a vector space.\n2.  The vector is privatized using random flips.\n3.  Only **one random row** of the sketch matrix is transmitted to the server to further reduce information leakage.\n4.  The server **aggregates** noisy vectors from many users and **averages them**, estimating population-level statistics (e.g., the most common emojis or words).\n\nThis setup provides good privacy with moderate utility, especially over large user populations.",
    "order": 7,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 2,
    "tags": [
      "ondevice ai"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 228,
      "contentLength": 5744
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#count-mean-sketch-(cms)",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-hadamard-count-mean-sketch-hcms-8",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Techniques",
    "title": "Hadamard Count Mean Sketch (HCMS)",
    "subtitle": "Techniques",
    "contentHtml": "<ul>\n  <li>A refinement over CMS, the HCMS adds a <strong>Hadamard basis transformation</strong> to the vector before privatization.</li>\n  <li>\n    <p>After this transformation:</p>\n\n    <ul>\n      <li>Only <strong>a single bit</strong> is sampled and transmitted to the server per query.</li>\n      <li>This reduces communication cost to <strong>just 1 bit per user per record</strong>, at the cost of slightly reduced accuracy.</li>\n    </ul>\n  </li>\n</ul>\n<p>After this transformation:</p>\n<ul>\n      <li>Only <strong>a single bit</strong> is sampled and transmitted to the server per query.</li>\n      <li>This reduces communication cost to <strong>just 1 bit per user per record</strong>, at the cost of slightly reduced accuracy.</li>\n    </ul>\n<h4 id=\"advantages\">Advantages</h4>\n<ul>\n  <li>More efficient in bandwidth-constrained settings (e.g., mobile devices).</li>\n  <li>\n    <p>Useful for <strong>telemetry collection at scale</strong>, where millions of users contribute daily.</p>\n  </li>\n  <li>Both techniques are used to power <strong>Apple’s differential privacy systems</strong>, as seen in their emoji, QuickType, and Safari data collection pipelines.</li>\n</ul>\n<p>Useful for <strong>telemetry collection at scale</strong>, where millions of users contribute daily.</p>",
    "contentMarkdown": "*   A refinement over CMS, the HCMS adds a **Hadamard basis transformation** to the vector before privatization.\n*   After this transformation:\n    \n    *   Only **a single bit** is sampled and transmitted to the server per query.\n    *   This reduces communication cost to **just 1 bit per user per record**, at the cost of slightly reduced accuracy.\n\nAfter this transformation:\n\n*   Only **a single bit** is sampled and transmitted to the server per query.\n*   This reduces communication cost to **just 1 bit per user per record**, at the cost of slightly reduced accuracy.\n\n#### Advantages\n\n*   More efficient in bandwidth-constrained settings (e.g., mobile devices).\n*   Useful for **telemetry collection at scale**, where millions of users contribute daily.\n    \n*   Both techniques are used to power **Apple’s differential privacy systems**, as seen in their emoji, QuickType, and Safari data collection pipelines.\n\nUseful for **telemetry collection at scale**, where millions of users contribute daily.",
    "order": 8,
    "orderInChapter": 2,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 150,
      "contentLength": 1290
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#hadamard-count-mean-sketch-(hcms)",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-dpsgd-core-idea-9",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "DP‑SGD and Implementation",
    "title": "DP‑SGD: Core Idea",
    "subtitle": "DP‑SGD and Implementation",
    "contentHtml": "<ul>\n  <li>The standard stochastic gradient descent (SGD) algorithm is modified to ensure that updates do not leak private information. This is done by controlling the sensitivity of each training step via two key operations:</li>\n</ul>\n<ol>\n  <li>\n    <p><strong>Gradient Clipping</strong>:</p>\n\n    <ul>\n      <li>For each training example, compute the per-sample gradient.</li>\n      <li>\n        <p>Clip the gradient to a fixed maximum norm <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-131\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-132\"><span class=\"mi\" id=\"MathJax-Span-133\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">C</script>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>g</mi><mi>i</mi></msub><mo stretchy=&quot;false&quot;>&amp;#x2190;</mo><msub><mi>g</mi><mi>i</mi></msub><mo>&amp;#x22C5;</mo><mo movablelimits=&quot;true&quot; form=&quot;prefix&quot;>min</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>,</mo><mfrac><mi>C</mi><mrow><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>&amp;#x2016;</mo><msub><mi>g</mi><mi>i</mi></msub><msub><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>&amp;#x2016;</mo><mn>2</mn></msub></mrow></mfrac></mrow><mo>)</mo></mrow></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-134\" style=\"width: 12.971em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(2.294em, 1010.63em, 4.846em, -999.997em); top: -3.799em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-135\"><span class=\"msubsup\" id=\"MathJax-Span-136\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-137\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-138\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-139\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">←</span><span class=\"msubsup\" id=\"MathJax-Span-140\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-141\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-142\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-143\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mo\" id=\"MathJax-Span-144\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">min</span><span class=\"mrow\" id=\"MathJax-Span-145\" style=\"padding-left: 0.211em;\"><span class=\"mo\" id=\"MathJax-Span-146\" style=\"vertical-align: -0.466em;\"><span><span style=\"font-size: 111%; font-family: STIXSizeTwoSym;\">(</span></span></span><span class=\"mrow\" id=\"MathJax-Span-147\"><span class=\"mn\" id=\"MathJax-Span-148\" style=\"font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-149\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mfrac\" id=\"MathJax-Span-150\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.362em;\"><span class=\"mi\" id=\"MathJax-Span-151\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.18em, 1002.24em, 4.378em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.143em;\"><span class=\"mrow\" id=\"MathJax-Span-152\"><span class=\"mo\" id=\"MathJax-Span-153\" style=\"font-family: STIXGeneral-Regular;\">‖</span><span class=\"msubsup\" id=\"MathJax-Span-154\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-155\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-156\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-157\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-158\" style=\"font-family: STIXGeneral-Regular;\">‖</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-159\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1002.35em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.346em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-160\" style=\"vertical-align: -0.466em;\"><span><span style=\"font-size: 111%; font-family: STIXSizeTwoSym;\">)</span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 3.805em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -1.122em; border-left: 0px solid; width: 0px; height: 2.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>g</mi><mi>i</mi></msub><mo stretchy=\"false\">←</mo><msub><mi>g</mi><mi>i</mi></msub><mo>⋅</mo><mo movablelimits=\"true\" form=\"prefix\">min</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>,</mo><mfrac><mi>C</mi><mrow><mo fence=\"false\" stretchy=\"false\">‖</mo><msub><mi>g</mi><mi>i</mi></msub><msub><mo fence=\"false\" stretchy=\"false\">‖</mo><mn>2</mn></msub></mrow></mfrac></mrow><mo>)</mo></mrow></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-22\">g_i \\leftarrow g_i \\cdot \\min\\left(1, \\frac{C}{\\|g_i\\|_2}\\right)</script>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Noise Addition</strong>:</p>\n\n    <ul>\n      <li>\n        <p>After averaging the clipped gradients, add Gaussian noise:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mover><mi>g</mi><mo stretchy=&quot;false&quot;>&amp;#x00AF;</mo></mover></mrow><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munder><mo>&amp;#x2211;</mo><mi>i</mi></munder><msub><mi>g</mi><mi>i</mi></msub><mo>+</mo><mi>N</mi><mo stretchy=&quot;false&quot;>(</mo><mn>0</mn><mo>,</mo><msup><mi>&amp;#x03C3;</mi><mn>2</mn></msup><msup><mi>C</mi><mn>2</mn></msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>I</mi></mrow><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-161\" style=\"width: 13.44em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 11.201em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(0.992em, 1011.15em, 3.909em, -999.997em); top: -2.497em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-162\"><span class=\"texatom\" id=\"MathJax-Span-163\"><span class=\"mrow\" id=\"MathJax-Span-164\"><span class=\"munderover\" id=\"MathJax-Span-165\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-166\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.232em, 1000.32em, 3.596em, -999.997em); top: -4.008em; left: 0.107em;\"><span class=\"mo\" id=\"MathJax-Span-167\" style=\"font-family: STIXGeneral-Regular;\">¯</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-168\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mfrac\" id=\"MathJax-Span-169\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;\"><span class=\"mn\" id=\"MathJax-Span-170\" style=\"font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.258em;\"><span class=\"mi\" id=\"MathJax-Span-171\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.63em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.628em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span class=\"munderover\" id=\"MathJax-Span-172\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(2.867em, 1001.2em, 4.638em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-173\" style=\"font-family: STIXSizeOneSym; vertical-align: -0.518em;\">∑</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.21em, 4.273em, -999.997em); top: -2.862em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-174\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-175\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-176\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-177\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-178\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-179\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">N<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-180\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mn\" id=\"MathJax-Span-181\" style=\"font-family: STIXGeneral-Regular;\">0</span><span class=\"mo\" id=\"MathJax-Span-182\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-183\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-184\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-185\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-186\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-187\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"mn\" id=\"MathJax-Span-188\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"texatom\" id=\"MathJax-Span-189\"><span class=\"mrow\" id=\"MathJax-Span-190\"><span class=\"mi\" id=\"MathJax-Span-191\" style=\"font-family: STIXGeneral; font-weight: bold;\">I</span></span></span><span class=\"mo\" id=\"MathJax-Span-192\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.503em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -1.559em; border-left: 0px solid; width: 0px; height: 3.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mrow class=\"MJX-TeXAtom-ORD\"><mover><mi>g</mi><mo stretchy=\"false\">¯</mo></mover></mrow><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>g</mi><mi>i</mi></msub><mo>+</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo>,</mo><msup><mi>σ</mi><mn>2</mn></msup><msup><mi>C</mi><mn>2</mn></msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"bold\">I</mi></mrow><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-23\">\\bar{g} = \\frac{1}{n} \\sum_i g_i + N(0, \\sigma^2 C^2 \\mathbf{I})</script>\n      </li>\n      <li>\n        <p>Here, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03C3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-193\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-194\"><span class=\"mi\" id=\"MathJax-Span-195\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>σ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">\\sigma</script> is the <strong>noise multiplier</strong> that controls the privacy-utility trade-off.</p>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Privacy Tracking</strong>:</p>\n\n    <ul>\n      <li>A <strong>privacy accountant</strong> (such as Rényi or Moments Accountant) keeps track of the cumulative privacy loss <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-196\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-197\"><span class=\"mi\" id=\"MathJax-Span-198\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">\\varepsilon</script> throughout training.</li>\n    </ul>\n  </li>\n</ol>\n<p><strong>Gradient Clipping</strong>:</p>\n<ul>\n      <li>For each training example, compute the per-sample gradient.</li>\n      <li>\n        <p>Clip the gradient to a fixed maximum norm <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-131\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-132\"><span class=\"mi\" id=\"MathJax-Span-133\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">C</script>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>g</mi><mi>i</mi></msub><mo stretchy=&quot;false&quot;>&amp;#x2190;</mo><msub><mi>g</mi><mi>i</mi></msub><mo>&amp;#x22C5;</mo><mo movablelimits=&quot;true&quot; form=&quot;prefix&quot;>min</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>,</mo><mfrac><mi>C</mi><mrow><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>&amp;#x2016;</mo><msub><mi>g</mi><mi>i</mi></msub><msub><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>&amp;#x2016;</mo><mn>2</mn></msub></mrow></mfrac></mrow><mo>)</mo></mrow></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-134\" style=\"width: 12.971em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(2.294em, 1010.63em, 4.846em, -999.997em); top: -3.799em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-135\"><span class=\"msubsup\" id=\"MathJax-Span-136\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-137\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-138\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-139\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">←</span><span class=\"msubsup\" id=\"MathJax-Span-140\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-141\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-142\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-143\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mo\" id=\"MathJax-Span-144\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">min</span><span class=\"mrow\" id=\"MathJax-Span-145\" style=\"padding-left: 0.211em;\"><span class=\"mo\" id=\"MathJax-Span-146\" style=\"vertical-align: -0.466em;\"><span><span style=\"font-size: 111%; font-family: STIXSizeTwoSym;\">(</span></span></span><span class=\"mrow\" id=\"MathJax-Span-147\"><span class=\"mn\" id=\"MathJax-Span-148\" style=\"font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-149\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mfrac\" id=\"MathJax-Span-150\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.362em;\"><span class=\"mi\" id=\"MathJax-Span-151\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.18em, 1002.24em, 4.378em, -999.997em); top: -3.331em; left: 50%; margin-left: -1.143em;\"><span class=\"mrow\" id=\"MathJax-Span-152\"><span class=\"mo\" id=\"MathJax-Span-153\" style=\"font-family: STIXGeneral-Regular;\">‖</span><span class=\"msubsup\" id=\"MathJax-Span-154\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-155\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-156\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-157\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.42em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-158\" style=\"font-family: STIXGeneral-Regular;\">‖</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-159\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1002.35em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 2.346em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-160\" style=\"vertical-align: -0.466em;\"><span><span style=\"font-size: 111%; font-family: STIXSizeTwoSym;\">)</span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 3.805em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -1.122em; border-left: 0px solid; width: 0px; height: 2.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>g</mi><mi>i</mi></msub><mo stretchy=\"false\">←</mo><msub><mi>g</mi><mi>i</mi></msub><mo>⋅</mo><mo movablelimits=\"true\" form=\"prefix\">min</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>,</mo><mfrac><mi>C</mi><mrow><mo fence=\"false\" stretchy=\"false\">‖</mo><msub><mi>g</mi><mi>i</mi></msub><msub><mo fence=\"false\" stretchy=\"false\">‖</mo><mn>2</mn></msub></mrow></mfrac></mrow><mo>)</mo></mrow></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-22\">g_i \\leftarrow g_i \\cdot \\min\\left(1, \\frac{C}{\\|g_i\\|_2}\\right)</script>\n      </li>\n    </ul>\n<p>Clip the gradient to a fixed maximum norm <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-131\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-132\"><span class=\"mi\" id=\"MathJax-Span-133\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">C</script>:</p>\n<p><strong>Noise Addition</strong>:</p>\n<ul>\n      <li>\n        <p>After averaging the clipped gradients, add Gaussian noise:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mover><mi>g</mi><mo stretchy=&quot;false&quot;>&amp;#x00AF;</mo></mover></mrow><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munder><mo>&amp;#x2211;</mo><mi>i</mi></munder><msub><mi>g</mi><mi>i</mi></msub><mo>+</mo><mi>N</mi><mo stretchy=&quot;false&quot;>(</mo><mn>0</mn><mo>,</mo><msup><mi>&amp;#x03C3;</mi><mn>2</mn></msup><msup><mi>C</mi><mn>2</mn></msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;bold&quot;>I</mi></mrow><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-161\" style=\"width: 13.44em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 11.201em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(0.992em, 1011.15em, 3.909em, -999.997em); top: -2.497em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-162\"><span class=\"texatom\" id=\"MathJax-Span-163\"><span class=\"mrow\" id=\"MathJax-Span-164\"><span class=\"munderover\" id=\"MathJax-Span-165\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-166\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.232em, 1000.32em, 3.596em, -999.997em); top: -4.008em; left: 0.107em;\"><span class=\"mo\" id=\"MathJax-Span-167\" style=\"font-family: STIXGeneral-Regular;\">¯</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-168\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mfrac\" id=\"MathJax-Span-169\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.258em;\"><span class=\"mn\" id=\"MathJax-Span-170\" style=\"font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.258em;\"><span class=\"mi\" id=\"MathJax-Span-171\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1000.63em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.628em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span class=\"munderover\" id=\"MathJax-Span-172\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(2.867em, 1001.2em, 4.638em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-173\" style=\"font-family: STIXSizeOneSym; vertical-align: -0.518em;\">∑</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.21em, 4.273em, -999.997em); top: -2.862em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-174\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-175\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-176\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-177\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-178\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-179\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">N<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-180\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mn\" id=\"MathJax-Span-181\" style=\"font-family: STIXGeneral-Regular;\">0</span><span class=\"mo\" id=\"MathJax-Span-182\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-183\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-184\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-185\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-186\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-187\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"mn\" id=\"MathJax-Span-188\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"texatom\" id=\"MathJax-Span-189\"><span class=\"mrow\" id=\"MathJax-Span-190\"><span class=\"mi\" id=\"MathJax-Span-191\" style=\"font-family: STIXGeneral; font-weight: bold;\">I</span></span></span><span class=\"mo\" id=\"MathJax-Span-192\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.503em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -1.559em; border-left: 0px solid; width: 0px; height: 3.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mrow class=\"MJX-TeXAtom-ORD\"><mover><mi>g</mi><mo stretchy=\"false\">¯</mo></mover></mrow><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>g</mi><mi>i</mi></msub><mo>+</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo>,</mo><msup><mi>σ</mi><mn>2</mn></msup><msup><mi>C</mi><mn>2</mn></msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"bold\">I</mi></mrow><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-23\">\\bar{g} = \\frac{1}{n} \\sum_i g_i + N(0, \\sigma^2 C^2 \\mathbf{I})</script>\n      </li>\n      <li>\n        <p>Here, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03C3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-193\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-194\"><span class=\"mi\" id=\"MathJax-Span-195\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>σ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">\\sigma</script> is the <strong>noise multiplier</strong> that controls the privacy-utility trade-off.</p>\n      </li>\n    </ul>\n<p>After averaging the clipped gradients, add Gaussian noise:</p>\n<p>Here, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03C3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-193\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-194\"><span class=\"mi\" id=\"MathJax-Span-195\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>σ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">\\sigma</script> is the <strong>noise multiplier</strong> that controls the privacy-utility trade-off.</p>\n<p><strong>Privacy Tracking</strong>:</p>\n<ul>\n      <li>A <strong>privacy accountant</strong> (such as Rényi or Moments Accountant) keeps track of the cumulative privacy loss <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-196\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-197\"><span class=\"mi\" id=\"MathJax-Span-198\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">\\varepsilon</script> throughout training.</li>\n    </ul>",
    "contentMarkdown": "*   The standard stochastic gradient descent (SGD) algorithm is modified to ensure that updates do not leak private information. This is done by controlling the sensitivity of each training step via two key operations:\n\n1.  **Gradient Clipping**:\n    \n    *   For each training example, compute the per-sample gradient.\n    *   Clip the gradient to a fixed maximum norm CCC:\n        \n        gi←gi⋅min(1,C‖gi‖2)gi←gi⋅min(1,C‖gi‖2)\n        \n        g\\_i \\\\leftarrow g\\_i \\\\cdot \\\\min\\\\left(1, \\\\frac{C}{\\\\|g\\_i\\\\|\\_2}\\\\right)\n2.  **Noise Addition**:\n    \n    *   After averaging the clipped gradients, add Gaussian noise:\n        \n        g¯\\=1n∑igi+N(0,σ2C2I)g¯\\=1n∑igi+N(0,σ2C2I)\n        \n        \\\\bar{g} = \\\\frac{1}{n} \\\\sum\\_i g\\_i + N(0, \\\\sigma^2 C^2 \\\\mathbf{I})\n    *   Here, σσ\\\\sigma is the **noise multiplier** that controls the privacy-utility trade-off.\n        \n3.  **Privacy Tracking**:\n    \n    *   A **privacy accountant** (such as Rényi or Moments Accountant) keeps track of the cumulative privacy loss εε\\\\varepsilon throughout training.\n\n**Gradient Clipping**:\n\n*   For each training example, compute the per-sample gradient.\n*   Clip the gradient to a fixed maximum norm CCC:\n    \n    gi←gi⋅min(1,C‖gi‖2)gi←gi⋅min(1,C‖gi‖2)\n    \n    g\\_i \\\\leftarrow g\\_i \\\\cdot \\\\min\\\\left(1, \\\\frac{C}{\\\\|g\\_i\\\\|\\_2}\\\\right)\n\nClip the gradient to a fixed maximum norm CCC:\n\n**Noise Addition**:\n\n*   After averaging the clipped gradients, add Gaussian noise:\n    \n    g¯\\=1n∑igi+N(0,σ2C2I)g¯\\=1n∑igi+N(0,σ2C2I)\n    \n    \\\\bar{g} = \\\\frac{1}{n} \\\\sum\\_i g\\_i + N(0, \\\\sigma^2 C^2 \\\\mathbf{I})\n*   Here, σσ\\\\sigma is the **noise multiplier** that controls the privacy-utility trade-off.\n    \n\nAfter averaging the clipped gradients, add Gaussian noise:\n\nHere, σσ\\\\sigma is the **noise multiplier** that controls the privacy-utility trade-off.\n\n**Privacy Tracking**:\n\n*   A **privacy accountant** (such as Rényi or Moments Accountant) keeps track of the cumulative privacy loss εε\\\\varepsilon throughout training.",
    "order": 9,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 2,
    "tags": [
      "ondevice ai",
      "gradient descent"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 233,
      "contentLength": 42915
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#dp‑sgd:-core-idea",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-pytorch-implementation-with-opacus-10",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "DP‑SGD and Implementation",
    "title": "PyTorch Implementation with Opacus",
    "subtitle": "DP‑SGD and Implementation",
    "contentHtml": "<ul>\n  <li>Facebook’s <a href=\"https://opacus.ai\">Opacus</a> library makes it easy to implement DP‑SGD in PyTorch with minimal code changes:</li>\n</ul>\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code0\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code0\"><span class=\"kn\">from</span> <span class=\"nn\">opacus</span> <span class=\"kn\">import</span> <span class=\"n\">PrivacyEngine</span>\n\n<span class=\"n\">privacy_engine</span> <span class=\"o\">=</span> <span class=\"n\">PrivacyEngine</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"p\">,</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">256</span><span class=\"p\">,</span>\n    <span class=\"n\">sample_size</span><span class=\"o\">=</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">),</span>\n    <span class=\"n\">noise_multiplier</span><span class=\"o\">=</span><span class=\"mf\">1.2</span><span class=\"p\">,</span>\n    <span class=\"n\">max_grad_norm</span><span class=\"o\">=</span><span class=\"mf\">1.0</span>\n<span class=\"p\">)</span>\n<span class=\"n\">privacy_engine</span><span class=\"p\">.</span><span class=\"n\">attach</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"p\">)</span>\n</code></pre></div></div>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code0\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code0\"><span class=\"kn\">from</span> <span class=\"nn\">opacus</span> <span class=\"kn\">import</span> <span class=\"n\">PrivacyEngine</span>\n\n<span class=\"n\">privacy_engine</span> <span class=\"o\">=</span> <span class=\"n\">PrivacyEngine</span><span class=\"p\">(</span>\n    <span class=\"n\">model</span><span class=\"p\">,</span>\n    <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">256</span><span class=\"p\">,</span>\n    <span class=\"n\">sample_size</span><span class=\"o\">=</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">),</span>\n    <span class=\"n\">noise_multiplier</span><span class=\"o\">=</span><span class=\"mf\">1.2</span><span class=\"p\">,</span>\n    <span class=\"n\">max_grad_norm</span><span class=\"o\">=</span><span class=\"mf\">1.0</span>\n<span class=\"p\">)</span>\n<span class=\"n\">privacy_engine</span><span class=\"p\">.</span><span class=\"n\">attach</span><span class=\"p\">(</span><span class=\"n\">optimizer</span><span class=\"p\">)</span>\n</code></pre>\n<ul>\n  <li><strong><code class=\"language-plaintext highlighter-rouge\">max_grad_norm</code></strong> defines the clipping threshold <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-26-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-199\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-200\"><span class=\"mi\" id=\"MathJax-Span-201\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-26\">C</script>.</li>\n  <li><strong><code class=\"language-plaintext highlighter-rouge\">noise_multiplier</code></strong> corresponds to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-27-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03C3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-202\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-203\"><span class=\"mi\" id=\"MathJax-Span-204\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>σ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-27\">\\sigma</script>.</li>\n  <li>Opacus automatically modifies the model to track <strong>per-sample gradients</strong>, apply clipping and noise, and track <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-28-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-205\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-206\"><span class=\"mi\" id=\"MathJax-Span-207\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-28\">\\varepsilon</script> across epochs.</li>\n</ul>",
    "contentMarkdown": "*   Facebook’s [Opacus](https://opacus.ai) library makes it easy to implement DP‑SGD in PyTorch with minimal code changes:\n\n![](https://aman.ai/images/copy.png)\n\n`from opacus import PrivacyEngine  privacy_engine = PrivacyEngine(     model,     batch_size=256,     sample_size=len(dataset),     noise_multiplier=1.2,     max_grad_norm=1.0 ) privacy_engine.attach(optimizer)`\n\n![](https://aman.ai/images/copy.png)\n\n`from opacus import PrivacyEngine  privacy_engine = PrivacyEngine(     model,     batch_size=256,     sample_size=len(dataset),     noise_multiplier=1.2,     max_grad_norm=1.0 ) privacy_engine.attach(optimizer)`\n\n*   **`max_grad_norm`** defines the clipping threshold CCC.\n*   **`noise_multiplier`** corresponds to σσ\\\\sigma.\n*   Opacus automatically modifies the model to track **per-sample gradients**, apply clipping and noise, and track εε\\\\varepsilon across epochs.",
    "order": 10,
    "orderInChapter": 2,
    "difficulty": 3,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": true,
      "hasImages": true,
      "wordCount": 77,
      "contentLength": 6975
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#pytorch-implementation-with-opacus",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-dpweights-post-training-differential-privacy-11",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "DP‑SGD and Implementation",
    "title": "DP‑Weights (Post-training Differential Privacy)",
    "subtitle": "DP‑SGD and Implementation",
    "contentHtml": "<ul>\n  <li>\n    <p>An alternative to DP‑SGD is <strong>DP‑Weights</strong>, where noise is added <strong>after training</strong>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-29-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msup><mi>&amp;#x03B8;</mi><mtext>private</mtext></msup><mo>=</mo><msup><mi>&amp;#x03B8;</mi><mtext>trained</mtext></msup><mo>+</mo><mi>N</mi><mo stretchy=&quot;false&quot;>(</mo><mn>0</mn><mo>,</mo><msup><mi>&amp;#x03C3;</mi><mn>2</mn></msup><mi>I</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-208\" style=\"width: 13.648em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 11.357em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1011.3em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-209\"><span class=\"msubsup\" id=\"MathJax-Span-210\"><span style=\"display: inline-block; position: relative; width: 2.607em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-211\" style=\"font-family: STIXGeneral-Italic;\">θ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mtext\" id=\"MathJax-Span-212\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">private</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-213\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-214\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.607em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Italic;\">θ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mtext\" id=\"MathJax-Span-216\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">trained</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">N<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-219\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mn\" id=\"MathJax-Span-220\" style=\"font-family: STIXGeneral-Regular;\">0</span><span class=\"mo\" id=\"MathJax-Span-221\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-222\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-223\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-224\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-225\" style=\"font-family: STIXGeneral-Italic;\">I<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-226\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msup><mi>θ</mi><mtext>private</mtext></msup><mo>=</mo><msup><mi>θ</mi><mtext>trained</mtext></msup><mo>+</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo>,</mo><msup><mi>σ</mi><mn>2</mn></msup><mi>I</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-29\">\\theta^\\text{private} = \\theta^\\text{trained} + N(0, \\sigma^2 I)</script>\n  </li>\n  <li>\n    <p>This is helpful when retraining is expensive, as it provides some privacy protection with lower overhead.</p>\n  </li>\n  <li>\n    <p>While not as strong as full DP‑SGD, it still <strong>prevents exact memorization</strong> of individual training records and can mitigate simple membership inference attacks.</p>\n  </li>\n</ul>\n<p>An alternative to DP‑SGD is <strong>DP‑Weights</strong>, where noise is added <strong>after training</strong>:</p>\n<p>This is helpful when retraining is expensive, as it provides some privacy protection with lower overhead.</p>\n<p>While not as strong as full DP‑SGD, it still <strong>prevents exact memorization</strong> of individual training records and can mitigate simple membership inference attacks.</p>",
    "contentMarkdown": "*   An alternative to DP‑SGD is **DP‑Weights**, where noise is added **after training**:\n    \n    θprivate\\=θtrained+N(0,σ2I)θprivate\\=θtrained+N(0,σ2I)\n    \n    \\\\theta^\\\\text{private} = \\\\theta^\\\\text{trained} + N(0, \\\\sigma^2 I)\n*   This is helpful when retraining is expensive, as it provides some privacy protection with lower overhead.\n    \n*   While not as strong as full DP‑SGD, it still **prevents exact memorization** of individual training records and can mitigate simple membership inference attacks.\n    \n\nAn alternative to DP‑SGD is **DP‑Weights**, where noise is added **after training**:\n\nThis is helpful when retraining is expensive, as it provides some privacy protection with lower overhead.\n\nWhile not as strong as full DP‑SGD, it still **prevents exact memorization** of individual training records and can mitigate simple membership inference attacks.",
    "order": 11,
    "orderInChapter": 3,
    "difficulty": 3,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 113,
      "contentLength": 6062
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#dp‑weights-(post-training-differential-privacy)",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-fine-tuning-with-dp-sgd-12",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Application to LLMs & NLP",
    "title": "Fine-Tuning with DP-SGD",
    "subtitle": "Application to LLMs & NLP",
    "contentHtml": "<p>When fine-tuning pre-trained LLMs on private datasets (e.g., clinical corpora or enterprise emails), the <strong>DP-SGD algorithm</strong> can be directly applied to protect individual data points. The typical pipeline involves:</p>\n<ol>\n  <li>\n    <p><strong>Privacy Parameter Selection</strong>:</p>\n\n    <ul>\n      <li>Choose an acceptable privacy budget <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-227\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-228\"><span class=\"mi\" id=\"MathJax-Span-229\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-30\">\\varepsilon</script> and failure probability <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B4;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-230\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-231\"><span class=\"mi\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Italic;\">δ</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>δ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-31\">\\delta</script>.</li>\n      <li>Common settings in literature: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi><mo>=</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-233\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.03em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-234\"><span class=\"mi\" id=\"MathJax-Span-235\" style=\"font-family: STIXGeneral-Italic;\">ε</span><span class=\"mo\" id=\"MathJax-Span-236\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-237\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi><mo>=</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">\\varepsilon = 1</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>10</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-238\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.99em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-239\"><span class=\"mn\" id=\"MathJax-Span-240\" style=\"font-family: STIXGeneral-Regular;\">10</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>10</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">10</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B4;</mi><mo>=</mo><msup><mn>10</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2212;</mo><mn>5</mn></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-241\" style=\"width: 4.482em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.701em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1003.7em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-242\"><span class=\"mi\" id=\"MathJax-Span-243\" style=\"font-family: STIXGeneral-Italic;\">δ</span><span class=\"mo\" id=\"MathJax-Span-244\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-245\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.93em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.99em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Regular;\">10</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.992em;\"><span class=\"texatom\" id=\"MathJax-Span-247\"><span class=\"mrow\" id=\"MathJax-Span-248\"><span class=\"mo\" id=\"MathJax-Span-249\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-250\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">5</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>δ</mi><mo>=</mo><msup><mn>10</mn><mrow class=\"MJX-TeXAtom-ORD\"><mo>−</mo><mn>5</mn></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">\\delta = 10^{-5}</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-35-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>10</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2212;</mo><mn>8</mn></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-251\" style=\"width: 2.346em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.93em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1001.93em, 2.294em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-252\"><span class=\"msubsup\" id=\"MathJax-Span-253\"><span style=\"display: inline-block; position: relative; width: 1.93em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.99em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Regular;\">10</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.992em;\"><span class=\"texatom\" id=\"MathJax-Span-255\"><span class=\"mrow\" id=\"MathJax-Span-256\"><span class=\"mo\" id=\"MathJax-Span-257\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-258\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">8</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mn>10</mn><mrow class=\"MJX-TeXAtom-ORD\"><mo>−</mo><mn>8</mn></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-35\">10^{-8}</script>.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Hyperparameter Calibration</strong>:</p>\n\n    <ul>\n      <li>Tune gradient clipping norm <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-259\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-260\"><span class=\"mi\" id=\"MathJax-Span-261\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-36\">C</script>, noise multiplier <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-37-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03C3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-262\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-263\"><span class=\"mi\" id=\"MathJax-Span-264\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>σ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-37\">\\sigma</script>, batch size, and learning rate.</li>\n      <li>Use a <strong>calibration set</strong> (non-sensitive) to test different combinations that optimize accuracy under a fixed privacy budget.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Training and Privacy Accounting</strong>:</p>\n\n    <ul>\n      <li>Train the model using DP-SGD (e.g., via Opacus), and track the total privacy loss across epochs.</li>\n      <li>Use <strong>moments accountant</strong> or <strong>Rényi differential privacy accountant</strong> for tighter analysis of cumulative <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-265\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-266\"><span class=\"mi\" id=\"MathJax-Span-267\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-38\">\\varepsilon</script>.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Model Evaluation</strong>:</p>\n\n    <ul>\n      <li>Evaluate utility trade-off: privacy often comes at the cost of <strong>increased perplexity</strong> or <strong>reduced BLEU/F1 scores</strong> in NLP tasks.</li>\n      <li>Trade-off improves with larger public pretraining and private fine-tuning.</li>\n    </ul>\n  </li>\n</ol>\n<p><strong>Privacy Parameter Selection</strong>:</p>\n<ul>\n      <li>Choose an acceptable privacy budget <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-227\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-228\"><span class=\"mi\" id=\"MathJax-Span-229\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-30\">\\varepsilon</script> and failure probability <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B4;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-230\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-231\"><span class=\"mi\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Italic;\">δ</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>δ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-31\">\\delta</script>.</li>\n      <li>Common settings in literature: <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi><mo>=</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-233\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.03em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-234\"><span class=\"mi\" id=\"MathJax-Span-235\" style=\"font-family: STIXGeneral-Italic;\">ε</span><span class=\"mo\" id=\"MathJax-Span-236\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-237\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi><mo>=</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">\\varepsilon = 1</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>10</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-238\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.99em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-239\"><span class=\"mn\" id=\"MathJax-Span-240\" style=\"font-family: STIXGeneral-Regular;\">10</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>10</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">10</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B4;</mi><mo>=</mo><msup><mn>10</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2212;</mo><mn>5</mn></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-241\" style=\"width: 4.482em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.701em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1003.7em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-242\"><span class=\"mi\" id=\"MathJax-Span-243\" style=\"font-family: STIXGeneral-Italic;\">δ</span><span class=\"mo\" id=\"MathJax-Span-244\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-245\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.93em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.99em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Regular;\">10</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.992em;\"><span class=\"texatom\" id=\"MathJax-Span-247\"><span class=\"mrow\" id=\"MathJax-Span-248\"><span class=\"mo\" id=\"MathJax-Span-249\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-250\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">5</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>δ</mi><mo>=</mo><msup><mn>10</mn><mrow class=\"MJX-TeXAtom-ORD\"><mo>−</mo><mn>5</mn></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">\\delta = 10^{-5}</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-35-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>10</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x2212;</mo><mn>8</mn></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-251\" style=\"width: 2.346em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.93em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.096em, 1001.93em, 2.294em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-252\"><span class=\"msubsup\" id=\"MathJax-Span-253\"><span style=\"display: inline-block; position: relative; width: 1.93em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.99em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Regular;\">10</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.992em;\"><span class=\"texatom\" id=\"MathJax-Span-255\"><span class=\"mrow\" id=\"MathJax-Span-256\"><span class=\"mo\" id=\"MathJax-Span-257\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-258\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">8</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mn>10</mn><mrow class=\"MJX-TeXAtom-ORD\"><mo>−</mo><mn>8</mn></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-35\">10^{-8}</script>.</li>\n    </ul>\n<p><strong>Hyperparameter Calibration</strong>:</p>\n<ul>\n      <li>Tune gradient clipping norm <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>C</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-259\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-260\"><span class=\"mi\" id=\"MathJax-Span-261\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-36\">C</script>, noise multiplier <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-37-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03C3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-262\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-263\"><span class=\"mi\" id=\"MathJax-Span-264\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>σ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-37\">\\sigma</script>, batch size, and learning rate.</li>\n      <li>Use a <strong>calibration set</strong> (non-sensitive) to test different combinations that optimize accuracy under a fixed privacy budget.</li>\n    </ul>\n<p><strong>Training and Privacy Accounting</strong>:</p>\n<ul>\n      <li>Train the model using DP-SGD (e.g., via Opacus), and track the total privacy loss across epochs.</li>\n      <li>Use <strong>moments accountant</strong> or <strong>Rényi differential privacy accountant</strong> for tighter analysis of cumulative <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-265\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-266\"><span class=\"mi\" id=\"MathJax-Span-267\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-38\">\\varepsilon</script>.</li>\n    </ul>\n<p><strong>Model Evaluation</strong>:</p>\n<ul>\n      <li>Evaluate utility trade-off: privacy often comes at the cost of <strong>increased perplexity</strong> or <strong>reduced BLEU/F1 scores</strong> in NLP tasks.</li>\n      <li>Trade-off improves with larger public pretraining and private fine-tuning.</li>\n    </ul>",
    "contentMarkdown": "When fine-tuning pre-trained LLMs on private datasets (e.g., clinical corpora or enterprise emails), the **DP-SGD algorithm** can be directly applied to protect individual data points. The typical pipeline involves:\n\n1.  **Privacy Parameter Selection**:\n    \n    *   Choose an acceptable privacy budget εε\\\\varepsilon and failure probability δδ\\\\delta.\n    *   Common settings in literature: ε\\=1ε\\=1\\\\varepsilon = 1 to 101010, δ\\=10−5δ\\=10−5\\\\delta = 10^{-5} to 10−810−810^{-8}.\n2.  **Hyperparameter Calibration**:\n    \n    *   Tune gradient clipping norm CCC, noise multiplier σσ\\\\sigma, batch size, and learning rate.\n    *   Use a **calibration set** (non-sensitive) to test different combinations that optimize accuracy under a fixed privacy budget.\n3.  **Training and Privacy Accounting**:\n    \n    *   Train the model using DP-SGD (e.g., via Opacus), and track the total privacy loss across epochs.\n    *   Use **moments accountant** or **Rényi differential privacy accountant** for tighter analysis of cumulative εε\\\\varepsilon.\n4.  **Model Evaluation**:\n    \n    *   Evaluate utility trade-off: privacy often comes at the cost of **increased perplexity** or **reduced BLEU/F1 scores** in NLP tasks.\n    *   Trade-off improves with larger public pretraining and private fine-tuning.\n\n**Privacy Parameter Selection**:\n\n*   Choose an acceptable privacy budget εε\\\\varepsilon and failure probability δδ\\\\delta.\n*   Common settings in literature: ε\\=1ε\\=1\\\\varepsilon = 1 to 101010, δ\\=10−5δ\\=10−5\\\\delta = 10^{-5} to 10−810−810^{-8}.\n\n**Hyperparameter Calibration**:\n\n*   Tune gradient clipping norm CCC, noise multiplier σσ\\\\sigma, batch size, and learning rate.\n*   Use a **calibration set** (non-sensitive) to test different combinations that optimize accuracy under a fixed privacy budget.\n\n**Training and Privacy Accounting**:\n\n*   Train the model using DP-SGD (e.g., via Opacus), and track the total privacy loss across epochs.\n*   Use **moments accountant** or **Rényi differential privacy accountant** for tighter analysis of cumulative εε\\\\varepsilon.\n\n**Model Evaluation**:\n\n*   Evaluate utility trade-off: privacy often comes at the cost of **increased perplexity** or **reduced BLEU/F1 scores** in NLP tasks.\n*   Trade-off improves with larger public pretraining and private fine-tuning.",
    "order": 12,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 2,
    "tags": [
      "ondevice ai",
      "llm",
      "nlp",
      "fine-tuning"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 295,
      "contentLength": 29442
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#fine-tuning-with-dp-sgd",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-membership-inference-protection-13",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Application to LLMs & NLP",
    "title": "Membership Inference & Protection",
    "subtitle": "Application to LLMs & NLP",
    "contentHtml": "<ul>\n  <li>Differential privacy is particularly effective at <strong>mitigating membership inference attacks</strong>—where an attacker queries a model and tries to determine whether specific records were part of its training set.</li>\n  <li>In NLP, these attacks are especially potent: LLMs can <strong>memorize rare sequences</strong> (e.g., uncommon names or numbers), which attackers can prompt into being reproduced.</li>\n  <li>DP-trained models are <strong>less likely to memorize</strong> such outliers, improving privacy robustness in deployment.</li>\n</ul>",
    "contentMarkdown": "*   Differential privacy is particularly effective at **mitigating membership inference attacks**—where an attacker queries a model and tries to determine whether specific records were part of its training set.\n*   In NLP, these attacks are especially potent: LLMs can **memorize rare sequences** (e.g., uncommon names or numbers), which attackers can prompt into being reproduced.\n*   DP-trained models are **less likely to memorize** such outliers, improving privacy robustness in deployment.",
    "order": 13,
    "orderInChapter": 2,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai",
      "llm",
      "nlp"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 69,
      "contentLength": 565
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#membership-inference-&-protection",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-recent-strategies-14",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Application to LLMs & NLP",
    "title": "Recent Strategies",
    "subtitle": "Application to LLMs & NLP",
    "contentHtml": "<ul>\n  <li>\n    <p><strong>Pre-train with DP, fine-tune with public data</strong>:</p>\n\n    <ul>\n      <li>Train a model under strong DP constraints (e.g., on private corpora).</li>\n      <li>Fine-tune on open-domain datasets (e.g., Wikipedia, C4) to <strong>recover utility</strong> without additional privacy cost.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Public target-tuning</strong>:</p>\n\n    <ul>\n      <li>Fine-tune a public model on public data to a target task.</li>\n      <li>Use DP-SGD on private examples only to adapt the model (e.g., via LoRA adapters) while preserving privacy.</li>\n    </ul>\n  </li>\n</ul>\n<p><strong>Pre-train with DP, fine-tune with public data</strong>:</p>\n<ul>\n      <li>Train a model under strong DP constraints (e.g., on private corpora).</li>\n      <li>Fine-tune on open-domain datasets (e.g., Wikipedia, C4) to <strong>recover utility</strong> without additional privacy cost.</li>\n    </ul>\n<p><strong>Public target-tuning</strong>:</p>\n<ul>\n      <li>Fine-tune a public model on public data to a target task.</li>\n      <li>Use DP-SGD on private examples only to adapt the model (e.g., via LoRA adapters) while preserving privacy.</li>\n    </ul>",
    "contentMarkdown": "*   **Pre-train with DP, fine-tune with public data**:\n    \n    *   Train a model under strong DP constraints (e.g., on private corpora).\n    *   Fine-tune on open-domain datasets (e.g., Wikipedia, C4) to **recover utility** without additional privacy cost.\n*   **Public target-tuning**:\n    \n    *   Fine-tune a public model on public data to a target task.\n    *   Use DP-SGD on private examples only to adapt the model (e.g., via LoRA adapters) while preserving privacy.\n\n**Pre-train with DP, fine-tune with public data**:\n\n*   Train a model under strong DP constraints (e.g., on private corpora).\n*   Fine-tune on open-domain datasets (e.g., Wikipedia, C4) to **recover utility** without additional privacy cost.\n\n**Public target-tuning**:\n\n*   Fine-tune a public model on public data to a target task.\n*   Use DP-SGD on private examples only to adapt the model (e.g., via LoRA adapters) while preserving privacy.",
    "order": 14,
    "orderInChapter": 3,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 134,
      "contentLength": 1192
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#recent-strategies",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-pros-15",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Pros & Cons",
    "title": "Pros",
    "subtitle": "Pros & Cons",
    "contentHtml": "<ul>\n  <li>\n    <p><strong>Formal Privacy Guarantees</strong>: DP provides mathematically provable bounds on the risk of individual data exposure—offering strong defense against attacks like membership inference and data reconstruction.</p>\n  </li>\n  <li>\n    <p><strong>Tooling Ecosystem</strong>: Libraries like <strong>Opacus</strong> (PyTorch) and <strong>TensorFlow Privacy</strong> streamline DP integration with deep learning models, supporting gradient clipping, noise addition, and privacy accounting.</p>\n  </li>\n  <li>\n    <p><strong>General Applicability</strong>: Can be applied to various components: model training (via DP-SGD), post-training (via DP-Weights), or user-level contributions (via local DP mechanisms).</p>\n  </li>\n  <li>\n    <p><strong>Defends Against Real-World Threats</strong>: Especially valuable in medical, financial, or sensitive NLP domains where privacy breaches can have serious consequences.</p>\n  </li>\n</ul>\n<p><strong>Formal Privacy Guarantees</strong>: DP provides mathematically provable bounds on the risk of individual data exposure—offering strong defense against attacks like membership inference and data reconstruction.</p>\n<p><strong>Tooling Ecosystem</strong>: Libraries like <strong>Opacus</strong> (PyTorch) and <strong>TensorFlow Privacy</strong> streamline DP integration with deep learning models, supporting gradient clipping, noise addition, and privacy accounting.</p>\n<p><strong>General Applicability</strong>: Can be applied to various components: model training (via DP-SGD), post-training (via DP-Weights), or user-level contributions (via local DP mechanisms).</p>\n<p><strong>Defends Against Real-World Threats</strong>: Especially valuable in medical, financial, or sensitive NLP domains where privacy breaches can have serious consequences.</p>",
    "contentMarkdown": "*   **Formal Privacy Guarantees**: DP provides mathematically provable bounds on the risk of individual data exposure—offering strong defense against attacks like membership inference and data reconstruction.\n    \n*   **Tooling Ecosystem**: Libraries like **Opacus** (PyTorch) and **TensorFlow Privacy** streamline DP integration with deep learning models, supporting gradient clipping, noise addition, and privacy accounting.\n    \n*   **General Applicability**: Can be applied to various components: model training (via DP-SGD), post-training (via DP-Weights), or user-level contributions (via local DP mechanisms).\n    \n*   **Defends Against Real-World Threats**: Especially valuable in medical, financial, or sensitive NLP domains where privacy breaches can have serious consequences.\n    \n\n**Formal Privacy Guarantees**: DP provides mathematically provable bounds on the risk of individual data exposure—offering strong defense against attacks like membership inference and data reconstruction.\n\n**Tooling Ecosystem**: Libraries like **Opacus** (PyTorch) and **TensorFlow Privacy** streamline DP integration with deep learning models, supporting gradient clipping, noise addition, and privacy accounting.\n\n**General Applicability**: Can be applied to various components: model training (via DP-SGD), post-training (via DP-Weights), or user-level contributions (via local DP mechanisms).\n\n**Defends Against Real-World Threats**: Especially valuable in medical, financial, or sensitive NLP domains where privacy breaches can have serious consequences.",
    "order": 15,
    "orderInChapter": 1,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "ondevice ai",
      "deep learning",
      "nlp"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 186,
      "contentLength": 1812
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#pros",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  },
  {
    "id": "ai-differential-privacy-cons-16",
    "domain": "ai_primers",
    "category": "On-Device AI",
    "article": "Differential Privacy",
    "articleSlug": "differential-privacy",
    "chapter": "Pros & Cons",
    "title": "Cons",
    "subtitle": "Pros & Cons",
    "contentHtml": "<ul>\n  <li>\n    <p><strong>Utility Degradation</strong>: Injecting noise during training often leads to <strong>higher perplexity</strong>, <strong>lower F1 scores</strong>, or degraded generation quality—especially for smaller datasets or tasks requiring fine detail.</p>\n  </li>\n  <li>\n    <p><strong>Complex Hyperparameter Tuning</strong>: Requires careful balancing of noise multiplier, clipping norms, batch sizes, and learning rate. Poor tuning can nullify either privacy or utility.</p>\n  </li>\n  <li>\n    <p><strong>Privacy Budget Exhaustion</strong>: Each training epoch and query consumes part of the privacy budget <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-268\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-269\"><span class=\"mi\" id=\"MathJax-Span-270\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">\\varepsilon</script>; long training or frequent evaluations can <strong>accumulate privacy loss</strong> quickly.</p>\n  </li>\n  <li>\n    <p><strong>Scalability Concerns</strong>: Computing per-sample gradients (needed for DP-SGD) is computationally expensive, especially for large LLMs.</p>\n  </li>\n  <li>\n    <p><strong>Task Sensitivity</strong>: Some NLP tasks (e.g., rare token generation, open-ended dialogue) are more vulnerable to degradation under DP due to their reliance on nuanced memorization.</p>\n  </li>\n</ul>\n<p><strong>Utility Degradation</strong>: Injecting noise during training often leads to <strong>higher perplexity</strong>, <strong>lower F1 scores</strong>, or degraded generation quality—especially for smaller datasets or tasks requiring fine detail.</p>\n<p><strong>Complex Hyperparameter Tuning</strong>: Requires careful balancing of noise multiplier, clipping norms, batch sizes, and learning rate. Poor tuning can nullify either privacy or utility.</p>\n<p><strong>Privacy Budget Exhaustion</strong>: Each training epoch and query consumes part of the privacy budget <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B5;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-268\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-269\"><span class=\"mi\" id=\"MathJax-Span-270\" style=\"font-family: STIXGeneral-Italic;\">ε</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ε</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">\\varepsilon</script>; long training or frequent evaluations can <strong>accumulate privacy loss</strong> quickly.</p>\n<p><strong>Scalability Concerns</strong>: Computing per-sample gradients (needed for DP-SGD) is computationally expensive, especially for large LLMs.</p>\n<p><strong>Task Sensitivity</strong>: Some NLP tasks (e.g., rare token generation, open-ended dialogue) are more vulnerable to degradation under DP due to their reliance on nuanced memorization.</p>",
    "contentMarkdown": "*   **Utility Degradation**: Injecting noise during training often leads to **higher perplexity**, **lower F1 scores**, or degraded generation quality—especially for smaller datasets or tasks requiring fine detail.\n    \n*   **Complex Hyperparameter Tuning**: Requires careful balancing of noise multiplier, clipping norms, batch sizes, and learning rate. Poor tuning can nullify either privacy or utility.\n    \n*   **Privacy Budget Exhaustion**: Each training epoch and query consumes part of the privacy budget εε\\\\varepsilon; long training or frequent evaluations can **accumulate privacy loss** quickly.\n    \n*   **Scalability Concerns**: Computing per-sample gradients (needed for DP-SGD) is computationally expensive, especially for large LLMs.\n    \n*   **Task Sensitivity**: Some NLP tasks (e.g., rare token generation, open-ended dialogue) are more vulnerable to degradation under DP due to their reliance on nuanced memorization.\n    \n\n**Utility Degradation**: Injecting noise during training often leads to **higher perplexity**, **lower F1 scores**, or degraded generation quality—especially for smaller datasets or tasks requiring fine detail.\n\n**Complex Hyperparameter Tuning**: Requires careful balancing of noise multiplier, clipping norms, batch sizes, and learning rate. Poor tuning can nullify either privacy or utility.\n\n**Privacy Budget Exhaustion**: Each training epoch and query consumes part of the privacy budget εε\\\\varepsilon; long training or frequent evaluations can **accumulate privacy loss** quickly.\n\n**Scalability Concerns**: Computing per-sample gradients (needed for DP-SGD) is computationally expensive, especially for large LLMs.\n\n**Task Sensitivity**: Some NLP tasks (e.g., rare token generation, open-ended dialogue) are more vulnerable to degradation under DP due to their reliance on nuanced memorization.",
    "order": 16,
    "orderInChapter": 2,
    "difficulty": 4,
    "estimatedMinutes": 2,
    "tags": [
      "ondevice ai",
      "llm",
      "nlp"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 235,
      "contentLength": 4551
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/differential-privacy/#cons",
    "scrapedAt": "2025-12-28T11:56:06.248Z"
  }
]