[
  {
    "id": "ai-gemma-3n-per-layer-embeddings-ple-1",
    "domain": "ai_primers",
    "category": "Models",
    "article": "Gemma 3n",
    "articleSlug": "gemma-3n",
    "chapter": "Key Architectural Innovations",
    "title": "Per-Layer Embeddings (PLE)",
    "subtitle": "Key Architectural Innovations",
    "contentHtml": "<ul>\n  <li>\n    <p><a href=\"https://ai.google.dev/gemma/docs/gemma-3n#ple-caching\">Per-Layer Embeddings (PLE)</a> is a technique designed to offload a significant portion of model memory requirements from high-speed device accelerators (like mobile GPUs or TPUs) to more accessible CPU memory, enabling large models to run on constrained devices without compromising performance.</p>\n  </li>\n  <li>\n    <p>PLE decouples the per-layer token embeddings from the core model, caching them separately and computing them efficiently outside of the accelerator. For example, while Gemma 3n models may have total parameter counts of 5B (E2B) and 8B (E4B), only about 2B and 4B of those parameters, respectively, are needed in active accelerator memory during inference. This leads to substantial reductions in required VRAM without a drop in model quality.</p>\n  </li>\n  <li>\n    <p>This optimization is particularly well-suited for edge deployment scenarios where accelerator memory is a bottleneck. The embedding computations can be executed on-device CPU threads and merged into the transformer’s residual pathways at runtime.</p>\n  </li>\n  <li>\n    <p>For instance, the elastic 2B submodel configuration (E2B) is a lightweight elastic submodel derived from a larger model (e.g., 4B or 8B), running with the efficiency of a 2B model by activating only a subset of the full architecture. The figure below (<a href=\"https://ai.google.dev/gemma/docs/gemma-3n\">source</a>) illustrates the Gemma 3n E2B model’s parameters running in standard execution versus an effectively lower parameter load using PLE caching and parameter skipping techniques. Put simply, with PLE, you can use Gemma 3n E2B while only having ~2B parameters loaded in your accelerator.</p>\n  </li>\n</ul>\n<p><a href=\"https://ai.google.dev/gemma/docs/gemma-3n#ple-caching\">Per-Layer Embeddings (PLE)</a> is a technique designed to offload a significant portion of model memory requirements from high-speed device accelerators (like mobile GPUs or TPUs) to more accessible CPU memory, enabling large models to run on constrained devices without compromising performance.</p>\n<p>PLE decouples the per-layer token embeddings from the core model, caching them separately and computing them efficiently outside of the accelerator. For example, while Gemma 3n models may have total parameter counts of 5B (E2B) and 8B (E4B), only about 2B and 4B of those parameters, respectively, are needed in active accelerator memory during inference. This leads to substantial reductions in required VRAM without a drop in model quality.</p>\n<p>This optimization is particularly well-suited for edge deployment scenarios where accelerator memory is a bottleneck. The embedding computations can be executed on-device CPU threads and merged into the transformer’s residual pathways at runtime.</p>\n<p>For instance, the elastic 2B submodel configuration (E2B) is a lightweight elastic submodel derived from a larger model (e.g., 4B or 8B), running with the efficiency of a 2B model by activating only a subset of the full architecture. The figure below (<a href=\"https://ai.google.dev/gemma/docs/gemma-3n\">source</a>) illustrates the Gemma 3n E2B model’s parameters running in standard execution versus an effectively lower parameter load using PLE caching and parameter skipping techniques. Put simply, with PLE, you can use Gemma 3n E2B while only having ~2B parameters loaded in your accelerator.</p>\n<p><img src=\"/primers/ai/assets/gemma-3n/PLE.jpg\" alt=\"\"></p>\n<ul>\n  <li>From a deployment perspective, this mechanism empowers developers to run advanced Gemma 3n models on devices with as little as 2GB of RAM for E2B or 3GB for E4B—dramatically expanding the reach of high-quality on-device AI.</li>\n</ul>",
    "contentMarkdown": "*   [Per-Layer Embeddings (PLE)](https://ai.google.dev/gemma/docs/gemma-3n#ple-caching) is a technique designed to offload a significant portion of model memory requirements from high-speed device accelerators (like mobile GPUs or TPUs) to more accessible CPU memory, enabling large models to run on constrained devices without compromising performance.\n    \n*   PLE decouples the per-layer token embeddings from the core model, caching them separately and computing them efficiently outside of the accelerator. For example, while Gemma 3n models may have total parameter counts of 5B (E2B) and 8B (E4B), only about 2B and 4B of those parameters, respectively, are needed in active accelerator memory during inference. This leads to substantial reductions in required VRAM without a drop in model quality.\n    \n*   This optimization is particularly well-suited for edge deployment scenarios where accelerator memory is a bottleneck. The embedding computations can be executed on-device CPU threads and merged into the transformer’s residual pathways at runtime.\n    \n*   For instance, the elastic 2B submodel configuration (E2B) is a lightweight elastic submodel derived from a larger model (e.g., 4B or 8B), running with the efficiency of a 2B model by activating only a subset of the full architecture. The figure below ([source](https://ai.google.dev/gemma/docs/gemma-3n)) illustrates the Gemma 3n E2B model’s parameters running in standard execution versus an effectively lower parameter load using PLE caching and parameter skipping techniques. Put simply, with PLE, you can use Gemma 3n E2B while only having ~2B parameters loaded in your accelerator.\n    \n\n[Per-Layer Embeddings (PLE)](https://ai.google.dev/gemma/docs/gemma-3n#ple-caching) is a technique designed to offload a significant portion of model memory requirements from high-speed device accelerators (like mobile GPUs or TPUs) to more accessible CPU memory, enabling large models to run on constrained devices without compromising performance.\n\nPLE decouples the per-layer token embeddings from the core model, caching them separately and computing them efficiently outside of the accelerator. For example, while Gemma 3n models may have total parameter counts of 5B (E2B) and 8B (E4B), only about 2B and 4B of those parameters, respectively, are needed in active accelerator memory during inference. This leads to substantial reductions in required VRAM without a drop in model quality.\n\nThis optimization is particularly well-suited for edge deployment scenarios where accelerator memory is a bottleneck. The embedding computations can be executed on-device CPU threads and merged into the transformer’s residual pathways at runtime.\n\nFor instance, the elastic 2B submodel configuration (E2B) is a lightweight elastic submodel derived from a larger model (e.g., 4B or 8B), running with the efficiency of a 2B model by activating only a subset of the full architecture. The figure below ([source](https://ai.google.dev/gemma/docs/gemma-3n)) illustrates the Gemma 3n E2B model’s parameters running in standard execution versus an effectively lower parameter load using PLE caching and parameter skipping techniques. Put simply, with PLE, you can use Gemma 3n E2B while only having ~2B parameters loaded in your accelerator.\n\n![](/primers/ai/assets/gemma-3n/PLE.jpg)\n\n*   From a deployment perspective, this mechanism empowers developers to run advanced Gemma 3n models on devices with as little as 2GB of RAM for E2B or 3GB for E4B—dramatically expanding the reach of high-quality on-device AI.",
    "order": 1,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 3,
    "tags": [
      "models",
      "transformer",
      "embedding",
      "optimization"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 500,
      "contentLength": 3748
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/gemma-3n/#per-layer-embeddings-(ple)",
    "scrapedAt": "2025-12-28T11:52:03.953Z"
  },
  {
    "id": "ai-gemma-3n-matryoshka-transformer-matformer-architecture-2",
    "domain": "ai_primers",
    "category": "Models",
    "article": "Gemma 3n",
    "articleSlug": "gemma-3n",
    "chapter": "Key Architectural Innovations",
    "title": "Matryoshka Transformer (MatFormer) Architecture",
    "subtitle": "Key Architectural Innovations",
    "contentHtml": "<ul>\n  <li>\n    <p>The <a href=\"https://ai.google.dev/gemma/docs/gemma-3n#matformer\">Matryoshka Transformer (MatFormer)</a> architecture, proposed in <a href=\"https://arxiv.org/abs/2310.07707\">MatFormer: Nested Transformer for Elastic Inference</a> by Devvrit et al. (2024), is central to Gemma 3n’s compute-efficiency. Inspired by Matryoshka dolls, it enables a larger model to contain smaller, independently usable submodels with no retraining or architecture changes required.</p>\n  </li>\n  <li>\n    <p>In Gemma 3n, MatFormer is the key to <strong>elastic inference</strong>: a single trained model (e.g., E4B) includes within it a lightweight, independently usable E2B model—and developers can also interpolate sizes between these via the Mix’n’Match method.</p>\n  </li>\n</ul>\n<p>The <a href=\"https://ai.google.dev/gemma/docs/gemma-3n#matformer\">Matryoshka Transformer (MatFormer)</a> architecture, proposed in <a href=\"https://arxiv.org/abs/2310.07707\">MatFormer: Nested Transformer for Elastic Inference</a> by Devvrit et al. (2024), is central to Gemma 3n’s compute-efficiency. Inspired by Matryoshka dolls, it enables a larger model to contain smaller, independently usable submodels with no retraining or architecture changes required.</p>\n<p>In Gemma 3n, MatFormer is the key to <strong>elastic inference</strong>: a single trained model (e.g., E4B) includes within it a lightweight, independently usable E2B model—and developers can also interpolate sizes between these via the Mix’n’Match method.</p>\n<h4 id=\"nested-ffn-block-design\">Nested FFN Block Design</h4>\n<ul>\n  <li>\n    <p>The MatFormer architecture in Gemma 3n incorporates a nested structure within the Transformer block’s feedforward network (FFN), enabling dynamic submodel scaling during inference without incurring additional training costs.</p>\n  </li>\n  <li>\n    <p>MatFormer builds a hierarchy of Transformer blocks:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-1-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>T</mi><mn>1</mn></msub><mo>&amp;#x2282;</mo><msub><mi>T</mi><mn>2</mn></msub><mo>&amp;#x2282;</mo><mo>&amp;#x22EF;</mo><mo>&amp;#x2282;</mo><msub><mi>T</mi><mi>g</mi></msub></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1\" style=\"width: 9.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.763em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1007.76em, 2.867em, -999.997em); top: -2.393em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2\"><span class=\"msubsup\" id=\"MathJax-Span-3\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-4\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-5\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-6\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">⊂</span><span class=\"msubsup\" id=\"MathJax-Span-7\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-8\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-9\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-10\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">⊂</span><span class=\"mo\" id=\"MathJax-Span-11\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">⋯</span><span class=\"mo\" id=\"MathJax-Span-12\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">⊂</span><span class=\"msubsup\" id=\"MathJax-Span-13\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-14\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-15\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.398em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>T</mi><mn>1</mn></msub><mo>⊂</mo><msub><mi>T</mi><mn>2</mn></msub><mo>⊂</mo><mo>⋯</mo><mo>⊂</mo><msub><mi>T</mi><mi>g</mi></msub></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-1\">T_1 \\subset T_2 \\subset \\cdots \\subset T_g</script>\n\n    <ul>\n      <li>where each block <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-2-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-16\" style=\"width: 1.044em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.84em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-17\"><span class=\"msubsup\" id=\"MathJax-Span-18\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-19\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-20\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-2\">T_i</script> shares parameters with its supersets, enabling parameter reuse and minimizing overhead. This design is centered in the FFN block, which is the primary contributor to a Transformer’s computational and memory demands—often accounting for over 60% of resource use in large language and vision models.</li>\n    </ul>\n  </li>\n  <li>Let:\n    <ul>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-3-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>model</mtext></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-21\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.35em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-22\"><span class=\"msubsup\" id=\"MathJax-Span-23\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-24\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-25\"><span class=\"mrow\" id=\"MathJax-Span-26\"><span class=\"mtext\" id=\"MathJax-Span-27\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">model</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>model</mtext></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-3\">d_{\\text{model}}</script> be the model’s hidden dimension</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-4-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>ff</mtext></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-28\" style=\"width: 1.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.04em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-29\"><span class=\"msubsup\" id=\"MathJax-Span-30\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-31\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-32\"><span class=\"mrow\" id=\"MathJax-Span-33\"><span class=\"mtext\" id=\"MathJax-Span-34\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">ff</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>ff</mtext></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-4\">d_{\\text{ff}}</script> be the width of the FFN layer</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-5-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-35\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-36\"><span class=\"mi\" id=\"MathJax-Span-37\" style=\"font-family: STIXGeneral-Italic;\">g</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-5\">g</script> be the number of granularities (typically 4)</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-6-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>m</mi><mn>1</mn></msub><mo>&amp;lt;</mo><msub><mi>m</mi><mn>2</mn></msub><mo>&amp;lt;</mo><mo>&amp;#x22EF;</mo><mo>&amp;lt;</mo><msub><mi>m</mi><mi>g</mi></msub><mo>=</mo><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>ff</mtext></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-38\" style=\"width: 12.346em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1010.26em, 2.867em, -999.997em); top: -2.393em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-39\"><span class=\"msubsup\" id=\"MathJax-Span-40\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-41\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mn\" id=\"MathJax-Span-42\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-43\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">&lt;</span><span class=\"msubsup\" id=\"MathJax-Span-44\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-45\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mn\" id=\"MathJax-Span-46\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-47\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">&lt;</span><span class=\"mo\" id=\"MathJax-Span-48\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">⋯</span><span class=\"mo\" id=\"MathJax-Span-49\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">&lt;</span><span class=\"msubsup\" id=\"MathJax-Span-50\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-51\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-52\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-53\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-54\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-55\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-56\"><span class=\"mrow\" id=\"MathJax-Span-57\"><span class=\"mtext\" id=\"MathJax-Span-58\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">ff</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.398em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>m</mi><mn>1</mn></msub><mo>&lt;</mo><msub><mi>m</mi><mn>2</mn></msub><mo>&lt;</mo><mo>⋯</mo><mo>&lt;</mo><msub><mi>m</mi><mi>g</mi></msub><mo>=</mo><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>ff</mtext></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-6\">m_1 < m_2 < \\cdots < m_g = d_{\\text{ff}}</script> be the neuron counts for each submodel</li>\n    </ul>\n  </li>\n  <li>\n    <p>The FFN function for the <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-7-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>i</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>h</mi></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-59\" style=\"width: 1.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1000.94em, 2.294em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-60\"><span class=\"msubsup\" id=\"MathJax-Span-61\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.26em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-62\" style=\"font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.263em;\"><span class=\"texatom\" id=\"MathJax-Span-63\"><span class=\"mrow\" id=\"MathJax-Span-64\"><span class=\"mi\" id=\"MathJax-Span-65\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-66\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>i</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>t</mi><mi>h</mi></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-7\">i^{th}</script> submodel is:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-8-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>T</mi><mi>i</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>FFN</mtext></mrow></msubsup><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mi>&amp;#x03C3;</mi><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo>&amp;#x22C5;</mo><msub><mi>W</mi><mn>1</mn></msub><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>:</mo><msub><mi>m</mi><mi>i</mi></msub><msup><mo stretchy=&quot;false&quot;>]</mo><mi mathvariant=&quot;normal&quot;>&amp;#x22A4;</mi></msup><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x22C5;</mo><msub><mi>W</mi><mn>2</mn></msub><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>:</mo><msub><mi>m</mi><mi>i</mi></msub><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-67\" style=\"width: 20.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1017.24em, 2.711em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-68\"><span class=\"msubsup\" id=\"MathJax-Span-69\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-70\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.36em, 4.169em, -999.997em); top: -4.372em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-71\"><span class=\"mrow\" id=\"MathJax-Span-72\"><span class=\"mtext\" id=\"MathJax-Span-73\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">FFN</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -3.695em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-74\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-75\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-76\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-77\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-78\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-79\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-80\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-81\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-82\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-83\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-84\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-85\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-86\" style=\"font-family: STIXGeneral-Regular;\">[</span><span class=\"mn\" id=\"MathJax-Span-87\" style=\"font-family: STIXGeneral-Regular;\">0</span><span class=\"mo\" id=\"MathJax-Span-88\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">:</span><span class=\"msubsup\" id=\"MathJax-Span-89\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-90\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-91\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-92\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.26em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-93\" style=\"font-family: STIXGeneral-Regular;\">]</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.315em;\"><span class=\"mi\" id=\"MathJax-Span-94\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">⊤</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-95\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-96\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"msubsup\" id=\"MathJax-Span-97\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-98\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-99\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-100\" style=\"font-family: STIXGeneral-Regular;\">[</span><span class=\"mn\" id=\"MathJax-Span-101\" style=\"font-family: STIXGeneral-Regular;\">0</span><span class=\"mo\" id=\"MathJax-Span-102\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">:</span><span class=\"msubsup\" id=\"MathJax-Span-103\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-104\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-105\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-106\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.566em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msubsup><mi>T</mi><mi>i</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>FFN</mtext></mrow></msubsup><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo>⋅</mo><msub><mi>W</mi><mn>1</mn></msub><mo stretchy=\"false\">[</mo><mn>0</mn><mo>:</mo><msub><mi>m</mi><mi>i</mi></msub><msup><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">⊤</mi></msup><mo stretchy=\"false\">)</mo><mo>⋅</mo><msub><mi>W</mi><mn>2</mn></msub><mo stretchy=\"false\">[</mo><mn>0</mn><mo>:</mo><msub><mi>m</mi><mi>i</mi></msub><mo stretchy=\"false\">]</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-8\">T^{\\text{FFN}}_i(x) = \\sigma(x \\cdot W_1[0:m_i]^\\top) \\cdot W_2[0:m_i]</script>\n\n    <ul>\n      <li>where:\n        <ul>\n          <li>\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>x</mi><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>model</mtext></mrow></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-107\" style=\"width: 5.107em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.221em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1004.22em, 2.451em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-108\"><span class=\"mi\" id=\"MathJax-Span-109\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-110\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-111\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.503em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-112\"><span class=\"mrow\" id=\"MathJax-Span-113\"><span class=\"mi\" id=\"MathJax-Span-114\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-115\"><span class=\"mrow\" id=\"MathJax-Span-116\"><span class=\"msubsup\" id=\"MathJax-Span-117\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-118\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-119\"><span class=\"mrow\" id=\"MathJax-Span-120\"><span class=\"mtext\" id=\"MathJax-Span-121\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">model</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>x</mi><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>model</mtext></mrow></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-9\">x \\in \\mathbb{R}^{d_{\\text{model}}}</script>\n          </li>\n          <li>\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>W</mi><mn>1</mn></msub><mo>,</mo><msub><mi>W</mi><mn>2</mn></msub><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>ff</mtext></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>model</mtext></mrow></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-122\" style=\"width: 9.378em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.815em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1007.82em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-123\"><span class=\"msubsup\" id=\"MathJax-Span-124\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-125\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-126\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-127\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-128\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-129\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-130\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-131\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-132\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.648em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-133\"><span class=\"mrow\" id=\"MathJax-Span-134\"><span class=\"mi\" id=\"MathJax-Span-135\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-136\"><span class=\"mrow\" id=\"MathJax-Span-137\"><span class=\"msubsup\" id=\"MathJax-Span-138\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-139\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-140\"><span class=\"mrow\" id=\"MathJax-Span-141\"><span class=\"mtext\" id=\"MathJax-Span-142\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">ff</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-143\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-144\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-145\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-146\"><span class=\"mrow\" id=\"MathJax-Span-147\"><span class=\"mtext\" id=\"MathJax-Span-148\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">model</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>W</mi><mn>1</mn></msub><mo>,</mo><msub><mi>W</mi><mn>2</mn></msub><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>ff</mtext></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>model</mtext></mrow></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-10\">W_1, W_2 \\in \\mathbb{R}^{d_{\\text{ff}} \\times d_{\\text{model}}}</script>\n          </li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03C3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-149\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-150\"><span class=\"mi\" id=\"MathJax-Span-151\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>σ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-11\">\\sigma</script> is a nonlinearity, such as GELU or squared ReLU</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>:</mo><msub><mi>m</mi><mi>i</mi></msub><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-152\" style=\"width: 4.898em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.065em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.96em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-153\"><span class=\"mi\" id=\"MathJax-Span-154\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-155\" style=\"font-family: STIXGeneral-Regular;\">[</span><span class=\"mn\" id=\"MathJax-Span-156\" style=\"font-family: STIXGeneral-Regular;\">0</span><span class=\"mo\" id=\"MathJax-Span-157\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">:</span><span class=\"msubsup\" id=\"MathJax-Span-158\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-159\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-160\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-161\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>W</mi><mo stretchy=\"false\">[</mo><mn>0</mn><mo>:</mo><msub><mi>m</mi><mi>i</mi></msub><mo stretchy=\"false\">]</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">W[0:m_i]</script> denotes selecting the top <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>m</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-162\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-163\"><span class=\"msubsup\" id=\"MathJax-Span-164\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-165\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-166\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>m</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">m_i</script> rows from weight matrix <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-14-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-167\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.99em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-168\"><span class=\"mi\" id=\"MathJax-Span-169\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>W</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-14\">W</script></li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>In practice, exponentially spaced FFN ratios are used:</li>\n</ul>\n<p>The MatFormer architecture in Gemma 3n incorporates a nested structure within the Transformer block’s feedforward network (FFN), enabling dynamic submodel scaling during inference without incurring additional training costs.</p>\n<p>MatFormer builds a hierarchy of Transformer blocks:</p>\n<ul>\n      <li>where each block <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-2-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-16\" style=\"width: 1.044em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.84em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-17\"><span class=\"msubsup\" id=\"MathJax-Span-18\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-19\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-20\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-2\">T_i</script> shares parameters with its supersets, enabling parameter reuse and minimizing overhead. This design is centered in the FFN block, which is the primary contributor to a Transformer’s computational and memory demands—often accounting for over 60% of resource use in large language and vision models.</li>\n    </ul>\n<ul>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-3-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>model</mtext></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-21\" style=\"width: 2.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1002.35em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-22\"><span class=\"msubsup\" id=\"MathJax-Span-23\"><span style=\"display: inline-block; position: relative; width: 2.346em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-24\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-25\"><span class=\"mrow\" id=\"MathJax-Span-26\"><span class=\"mtext\" id=\"MathJax-Span-27\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">model</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>model</mtext></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-3\">d_{\\text{model}}</script> be the model’s hidden dimension</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-4-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>ff</mtext></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-28\" style=\"width: 1.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.04em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-29\"><span class=\"msubsup\" id=\"MathJax-Span-30\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-31\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-32\"><span class=\"mrow\" id=\"MathJax-Span-33\"><span class=\"mtext\" id=\"MathJax-Span-34\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">ff</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>ff</mtext></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-4\">d_{\\text{ff}}</script> be the width of the FFN layer</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-5-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-35\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-36\"><span class=\"mi\" id=\"MathJax-Span-37\" style=\"font-family: STIXGeneral-Italic;\">g</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-5\">g</script> be the number of granularities (typically 4)</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-6-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>m</mi><mn>1</mn></msub><mo>&amp;lt;</mo><msub><mi>m</mi><mn>2</mn></msub><mo>&amp;lt;</mo><mo>&amp;#x22EF;</mo><mo>&amp;lt;</mo><msub><mi>m</mi><mi>g</mi></msub><mo>=</mo><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>ff</mtext></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-38\" style=\"width: 12.346em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.263em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1010.26em, 2.867em, -999.997em); top: -2.393em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-39\"><span class=\"msubsup\" id=\"MathJax-Span-40\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-41\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mn\" id=\"MathJax-Span-42\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-43\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">&lt;</span><span class=\"msubsup\" id=\"MathJax-Span-44\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-45\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mn\" id=\"MathJax-Span-46\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-47\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">&lt;</span><span class=\"mo\" id=\"MathJax-Span-48\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">⋯</span><span class=\"mo\" id=\"MathJax-Span-49\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">&lt;</span><span class=\"msubsup\" id=\"MathJax-Span-50\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-51\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-52\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-53\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"msubsup\" id=\"MathJax-Span-54\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-55\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-56\"><span class=\"mrow\" id=\"MathJax-Span-57\"><span class=\"mtext\" id=\"MathJax-Span-58\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">ff</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.398em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>m</mi><mn>1</mn></msub><mo>&lt;</mo><msub><mi>m</mi><mn>2</mn></msub><mo>&lt;</mo><mo>⋯</mo><mo>&lt;</mo><msub><mi>m</mi><mi>g</mi></msub><mo>=</mo><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>ff</mtext></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-6\">m_1 < m_2 < \\cdots < m_g = d_{\\text{ff}}</script> be the neuron counts for each submodel</li>\n    </ul>\n<p>The FFN function for the <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-7-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>i</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>h</mi></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-59\" style=\"width: 1.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1000.94em, 2.294em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-60\"><span class=\"msubsup\" id=\"MathJax-Span-61\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.26em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-62\" style=\"font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.263em;\"><span class=\"texatom\" id=\"MathJax-Span-63\"><span class=\"mrow\" id=\"MathJax-Span-64\"><span class=\"mi\" id=\"MathJax-Span-65\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-66\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>i</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>t</mi><mi>h</mi></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-7\">i^{th}</script> submodel is:</p>\n<ul>\n      <li>where:\n        <ul>\n          <li>\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>x</mi><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>model</mtext></mrow></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-107\" style=\"width: 5.107em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.221em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1004.22em, 2.451em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-108\"><span class=\"mi\" id=\"MathJax-Span-109\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-110\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-111\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.503em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-112\"><span class=\"mrow\" id=\"MathJax-Span-113\"><span class=\"mi\" id=\"MathJax-Span-114\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-115\"><span class=\"mrow\" id=\"MathJax-Span-116\"><span class=\"msubsup\" id=\"MathJax-Span-117\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-118\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-119\"><span class=\"mrow\" id=\"MathJax-Span-120\"><span class=\"mtext\" id=\"MathJax-Span-121\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">model</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>x</mi><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>model</mtext></mrow></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-9\">x \\in \\mathbb{R}^{d_{\\text{model}}}</script>\n          </li>\n          <li>\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>W</mi><mn>1</mn></msub><mo>,</mo><msub><mi>W</mi><mn>2</mn></msub><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>ff</mtext></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>model</mtext></mrow></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-122\" style=\"width: 9.378em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.815em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1007.82em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-123\"><span class=\"msubsup\" id=\"MathJax-Span-124\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-125\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-126\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-127\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-128\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-129\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-130\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-131\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-132\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.648em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-133\"><span class=\"mrow\" id=\"MathJax-Span-134\"><span class=\"mi\" id=\"MathJax-Span-135\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-136\"><span class=\"mrow\" id=\"MathJax-Span-137\"><span class=\"msubsup\" id=\"MathJax-Span-138\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-139\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-140\"><span class=\"mrow\" id=\"MathJax-Span-141\"><span class=\"mtext\" id=\"MathJax-Span-142\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">ff</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-143\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-144\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-145\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-146\"><span class=\"mrow\" id=\"MathJax-Span-147\"><span class=\"mtext\" id=\"MathJax-Span-148\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">model</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>W</mi><mn>1</mn></msub><mo>,</mo><msub><mi>W</mi><mn>2</mn></msub><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>ff</mtext></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>model</mtext></mrow></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-10\">W_1, W_2 \\in \\mathbb{R}^{d_{\\text{ff}} \\times d_{\\text{model}}}</script>\n          </li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03C3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-149\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-150\"><span class=\"mi\" id=\"MathJax-Span-151\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>σ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-11\">\\sigma</script> is a nonlinearity, such as GELU or squared ReLU</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>:</mo><msub><mi>m</mi><mi>i</mi></msub><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-152\" style=\"width: 4.898em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.065em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.96em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-153\"><span class=\"mi\" id=\"MathJax-Span-154\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-155\" style=\"font-family: STIXGeneral-Regular;\">[</span><span class=\"mn\" id=\"MathJax-Span-156\" style=\"font-family: STIXGeneral-Regular;\">0</span><span class=\"mo\" id=\"MathJax-Span-157\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">:</span><span class=\"msubsup\" id=\"MathJax-Span-158\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-159\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-160\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-161\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>W</mi><mo stretchy=\"false\">[</mo><mn>0</mn><mo>:</mo><msub><mi>m</mi><mi>i</mi></msub><mo stretchy=\"false\">]</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">W[0:m_i]</script> denotes selecting the top <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>m</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-162\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-163\"><span class=\"msubsup\" id=\"MathJax-Span-164\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-165\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-166\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>m</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">m_i</script> rows from weight matrix <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-14-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-167\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.99em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-168\"><span class=\"mi\" id=\"MathJax-Span-169\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>W</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-14\">W</script></li>\n        </ul>\n      </li>\n    </ul>\n<ul>\n          <li>\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>x</mi><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>model</mtext></mrow></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-107\" style=\"width: 5.107em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.221em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1004.22em, 2.451em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-108\"><span class=\"mi\" id=\"MathJax-Span-109\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-110\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-111\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 2.503em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-112\"><span class=\"mrow\" id=\"MathJax-Span-113\"><span class=\"mi\" id=\"MathJax-Span-114\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-115\"><span class=\"mrow\" id=\"MathJax-Span-116\"><span class=\"msubsup\" id=\"MathJax-Span-117\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-118\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-119\"><span class=\"mrow\" id=\"MathJax-Span-120\"><span class=\"mtext\" id=\"MathJax-Span-121\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">model</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>x</mi><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>model</mtext></mrow></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-9\">x \\in \\mathbb{R}^{d_{\\text{model}}}</script>\n          </li>\n          <li>\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>W</mi><mn>1</mn></msub><mo>,</mo><msub><mi>W</mi><mn>2</mn></msub><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>ff</mtext></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>model</mtext></mrow></msub></mrow></msup></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-122\" style=\"width: 9.378em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.815em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1007.82em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-123\"><span class=\"msubsup\" id=\"MathJax-Span-124\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-125\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-126\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-127\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-128\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-129\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-130\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-131\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">∈</span><span class=\"msubsup\" id=\"MathJax-Span-132\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 3.648em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-133\"><span class=\"mrow\" id=\"MathJax-Span-134\"><span class=\"mi\" id=\"MathJax-Span-135\" style=\"font-family: STIXGeneral-Regular;\">ℝ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-136\"><span class=\"mrow\" id=\"MathJax-Span-137\"><span class=\"msubsup\" id=\"MathJax-Span-138\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-139\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-140\"><span class=\"mrow\" id=\"MathJax-Span-141\"><span class=\"mtext\" id=\"MathJax-Span-142\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">ff</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-143\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-144\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.37em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-145\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-146\"><span class=\"mrow\" id=\"MathJax-Span-147\"><span class=\"mtext\" id=\"MathJax-Span-148\" style=\"font-size: 50%; font-family: STIXGeneral-Regular;\">model</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>W</mi><mn>1</mn></msub><mo>,</mo><msub><mi>W</mi><mn>2</mn></msub><mo>∈</mo><msup><mrow class=\"MJX-TeXAtom-ORD\"><mi mathvariant=\"double-struck\">R</mi></mrow><mrow class=\"MJX-TeXAtom-ORD\"><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>ff</mtext></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>model</mtext></mrow></msub></mrow></msup></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-10\">W_1, W_2 \\in \\mathbb{R}^{d_{\\text{ff}} \\times d_{\\text{model}}}</script>\n          </li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03C3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-149\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-150\"><span class=\"mi\" id=\"MathJax-Span-151\" style=\"font-family: STIXGeneral-Italic;\">σ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.628em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>σ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-11\">\\sigma</script> is a nonlinearity, such as GELU or squared ReLU</li>\n          <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>:</mo><msub><mi>m</mi><mi>i</mi></msub><mo stretchy=&quot;false&quot;>]</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-152\" style=\"width: 4.898em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.065em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.96em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-153\"><span class=\"mi\" id=\"MathJax-Span-154\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-155\" style=\"font-family: STIXGeneral-Regular;\">[</span><span class=\"mn\" id=\"MathJax-Span-156\" style=\"font-family: STIXGeneral-Regular;\">0</span><span class=\"mo\" id=\"MathJax-Span-157\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">:</span><span class=\"msubsup\" id=\"MathJax-Span-158\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-159\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-160\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-161\" style=\"font-family: STIXGeneral-Regular;\">]</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>W</mi><mo stretchy=\"false\">[</mo><mn>0</mn><mo>:</mo><msub><mi>m</mi><mi>i</mi></msub><mo stretchy=\"false\">]</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">W[0:m_i]</script> denotes selecting the top <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>m</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-162\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-163\"><span class=\"msubsup\" id=\"MathJax-Span-164\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-165\" style=\"font-family: STIXGeneral-Italic;\">m</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"mi\" id=\"MathJax-Span-166\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>m</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">m_i</script> rows from weight matrix <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-14-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-167\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.99em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-168\"><span class=\"mi\" id=\"MathJax-Span-169\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>W</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-14\">W</script></li>\n        </ul>\n<div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-15-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mrow><mo>{</mo><mrow><mfrac><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>ff</mtext></mrow></msub><mn>8</mn></mfrac><mo>,</mo><mfrac><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>ff</mtext></mrow></msub><mn>4</mn></mfrac><mo>,</mo><mfrac><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>ff</mtext></mrow></msub><mn>2</mn></mfrac><mo>,</mo><msub><mi>d</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>ff</mtext></mrow></msub></mrow><mo>}</mo></mrow></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-170\" style=\"width: 9.794em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.128em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(2.294em, 1007.97em, 4.742em, -999.997em); top: -3.799em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-171\"><span class=\"mrow\" id=\"MathJax-Span-172\"><span class=\"mo\" id=\"MathJax-Span-173\" style=\"vertical-align: -0.466em;\"><span><span style=\"font-size: 111%; font-family: STIXSizeTwoSym;\">{</span></span></span><span class=\"mrow\" id=\"MathJax-Span-174\"><span class=\"mfrac\" id=\"MathJax-Span-175\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.18em, 1001.04em, 4.326em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.518em;\"><span class=\"msubsup\" id=\"MathJax-Span-176\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-177\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-178\"><span class=\"mrow\" id=\"MathJax-Span-179\"><span class=\"mtext\" id=\"MathJax-Span-180\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">ff</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.258em;\"><span class=\"mn\" id=\"MathJax-Span-181\" style=\"font-family: STIXGeneral-Regular;\">8</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-182\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mfrac\" id=\"MathJax-Span-183\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.18em, 1001.04em, 4.326em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.518em;\"><span class=\"msubsup\" id=\"MathJax-Span-184\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-185\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-186\"><span class=\"mrow\" id=\"MathJax-Span-187\"><span class=\"mtext\" id=\"MathJax-Span-188\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">ff</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.258em;\"><span class=\"mn\" id=\"MathJax-Span-189\" style=\"font-family: STIXGeneral-Regular;\">4</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-190\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mfrac\" id=\"MathJax-Span-191\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px; margin-right: 0.107em; margin-left: 0.107em;\"><span style=\"position: absolute; clip: rect(3.18em, 1001.04em, 4.326em, -999.997em); top: -4.685em; left: 50%; margin-left: -0.518em;\"><span class=\"msubsup\" id=\"MathJax-Span-192\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-193\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-194\"><span class=\"mrow\" id=\"MathJax-Span-195\"><span class=\"mtext\" id=\"MathJax-Span-196\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">ff</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -3.331em; left: 50%; margin-left: -0.258em;\"><span class=\"mn\" id=\"MathJax-Span-197\" style=\"font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(0.836em, 1001.15em, 1.201em, -999.997em); top: -1.247em; left: 0em;\"><span style=\"display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.148em; height: 0px;\"></span><span style=\"display: inline-block; width: 0px; height: 1.044em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-198\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-199\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.044em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-200\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-201\"><span class=\"mrow\" id=\"MathJax-Span-202\"><span class=\"mtext\" id=\"MathJax-Span-203\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">ff</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-204\" style=\"vertical-align: -0.466em;\"><span><span style=\"font-size: 111%; font-family: STIXSizeTwoSym;\">}</span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 3.805em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.997em; border-left: 0px solid; width: 0px; height: 2.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mrow><mo>{</mo><mrow><mfrac><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>ff</mtext></mrow></msub><mn>8</mn></mfrac><mo>,</mo><mfrac><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>ff</mtext></mrow></msub><mn>4</mn></mfrac><mo>,</mo><mfrac><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>ff</mtext></mrow></msub><mn>2</mn></mfrac><mo>,</mo><msub><mi>d</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>ff</mtext></mrow></msub></mrow><mo>}</mo></mrow></math></span></span></div>\n<ul>\n  <li>\n    <p>This allows efficient sharing and ensures that the smallest submodel receives the most frequent gradient updates, enhancing training stability and representational consistency across granularities.</p>\n  </li>\n  <li>\n    <p>Each submodel <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-16-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>M</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-205\" style=\"width: 1.357em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.1em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-206\"><span class=\"msubsup\" id=\"MathJax-Span-207\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-208\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-209\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>M</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-16\">M_i</script> is built by stacking <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-210\" style=\"width: 1.044em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.84em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-211\"><span class=\"msubsup\" id=\"MathJax-Span-212\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-213\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-214\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-17\">T_i</script> across all layers:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>M</mi><mi>i</mi></msub><mo>=</mo><mo stretchy=&quot;false&quot;>[</mo><msub><mi>T</mi><mi>i</mi></msub><msup><mo stretchy=&quot;false&quot;>]</mo><mi>&amp;#x2113;</mi></msup><mo>,</mo><mspace width=&quot;1em&quot; /><mtext>for&amp;#xA0;</mtext><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><mi>g</mi></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-215\" style=\"width: 14.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 11.93em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1011.88em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-216\"><span class=\"msubsup\" id=\"MathJax-Span-217\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-219\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-220\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mo\" id=\"MathJax-Span-221\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">[</span><span class=\"msubsup\" id=\"MathJax-Span-222\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-223\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-224\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-225\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.26em, 4.326em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mo\" id=\"MathJax-Span-226\" style=\"font-family: STIXGeneral-Regular;\">]</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.315em;\"><span class=\"mi\" id=\"MathJax-Span-227\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">ℓ</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-228\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mspace\" id=\"MathJax-Span-229\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"mtext\" id=\"MathJax-Span-230\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">for&nbsp;</span><span class=\"mi\" id=\"MathJax-Span-231\" style=\"font-family: STIXGeneral-Italic;\">i</span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-233\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1</span><span class=\"mo\" id=\"MathJax-Span-234\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-235\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-236\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"mi\" id=\"MathJax-Span-237\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">g</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.441em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>M</mi><mi>i</mi></msub><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>T</mi><mi>i</mi></msub><msup><mo stretchy=\"false\">]</mo><mi>ℓ</mi></msup><mo>,</mo><mspace width=\"1em\"></mspace><mtext>for&nbsp;</mtext><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>g</mi></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-18\">M_i = [T_i]^\\ell, \\quad \\text{for } i = 1, \\ldots, g</script>\n\n    <ul>\n      <li>with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x2113;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-238\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-239\"><span class=\"mi\" id=\"MathJax-Span-240\" style=\"font-family: STIXGeneral-Italic;\">ℓ</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ℓ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-19\">\\ell</script> being the total number of Transformer layers.</li>\n    </ul>\n  </li>\n</ul>\n<p>This allows efficient sharing and ensures that the smallest submodel receives the most frequent gradient updates, enhancing training stability and representational consistency across granularities.</p>\n<p>Each submodel <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-16-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>M</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-205\" style=\"width: 1.357em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.1em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-206\"><span class=\"msubsup\" id=\"MathJax-Span-207\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-208\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-209\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>M</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-16\">M_i</script> is built by stacking <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-210\" style=\"width: 1.044em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.84em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-211\"><span class=\"msubsup\" id=\"MathJax-Span-212\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-213\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-214\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-17\">T_i</script> across all layers:</p>\n<ul>\n      <li>with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x2113;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-238\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-239\"><span class=\"mi\" id=\"MathJax-Span-240\" style=\"font-family: STIXGeneral-Italic;\">ℓ</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ℓ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-19\">\\ell</script> being the total number of Transformer layers.</li>\n    </ul>",
    "contentMarkdown": "*   The [Matryoshka Transformer (MatFormer)](https://ai.google.dev/gemma/docs/gemma-3n#matformer) architecture, proposed in [MatFormer: Nested Transformer for Elastic Inference](https://arxiv.org/abs/2310.07707) by Devvrit et al. (2024), is central to Gemma 3n’s compute-efficiency. Inspired by Matryoshka dolls, it enables a larger model to contain smaller, independently usable submodels with no retraining or architecture changes required.\n    \n*   In Gemma 3n, MatFormer is the key to **elastic inference**: a single trained model (e.g., E4B) includes within it a lightweight, independently usable E2B model—and developers can also interpolate sizes between these via the Mix’n’Match method.\n    \n\nThe [Matryoshka Transformer (MatFormer)](https://ai.google.dev/gemma/docs/gemma-3n#matformer) architecture, proposed in [MatFormer: Nested Transformer for Elastic Inference](https://arxiv.org/abs/2310.07707) by Devvrit et al. (2024), is central to Gemma 3n’s compute-efficiency. Inspired by Matryoshka dolls, it enables a larger model to contain smaller, independently usable submodels with no retraining or architecture changes required.\n\nIn Gemma 3n, MatFormer is the key to **elastic inference**: a single trained model (e.g., E4B) includes within it a lightweight, independently usable E2B model—and developers can also interpolate sizes between these via the Mix’n’Match method.\n\n#### Nested FFN Block Design\n\n*   The MatFormer architecture in Gemma 3n incorporates a nested structure within the Transformer block’s feedforward network (FFN), enabling dynamic submodel scaling during inference without incurring additional training costs.\n    \n*   MatFormer builds a hierarchy of Transformer blocks:\n    \n    T1⊂T2⊂⋯⊂TgT1⊂T2⊂⋯⊂Tg\n    \n    T\\_1 \\\\subset T\\_2 \\\\subset \\\\cdots \\\\subset T\\_g\n    *   where each block TiTiT\\_i shares parameters with its supersets, enabling parameter reuse and minimizing overhead. This design is centered in the FFN block, which is the primary contributor to a Transformer’s computational and memory demands—often accounting for over 60% of resource use in large language and vision models.\n*   Let:\n    *   dmodeldmodeld\\_{\\\\text{model}} be the model’s hidden dimension\n    *   dffdffd\\_{\\\\text{ff}} be the width of the FFN layer\n    *   ggg be the number of granularities (typically 4)\n    *   m1<m2<⋯<mg\\=dffm1<m2<⋯<mg\\=dffm\\_1 < m\\_2 < \\\\cdots < m\\_g = d\\_{\\\\text{ff}} be the neuron counts for each submodel\n*   The FFN function for the ithithi^{th} submodel is:\n    \n    TFFNi(x)\\=σ(x⋅W1\\[0:mi\\]⊤)⋅W2\\[0:mi\\]TiFFN(x)\\=σ(x⋅W1\\[0:mi\\]⊤)⋅W2\\[0:mi\\]\n    \n    T^{\\\\text{FFN}}\\_i(x) = \\\\sigma(x \\\\cdot W\\_1\\[0:m\\_i\\]^\\\\top) \\\\cdot W\\_2\\[0:m\\_i\\]\n    *   where:\n        *   x∈ℝdmodelx∈Rdmodel\n            \n            x \\\\in \\\\mathbb{R}^{d\\_{\\\\text{model}}}\n        *   W1,W2∈ℝdff×dmodelW1,W2∈Rdff×dmodel\n            \n            W\\_1, W\\_2 \\\\in \\\\mathbb{R}^{d\\_{\\\\text{ff}} \\\\times d\\_{\\\\text{model}}}\n        *   σσ\\\\sigma is a nonlinearity, such as GELU or squared ReLU\n        *   W\\[0:mi\\]W\\[0:mi\\]W\\[0:m\\_i\\] denotes selecting the top mimim\\_i rows from weight matrix WWW\n*   In practice, exponentially spaced FFN ratios are used:\n\nThe MatFormer architecture in Gemma 3n incorporates a nested structure within the Transformer block’s feedforward network (FFN), enabling dynamic submodel scaling during inference without incurring additional training costs.\n\nMatFormer builds a hierarchy of Transformer blocks:\n\n*   where each block TiTiT\\_i shares parameters with its supersets, enabling parameter reuse and minimizing overhead. This design is centered in the FFN block, which is the primary contributor to a Transformer’s computational and memory demands—often accounting for over 60% of resource use in large language and vision models.\n\n*   dmodeldmodeld\\_{\\\\text{model}} be the model’s hidden dimension\n*   dffdffd\\_{\\\\text{ff}} be the width of the FFN layer\n*   ggg be the number of granularities (typically 4)\n*   m1<m2<⋯<mg\\=dffm1<m2<⋯<mg\\=dffm\\_1 < m\\_2 < \\\\cdots < m\\_g = d\\_{\\\\text{ff}} be the neuron counts for each submodel\n\nThe FFN function for the ithithi^{th} submodel is:\n\n*   where:\n    *   x∈ℝdmodelx∈Rdmodel\n        \n        x \\\\in \\\\mathbb{R}^{d\\_{\\\\text{model}}}\n    *   W1,W2∈ℝdff×dmodelW1,W2∈Rdff×dmodel\n        \n        W\\_1, W\\_2 \\\\in \\\\mathbb{R}^{d\\_{\\\\text{ff}} \\\\times d\\_{\\\\text{model}}}\n    *   σσ\\\\sigma is a nonlinearity, such as GELU or squared ReLU\n    *   W\\[0:mi\\]W\\[0:mi\\]W\\[0:m\\_i\\] denotes selecting the top mimim\\_i rows from weight matrix WWW\n\n*   x∈ℝdmodelx∈Rdmodel\n    \n    x \\\\in \\\\mathbb{R}^{d\\_{\\\\text{model}}}\n*   W1,W2∈ℝdff×dmodelW1,W2∈Rdff×dmodel\n    \n    W\\_1, W\\_2 \\\\in \\\\mathbb{R}^{d\\_{\\\\text{ff}} \\\\times d\\_{\\\\text{model}}}\n*   σσ\\\\sigma is a nonlinearity, such as GELU or squared ReLU\n*   W\\[0:mi\\]W\\[0:mi\\]W\\[0:m\\_i\\] denotes selecting the top mimim\\_i rows from weight matrix WWW\n\n{dff8,dff4,dff2,dff}{dff8,dff4,dff2,dff}\n\n*   This allows efficient sharing and ensures that the smallest submodel receives the most frequent gradient updates, enhancing training stability and representational consistency across granularities.\n    \n*   Each submodel MiMiM\\_i is built by stacking TiTiT\\_i across all layers:\n    \n    Mi\\=\\[Ti\\]ℓ,for i\\=1,…,gMi\\=\\[Ti\\]ℓ,for i\\=1,…,g\n    \n    M\\_i = \\[T\\_i\\]^\\\\ell, \\\\quad \\\\text{for } i = 1, \\\\ldots, g\n    *   with ℓℓ\\\\ell being the total number of Transformer layers.\n\nThis allows efficient sharing and ensures that the smallest submodel receives the most frequent gradient updates, enhancing training stability and representational consistency across granularities.\n\nEach submodel MiMiM\\_i is built by stacking TiTiT\\_i across all layers:\n\n*   with ℓℓ\\\\ell being the total number of Transformer layers.",
    "order": 2,
    "orderInChapter": 2,
    "difficulty": 4,
    "estimatedMinutes": 4,
    "tags": [
      "models",
      "transformer"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 688,
      "contentLength": 124904
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/gemma-3n/#matryoshka-transformer-(matformer)-architecture",
    "scrapedAt": "2025-12-28T11:52:03.953Z"
  },
  {
    "id": "ai-gemma-3n-training-strategy-3",
    "domain": "ai_primers",
    "category": "Models",
    "article": "Gemma 3n",
    "articleSlug": "gemma-3n",
    "chapter": "Key Architectural Innovations",
    "title": "Training Strategy",
    "subtitle": "Key Architectural Innovations",
    "contentHtml": "<ul>\n  <li>The training process for MatFormer follows a lightweight and elegant sampling-based strategy. At each training step, one of the <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-20-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-241\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-242\"><span class=\"mi\" id=\"MathJax-Span-243\" style=\"font-family: STIXGeneral-Italic;\">g</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-20\">g</script> submodels is sampled randomly, and the corresponding parameters are updated via standard gradient descent.</li>\n  <li>\n    <p>Given a loss function <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-244\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-245\"><span class=\"mi\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">L</script>, the training objective becomes:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>L</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>sampling</mtext></mrow></msub><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mi>L</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>M</mi><mi>i</mi></msub><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo stretchy=&quot;false&quot;>)</mo><mo>,</mo><mi>y</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-247\" style=\"width: 13.284em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 11.044em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1010.99em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-248\"><span class=\"msubsup\" id=\"MathJax-Span-249\"><span style=\"display: inline-block; position: relative; width: 3.232em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"texatom\" id=\"MathJax-Span-251\"><span class=\"mrow\" id=\"MathJax-Span-252\"><span class=\"mtext\" id=\"MathJax-Span-253\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">sampling</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-255\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-256\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-257\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">y</span><span class=\"mo\" id=\"MathJax-Span-258\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-259\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-260\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-261\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-262\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-263\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-264\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-265\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-266\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-267\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-268\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-269\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">y</span><span class=\"mo\" id=\"MathJax-Span-270\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>L</mi><mrow class=\"MJX-TeXAtom-ORD\"><mtext>sampling</mtext></mrow></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>L</mi><mo stretchy=\"false\">(</mo><msub><mi>M</mi><mi>i</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-22\">L_{\\text{sampling}}(x, y) = L(M_i(x), y)</script>\n\n    <ul>\n      <li>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>M</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-271\" style=\"width: 1.357em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.1em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-272\"><span class=\"msubsup\" id=\"MathJax-Span-273\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-274\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-275\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>M</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-23\">M_i</script> is chosen uniformly at random from the nested submodels <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>{</mo><msub><mi>M</mi><mn>1</mn></msub><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><msub><mi>M</mi><mi>g</mi></msub><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>}</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-276\" style=\"width: 6.773em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.52em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-277\"><span class=\"mo\" id=\"MathJax-Span-278\" style=\"font-family: STIXGeneral-Regular;\">{</span><span class=\"msubsup\" id=\"MathJax-Span-279\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-280\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-281\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-282\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-283\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-284\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-285\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-286\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-287\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-288\" style=\"font-family: STIXGeneral-Regular;\">}</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo fence=\"false\" stretchy=\"false\">{</mo><msub><mi>M</mi><mn>1</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>M</mi><mi>g</mi></msub><mo fence=\"false\" stretchy=\"false\">}</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">\\{M_1, \\ldots, M_g\\}</script>. While uniform sampling is used in most settings, tuning the sampling distribution <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>{</mo><msub><mi>p</mi><mn>1</mn></msub><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><msub><mi>p</mi><mi>g</mi></msub><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>}</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-289\" style=\"width: 6.044em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.003em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.9em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-290\"><span class=\"mo\" id=\"MathJax-Span-291\" style=\"font-family: STIXGeneral-Regular;\">{</span><span class=\"msubsup\" id=\"MathJax-Span-292\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-293\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-294\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-295\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-296\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-297\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-298\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-299\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-300\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-301\" style=\"font-family: STIXGeneral-Regular;\">}</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo fence=\"false\" stretchy=\"false\">{</mo><msub><mi>p</mi><mn>1</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>p</mi><mi>g</mi></msub><mo fence=\"false\" stretchy=\"false\">}</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">\\{p_1, \\ldots, p_g\\}</script> can yield performance gains—though even simple uniform distributions result in strong submodel accuracy.</li>\n    </ul>\n  </li>\n  <li>\n    <p>This design ensures that:</p>\n\n    <ol>\n      <li>Shared parameters across models are updated frequently.</li>\n      <li>Smaller submodels receive more updates due to their inclusion in every larger submodel.</li>\n      <li>All submodels are jointly trained with no additional memory overhead.</li>\n    </ol>\n  </li>\n  <li>The result is a single, universal model <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-26-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>M</mi><mi>g</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-302\" style=\"width: 1.513em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.25em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-303\"><span class=\"msubsup\" id=\"MathJax-Span-304\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-305\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-306\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>M</mi><mi>g</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-26\">M_g</script> that embeds all submodels <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-27-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>{</mo><msub><mi>M</mi><mn>1</mn></msub><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><msub><mi>M</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>g</mi><mo>&amp;#x2212;</mo><mn>1</mn></mrow></msub><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>}</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-307\" style=\"width: 7.763em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.461em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.36em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-308\"><span class=\"mo\" id=\"MathJax-Span-309\" style=\"font-family: STIXGeneral-Regular;\">{</span><span class=\"msubsup\" id=\"MathJax-Span-310\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-311\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-312\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-313\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-314\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-315\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-316\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-317\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-318\"><span class=\"mrow\" id=\"MathJax-Span-319\"><span class=\"mi\" id=\"MathJax-Span-320\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">g</span><span class=\"mo\" id=\"MathJax-Span-321\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-322\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-323\" style=\"font-family: STIXGeneral-Regular;\">}</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo fence=\"false\" stretchy=\"false\">{</mo><msub><mi>M</mi><mn>1</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>M</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>g</mi><mo>−</mo><mn>1</mn></mrow></msub><mo fence=\"false\" stretchy=\"false\">}</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-27\">\\{M_1, \\ldots, M_{g-1}\\}</script> within itself—without the need for post-hoc pruning, distillation, or retraining.</li>\n</ul>\n<p>Given a loss function <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-244\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-245\"><span class=\"mi\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">L</script>, the training objective becomes:</p>\n<ul>\n      <li>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>M</mi><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-271\" style=\"width: 1.357em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.1em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-272\"><span class=\"msubsup\" id=\"MathJax-Span-273\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-274\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-275\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>M</mi><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-23\">M_i</script> is chosen uniformly at random from the nested submodels <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>{</mo><msub><mi>M</mi><mn>1</mn></msub><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><msub><mi>M</mi><mi>g</mi></msub><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>}</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-276\" style=\"width: 6.773em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.52em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-277\"><span class=\"mo\" id=\"MathJax-Span-278\" style=\"font-family: STIXGeneral-Regular;\">{</span><span class=\"msubsup\" id=\"MathJax-Span-279\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-280\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-281\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-282\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-283\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-284\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-285\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-286\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-287\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-288\" style=\"font-family: STIXGeneral-Regular;\">}</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo fence=\"false\" stretchy=\"false\">{</mo><msub><mi>M</mi><mn>1</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>M</mi><mi>g</mi></msub><mo fence=\"false\" stretchy=\"false\">}</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">\\{M_1, \\ldots, M_g\\}</script>. While uniform sampling is used in most settings, tuning the sampling distribution <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>{</mo><msub><mi>p</mi><mn>1</mn></msub><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><msub><mi>p</mi><mi>g</mi></msub><mo fence=&quot;false&quot; stretchy=&quot;false&quot;>}</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-289\" style=\"width: 6.044em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.003em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.9em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-290\"><span class=\"mo\" id=\"MathJax-Span-291\" style=\"font-family: STIXGeneral-Regular;\">{</span><span class=\"msubsup\" id=\"MathJax-Span-292\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-293\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mn\" id=\"MathJax-Span-294\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-295\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-296\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-297\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-298\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-299\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-300\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-301\" style=\"font-family: STIXGeneral-Regular;\">}</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo fence=\"false\" stretchy=\"false\">{</mo><msub><mi>p</mi><mn>1</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>p</mi><mi>g</mi></msub><mo fence=\"false\" stretchy=\"false\">}</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">\\{p_1, \\ldots, p_g\\}</script> can yield performance gains—though even simple uniform distributions result in strong submodel accuracy.</li>\n    </ul>\n<p>This design ensures that:</p>\n<ol>\n      <li>Shared parameters across models are updated frequently.</li>\n      <li>Smaller submodels receive more updates due to their inclusion in every larger submodel.</li>\n      <li>All submodels are jointly trained with no additional memory overhead.</li>\n    </ol>\n<h4 id=\"mixnmatch-inference\">Mix’n’Match Inference</h4>\n<ul>\n  <li>\n    <p>Mix’n’Match Inference is a key feature enabled by the Matryoshka Transformer (MatFormer) architecture used in Gemma 3n. It allows developers to dynamically create hybrid submodels during inference by mixing granularities across different Transformer layers. While only a small number of submodels are explicitly optimized during training (typically 4, corresponding to different FFN widths), the nesting structure allows the formation of exponentially more configurations post-training.</p>\n  </li>\n  <li><strong>Submodel Construction</strong>:\n    <ul>\n      <li>Instead of uniformly stacking one of the predefined granularities across all layers (e.g., using only <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-28-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mn>2</mn></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-324\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-325\"><span class=\"msubsup\" id=\"MathJax-Span-326\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-327\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-328\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mn>2</mn></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-28\">T_2</script> in every layer to build model <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-29-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>M</mi><mn>2</mn></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-329\" style=\"width: 1.513em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.25em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-330\"><span class=\"msubsup\" id=\"MathJax-Span-331\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-332\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-333\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>M</mi><mn>2</mn></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-29\">M_2</script>), Mix’n’Match selects different granularities for each layer. For example, layer 1 could use <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mn>2</mn></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-334\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-335\"><span class=\"msubsup\" id=\"MathJax-Span-336\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-337\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-338\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mn>2</mn></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-30\">T_2</script>, layer 2 use <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mn>3</mn></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-339\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-340\"><span class=\"msubsup\" id=\"MathJax-Span-341\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-342\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-343\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">3</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mn>3</mn></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-31\">T_3</script>, and so on.</li>\n      <li>The following figure (<a href=\"https://arxiv.org/abs/2310.07707\">source</a>) illustrates the nested structure that MatFormer introduces into the Transformer’s FFN block &amp; trains all the submodels, enabling free extraction of hundreds of accurate submodels for elastic inference.</li>\n    </ul>\n\n    <p><img src=\"/primers/ai/assets/gemma-3n/MatFormer.jpg\" alt=\"Placeholder: Fig. 1 – MatFormer block with nested FFN submodels and example Mix’n’Match paths\"></p>\n  </li>\n  <li>\n    <p><strong>Exponential Flexibility</strong>: Given <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-344\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-345\"><span class=\"mi\" id=\"MathJax-Span-346\" style=\"font-family: STIXGeneral-Italic;\">g</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">g</script> granularities and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x2113;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-347\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-348\"><span class=\"mi\" id=\"MathJax-Span-349\" style=\"font-family: STIXGeneral-Italic;\">ℓ</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ℓ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">\\ell</script> Transformer layers, the total number of possible submodels that can be formed via Mix’n’Match is <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>g</mi><mi>&amp;#x2113;</mi></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-350\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1000.99em, 2.503em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-351\"><span class=\"msubsup\" id=\"MathJax-Span-352\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-353\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-354\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">ℓ</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>g</mi><mi>ℓ</mi></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">g^\\ell</script>. For instance, with 4 granularities and 24 layers, there are over 2.8 trillion possible configurations.</p>\n  </li>\n  <li><strong>Heuristic for Selection</strong>:\n    <ul>\n      <li>A simple yet effective strategy for choosing which submodel to use is the monotonically non-decreasing granularity heuristic. That is, the model uses equal or increasing granularity levels as it progresses deeper into the network. Mathematically,</li>\n    </ul>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-35-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>granularity</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>L</mi><mi>j</mi></msub><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2265;</mo><mtext>granularity</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>L</mi><mi>i</mi></msub><mo stretchy=&quot;false&quot;>)</mo><mspace width=&quot;1em&quot; /><mtext>for</mtext><mspace width=&quot;1em&quot; /><mi>j</mi><mo>&amp;gt;</mo><mi>i</mi></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-355\" style=\"width: 21.826em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 18.18em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1018.18em, 2.659em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-356\"><span class=\"mtext\" id=\"MathJax-Span-357\" style=\"font-family: STIXGeneral-Regular;\">granularity</span><span class=\"mo\" id=\"MathJax-Span-358\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-359\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-360\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-361\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-362\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-363\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≥</span><span class=\"mtext\" id=\"MathJax-Span-364\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">granularity</span><span class=\"mo\" id=\"MathJax-Span-365\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-366\"><span style=\"display: inline-block; position: relative; width: 0.836em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-367\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-368\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-369\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mspace\" id=\"MathJax-Span-370\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"mtext\" id=\"MathJax-Span-371\" style=\"font-family: STIXGeneral-Regular;\">for</span><span class=\"mspace\" id=\"MathJax-Span-372\" style=\"height: 0em; vertical-align: 0em; width: 1.148em; display: inline-block; overflow: hidden;\"></span><span class=\"mi\" id=\"MathJax-Span-373\" style=\"font-family: STIXGeneral-Italic;\">j<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-374\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">&gt;</span><span class=\"mi\" id=\"MathJax-Span-375\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">i</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mtext>granularity</mtext><mo stretchy=\"false\">(</mo><msub><mi>L</mi><mi>j</mi></msub><mo stretchy=\"false\">)</mo><mo>≥</mo><mtext>granularity</mtext><mo stretchy=\"false\">(</mo><msub><mi>L</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mspace width=\"1em\"></mspace><mtext>for</mtext><mspace width=\"1em\"></mspace><mi>j</mi><mo>&gt;</mo><mi>i</mi></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-35\">\\text{granularity}(L_j) \\geq \\text{granularity}(L_i) \\quad \\text{for} \\quad j > i</script>\n\n    <ul>\n      <li>This configuration aligns well with the training regime and tends to perform better than randomly mixed or non-monotonic configurations. Empirical results show that submodels formed this way maintain performance fidelity along the accuracy-compute tradeoff curve.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>No Additional Training Required</strong>: These hybrid submodels are not trained individually. However, because the MatFormer architecture trains the shared parameters across all granularities, the Mix’n’Match models inherit the robustness and consistency of the trained submodels, showing strong performance even when their exact configuration was not seen during training.</p>\n  </li>\n  <li>\n    <p><strong>Consistency and Deployment Benefits</strong>: The Mix’n’Match models maintain high output consistency with the full model (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>M</mi><mi>g</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-376\" style=\"width: 1.513em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.25em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-377\"><span class=\"msubsup\" id=\"MathJax-Span-378\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-379\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-380\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>M</mi><mi>g</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-36\">M_g</script>), making them ideal for techniques like speculative decoding, where draft models propose outputs and a larger model verifies them. This consistency helps minimize rollbacks and speeds up inference.</p>\n  </li>\n  <li><strong>Efficiency and Adaptability</strong>: In resource-constrained settings, such as on-device inference, Mix’n’Match allows the model to adapt dynamically to available memory or compute budgets, selecting a configuration that maximizes performance for the given constraints.</li>\n</ul>\n<p>Mix’n’Match Inference is a key feature enabled by the Matryoshka Transformer (MatFormer) architecture used in Gemma 3n. It allows developers to dynamically create hybrid submodels during inference by mixing granularities across different Transformer layers. While only a small number of submodels are explicitly optimized during training (typically 4, corresponding to different FFN widths), the nesting structure allows the formation of exponentially more configurations post-training.</p>\n<ul>\n      <li>Instead of uniformly stacking one of the predefined granularities across all layers (e.g., using only <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-28-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mn>2</mn></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-324\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-325\"><span class=\"msubsup\" id=\"MathJax-Span-326\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-327\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-328\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mn>2</mn></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-28\">T_2</script> in every layer to build model <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-29-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>M</mi><mn>2</mn></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-329\" style=\"width: 1.513em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.25em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-330\"><span class=\"msubsup\" id=\"MathJax-Span-331\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-332\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mn\" id=\"MathJax-Span-333\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>M</mi><mn>2</mn></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-29\">M_2</script>), Mix’n’Match selects different granularities for each layer. For example, layer 1 could use <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mn>2</mn></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-334\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-335\"><span class=\"msubsup\" id=\"MathJax-Span-336\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-337\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-338\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.066em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mn>2</mn></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-30\">T_2</script>, layer 2 use <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>T</mi><mn>3</mn></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-339\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1000.99em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-340\"><span class=\"msubsup\" id=\"MathJax-Span-341\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-342\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-343\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">3</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>T</mi><mn>3</mn></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-31\">T_3</script>, and so on.</li>\n      <li>The following figure (<a href=\"https://arxiv.org/abs/2310.07707\">source</a>) illustrates the nested structure that MatFormer introduces into the Transformer’s FFN block &amp; trains all the submodels, enabling free extraction of hundreds of accurate submodels for elastic inference.</li>\n    </ul>\n<p><img src=\"/primers/ai/assets/gemma-3n/MatFormer.jpg\" alt=\"Placeholder: Fig. 1 – MatFormer block with nested FFN submodels and example Mix’n’Match paths\"></p>\n<p><strong>Exponential Flexibility</strong>: Given <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-344\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-345\"><span class=\"mi\" id=\"MathJax-Span-346\" style=\"font-family: STIXGeneral-Italic;\">g</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">g</script> granularities and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x2113;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-347\" style=\"width: 0.576em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.47em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-348\"><span class=\"mi\" id=\"MathJax-Span-349\" style=\"font-family: STIXGeneral-Italic;\">ℓ</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>ℓ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">\\ell</script> Transformer layers, the total number of possible submodels that can be formed via Mix’n’Match is <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>g</mi><mi>&amp;#x2113;</mi></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-350\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1000.99em, 2.503em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-351\"><span class=\"msubsup\" id=\"MathJax-Span-352\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-353\" style=\"font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-354\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">ℓ</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>g</mi><mi>ℓ</mi></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">g^\\ell</script>. For instance, with 4 granularities and 24 layers, there are over 2.8 trillion possible configurations.</p>\n<ul>\n      <li>A simple yet effective strategy for choosing which submodel to use is the monotonically non-decreasing granularity heuristic. That is, the model uses equal or increasing granularity levels as it progresses deeper into the network. Mathematically,</li>\n    </ul>\n<ul>\n      <li>This configuration aligns well with the training regime and tends to perform better than randomly mixed or non-monotonic configurations. Empirical results show that submodels formed this way maintain performance fidelity along the accuracy-compute tradeoff curve.</li>\n    </ul>\n<p><strong>No Additional Training Required</strong>: These hybrid submodels are not trained individually. However, because the MatFormer architecture trains the shared parameters across all granularities, the Mix’n’Match models inherit the robustness and consistency of the trained submodels, showing strong performance even when their exact configuration was not seen during training.</p>\n<p><strong>Consistency and Deployment Benefits</strong>: The Mix’n’Match models maintain high output consistency with the full model (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>M</mi><mi>g</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-376\" style=\"width: 1.513em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.25em, 2.607em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-377\"><span class=\"msubsup\" id=\"MathJax-Span-378\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-379\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"mi\" id=\"MathJax-Span-380\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">g</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.434em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>M</mi><mi>g</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-36\">M_g</script>), making them ideal for techniques like speculative decoding, where draft models propose outputs and a larger model verifies them. This consistency helps minimize rollbacks and speeds up inference.</p>\n<h4 id=\"deployment-advantages\">Deployment Advantages</h4>\n<ul>\n  <li>\n    <p>The blog post introduces <strong>MatFormer Lab</strong>, a tool that helps developers experiment with custom submodel configurations between E2B and E4B. These configurations are evaluated on benchmarks like MMLU to find optimal slices for specific use cases (<a href=\"https://goo.gle/gemma3n-matformer-lab\">MatFormer Lab</a>).</p>\n  </li>\n  <li>\n    <p><strong>Two main deployment modes</strong> emerge:</p>\n\n    <ol>\n      <li><strong>Pre-extracted models</strong>: E2B is available as a separately exported model for fast deployment (up to 2x faster inference).</li>\n      <li><strong>On-the-fly slicing</strong>: Use Mix’n’Match to define custom models between E2B and E4B depending on current memory/compute availability.</li>\n    </ol>\n  </li>\n  <li>\n    <p>Looking forward, the architecture is built to support <strong>runtime switching</strong> between submodels (e.g., transitioning from E4B to E2B mid-session), though this is not enabled in the current release.</p>\n  </li>\n  <li>\n    <p>MatFormer-based submodels are exported to TFLite <code class=\"language-plaintext highlighter-rouge\">.task</code> containers and share parameter memory, enabling efficient co-location and dynamic dispatch during inference.</p>\n  </li>\n  <li>\n    <p>These innovations support speculative decoding, adaptive workload tuning, and performance optimization on mobile chips—all without altering the architecture or retraining the model.</p>\n  </li>\n</ul>\n<p>The blog post introduces <strong>MatFormer Lab</strong>, a tool that helps developers experiment with custom submodel configurations between E2B and E4B. These configurations are evaluated on benchmarks like MMLU to find optimal slices for specific use cases (<a href=\"https://goo.gle/gemma3n-matformer-lab\">MatFormer Lab</a>).</p>\n<p><strong>Two main deployment modes</strong> emerge:</p>\n<ol>\n      <li><strong>Pre-extracted models</strong>: E2B is available as a separately exported model for fast deployment (up to 2x faster inference).</li>\n      <li><strong>On-the-fly slicing</strong>: Use Mix’n’Match to define custom models between E2B and E4B depending on current memory/compute availability.</li>\n    </ol>\n<p>Looking forward, the architecture is built to support <strong>runtime switching</strong> between submodels (e.g., transitioning from E4B to E2B mid-session), though this is not enabled in the current release.</p>\n<p>MatFormer-based submodels are exported to TFLite <code class=\"language-plaintext highlighter-rouge\">.task</code> containers and share parameter memory, enabling efficient co-location and dynamic dispatch during inference.</p>\n<p>These innovations support speculative decoding, adaptive workload tuning, and performance optimization on mobile chips—all without altering the architecture or retraining the model.</p>\n<h4 id=\"integration-in-gemma-3n\">Integration in Gemma 3n</h4>\n<ul>\n  <li>MatFormer is the backbone of Gemma 3n’s nested model strategy. For example, the E2B model is a subset of E4B, achieved via FFN nesting.</li>\n  <li>These submodels are exported to TFLite format and included in <code class=\"language-plaintext highlighter-rouge\">.task</code> archives, enabling scalable inference on-device with flexible tradeoffs between performance and resource use.</li>\n  <li>No architectural changes or re-training are needed when switching between sizes—Gemma simply activates a smaller slice of the model.</li>\n</ul>",
    "contentMarkdown": "*   The training process for MatFormer follows a lightweight and elegant sampling-based strategy. At each training step, one of the ggg submodels is sampled randomly, and the corresponding parameters are updated via standard gradient descent.\n*   Given a loss function LLL, the training objective becomes:\n    \n    Lsampling(x,y)\\=L(Mi(x),y)Lsampling(x,y)\\=L(Mi(x),y)\n    \n    L\\_{\\\\text{sampling}}(x, y) = L(M\\_i(x), y)\n    *   where MiMiM\\_i is chosen uniformly at random from the nested submodels {M1,…,Mg}{M1,…,Mg}\\\\{M\\_1, \\\\ldots, M\\_g\\\\}. While uniform sampling is used in most settings, tuning the sampling distribution {p1,…,pg}{p1,…,pg}\\\\{p\\_1, \\\\ldots, p\\_g\\\\} can yield performance gains—though even simple uniform distributions result in strong submodel accuracy.\n*   This design ensures that:\n    \n    1.  Shared parameters across models are updated frequently.\n    2.  Smaller submodels receive more updates due to their inclusion in every larger submodel.\n    3.  All submodels are jointly trained with no additional memory overhead.\n*   The result is a single, universal model MgMgM\\_g that embeds all submodels {M1,…,Mg−1}{M1,…,Mg−1}\\\\{M\\_1, \\\\ldots, M\\_{g-1}\\\\} within itself—without the need for post-hoc pruning, distillation, or retraining.\n\nGiven a loss function LLL, the training objective becomes:\n\n*   where MiMiM\\_i is chosen uniformly at random from the nested submodels {M1,…,Mg}{M1,…,Mg}\\\\{M\\_1, \\\\ldots, M\\_g\\\\}. While uniform sampling is used in most settings, tuning the sampling distribution {p1,…,pg}{p1,…,pg}\\\\{p\\_1, \\\\ldots, p\\_g\\\\} can yield performance gains—though even simple uniform distributions result in strong submodel accuracy.\n\nThis design ensures that:\n\n1.  Shared parameters across models are updated frequently.\n2.  Smaller submodels receive more updates due to their inclusion in every larger submodel.\n3.  All submodels are jointly trained with no additional memory overhead.\n\n#### Mix’n’Match Inference\n\n*   Mix’n’Match Inference is a key feature enabled by the Matryoshka Transformer (MatFormer) architecture used in Gemma 3n. It allows developers to dynamically create hybrid submodels during inference by mixing granularities across different Transformer layers. While only a small number of submodels are explicitly optimized during training (typically 4, corresponding to different FFN widths), the nesting structure allows the formation of exponentially more configurations post-training.\n    \n*   **Submodel Construction**:\n    \n    *   Instead of uniformly stacking one of the predefined granularities across all layers (e.g., using only T2T2T\\_2 in every layer to build model M2M2M\\_2), Mix’n’Match selects different granularities for each layer. For example, layer 1 could use T2T2T\\_2, layer 2 use T3T3T\\_3, and so on.\n    *   The following figure ([source](https://arxiv.org/abs/2310.07707)) illustrates the nested structure that MatFormer introduces into the Transformer’s FFN block & trains all the submodels, enabling free extraction of hundreds of accurate submodels for elastic inference.\n    \n    ![Placeholder: Fig. 1 – MatFormer block with nested FFN submodels and example Mix’n’Match paths](/primers/ai/assets/gemma-3n/MatFormer.jpg)\n    \n*   **Exponential Flexibility**: Given ggg granularities and ℓℓ\\\\ell Transformer layers, the total number of possible submodels that can be formed via Mix’n’Match is gℓgℓg^\\\\ell. For instance, with 4 granularities and 24 layers, there are over 2.8 trillion possible configurations.\n    \n*   **Heuristic for Selection**:\n    \n    *   A simple yet effective strategy for choosing which submodel to use is the monotonically non-decreasing granularity heuristic. That is, the model uses equal or increasing granularity levels as it progresses deeper into the network. Mathematically,\n    \n    granularity(Lj)≥granularity(Li)forj\\>igranularity(Lj)≥granularity(Li)forj\\>i\n    \n    \\\\text{granularity}(L\\_j) \\\\geq \\\\text{granularity}(L\\_i) \\\\quad \\\\text{for} \\\\quad j > i\n    *   This configuration aligns well with the training regime and tends to perform better than randomly mixed or non-monotonic configurations. Empirical results show that submodels formed this way maintain performance fidelity along the accuracy-compute tradeoff curve.\n*   **No Additional Training Required**: These hybrid submodels are not trained individually. However, because the MatFormer architecture trains the shared parameters across all granularities, the Mix’n’Match models inherit the robustness and consistency of the trained submodels, showing strong performance even when their exact configuration was not seen during training.\n    \n*   **Consistency and Deployment Benefits**: The Mix’n’Match models maintain high output consistency with the full model (MgMgM\\_g), making them ideal for techniques like speculative decoding, where draft models propose outputs and a larger model verifies them. This consistency helps minimize rollbacks and speeds up inference.\n    \n*   **Efficiency and Adaptability**: In resource-constrained settings, such as on-device inference, Mix’n’Match allows the model to adapt dynamically to available memory or compute budgets, selecting a configuration that maximizes performance for the given constraints.\n\nMix’n’Match Inference is a key feature enabled by the Matryoshka Transformer (MatFormer) architecture used in Gemma 3n. It allows developers to dynamically create hybrid submodels during inference by mixing granularities across different Transformer layers. While only a small number of submodels are explicitly optimized during training (typically 4, corresponding to different FFN widths), the nesting structure allows the formation of exponentially more configurations post-training.\n\n*   Instead of uniformly stacking one of the predefined granularities across all layers (e.g., using only T2T2T\\_2 in every layer to build model M2M2M\\_2), Mix’n’Match selects different granularities for each layer. For example, layer 1 could use T2T2T\\_2, layer 2 use T3T3T\\_3, and so on.\n*   The following figure ([source](https://arxiv.org/abs/2310.07707)) illustrates the nested structure that MatFormer introduces into the Transformer’s FFN block & trains all the submodels, enabling free extraction of hundreds of accurate submodels for elastic inference.\n\n![Placeholder: Fig. 1 – MatFormer block with nested FFN submodels and example Mix’n’Match paths](/primers/ai/assets/gemma-3n/MatFormer.jpg)\n\n**Exponential Flexibility**: Given ggg granularities and ℓℓ\\\\ell Transformer layers, the total number of possible submodels that can be formed via Mix’n’Match is gℓgℓg^\\\\ell. For instance, with 4 granularities and 24 layers, there are over 2.8 trillion possible configurations.\n\n*   A simple yet effective strategy for choosing which submodel to use is the monotonically non-decreasing granularity heuristic. That is, the model uses equal or increasing granularity levels as it progresses deeper into the network. Mathematically,\n\n*   This configuration aligns well with the training regime and tends to perform better than randomly mixed or non-monotonic configurations. Empirical results show that submodels formed this way maintain performance fidelity along the accuracy-compute tradeoff curve.\n\n**No Additional Training Required**: These hybrid submodels are not trained individually. However, because the MatFormer architecture trains the shared parameters across all granularities, the Mix’n’Match models inherit the robustness and consistency of the trained submodels, showing strong performance even when their exact configuration was not seen during training.\n\n**Consistency and Deployment Benefits**: The Mix’n’Match models maintain high output consistency with the full model (MgMgM\\_g), making them ideal for techniques like speculative decoding, where draft models propose outputs and a larger model verifies them. This consistency helps minimize rollbacks and speeds up inference.\n\n#### Deployment Advantages\n\n*   The blog post introduces **MatFormer Lab**, a tool that helps developers experiment with custom submodel configurations between E2B and E4B. These configurations are evaluated on benchmarks like MMLU to find optimal slices for specific use cases ([MatFormer Lab](https://goo.gle/gemma3n-matformer-lab)).\n    \n*   **Two main deployment modes** emerge:\n    \n    1.  **Pre-extracted models**: E2B is available as a separately exported model for fast deployment (up to 2x faster inference).\n    2.  **On-the-fly slicing**: Use Mix’n’Match to define custom models between E2B and E4B depending on current memory/compute availability.\n*   Looking forward, the architecture is built to support **runtime switching** between submodels (e.g., transitioning from E4B to E2B mid-session), though this is not enabled in the current release.\n    \n*   MatFormer-based submodels are exported to TFLite `.task` containers and share parameter memory, enabling efficient co-location and dynamic dispatch during inference.\n    \n*   These innovations support speculative decoding, adaptive workload tuning, and performance optimization on mobile chips—all without altering the architecture or retraining the model.\n    \n\nThe blog post introduces **MatFormer Lab**, a tool that helps developers experiment with custom submodel configurations between E2B and E4B. These configurations are evaluated on benchmarks like MMLU to find optimal slices for specific use cases ([MatFormer Lab](https://goo.gle/gemma3n-matformer-lab)).\n\n**Two main deployment modes** emerge:\n\n1.  **Pre-extracted models**: E2B is available as a separately exported model for fast deployment (up to 2x faster inference).\n2.  **On-the-fly slicing**: Use Mix’n’Match to define custom models between E2B and E4B depending on current memory/compute availability.\n\nLooking forward, the architecture is built to support **runtime switching** between submodels (e.g., transitioning from E4B to E2B mid-session), though this is not enabled in the current release.\n\nMatFormer-based submodels are exported to TFLite `.task` containers and share parameter memory, enabling efficient co-location and dynamic dispatch during inference.\n\nThese innovations support speculative decoding, adaptive workload tuning, and performance optimization on mobile chips—all without altering the architecture or retraining the model.\n\n#### Integration in Gemma 3n\n\n*   MatFormer is the backbone of Gemma 3n’s nested model strategy. For example, the E2B model is a subset of E4B, achieved via FFN nesting.\n*   These submodels are exported to TFLite format and included in `.task` archives, enabling scalable inference on-device with flexible tradeoffs between performance and resource use.\n*   No architectural changes or re-training are needed when switching between sizes—Gemma simply activates a smaller slice of the model.",
    "order": 3,
    "orderInChapter": 3,
    "difficulty": 4,
    "estimatedMinutes": 8,
    "tags": [
      "models",
      "transformer",
      "optimization",
      "gradient descent",
      "loss function"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": true,
      "hasImages": true,
      "wordCount": 1404,
      "contentLength": 76665
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/gemma-3n/#training-strategy",
    "scrapedAt": "2025-12-28T11:52:03.953Z"
  },
  {
    "id": "ai-gemma-3n-conditional-parameter-loading-4",
    "domain": "ai_primers",
    "category": "Models",
    "article": "Gemma 3n",
    "articleSlug": "gemma-3n",
    "chapter": "Key Architectural Innovations",
    "title": "Conditional Parameter Loading",
    "subtitle": "Key Architectural Innovations",
    "contentHtml": "<ul>\n  <li>\n    <p><a href=\"https://ai.google.dev/gemma/docs/gemma-3n#conditional-parameter\">Conditional Parameter Loading</a> is a runtime optimization strategy that allows Gemma 3n to load only the components relevant to a given task. For example, if the input is purely textual, the model can skip initializing its vision or audio encoders, thereby reducing memory overhead.</p>\n  </li>\n  <li>\n    <p>In Gemma 3n, this mechanism is particularly valuable because of the model’s <strong>native multimodality</strong> (text, image, audio, and video). By selectively activating only the necessary modules, such as the MobileNet-V5 vision encoder or the USM-based audio encoder, the system minimizes the active parameter set.</p>\n  </li>\n  <li>\n    <p>This approach works in tandem with <strong>Per-Layer Embeddings (PLE)</strong> and <strong>MatFormer</strong>, ensuring that both the core transformer layers and their auxiliary modules can operate within strict device memory constraints—often as low as 2GB for E2B models and 3GB for E4B.</p>\n  </li>\n  <li>\n    <p>Conditional Parameter Loading also simplifies <strong>deployment optimization</strong>:</p>\n\n    <ul>\n      <li>Developers can <strong>ship a single universal model</strong> and dynamically enable or disable modalities based on input signals.</li>\n      <li>For static workloads, stripped-down models can be precompiled for even lower memory consumption.</li>\n    </ul>\n  </li>\n  <li>\n    <p>When combined with features like <strong>KV Cache Sharing</strong> (for faster streaming prefill) and <strong>Mix’n’Match inference</strong>, this technique ensures that Gemma 3n achieves near cloud-level performance while staying resource-efficient on mobile hardware.</p>\n  </li>\n</ul>\n<p><a href=\"https://ai.google.dev/gemma/docs/gemma-3n#conditional-parameter\">Conditional Parameter Loading</a> is a runtime optimization strategy that allows Gemma 3n to load only the components relevant to a given task. For example, if the input is purely textual, the model can skip initializing its vision or audio encoders, thereby reducing memory overhead.</p>\n<p>In Gemma 3n, this mechanism is particularly valuable because of the model’s <strong>native multimodality</strong> (text, image, audio, and video). By selectively activating only the necessary modules, such as the MobileNet-V5 vision encoder or the USM-based audio encoder, the system minimizes the active parameter set.</p>\n<p>This approach works in tandem with <strong>Per-Layer Embeddings (PLE)</strong> and <strong>MatFormer</strong>, ensuring that both the core transformer layers and their auxiliary modules can operate within strict device memory constraints—often as low as 2GB for E2B models and 3GB for E4B.</p>\n<p>Conditional Parameter Loading also simplifies <strong>deployment optimization</strong>:</p>\n<ul>\n      <li>Developers can <strong>ship a single universal model</strong> and dynamically enable or disable modalities based on input signals.</li>\n      <li>For static workloads, stripped-down models can be precompiled for even lower memory consumption.</li>\n    </ul>\n<p>When combined with features like <strong>KV Cache Sharing</strong> (for faster streaming prefill) and <strong>Mix’n’Match inference</strong>, this technique ensures that Gemma 3n achieves near cloud-level performance while staying resource-efficient on mobile hardware.</p>",
    "contentMarkdown": "*   [Conditional Parameter Loading](https://ai.google.dev/gemma/docs/gemma-3n#conditional-parameter) is a runtime optimization strategy that allows Gemma 3n to load only the components relevant to a given task. For example, if the input is purely textual, the model can skip initializing its vision or audio encoders, thereby reducing memory overhead.\n    \n*   In Gemma 3n, this mechanism is particularly valuable because of the model’s **native multimodality** (text, image, audio, and video). By selectively activating only the necessary modules, such as the MobileNet-V5 vision encoder or the USM-based audio encoder, the system minimizes the active parameter set.\n    \n*   This approach works in tandem with **Per-Layer Embeddings (PLE)** and **MatFormer**, ensuring that both the core transformer layers and their auxiliary modules can operate within strict device memory constraints—often as low as 2GB for E2B models and 3GB for E4B.\n    \n*   Conditional Parameter Loading also simplifies **deployment optimization**:\n    \n    *   Developers can **ship a single universal model** and dynamically enable or disable modalities based on input signals.\n    *   For static workloads, stripped-down models can be precompiled for even lower memory consumption.\n*   When combined with features like **KV Cache Sharing** (for faster streaming prefill) and **Mix’n’Match inference**, this technique ensures that Gemma 3n achieves near cloud-level performance while staying resource-efficient on mobile hardware.\n    \n\n[Conditional Parameter Loading](https://ai.google.dev/gemma/docs/gemma-3n#conditional-parameter) is a runtime optimization strategy that allows Gemma 3n to load only the components relevant to a given task. For example, if the input is purely textual, the model can skip initializing its vision or audio encoders, thereby reducing memory overhead.\n\nIn Gemma 3n, this mechanism is particularly valuable because of the model’s **native multimodality** (text, image, audio, and video). By selectively activating only the necessary modules, such as the MobileNet-V5 vision encoder or the USM-based audio encoder, the system minimizes the active parameter set.\n\nThis approach works in tandem with **Per-Layer Embeddings (PLE)** and **MatFormer**, ensuring that both the core transformer layers and their auxiliary modules can operate within strict device memory constraints—often as low as 2GB for E2B models and 3GB for E4B.\n\nConditional Parameter Loading also simplifies **deployment optimization**:\n\n*   Developers can **ship a single universal model** and dynamically enable or disable modalities based on input signals.\n*   For static workloads, stripped-down models can be precompiled for even lower memory consumption.\n\nWhen combined with features like **KV Cache Sharing** (for faster streaming prefill) and **Mix’n’Match inference**, this technique ensures that Gemma 3n achieves near cloud-level performance while staying resource-efficient on mobile hardware.",
    "order": 4,
    "orderInChapter": 4,
    "difficulty": 2,
    "estimatedMinutes": 3,
    "tags": [
      "models",
      "transformer",
      "embedding",
      "optimization"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 401,
      "contentLength": 3380
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/gemma-3n/#conditional-parameter-loading",
    "scrapedAt": "2025-12-28T11:52:03.953Z"
  },
  {
    "id": "ai-gemma-3n-core-modules-and-functional-breakdown-5",
    "domain": "ai_primers",
    "category": "Models",
    "article": "Gemma 3n",
    "articleSlug": "gemma-3n",
    "chapter": "Model Components and Structure",
    "title": "Core Modules and Functional Breakdown",
    "subtitle": "Model Components and Structure",
    "contentHtml": "<ul>\n  <li>\n    <p>Gemma 3n’s architecture comprises of the following modular components packed within <code class=\"language-plaintext highlighter-rouge\">.task</code> ZIP archives of TFLite models.</p>\n\n    <ul>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_PREFILL_DECODE (2.55 GB):</code></strong> Main language model decoder component.</p>\n      </li>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_PER_LAYER_EMBEDDER (1.23 GB):</code></strong> Generates per-layer token-specific embeddings used in gating residual streams.</p>\n      </li>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_EMBEDDER (259 MB):</code></strong> Initial input embedding generator.</p>\n      </li>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_VISION_ENCODER (146 MB):</code></strong> Converts image input into dense feature embeddings.</p>\n      </li>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_VISION_ADAPTER (17 MB):</code></strong> Adapts visual embeddings into the language token stream.</p>\n      </li>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TOKENIZER_MODEL (4.5 MB):</code></strong> Subword tokenizer supporting a vocabulary of 262,144 tokens.</p>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p>These components support a wide range of functionalities optimized for edge inference and are designed for extensibility via innovations like <a href=\"#learned-augmented-residual-layer-laurel\">LAuReL</a> and PLE.</p>\n  </li>\n</ul>\n<p>Gemma 3n’s architecture comprises of the following modular components packed within <code class=\"language-plaintext highlighter-rouge\">.task</code> ZIP archives of TFLite models.</p>\n<ul>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_PREFILL_DECODE (2.55 GB):</code></strong> Main language model decoder component.</p>\n      </li>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_PER_LAYER_EMBEDDER (1.23 GB):</code></strong> Generates per-layer token-specific embeddings used in gating residual streams.</p>\n      </li>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_EMBEDDER (259 MB):</code></strong> Initial input embedding generator.</p>\n      </li>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_VISION_ENCODER (146 MB):</code></strong> Converts image input into dense feature embeddings.</p>\n      </li>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_VISION_ADAPTER (17 MB):</code></strong> Adapts visual embeddings into the language token stream.</p>\n      </li>\n      <li>\n        <p><strong><code class=\"language-plaintext highlighter-rouge\">TOKENIZER_MODEL (4.5 MB):</code></strong> Subword tokenizer supporting a vocabulary of 262,144 tokens.</p>\n      </li>\n    </ul>\n<p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_PREFILL_DECODE (2.55 GB):</code></strong> Main language model decoder component.</p>\n<p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_PER_LAYER_EMBEDDER (1.23 GB):</code></strong> Generates per-layer token-specific embeddings used in gating residual streams.</p>\n<p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_EMBEDDER (259 MB):</code></strong> Initial input embedding generator.</p>\n<p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_VISION_ENCODER (146 MB):</code></strong> Converts image input into dense feature embeddings.</p>\n<p><strong><code class=\"language-plaintext highlighter-rouge\">TF_LITE_VISION_ADAPTER (17 MB):</code></strong> Adapts visual embeddings into the language token stream.</p>\n<p><strong><code class=\"language-plaintext highlighter-rouge\">TOKENIZER_MODEL (4.5 MB):</code></strong> Subword tokenizer supporting a vocabulary of 262,144 tokens.</p>\n<p>These components support a wide range of functionalities optimized for edge inference and are designed for extensibility via innovations like <a href=\"#learned-augmented-residual-layer-laurel\">LAuReL</a> and PLE.</p>",
    "contentMarkdown": "*   Gemma 3n’s architecture comprises of the following modular components packed within `.task` ZIP archives of TFLite models.\n    \n    *   **`TF_LITE_PREFILL_DECODE (2.55 GB):`** Main language model decoder component.\n        \n    *   **`TF_LITE_PER_LAYER_EMBEDDER (1.23 GB):`** Generates per-layer token-specific embeddings used in gating residual streams.\n        \n    *   **`TF_LITE_EMBEDDER (259 MB):`** Initial input embedding generator.\n        \n    *   **`TF_LITE_VISION_ENCODER (146 MB):`** Converts image input into dense feature embeddings.\n        \n    *   **`TF_LITE_VISION_ADAPTER (17 MB):`** Adapts visual embeddings into the language token stream.\n        \n    *   **`TOKENIZER_MODEL (4.5 MB):`** Subword tokenizer supporting a vocabulary of 262,144 tokens.\n        \n*   These components support a wide range of functionalities optimized for edge inference and are designed for extensibility via innovations like [LAuReL](#learned-augmented-residual-layer-laurel) and PLE.\n    \n\nGemma 3n’s architecture comprises of the following modular components packed within `.task` ZIP archives of TFLite models.\n\n*   **`TF_LITE_PREFILL_DECODE (2.55 GB):`** Main language model decoder component.\n    \n*   **`TF_LITE_PER_LAYER_EMBEDDER (1.23 GB):`** Generates per-layer token-specific embeddings used in gating residual streams.\n    \n*   **`TF_LITE_EMBEDDER (259 MB):`** Initial input embedding generator.\n    \n*   **`TF_LITE_VISION_ENCODER (146 MB):`** Converts image input into dense feature embeddings.\n    \n*   **`TF_LITE_VISION_ADAPTER (17 MB):`** Adapts visual embeddings into the language token stream.\n    \n*   **`TOKENIZER_MODEL (4.5 MB):`** Subword tokenizer supporting a vocabulary of 262,144 tokens.\n    \n\n**`TF_LITE_PREFILL_DECODE (2.55 GB):`** Main language model decoder component.\n\n**`TF_LITE_PER_LAYER_EMBEDDER (1.23 GB):`** Generates per-layer token-specific embeddings used in gating residual streams.\n\n**`TF_LITE_EMBEDDER (259 MB):`** Initial input embedding generator.\n\n**`TF_LITE_VISION_ENCODER (146 MB):`** Converts image input into dense feature embeddings.\n\n**`TF_LITE_VISION_ADAPTER (17 MB):`** Adapts visual embeddings into the language token stream.\n\n**`TOKENIZER_MODEL (4.5 MB):`** Subword tokenizer supporting a vocabulary of 262,144 tokens.\n\nThese components support a wide range of functionalities optimized for edge inference and are designed for extensibility via innovations like [LAuReL](#learned-augmented-residual-layer-laurel) and PLE.",
    "order": 5,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 2,
    "tags": [
      "models",
      "embedding"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 271,
      "contentLength": 4282
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/gemma-3n/#core-modules-and-functional-breakdown",
    "scrapedAt": "2025-12-28T11:52:03.953Z"
  },
  {
    "id": "ai-gemma-3n-model-graph-exploration-via-netron-6",
    "domain": "ai_primers",
    "category": "Models",
    "article": "Gemma 3n",
    "articleSlug": "gemma-3n",
    "chapter": "Model Components and Structure",
    "title": "Model Graph Exploration Via Netron",
    "subtitle": "Model Components and Structure",
    "contentHtml": "<ul>\n  <li>\n    <p>Using tools like <a href=\"https://netron.app/\">Netron</a>, the unpacked TFLite models reveal the computation graph. Observations include:</p>\n\n    <ul>\n      <li>Modular layer sequencing aligned with MatFormer and PLE caching</li>\n      <li>Runtime-skippable components (e.g., vision adapter paths via conditional parameter paths gated by input flags)</li>\n      <li>Learned scalar parameters at merge points (consistent with LAuReL-RW)</li>\n      <li>Substructure consistent with MatFormer’s nested FFN blocks</li>\n    </ul>\n  </li>\n  <li>\n    <p>The following figure (<a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r\">source</a>) illustrates the TFLite model computation graph as visualized in Netron from unpacked <code class=\"language-plaintext highlighter-rouge\">.task</code> containers, showing Gemma 3n’s modular structure with components like the vision adapter routed via conditional parameter paths. This layout highlights composability, runtime-skippable submodules, and support for dynamic inference pathways—evidence of innovations like MatFormer and LAuReL-based gating.</p>\n  </li>\n</ul>\n<p>Using tools like <a href=\"https://netron.app/\">Netron</a>, the unpacked TFLite models reveal the computation graph. Observations include:</p>\n<ul>\n      <li>Modular layer sequencing aligned with MatFormer and PLE caching</li>\n      <li>Runtime-skippable components (e.g., vision adapter paths via conditional parameter paths gated by input flags)</li>\n      <li>Learned scalar parameters at merge points (consistent with LAuReL-RW)</li>\n      <li>Substructure consistent with MatFormer’s nested FFN blocks</li>\n    </ul>\n<p>The following figure (<a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r\">source</a>) illustrates the TFLite model computation graph as visualized in Netron from unpacked <code class=\"language-plaintext highlighter-rouge\">.task</code> containers, showing Gemma 3n’s modular structure with components like the vision adapter routed via conditional parameter paths. This layout highlights composability, runtime-skippable submodules, and support for dynamic inference pathways—evidence of innovations like MatFormer and LAuReL-based gating.</p>\n<p><img src=\"/primers/ai/assets/gemma-3n/gemma-3n-architectural-innovations-speculation-and-poking-v0-tvl3od2v3w2f1.webp\" alt=\"Placeholder – TFLite model computation graph via Netron\"></p>",
    "contentMarkdown": "*   Using tools like [Netron](https://netron.app/), the unpacked TFLite models reveal the computation graph. Observations include:\n    \n    *   Modular layer sequencing aligned with MatFormer and PLE caching\n    *   Runtime-skippable components (e.g., vision adapter paths via conditional parameter paths gated by input flags)\n    *   Learned scalar parameters at merge points (consistent with LAuReL-RW)\n    *   Substructure consistent with MatFormer’s nested FFN blocks\n*   The following figure ([source](https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r)) illustrates the TFLite model computation graph as visualized in Netron from unpacked `.task` containers, showing Gemma 3n’s modular structure with components like the vision adapter routed via conditional parameter paths. This layout highlights composability, runtime-skippable submodules, and support for dynamic inference pathways—evidence of innovations like MatFormer and LAuReL-based gating.\n    \n\nUsing tools like [Netron](https://netron.app/), the unpacked TFLite models reveal the computation graph. Observations include:\n\n*   Modular layer sequencing aligned with MatFormer and PLE caching\n*   Runtime-skippable components (e.g., vision adapter paths via conditional parameter paths gated by input flags)\n*   Learned scalar parameters at merge points (consistent with LAuReL-RW)\n*   Substructure consistent with MatFormer’s nested FFN blocks\n\nThe following figure ([source](https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r)) illustrates the TFLite model computation graph as visualized in Netron from unpacked `.task` containers, showing Gemma 3n’s modular structure with components like the vision adapter routed via conditional parameter paths. This layout highlights composability, runtime-skippable submodules, and support for dynamic inference pathways—evidence of innovations like MatFormer and LAuReL-based gating.\n\n![Placeholder – TFLite model computation graph via Netron](/primers/ai/assets/gemma-3n/gemma-3n-architectural-innovations-speculation-and-poking-v0-tvl3od2v3w2f1.webp)",
    "order": 6,
    "orderInChapter": 2,
    "difficulty": 3,
    "estimatedMinutes": 2,
    "tags": [
      "models"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 230,
      "contentLength": 2404
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/gemma-3n/#model-graph-exploration-via-netron",
    "scrapedAt": "2025-12-28T11:52:03.954Z"
  },
  {
    "id": "ai-gemma-3n-internal-transformer-structure-and-residual-design-7",
    "domain": "ai_primers",
    "category": "Models",
    "article": "Gemma 3n",
    "articleSlug": "gemma-3n",
    "chapter": "Model Components and Structure",
    "title": "Internal Transformer Structure and Residual Design",
    "subtitle": "Model Components and Structure",
    "contentHtml": "<ul>\n  <li>\n    <p>Gemma 3n uses <strong>35 Transformer blocks</strong>, each with:</p>\n\n    <ul>\n      <li>Hidden dimension: 2048</li>\n      <li>FFN expansion: up to 16,384 (with GeGLU activation)</li>\n      <li>LAuReL-style modified residual pathways, modulated by PLE outputs</li>\n      <li>Token-specific low-rank gates, dynamically computed per layer</li>\n    </ul>\n  </li>\n  <li>\n    <p>These layers follow a layout similar to LAuReL-RW, with low-rank down-projection, token-aware gating, and re-projection before residual merging. This enhances fine-grained control over information flow per token and per layer.</p>\n  </li>\n  <li>\n    <p>The following figure (<a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r\">source</a>) shows the flow of Gemma 3n’s transformer blocks illustrating token-conditioned low-rank projections modulating the residual stream. This confirms the presence of modified residual connections resembling LAuReL-RW, with 35 blocks, a 2048-dimensional core, and GeGLU-activated 16384-wide FFNs—supporting both depth and dynamic token-specific gating. The structure reveals layer-wise low-rank projections gated by PLE outputs, consistent with LAuReL principles.</p>\n  </li>\n</ul>\n<p>Gemma 3n uses <strong>35 Transformer blocks</strong>, each with:</p>\n<ul>\n      <li>Hidden dimension: 2048</li>\n      <li>FFN expansion: up to 16,384 (with GeGLU activation)</li>\n      <li>LAuReL-style modified residual pathways, modulated by PLE outputs</li>\n      <li>Token-specific low-rank gates, dynamically computed per layer</li>\n    </ul>\n<p>These layers follow a layout similar to LAuReL-RW, with low-rank down-projection, token-aware gating, and re-projection before residual merging. This enhances fine-grained control over information flow per token and per layer.</p>\n<p>The following figure (<a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r\">source</a>) shows the flow of Gemma 3n’s transformer blocks illustrating token-conditioned low-rank projections modulating the residual stream. This confirms the presence of modified residual connections resembling LAuReL-RW, with 35 blocks, a 2048-dimensional core, and GeGLU-activated 16384-wide FFNs—supporting both depth and dynamic token-specific gating. The structure reveals layer-wise low-rank projections gated by PLE outputs, consistent with LAuReL principles.</p>\n<p><img src=\"/primers/ai/assets/gemma-3n/gemma-3n-architectural-innovations-speculation-and-poking-v0-wca7kzfq5w2f1.webp\" alt=\"Token-conditioned residual gate\"></p>\n<h4 id=\"learned-augmented-residual-layer-laurel\">Learned Augmented Residual Layer (LAuReL)</h4>\n<ul>\n  <li>\n    <p>Proposed in <a href=\"https://arxiv.org/abs/2411.07501\">LAuReL: Learned Augmented Residual Layer</a> by Menghani et al. (2025), LAuReL generalizes standard residual connections:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-37-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>&amp;#x03B1;</mi><mo>&amp;#x22C5;</mo><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mo>&amp;#x2212;</mo><mn>1</mn></mrow></msub><mo>,</mo><mo>&amp;#x2026;</mo><mo>,</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-381\" style=\"width: 17.138em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 14.273em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1014.22em, 2.659em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-382\"><span class=\"msubsup\" id=\"MathJax-Span-383\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-384\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-385\"><span class=\"mrow\" id=\"MathJax-Span-386\"><span class=\"mi\" id=\"MathJax-Span-387\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mo\" id=\"MathJax-Span-388\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mn\" id=\"MathJax-Span-389\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-390\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mi\" id=\"MathJax-Span-391\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.315em;\">α</span><span class=\"mo\" id=\"MathJax-Span-392\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-393\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">f<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.159em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-394\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-395\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-396\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-397\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-398\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-399\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-400\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">g</span><span class=\"mo\" id=\"MathJax-Span-401\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-402\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-403\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-404\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-405\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-406\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-407\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-408\"><span class=\"mrow\" id=\"MathJax-Span-409\"><span class=\"mi\" id=\"MathJax-Span-410\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mo\" id=\"MathJax-Span-411\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">−</span><span class=\"mn\" id=\"MathJax-Span-412\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-413\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-414\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"mo\" id=\"MathJax-Span-415\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-416\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-417\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-418\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">0</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-419\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>α</mi><mo>⋅</mo><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>+</mo><mi>g</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-37\">x_{i+1} = \\alpha \\cdot f(x_i) + g(x_i, x_{i-1}, \\ldots, x_0)</script>\n\n    <ul>\n      <li>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B1;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-420\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-421\"><span class=\"mi\" id=\"MathJax-Span-422\" style=\"font-family: STIXGeneral-Italic;\">α</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>α</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-38\">\\alpha</script> is a learnable scalar and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><mo>&amp;#x22C5;</mo><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-423\" style=\"width: 1.982em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1001.57em, 2.607em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-424\"><span class=\"mi\" id=\"MathJax-Span-425\" style=\"font-family: STIXGeneral-Italic;\">g</span><span class=\"mo\" id=\"MathJax-Span-426\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mo\" id=\"MathJax-Span-427\" style=\"font-family: STIXGeneral-Regular;\">⋅</span><span class=\"mo\" id=\"MathJax-Span-428\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi><mo stretchy=\"false\">(</mo><mo>⋅</mo><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">g(\\cdot)</script> is a learned linear map (e.g., low-rank transformation or weighted combination of past activations).</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Inferred Implementation in Gemma 3n:</strong></p>\n\n    <ul>\n      <li>Applies low-rank down-projection to residual streams</li>\n      <li>Multiplies the projection by a token-specific gate from the PLE module</li>\n      <li>Re-projects to full dimension and merges with non-linear output</li>\n      <li>Uses forms similar to LAuReL-RW and LAuReL-LR variants</li>\n    </ul>\n  </li>\n  <li>\n    <p>The following figure (<a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r\">source</a>) shows a detailed Netron view of LAuReL-style residual merging. Shows residual down-projection, modulation by token-specific gate, and re-projection to full dimension before merging—indicating implementation of LAuReL-RW with PLE-driven control.</p>\n  </li>\n</ul>\n<p>Proposed in <a href=\"https://arxiv.org/abs/2411.07501\">LAuReL: Learned Augmented Residual Layer</a> by Menghani et al. (2025), LAuReL generalizes standard residual connections:</p>\n<ul>\n      <li>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B1;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-420\" style=\"width: 0.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-421\"><span class=\"mi\" id=\"MathJax-Span-422\" style=\"font-family: STIXGeneral-Italic;\">α</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>α</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-38\">\\alpha</script> is a learnable scalar and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><mo>&amp;#x22C5;</mo><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-423\" style=\"width: 1.982em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.617em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1001.57em, 2.607em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-424\"><span class=\"mi\" id=\"MathJax-Span-425\" style=\"font-family: STIXGeneral-Italic;\">g</span><span class=\"mo\" id=\"MathJax-Span-426\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mo\" id=\"MathJax-Span-427\" style=\"font-family: STIXGeneral-Regular;\">⋅</span><span class=\"mo\" id=\"MathJax-Span-428\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>g</mi><mo stretchy=\"false\">(</mo><mo>⋅</mo><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">g(\\cdot)</script> is a learned linear map (e.g., low-rank transformation or weighted combination of past activations).</li>\n    </ul>\n<p><strong>Inferred Implementation in Gemma 3n:</strong></p>\n<ul>\n      <li>Applies low-rank down-projection to residual streams</li>\n      <li>Multiplies the projection by a token-specific gate from the PLE module</li>\n      <li>Re-projects to full dimension and merges with non-linear output</li>\n      <li>Uses forms similar to LAuReL-RW and LAuReL-LR variants</li>\n    </ul>\n<p>The following figure (<a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r\">source</a>) shows a detailed Netron view of LAuReL-style residual merging. Shows residual down-projection, modulation by token-specific gate, and re-projection to full dimension before merging—indicating implementation of LAuReL-RW with PLE-driven control.</p>\n<p><img src=\"/primers/ai/assets/gemma-3n/gemma-3n-architectural-innovations-speculation-and-poking-v0-lchxfc6w6w2f1.webp\" alt=\"\"></p>",
    "contentMarkdown": "*   Gemma 3n uses **35 Transformer blocks**, each with:\n    \n    *   Hidden dimension: 2048\n    *   FFN expansion: up to 16,384 (with GeGLU activation)\n    *   LAuReL-style modified residual pathways, modulated by PLE outputs\n    *   Token-specific low-rank gates, dynamically computed per layer\n*   These layers follow a layout similar to LAuReL-RW, with low-rank down-projection, token-aware gating, and re-projection before residual merging. This enhances fine-grained control over information flow per token and per layer.\n    \n*   The following figure ([source](https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r)) shows the flow of Gemma 3n’s transformer blocks illustrating token-conditioned low-rank projections modulating the residual stream. This confirms the presence of modified residual connections resembling LAuReL-RW, with 35 blocks, a 2048-dimensional core, and GeGLU-activated 16384-wide FFNs—supporting both depth and dynamic token-specific gating. The structure reveals layer-wise low-rank projections gated by PLE outputs, consistent with LAuReL principles.\n    \n\nGemma 3n uses **35 Transformer blocks**, each with:\n\n*   Hidden dimension: 2048\n*   FFN expansion: up to 16,384 (with GeGLU activation)\n*   LAuReL-style modified residual pathways, modulated by PLE outputs\n*   Token-specific low-rank gates, dynamically computed per layer\n\nThese layers follow a layout similar to LAuReL-RW, with low-rank down-projection, token-aware gating, and re-projection before residual merging. This enhances fine-grained control over information flow per token and per layer.\n\nThe following figure ([source](https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r)) shows the flow of Gemma 3n’s transformer blocks illustrating token-conditioned low-rank projections modulating the residual stream. This confirms the presence of modified residual connections resembling LAuReL-RW, with 35 blocks, a 2048-dimensional core, and GeGLU-activated 16384-wide FFNs—supporting both depth and dynamic token-specific gating. The structure reveals layer-wise low-rank projections gated by PLE outputs, consistent with LAuReL principles.\n\n![Token-conditioned residual gate](/primers/ai/assets/gemma-3n/gemma-3n-architectural-innovations-speculation-and-poking-v0-wca7kzfq5w2f1.webp)\n\n#### Learned Augmented Residual Layer (LAuReL)\n\n*   Proposed in [LAuReL: Learned Augmented Residual Layer](https://arxiv.org/abs/2411.07501) by Menghani et al. (2025), LAuReL generalizes standard residual connections:\n    \n    xi+1\\=α⋅f(xi)+g(xi,xi−1,…,x0)xi+1\\=α⋅f(xi)+g(xi,xi−1,…,x0)\n    \n    x\\_{i+1} = \\\\alpha \\\\cdot f(x\\_i) + g(x\\_i, x\\_{i-1}, \\\\ldots, x\\_0)\n    *   where αα\\\\alpha is a learnable scalar and g(⋅)g(⋅)g(\\\\cdot) is a learned linear map (e.g., low-rank transformation or weighted combination of past activations).\n*   **Inferred Implementation in Gemma 3n:**\n    \n    *   Applies low-rank down-projection to residual streams\n    *   Multiplies the projection by a token-specific gate from the PLE module\n    *   Re-projects to full dimension and merges with non-linear output\n    *   Uses forms similar to LAuReL-RW and LAuReL-LR variants\n*   The following figure ([source](https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r)) shows a detailed Netron view of LAuReL-style residual merging. Shows residual down-projection, modulation by token-specific gate, and re-projection to full dimension before merging—indicating implementation of LAuReL-RW with PLE-driven control.\n    \n\nProposed in [LAuReL: Learned Augmented Residual Layer](https://arxiv.org/abs/2411.07501) by Menghani et al. (2025), LAuReL generalizes standard residual connections:\n\n*   where αα\\\\alpha is a learnable scalar and g(⋅)g(⋅)g(\\\\cdot) is a learned linear map (e.g., low-rank transformation or weighted combination of past activations).\n\n**Inferred Implementation in Gemma 3n:**\n\n*   Applies low-rank down-projection to residual streams\n*   Multiplies the projection by a token-specific gate from the PLE module\n*   Re-projects to full dimension and merges with non-linear output\n*   Uses forms similar to LAuReL-RW and LAuReL-LR variants\n\nThe following figure ([source](https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r)) shows a detailed Netron view of LAuReL-style residual merging. Shows residual down-projection, modulation by token-specific gate, and re-projection to full dimension before merging—indicating implementation of LAuReL-RW with PLE-driven control.\n\n![](/primers/ai/assets/gemma-3n/gemma-3n-architectural-innovations-speculation-and-poking-v0-lchxfc6w6w2f1.webp)",
    "order": 7,
    "orderInChapter": 3,
    "difficulty": 3,
    "estimatedMinutes": 3,
    "tags": [
      "models",
      "transformer",
      "activation"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": true,
      "wordCount": 515,
      "contentLength": 19020
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/gemma-3n/#internal-transformer-structure-and-residual-design",
    "scrapedAt": "2025-12-28T11:52:03.954Z"
  },
  {
    "id": "ai-gemma-3n-per-layer-embedding-mechanism-8",
    "domain": "ai_primers",
    "category": "Models",
    "article": "Gemma 3n",
    "articleSlug": "gemma-3n",
    "chapter": "Model Components and Structure",
    "title": "Per-Layer Embedding Mechanism",
    "subtitle": "Model Components and Structure",
    "contentHtml": "<ul>\n  <li>\n    <p>The <code class=\"language-plaintext highlighter-rouge\">TF_LITE_PER_LAYER_EMBEDDER</code> holds large token-layer lookup tables of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-40-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>262144</mn><mo>&amp;#x00D7;</mo><mn>256</mn><mo>&amp;#x00D7;</mo><mn>35</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-429\" style=\"width: 9.221em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.61em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-430\"><span class=\"mn\" id=\"MathJax-Span-431\" style=\"font-family: STIXGeneral-Regular;\">262144</span><span class=\"mo\" id=\"MathJax-Span-432\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-433\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">256</span><span class=\"mo\" id=\"MathJax-Span-434\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-435\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">35</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>262144</mn><mo>×</mo><mn>256</mn><mo>×</mo><mn>35</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-40\">262144 \\times 256 \\times 35</script>, producing 256-dimensional embeddings per token per layer. These embeddings modulate a down-projected residual stream:</p>\n\n    <ol>\n      <li>Residual stream (2048) → downprojected to 256</li>\n      <li>Element-wise multiplied with per-token embedding</li>\n      <li>Re-projected to 2048 and added back</li>\n    </ol>\n  </li>\n  <li>\n    <p>This is conceptually similar to a token- and layer-conditioned LoRA gating mechanism.</p>\n  </li>\n  <li>\n    <p>The following figure (<a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r\">source</a>) illustrates how per-layer embeddings gate residual information. It shows the &lt;&gt;-token lookup interaction and confirms the use of layer-specific control mechanisms in Gemma 3n.</p>\n  </li>\n</ul>\n<p>The <code class=\"language-plaintext highlighter-rouge\">TF_LITE_PER_LAYER_EMBEDDER</code> holds large token-layer lookup tables of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-40-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>262144</mn><mo>&amp;#x00D7;</mo><mn>256</mn><mo>&amp;#x00D7;</mo><mn>35</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-429\" style=\"width: 9.221em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.61em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-430\"><span class=\"mn\" id=\"MathJax-Span-431\" style=\"font-family: STIXGeneral-Regular;\">262144</span><span class=\"mo\" id=\"MathJax-Span-432\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-433\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">256</span><span class=\"mo\" id=\"MathJax-Span-434\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-435\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">35</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>262144</mn><mo>×</mo><mn>256</mn><mo>×</mo><mn>35</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-40\">262144 \\times 256 \\times 35</script>, producing 256-dimensional embeddings per token per layer. These embeddings modulate a down-projected residual stream:</p>\n<ol>\n      <li>Residual stream (2048) → downprojected to 256</li>\n      <li>Element-wise multiplied with per-token embedding</li>\n      <li>Re-projected to 2048 and added back</li>\n    </ol>\n<p>This is conceptually similar to a token- and layer-conditioned LoRA gating mechanism.</p>\n<p>The following figure (<a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r\">source</a>) illustrates how per-layer embeddings gate residual information. It shows the &lt;&gt;-token lookup interaction and confirms the use of layer-specific control mechanisms in Gemma 3n.</p>\n<p><img src=\"/primers/ai/assets/gemma-3n/gemma-3n-architectural-innovations-speculation-and-poking-v0-foq74ff15w2f1.webp\" alt=\"Placeholder – Per-layer embedding lookup and gating\"></p>",
    "contentMarkdown": "*   The `TF_LITE_PER_LAYER_EMBEDDER` holds large token-layer lookup tables of shape 262144×256×35262144×256×35262144 \\\\times 256 \\\\times 35, producing 256-dimensional embeddings per token per layer. These embeddings modulate a down-projected residual stream:\n    \n    1.  Residual stream (2048) → downprojected to 256\n    2.  Element-wise multiplied with per-token embedding\n    3.  Re-projected to 2048 and added back\n*   This is conceptually similar to a token- and layer-conditioned LoRA gating mechanism.\n    \n*   The following figure ([source](https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r)) illustrates how per-layer embeddings gate residual information. It shows the <>-token lookup interaction and confirms the use of layer-specific control mechanisms in Gemma 3n.\n    \n\nThe `TF_LITE_PER_LAYER_EMBEDDER` holds large token-layer lookup tables of shape 262144×256×35262144×256×35262144 \\\\times 256 \\\\times 35, producing 256-dimensional embeddings per token per layer. These embeddings modulate a down-projected residual stream:\n\n1.  Residual stream (2048) → downprojected to 256\n2.  Element-wise multiplied with per-token embedding\n3.  Re-projected to 2048 and added back\n\nThis is conceptually similar to a token- and layer-conditioned LoRA gating mechanism.\n\nThe following figure ([source](https://www.reddit.com/r/LocalLLaMA/comments/1kuy45r)) illustrates how per-layer embeddings gate residual information. It shows the <>-token lookup interaction and confirms the use of layer-specific control mechanisms in Gemma 3n.\n\n![Placeholder – Per-layer embedding lookup and gating](/primers/ai/assets/gemma-3n/gemma-3n-architectural-innovations-speculation-and-poking-v0-foq74ff15w2f1.webp)",
    "order": 8,
    "orderInChapter": 4,
    "difficulty": 3,
    "estimatedMinutes": 1,
    "tags": [
      "models",
      "embedding"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": true,
      "hasImages": true,
      "wordCount": 188,
      "contentLength": 5483
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/gemma-3n/#per-layer-embedding-mechanism",
    "scrapedAt": "2025-12-28T11:52:03.954Z"
  },
  {
    "id": "ai-gemma-3n-alternating-updates-for-efficient-transformers-alt-9",
    "domain": "ai_primers",
    "category": "Models",
    "article": "Gemma 3n",
    "articleSlug": "gemma-3n",
    "chapter": "Model Components and Structure",
    "title": "Alternating Updates for Efficient Transformers (AltUp)",
    "subtitle": "Model Components and Structure",
    "contentHtml": "<ul>\n  <li>\n    <p><strong>Alternating Updates (AltUp)</strong>, proposed in <a href=\"https://arxiv.org/abs/2301.13310\">Alternating Updates for Efficient Transformers</a> by Baykal et al. (2023), is a technique designed to increase a transformer’s representational capacity (e.g., wider token embeddings) without incurring a proportional increase in computation or memory overhead. It is particularly relevant to on-device architectures like Gemma 3n, where hardware constraints demand high efficiency at runtime.</p>\n  </li>\n  <li>\n    <p>AltUp widens the representation dimension (e.g., from 2048 to 4096) but avoids computing over the entire width in each layer. Instead, each transformer layer updates only a <strong>sub-block</strong> (e.g., one-quarter) of the full vector, and uses a lightweight <strong>predict-correct mechanism</strong> to infer updates for the rest.</p>\n  </li>\n</ul>\n<p><strong>Alternating Updates (AltUp)</strong>, proposed in <a href=\"https://arxiv.org/abs/2301.13310\">Alternating Updates for Efficient Transformers</a> by Baykal et al. (2023), is a technique designed to increase a transformer’s representational capacity (e.g., wider token embeddings) without incurring a proportional increase in computation or memory overhead. It is particularly relevant to on-device architectures like Gemma 3n, where hardware constraints demand high efficiency at runtime.</p>\n<p>AltUp widens the representation dimension (e.g., from 2048 to 4096) but avoids computing over the entire width in each layer. Instead, each transformer layer updates only a <strong>sub-block</strong> (e.g., one-quarter) of the full vector, and uses a lightweight <strong>predict-correct mechanism</strong> to infer updates for the rest.</p>\n<h4 id=\"core-idea-predictcomputecorrect\">Core Idea: Predict–Compute–Correct</h4>\n<ul>\n  <li>\n    <p>Suppose the token representation is expanded from dimension <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-41-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-436\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-437\"><span class=\"mi\" id=\"MathJax-Span-438\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-41\">d</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-42-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi><mo>&amp;#x22C5;</mo><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-439\" style=\"width: 2.763em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1002.29em, 2.398em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-440\"><span class=\"mi\" id=\"MathJax-Span-441\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-442\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-443\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi><mo>⋅</mo><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-42\">K \\cdot d</script>. AltUp divides this expanded vector into <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-43-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-444\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-445\"><span class=\"mi\" id=\"MathJax-Span-446\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-43\">K</script> chunks, e.g., for <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-44-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi><mo>=</mo><mn>2</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-447\" style=\"width: 2.971em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.451em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.45em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-448\"><span class=\"mi\" id=\"MathJax-Span-449\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-450\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-451\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi><mo>=</mo><mn>2</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-44\">K = 2</script>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-45-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>x</mi><mo>=</mo><mtext>concat</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-452\" style=\"width: 8.648em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 7.19em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1007.14em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-453\"><span class=\"mi\" id=\"MathJax-Span-454\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-455\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-456\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">concat</span><span class=\"mo\" id=\"MathJax-Span-457\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-458\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-459\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-460\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-461\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-462\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-463\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-464\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-465\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>x</mi><mo>=</mo><mtext>concat</mtext><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-45\">x = \\text{concat}(x_1, x_2)</script>\n  </li>\n  <li>\n    <p>At each transformer layer:</p>\n\n    <ol>\n      <li><strong>Predict</strong>: Compute an estimate <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-46-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mover><mi>x</mi><mo stretchy=&quot;false&quot;>&amp;#x005E;</mo></mover></mrow><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-466\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-467\"><span class=\"msubsup\" id=\"MathJax-Span-468\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.128em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-469\"><span class=\"mrow\" id=\"MathJax-Span-470\"><span class=\"munderover\" id=\"MathJax-Span-471\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-472\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.06em; left: 0.107em;\"><span style=\"height: 0em; vertical-align: 0em; width: 0.367em; display: inline-block; overflow: hidden;\"></span><span class=\"mo\" id=\"MathJax-Span-473\" style=\"font-family: STIXGeneral-Regular;\">̂&nbsp;<span style=\"height: 0em; vertical-align: 0em; margin-left: -0.258em;\"></span></span><span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0em;\"></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-474\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mrow class=\"MJX-TeXAtom-ORD\"><mover><mi>x</mi><mo stretchy=\"false\">^</mo></mover></mrow><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-46\">\\hat{x}_i</script> for each sub-block as a linear combination of the others.</li>\n      <li><strong>Compute</strong>: Apply the transformer layer to only one sub-block (e.g., <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-47-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mn>1</mn></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-475\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-476\"><span class=\"msubsup\" id=\"MathJax-Span-477\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-478\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-479\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>x</mi><mn>1</mn></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-47\">x_1</script>).</li>\n      <li><strong>Correct</strong>: Use the updated sub-block to refine predictions for all other sub-blocks.</li>\n    </ol>\n  </li>\n  <li>\n    <p>This approach ensures that each part of the expanded representation gets updated across layers (e.g., via round-robin or alternating scheduling) without processing the full width at once.</p>\n  </li>\n</ul>\n<p>Suppose the token representation is expanded from dimension <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-41-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-436\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-437\"><span class=\"mi\" id=\"MathJax-Span-438\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-41\">d</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-42-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi><mo>&amp;#x22C5;</mo><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-439\" style=\"width: 2.763em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1002.29em, 2.398em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-440\"><span class=\"mi\" id=\"MathJax-Span-441\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-442\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">⋅</span><span class=\"mi\" id=\"MathJax-Span-443\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi><mo>⋅</mo><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-42\">K \\cdot d</script>. AltUp divides this expanded vector into <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-43-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-444\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-445\"><span class=\"mi\" id=\"MathJax-Span-446\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-43\">K</script> chunks, e.g., for <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-44-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi><mo>=</mo><mn>2</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-447\" style=\"width: 2.971em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.451em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.45em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-448\"><span class=\"mi\" id=\"MathJax-Span-449\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-450\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-451\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">2</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi><mo>=</mo><mn>2</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-44\">K = 2</script>:</p>\n<p>At each transformer layer:</p>\n<ol>\n      <li><strong>Predict</strong>: Compute an estimate <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-46-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mover><mi>x</mi><mo stretchy=&quot;false&quot;>&amp;#x005E;</mo></mover></mrow><mi>i</mi></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-466\" style=\"width: 0.888em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.253em, 1000.73em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-467\"><span class=\"msubsup\" id=\"MathJax-Span-468\"><span style=\"display: inline-block; position: relative; width: 0.732em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.128em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-469\"><span class=\"mrow\" id=\"MathJax-Span-470\"><span class=\"munderover\" id=\"MathJax-Span-471\"><span style=\"display: inline-block; position: relative; width: 0.471em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-472\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.06em; left: 0.107em;\"><span style=\"height: 0em; vertical-align: 0em; width: 0.367em; display: inline-block; overflow: hidden;\"></span><span class=\"mo\" id=\"MathJax-Span-473\" style=\"font-family: STIXGeneral-Regular;\">̂&nbsp;<span style=\"height: 0em; vertical-align: 0em; margin-left: -0.258em;\"></span></span><span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0em;\"></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mi\" id=\"MathJax-Span-474\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mrow class=\"MJX-TeXAtom-ORD\"><mover><mi>x</mi><mo stretchy=\"false\">^</mo></mover></mrow><mi>i</mi></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-46\">\\hat{x}_i</script> for each sub-block as a linear combination of the others.</li>\n      <li><strong>Compute</strong>: Apply the transformer layer to only one sub-block (e.g., <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-47-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mn>1</mn></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-475\" style=\"width: 1.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1000.89em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-476\"><span class=\"msubsup\" id=\"MathJax-Span-477\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-478\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"mn\" id=\"MathJax-Span-479\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>x</mi><mn>1</mn></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-47\">x_1</script>).</li>\n      <li><strong>Correct</strong>: Use the updated sub-block to refine predictions for all other sub-blocks.</li>\n    </ol>\n<p>This approach ensures that each part of the expanded representation gets updated across layers (e.g., via round-robin or alternating scheduling) without processing the full width at once.</p>\n<h4 id=\"efficiency-benefits\">Efficiency Benefits</h4>\n<ul>\n  <li>\n    <p>AltUp avoids the <strong>quadratic scaling</strong> of computation cost with dimension width. Instead of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-48-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>K</mi><mn>2</mn></msup><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-480\" style=\"width: 4.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.596em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1003.54em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-481\"><span class=\"mi\" id=\"MathJax-Span-482\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-483\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-484\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-485\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.784em;\"><span class=\"mn\" id=\"MathJax-Span-486\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-487\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-488\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-489\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-490\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>K</mi><mn>2</mn></msup><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-48\">O(K^2d^2)</script> for a naïvely widened model, AltUp achieves <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-49-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>d</mi><mn>2</mn></msup><mo>+</mo><msup><mi>K</mi><mn>2</mn></msup><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-491\" style=\"width: 6.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.211em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1005.16em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-492\"><span class=\"mi\" id=\"MathJax-Span-493\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-494\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-495\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-496\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-497\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-498\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"msubsup\" id=\"MathJax-Span-499\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-500\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.784em;\"><span class=\"mn\" id=\"MathJax-Span-501\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-502\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-503\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>d</mi><mn>2</mn></msup><mo>+</mo><msup><mi>K</mi><mn>2</mn></msup><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-49\">O(d^2 + K^2d)</script> complexity per layer.</p>\n  </li>\n  <li>\n    <p>Only a few learnable parameters are introduced per layer (on the order of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-50-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>K</mi><mn>2</mn></msup><mo>+</mo><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-504\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1003.08em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-505\"><span class=\"msubsup\" id=\"MathJax-Span-506\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-507\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.784em;\"><span class=\"mn\" id=\"MathJax-Span-508\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-509\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-510\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>K</mi><mn>2</mn></msup><mo>+</mo><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-50\">K^2 + K</script>), and memory impact is minimal. At inference, the <strong>Key-Value cache is unaffected</strong>, which is essential for real-time generation tasks.</p>\n  </li>\n  <li>\n    <p>The method scales well and shows up to <strong>87% speedups</strong> on benchmarks like SuperGLUE and SQuAD when applied to T5 models, without loss in accuracy.</p>\n  </li>\n</ul>\n<p>AltUp avoids the <strong>quadratic scaling</strong> of computation cost with dimension width. Instead of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-48-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>K</mi><mn>2</mn></msup><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-480\" style=\"width: 4.326em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.596em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1003.54em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-481\"><span class=\"mi\" id=\"MathJax-Span-482\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-483\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-484\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-485\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.784em;\"><span class=\"mn\" id=\"MathJax-Span-486\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-487\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-488\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-489\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-490\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>K</mi><mn>2</mn></msup><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-48\">O(K^2d^2)</script> for a naïvely widened model, AltUp achieves <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-49-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>d</mi><mn>2</mn></msup><mo>+</mo><msup><mi>K</mi><mn>2</mn></msup><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-491\" style=\"width: 6.253em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.211em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1005.16em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-492\"><span class=\"mi\" id=\"MathJax-Span-493\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-494\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-495\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.52em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-496\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.576em;\"><span class=\"mn\" id=\"MathJax-Span-497\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-498\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"msubsup\" id=\"MathJax-Span-499\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-500\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.784em;\"><span class=\"mn\" id=\"MathJax-Span-501\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-502\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-503\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>d</mi><mn>2</mn></msup><mo>+</mo><msup><mi>K</mi><mn>2</mn></msup><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-49\">O(d^2 + K^2d)</script> complexity per layer.</p>\n<p>Only a few learnable parameters are introduced per layer (on the order of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-50-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>K</mi><mn>2</mn></msup><mo>+</mo><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-504\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1003.08em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-505\"><span class=\"msubsup\" id=\"MathJax-Span-506\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.73em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-507\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.784em;\"><span class=\"mn\" id=\"MathJax-Span-508\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-509\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-510\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>K</mi><mn>2</mn></msup><mo>+</mo><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-50\">K^2 + K</script>), and memory impact is minimal. At inference, the <strong>Key-Value cache is unaffected</strong>, which is essential for real-time generation tasks.</p>\n<p>The method scales well and shows up to <strong>87% speedups</strong> on benchmarks like SuperGLUE and SQuAD when applied to T5 models, without loss in accuracy.</p>\n<h4 id=\"practical-extensions\">Practical Extensions</h4>\n<ul>\n  <li>\n    <p><strong>Recycled-AltUp</strong>: Avoids expanding the embedding table by reusing a narrow embedding and duplicating it across chunks. At the output layer, it sums the sub-blocks and projects back to standard size. This offers improved speed and parameter efficiency with negligible loss in quality.</p>\n  </li>\n  <li>\n    <p><strong>Sequence-AltUp</strong>: Applies the AltUp strategy to the sequence dimension instead of the embedding dimension. It selectively processes only a subset of sequence positions in each layer (similar to strided sampling) while predicting and correcting the rest. This drastically reduces attention computation in long contexts.</p>\n  </li>\n</ul>\n<p><strong>Recycled-AltUp</strong>: Avoids expanding the embedding table by reusing a narrow embedding and duplicating it across chunks. At the output layer, it sums the sub-blocks and projects back to standard size. This offers improved speed and parameter efficiency with negligible loss in quality.</p>\n<p><strong>Sequence-AltUp</strong>: Applies the AltUp strategy to the sequence dimension instead of the embedding dimension. It selectively processes only a subset of sequence positions in each layer (similar to strided sampling) while predicting and correcting the rest. This drastically reduces attention computation in long contexts.</p>\n<h4 id=\"integration-with-gemma-3n\">Integration with Gemma 3n</h4>\n<ul>\n  <li>\n    <p>While not explicitly documented in the public Gemma 3n architecture, the <strong>developer blog confirms</strong> that AltUp is one of the novel architectural components behind its mobile-first design. In conjunction with LAuReL and MatFormer, it helps Gemma 3n achieve competitive performance under strict compute and memory limits.</p>\n  </li>\n  <li>\n    <p>AltUp’s low implementation complexity and synergy with other techniques like MoE or MatFormer make it a strong candidate for future multimodal model stacks that demand elastic scaling and efficient representation learning.</p>\n  </li>\n</ul>\n<p>While not explicitly documented in the public Gemma 3n architecture, the <strong>developer blog confirms</strong> that AltUp is one of the novel architectural components behind its mobile-first design. In conjunction with LAuReL and MatFormer, it helps Gemma 3n achieve competitive performance under strict compute and memory limits.</p>\n<p>AltUp’s low implementation complexity and synergy with other techniques like MoE or MatFormer make it a strong candidate for future multimodal model stacks that demand elastic scaling and efficient representation learning.</p>",
    "contentMarkdown": "*   **Alternating Updates (AltUp)**, proposed in [Alternating Updates for Efficient Transformers](https://arxiv.org/abs/2301.13310) by Baykal et al. (2023), is a technique designed to increase a transformer’s representational capacity (e.g., wider token embeddings) without incurring a proportional increase in computation or memory overhead. It is particularly relevant to on-device architectures like Gemma 3n, where hardware constraints demand high efficiency at runtime.\n    \n*   AltUp widens the representation dimension (e.g., from 2048 to 4096) but avoids computing over the entire width in each layer. Instead, each transformer layer updates only a **sub-block** (e.g., one-quarter) of the full vector, and uses a lightweight **predict-correct mechanism** to infer updates for the rest.\n    \n\n**Alternating Updates (AltUp)**, proposed in [Alternating Updates for Efficient Transformers](https://arxiv.org/abs/2301.13310) by Baykal et al. (2023), is a technique designed to increase a transformer’s representational capacity (e.g., wider token embeddings) without incurring a proportional increase in computation or memory overhead. It is particularly relevant to on-device architectures like Gemma 3n, where hardware constraints demand high efficiency at runtime.\n\nAltUp widens the representation dimension (e.g., from 2048 to 4096) but avoids computing over the entire width in each layer. Instead, each transformer layer updates only a **sub-block** (e.g., one-quarter) of the full vector, and uses a lightweight **predict-correct mechanism** to infer updates for the rest.\n\n#### Core Idea: Predict–Compute–Correct\n\n*   Suppose the token representation is expanded from dimension ddd to K⋅dK⋅dK \\\\cdot d. AltUp divides this expanded vector into KKK chunks, e.g., for K\\=2K\\=2K = 2:\n    \n    x\\=concat(x1,x2)x\\=concat(x1,x2)\n    \n    x = \\\\text{concat}(x\\_1, x\\_2)\n*   At each transformer layer:\n    \n    1.  **Predict**: Compute an estimate x̂ ix^i\\\\hat{x}\\_i for each sub-block as a linear combination of the others.\n    2.  **Compute**: Apply the transformer layer to only one sub-block (e.g., x1x1x\\_1).\n    3.  **Correct**: Use the updated sub-block to refine predictions for all other sub-blocks.\n*   This approach ensures that each part of the expanded representation gets updated across layers (e.g., via round-robin or alternating scheduling) without processing the full width at once.\n    \n\nSuppose the token representation is expanded from dimension ddd to K⋅dK⋅dK \\\\cdot d. AltUp divides this expanded vector into KKK chunks, e.g., for K\\=2K\\=2K = 2:\n\nAt each transformer layer:\n\n1.  **Predict**: Compute an estimate x̂ ix^i\\\\hat{x}\\_i for each sub-block as a linear combination of the others.\n2.  **Compute**: Apply the transformer layer to only one sub-block (e.g., x1x1x\\_1).\n3.  **Correct**: Use the updated sub-block to refine predictions for all other sub-blocks.\n\nThis approach ensures that each part of the expanded representation gets updated across layers (e.g., via round-robin or alternating scheduling) without processing the full width at once.\n\n#### Efficiency Benefits\n\n*   AltUp avoids the **quadratic scaling** of computation cost with dimension width. Instead of O(K2d2)O(K2d2)O(K^2d^2) for a naïvely widened model, AltUp achieves O(d2+K2d)O(d2+K2d)O(d^2 + K^2d) complexity per layer.\n    \n*   Only a few learnable parameters are introduced per layer (on the order of K2+KK2+KK^2 + K), and memory impact is minimal. At inference, the **Key-Value cache is unaffected**, which is essential for real-time generation tasks.\n    \n*   The method scales well and shows up to **87% speedups** on benchmarks like SuperGLUE and SQuAD when applied to T5 models, without loss in accuracy.\n    \n\nAltUp avoids the **quadratic scaling** of computation cost with dimension width. Instead of O(K2d2)O(K2d2)O(K^2d^2) for a naïvely widened model, AltUp achieves O(d2+K2d)O(d2+K2d)O(d^2 + K^2d) complexity per layer.\n\nOnly a few learnable parameters are introduced per layer (on the order of K2+KK2+KK^2 + K), and memory impact is minimal. At inference, the **Key-Value cache is unaffected**, which is essential for real-time generation tasks.\n\nThe method scales well and shows up to **87% speedups** on benchmarks like SuperGLUE and SQuAD when applied to T5 models, without loss in accuracy.\n\n#### Practical Extensions\n\n*   **Recycled-AltUp**: Avoids expanding the embedding table by reusing a narrow embedding and duplicating it across chunks. At the output layer, it sums the sub-blocks and projects back to standard size. This offers improved speed and parameter efficiency with negligible loss in quality.\n    \n*   **Sequence-AltUp**: Applies the AltUp strategy to the sequence dimension instead of the embedding dimension. It selectively processes only a subset of sequence positions in each layer (similar to strided sampling) while predicting and correcting the rest. This drastically reduces attention computation in long contexts.\n    \n\n**Recycled-AltUp**: Avoids expanding the embedding table by reusing a narrow embedding and duplicating it across chunks. At the output layer, it sums the sub-blocks and projects back to standard size. This offers improved speed and parameter efficiency with negligible loss in quality.\n\n**Sequence-AltUp**: Applies the AltUp strategy to the sequence dimension instead of the embedding dimension. It selectively processes only a subset of sequence positions in each layer (similar to strided sampling) while predicting and correcting the rest. This drastically reduces attention computation in long contexts.\n\n#### Integration with Gemma 3n\n\n*   While not explicitly documented in the public Gemma 3n architecture, the **developer blog confirms** that AltUp is one of the novel architectural components behind its mobile-first design. In conjunction with LAuReL and MatFormer, it helps Gemma 3n achieve competitive performance under strict compute and memory limits.\n    \n*   AltUp’s low implementation complexity and synergy with other techniques like MoE or MatFormer make it a strong candidate for future multimodal model stacks that demand elastic scaling and efficient representation learning.\n    \n\nWhile not explicitly documented in the public Gemma 3n architecture, the **developer blog confirms** that AltUp is one of the novel architectural components behind its mobile-first design. In conjunction with LAuReL and MatFormer, it helps Gemma 3n achieve competitive performance under strict compute and memory limits.\n\nAltUp’s low implementation complexity and synergy with other techniques like MoE or MatFormer make it a strong candidate for future multimodal model stacks that demand elastic scaling and efficient representation learning.",
    "order": 9,
    "orderInChapter": 5,
    "difficulty": 3,
    "estimatedMinutes": 5,
    "tags": [
      "models",
      "transformer",
      "attention",
      "embedding"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 936,
      "contentLength": 50373
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/gemma-3n/#alternating-updates-for-efficient-transformers-(altup)",
    "scrapedAt": "2025-12-28T11:52:03.954Z"
  }
]