[
  {
    "id": "ai-toolformer-sampling-api-calls-1",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Approach",
    "title": "Sampling API Calls",
    "order": 1,
    "orderInChapter": 1,
    "contentHtml": "<p><img src=\"/primers/ai/assets/toolformer/3.png\" alt=\"\"></p>\n<ul>\n  <li>The image above <a href=\"https://arxiv.org/pdf/2302.04761.pdf\">(source)</a> shows examples of the prompts Toolformer uses to make APIs calls given the user input.</li>\n  <li>Toolformer uses <api> and </api> to indicate the start and end of the API call.</li>\n  <li>A prompt is written for each API, which encourages the Toolformer to annotate an example with relevant API calls.</li>\n  <li>Toolformer assigns a probability to each token as a possible continuation of a given sequence.</li>\n  <li>The method involves sampling up to k candidate positions for API calls by computing the probability that the Toolformer assigns to starting an API call at each position in the sequence.</li>\n  <li>Positions with probabilities greater than a given threshold are kept, and for each position, up to m API calls are obtained by sampling from the Toolformer using the sequence with the API call as a prefix and the end-of-sequence token as the suffix.</li>\n</ul>",
    "contentMarkdown": "![](/primers/ai/assets/toolformer/3.png)\n\n*   The image above [(source)](https://arxiv.org/pdf/2302.04761.pdf) shows examples of the prompts Toolformer uses to make APIs calls given the user input.\n*   Toolformer uses and to indicate the start and end of the API call.\n*   A prompt is written for each API, which encourages the Toolformer to annotate an example with relevant API calls.\n*   Toolformer assigns a probability to each token as a possible continuation of a given sequence.\n*   The method involves sampling up to k candidate positions for API calls by computing the probability that the Toolformer assigns to starting an API call at each position in the sequence.\n*   Positions with probabilities greater than a given threshold are kept, and for each position, up to m API calls are obtained by sampling from the Toolformer using the sequence with the API call as a prefix and the end-of-sequence token as the suffix.",
    "contentLength": 1026,
    "wordCount": 147,
    "hasCode": false,
    "hasMath": false,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/toolformer/#sampling-api-calls"
  },
  {
    "id": "ai-toolformer-executing-api-calls-2",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Approach",
    "title": "Executing API Calls",
    "order": 2,
    "orderInChapter": 2,
    "contentHtml": "<ul>\n  <li>The next step in the architecture is to actually make the API calls.</li>\n  <li>This is entirely dependent on the client we are calling, whether it be another neural network, a Python script, or a retrieval system that searches over a large corpus.</li>\n  <li>The thing to note is that the response here needs to be in a singular text sequence.</li>\n</ul>",
    "contentMarkdown": "*   The next step in the architecture is to actually make the API calls.\n*   This is entirely dependent on the client we are calling, whether it be another neural network, a Python script, or a retrieval system that searches over a large corpus.\n*   The thing to note is that the response here needs to be in a singular text sequence.",
    "contentLength": 366,
    "wordCount": 62,
    "hasCode": false,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/toolformer/#executing-api-calls"
  },
  {
    "id": "ai-toolformer-filtering-api-calls-3",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Approach",
    "title": "Filtering API Calls",
    "order": 3,
    "orderInChapter": 3,
    "contentHtml": "<ul>\n  <li>During filtering, Toolformer calculates a weighted cross-entropy loss for Toolformer over the tokens following the API call.</li>\n  <li>Then, two different loss calculations are compared: one with the API call and its result given as input to Toolformer, and one with no API call or with the API call but not providing the result.</li>\n  <li>API calls are considered useful if providing them with both input and output makes it easier for Toolformer to predict future tokens.</li>\n  <li>A filtering threshold is applied to keep only API calls for which the difference between the two losses is greater than or equal to the threshold.</li>\n</ul>",
    "contentMarkdown": "*   During filtering, Toolformer calculates a weighted cross-entropy loss for Toolformer over the tokens following the API call.\n*   Then, two different loss calculations are compared: one with the API call and its result given as input to Toolformer, and one with no API call or with the API call but not providing the result.\n*   API calls are considered useful if providing them with both input and output makes it easier for Toolformer to predict future tokens.\n*   A filtering threshold is applied to keep only API calls for which the difference between the two losses is greater than or equal to the threshold.",
    "contentLength": 655,
    "wordCount": 105,
    "hasCode": false,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/toolformer/#filtering-api-calls"
  },
  {
    "id": "ai-toolformer-model-finetuning-4",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Approach",
    "title": "Model Finetuning",
    "order": 4,
    "orderInChapter": 4,
    "contentHtml": "<ul>\n  <li>Finally, Toolformer merges the remaining API calls with the original inputs and creates a new dataset augmented with API calls.</li>\n  <li>The new dataset is then used to finetune Toolformer using a standard language modeling objective.</li>\n  <li>Note: the augmented dataset contains the same texts as the original dataset, with only inserted API calls.</li>\n  <li>This is because this ensures that finetuning the model on the augmented dataset exposes it to the same content as finetuning on the original dataset.</li>\n  <li>By inserting API calls in the exact positions and with the inputs that help the model predict future tokens, finetuning on the augmented data enables the language model to learn when and how to use the API calls based on its own feedback.</li>\n</ul>",
    "contentMarkdown": "*   Finally, Toolformer merges the remaining API calls with the original inputs and creates a new dataset augmented with API calls.\n*   The new dataset is then used to finetune Toolformer using a standard language modeling objective.\n*   Note: the augmented dataset contains the same texts as the original dataset, with only inserted API calls.\n*   This is because this ensures that finetuning the model on the augmented dataset exposes it to the same content as finetuning on the original dataset.\n*   By inserting API calls in the exact positions and with the inputs that help the model predict future tokens, finetuning on the augmented data enables the language model to learn when and how to use the API calls based on its own feedback.",
    "contentLength": 787,
    "wordCount": 125,
    "hasCode": false,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/toolformer/#model-finetuning"
  },
  {
    "id": "ai-toolformer-inference-5",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Approach",
    "title": "Inference",
    "order": 5,
    "orderInChapter": 5,
    "contentHtml": "<ul>\n  <li>During inference, the decoding process is interrupted when the language model produces the “→” token, indicating the next expected response for an API call.</li>\n  <li>The appropriate API is then called to get the response, and decoding continues after inserting both the response and the “&lt;/API&gt;” token.</li>\n</ul>",
    "contentMarkdown": "*   During inference, the decoding process is interrupted when the language model produces the “→” token, indicating the next expected response for an API call.\n*   The appropriate API is then called to get the response, and decoding continues after inserting both the response and the “</API>” token.",
    "contentLength": 332,
    "wordCount": 48,
    "hasCode": false,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/toolformer/#inference"
  },
  {
    "id": "ai-toolformer-lama-6",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Experimental Results",
    "title": "LAMA",
    "order": 6,
    "orderInChapter": 1,
    "contentHtml": "<ul>\n  <li>Here, the task is to complete a statement with a missing fact.</li>\n  <li>Toolformer outperforms baseline models and even larger models such as GPT-3.</li>\n  <li>The authors also prevent Toolformer from using the Wikipedia Search API to avoid an unfair advantage.</li>\n  <li>The following table <a href=\"https://arxiv.org/pdf/2302.04761.pdf\">(source)</a> encapsulates the results obtained with LAMA API calls:</li>\n</ul>\n<p><img src=\"/primers/ai/assets/toolformer/5.png\" alt=\"\"></p>",
    "contentMarkdown": "*   Here, the task is to complete a statement with a missing fact.\n*   Toolformer outperforms baseline models and even larger models such as GPT-3.\n*   The authors also prevent Toolformer from using the Wikipedia Search API to avoid an unfair advantage.\n*   The following table [(source)](https://arxiv.org/pdf/2302.04761.pdf) encapsulates the results obtained with LAMA API calls:\n\n![](/primers/ai/assets/toolformer/5.png)",
    "contentLength": 493,
    "wordCount": 56,
    "hasCode": false,
    "hasMath": false,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/toolformer/#lama"
  },
  {
    "id": "ai-toolformer-math-datasets-7",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Experimental Results",
    "title": "Math Datasets",
    "order": 7,
    "orderInChapter": 2,
    "contentHtml": "<ul>\n  <li>The task here was to evaluate the mathematical reasoning abilities of Toolformer against various baseline models.</li>\n  <li>Toolformer performs better than the other models, possibly due to its fine-tuning on examples of API calls.</li>\n  <li>Allowing the model to make API calls significantly improves performance for all tasks and outperforms larger models like OPT and GPT-3.</li>\n  <li>In almost all cases, the model decides to ask the calculator tool for help.</li>\n  <li>The following table <a href=\"https://arxiv.org/pdf/2302.04761.pdf\">(source)</a> encapsulates the results obtained with Calculator API calls:</li>\n</ul>\n<p><img src=\"/primers/ai/assets/toolformer/6.png\" alt=\"\"></p>",
    "contentMarkdown": "*   The task here was to evaluate the mathematical reasoning abilities of Toolformer against various baseline models.\n*   Toolformer performs better than the other models, possibly due to its fine-tuning on examples of API calls.\n*   Allowing the model to make API calls significantly improves performance for all tasks and outperforms larger models like OPT and GPT-3.\n*   In almost all cases, the model decides to ask the calculator tool for help.\n*   The following table [(source)](https://arxiv.org/pdf/2302.04761.pdf) encapsulates the results obtained with Calculator API calls:\n\n![](/primers/ai/assets/toolformer/6.png)",
    "contentLength": 702,
    "wordCount": 86,
    "hasCode": false,
    "hasMath": false,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/toolformer/#math-datasets"
  },
  {
    "id": "ai-toolformer-question-answering-8",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Experimental Results",
    "title": "Question Answering",
    "order": 8,
    "orderInChapter": 3,
    "contentHtml": "<ul>\n  <li>Here, the model was tasked with question-answering.</li>\n  <li>We can see that Toolformer outperformed the baseline models of the same size but was outperformed by GPT-3 (175B).</li>\n  <li>Toolformer leveraged Wikipedia’s search tool for most of the examples in this task.</li>\n  <li>The authors attribute the pitfall here due to the lack of quality of their search engine.</li>\n  <li>The following table <a href=\"https://arxiv.org/pdf/2302.04761.pdf\">(source)</a> encapsulates the results obtained with the Wikipedia search tool API calls:</li>\n</ul>\n<p><img src=\"/primers/ai/assets/toolformer/7.png\" alt=\"\"></p>",
    "contentMarkdown": "*   Here, the model was tasked with question-answering.\n*   We can see that Toolformer outperformed the baseline models of the same size but was outperformed by GPT-3 (175B).\n*   Toolformer leveraged Wikipedia’s search tool for most of the examples in this task.\n*   The authors attribute the pitfall here due to the lack of quality of their search engine.\n*   The following table [(source)](https://arxiv.org/pdf/2302.04761.pdf) encapsulates the results obtained with the Wikipedia search tool API calls:\n\n![](/primers/ai/assets/toolformer/7.png)",
    "contentLength": 624,
    "wordCount": 76,
    "hasCode": false,
    "hasMath": false,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/toolformer/#question-answering"
  },
  {
    "id": "ai-toolformer-multilingual-question-answering-9",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Experimental Results",
    "title": "Multilingual Question Answering",
    "order": 9,
    "orderInChapter": 4,
    "contentHtml": "<ul>\n  <li>The question answering dataset was used for the multilingual question-answering benchmark, MLQA, with a context paragraph in English and questions in Arabic, German, Spanish, Hindi, Vietnamese, or Simplified Chinese.</li>\n  <li>Toolformer does not come out here as the strongest performer, perhaps due to the lack of CCNet being finetuned on all the languages.</li>\n  <li>The following table <a href=\"https://arxiv.org/pdf/2302.04761.pdf\">(source)</a> encapsulates the results obtained with the Wikipedia search tool API calls:</li>\n</ul>\n<p><img src=\"/primers/ai/assets/toolformer/8.png\" alt=\"\"></p>",
    "contentMarkdown": "*   The question answering dataset was used for the multilingual question-answering benchmark, MLQA, with a context paragraph in English and questions in Arabic, German, Spanish, Hindi, Vietnamese, or Simplified Chinese.\n*   Toolformer does not come out here as the strongest performer, perhaps due to the lack of CCNet being finetuned on all the languages.\n*   The following table [(source)](https://arxiv.org/pdf/2302.04761.pdf) encapsulates the results obtained with the Wikipedia search tool API calls:\n\n![](/primers/ai/assets/toolformer/8.png)",
    "contentLength": 611,
    "wordCount": 71,
    "hasCode": false,
    "hasMath": false,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/toolformer/#multilingual-question-answering"
  },
  {
    "id": "ai-toolformer-temporal-datasets-10",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Experimental Results",
    "title": "Temporal Datasets",
    "order": 10,
    "orderInChapter": 5,
    "contentHtml": "<ul>\n  <li>This is where knowing the current date is crucial to answering the question.</li>\n  <li>Toolformer was able to outperform the baseline, however, apparently it was not utilizing the calendar tool 100% of the time. Instead, it was using Wikipedia’s search.</li>\n  <li>The following table <a href=\"https://arxiv.org/pdf/2302.04761.pdf\">(source)</a> encapsulates the results obtained with the Wikipedia search tool API calls:</li>\n</ul>\n<p><img src=\"/primers/ai/assets/toolformer/9.png\" alt=\"\"></p>",
    "contentMarkdown": "*   This is where knowing the current date is crucial to answering the question.\n*   Toolformer was able to outperform the baseline, however, apparently it was not utilizing the calendar tool 100% of the time. Instead, it was using Wikipedia’s search.\n*   The following table [(source)](https://arxiv.org/pdf/2302.04761.pdf) encapsulates the results obtained with the Wikipedia search tool API calls:\n\n![](/primers/ai/assets/toolformer/9.png)",
    "contentLength": 505,
    "wordCount": 58,
    "hasCode": false,
    "hasMath": false,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/toolformer/#temporal-datasets"
  },
  {
    "id": "ai-toolformer-language-modeling-11",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Experimental Results",
    "title": "Language Modeling",
    "order": 11,
    "orderInChapter": 6,
    "contentHtml": "<ul>\n  <li>The study evaluates Toolformer on two language modeling datasets: WikiText and a subset of 10,000 randomly selected documents from CCNet.</li>\n  <li>The goal is to ensure that finetuning with API calls does not degrade the language modeling performance of Toolformer.</li>\n  <li>The models are evaluated based on their perplexity on the two datasets, with lower perplexity indicating better performance.</li>\n  <li>Toolformer, GPT-J, and GPT-J + CC perform similarly on both datasets, indicating that Toolformer does not degrade the language modeling performance of GPT-J.</li>\n  <li>The following table <a href=\"https://arxiv.org/pdf/2302.04761.pdf\">(source)</a> encapsulates the results obtained:</li>\n</ul>\n<p><img src=\"/primers/ai/assets/toolformer/10.png\" alt=\"\"></p>",
    "contentMarkdown": "*   The study evaluates Toolformer on two language modeling datasets: WikiText and a subset of 10,000 randomly selected documents from CCNet.\n*   The goal is to ensure that finetuning with API calls does not degrade the language modeling performance of Toolformer.\n*   The models are evaluated based on their perplexity on the two datasets, with lower perplexity indicating better performance.\n*   Toolformer, GPT-J, and GPT-J + CC perform similarly on both datasets, indicating that Toolformer does not degrade the language modeling performance of GPT-J.\n*   The following table [(source)](https://arxiv.org/pdf/2302.04761.pdf) encapsulates the results obtained:\n\n![](/primers/ai/assets/toolformer/10.png)",
    "contentLength": 783,
    "wordCount": 94,
    "hasCode": false,
    "hasMath": false,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/toolformer/#language-modeling"
  },
  {
    "id": "ai-toolformer-scaling-law-12",
    "articleSlug": "toolformer",
    "articleTitle": "Toolformer",
    "category": "Models",
    "chapter": "Experimental Results",
    "title": "Scaling Law",
    "order": 12,
    "orderInChapter": 7,
    "contentHtml": "<ul>\n  <li>The study evaluates the performance of four smaller models from the GPT-2 family (with 124M, 355M, 775M, and 1.6B parameters, respectively) using the Toolformer approach.</li>\n  <li>Only a subset of three tools are used: the question-answering system, the calculator, and the Wikipedia search engine.</li>\n  <li>The goal is to see how the Toolformer approach scales with the model size.</li>\n  <li>The following table <a href=\"https://arxiv.org/pdf/2302.04761.pdf\">(source)</a> encapsulates the results:</li>\n</ul>\n<p><img src=\"/primers/ai/assets/toolformer/11.png\" alt=\"\"></p>",
    "contentMarkdown": "*   The study evaluates the performance of four smaller models from the GPT-2 family (with 124M, 355M, 775M, and 1.6B parameters, respectively) using the Toolformer approach.\n*   Only a subset of three tools are used: the question-answering system, the calculator, and the Wikipedia search engine.\n*   The goal is to see how the Toolformer approach scales with the model size.\n*   The following table [(source)](https://arxiv.org/pdf/2302.04761.pdf) encapsulates the results:\n\n![](/primers/ai/assets/toolformer/11.png)",
    "contentLength": 588,
    "wordCount": 69,
    "hasCode": false,
    "hasMath": false,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/toolformer/#scaling-law"
  }
]