[
  {
    "id": "ai-dl-comp-use-cases-of-cnns-1",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "DL Architectures Comparative Analysis",
    "articleSlug": "dl-comp",
    "chapter": "Convolutional Neural Networks",
    "title": "Use-cases of CNNs",
    "subtitle": "Convolutional Neural Networks",
    "contentHtml": "<ul>\n  <li>CNNs are commonly used in solving problems related to spatial data, such as images (2D CNNs) and audio (1D CNNs).</li>\n  <li>Use cases for CNNs include facial recognition, medical analysis, and classification.</li>\n</ul>",
    "contentMarkdown": "*   CNNs are commonly used in solving problems related to spatial data, such as images (2D CNNs) and audio (1D CNNs).\n*   Use cases for CNNs include facial recognition, medical analysis, and classification.",
    "order": 1,
    "orderInChapter": 1,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "algorithmsarchitecture",
      "cnn"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 33,
      "contentLength": 231
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/dl-comp/#use-cases-of-cnns",
    "scrapedAt": "2025-12-28T11:45:51.813Z"
  },
  {
    "id": "ai-dl-comp-pros-of-cnns-compared-to-fcns-2",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "DL Architectures Comparative Analysis",
    "articleSlug": "dl-comp",
    "chapter": "Convolutional Neural Networks",
    "title": "Pros of CNNs Compared to FCNs",
    "subtitle": "Convolutional Neural Networks",
    "contentHtml": "<ul>\n  <li><strong>Parameter sharing/Computational tractability:</strong> Since CNNs utilize parameter sharing, the number of weights for a CNN vs. FCN architecture typically have a difference of several orders of magnitude.\n    <ul>\n      <li>For a fully connected layer, you have an input of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-1-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>H</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1\" style=\"width: 8.388em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.982em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.93em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2\"><span class=\"mo\" id=\"MathJax-Span-3\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-4\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.78em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-5\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-6\"><span class=\"mrow\" id=\"MathJax-Span-7\"><span class=\"mi\" id=\"MathJax-Span-8\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-9\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-10\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-11\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.461em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-12\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-13\"><span class=\"mrow\" id=\"MathJax-Span-14\"><span class=\"mi\" id=\"MathJax-Span-15\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-16\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-17\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-18\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-19\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-20\"><span class=\"mrow\" id=\"MathJax-Span-21\"><span class=\"mi\" id=\"MathJax-Span-22\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-23\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-24\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>H</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-1\">(H_{in} \\times W_{in} \\times C_{in})</script> and the output of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-2-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>H</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-25\" style=\"width: 9.69em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1008.02em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-26\"><span class=\"mo\" id=\"MathJax-Span-27\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-28\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.78em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-29\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-30\"><span class=\"mrow\" id=\"MathJax-Span-31\"><span class=\"mi\" id=\"MathJax-Span-32\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-33\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-34\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-35\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-36\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-37\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-38\"><span class=\"mrow\" id=\"MathJax-Span-39\"><span class=\"mi\" id=\"MathJax-Span-40\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-41\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-42\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-43\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-44\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-45\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-46\"><span class=\"mrow\" id=\"MathJax-Span-47\"><span class=\"mi\" id=\"MathJax-Span-48\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-49\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-50\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-51\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>H</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-2\">(H_{out} \\times W_{out} \\times C_{out})</script>. This means, that each color of the pixel of the output feature map is connected to every color of the pixel from the input feature map. There is a separate learnable parameter for each pixel in the input image and the output. Hence, one gets this huge number of parameters : <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-3-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>H</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>H</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-52\" style=\"width: 18.596em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 15.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1015.42em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-53\"><span class=\"mo\" id=\"MathJax-Span-54\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-55\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.78em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-56\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-57\"><span class=\"mrow\" id=\"MathJax-Span-58\"><span class=\"mi\" id=\"MathJax-Span-59\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-60\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-61\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-62\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.78em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-63\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-64\"><span class=\"mrow\" id=\"MathJax-Span-65\"><span class=\"mi\" id=\"MathJax-Span-66\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-67\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-68\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-69\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-70\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.461em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-71\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-72\"><span class=\"mrow\" id=\"MathJax-Span-73\"><span class=\"mi\" id=\"MathJax-Span-74\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-75\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-76\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-77\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-78\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-79\"><span class=\"mrow\" id=\"MathJax-Span-80\"><span class=\"mi\" id=\"MathJax-Span-81\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-82\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-83\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-84\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-85\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-86\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-87\"><span class=\"mrow\" id=\"MathJax-Span-88\"><span class=\"mi\" id=\"MathJax-Span-89\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-90\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-91\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-92\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-93\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-94\"><span class=\"mrow\" id=\"MathJax-Span-95\"><span class=\"mi\" id=\"MathJax-Span-96\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-97\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-98\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-99\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>H</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>H</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-3\">(H_{in} \\times H_{out} \\times  W_{in} \\times W_{out} \\times C_{in} \\times C_{out})</script></li>\n      <li>In the convolutional layer, the input is the image of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-4-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>H</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-100\" style=\"width: 6.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.68em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-101\"><span class=\"mo\" id=\"MathJax-Span-102\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-103\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.78em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-104\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-105\"><span class=\"mrow\" id=\"MathJax-Span-106\"><span class=\"mi\" id=\"MathJax-Span-107\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-108\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-109\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-110\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.461em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-111\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-112\"><span class=\"mrow\" id=\"MathJax-Span-113\"><span class=\"mi\" id=\"MathJax-Span-114\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-115\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-116\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-117\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-118\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-119\"><span class=\"mrow\" id=\"MathJax-Span-120\"><span class=\"mi\" id=\"MathJax-Span-121\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-122\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-123\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>H</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-4\">(H_{in}, W_{in}, C_{in})</script> and the weights account for the neighborhood of the given pixel, say of size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-5-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi><mo>&amp;#x00D7;</mo><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-124\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.66em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-125\"><span class=\"mi\" id=\"MathJax-Span-126\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-127\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-128\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi><mo>×</mo><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-5\">K \\times K</script>. The output is obtained as a weighted sum of the given pixel and its neighborhood. There is a separate kernel for each pair of the input and output channel <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-6-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-129\" style=\"width: 4.951em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.117em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.07em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-130\"><span class=\"mo\" id=\"MathJax-Span-131\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-132\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-133\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-134\"><span class=\"mrow\" id=\"MathJax-Span-135\"><span class=\"mi\" id=\"MathJax-Span-136\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-137\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-138\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-139\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-140\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-141\"><span class=\"mrow\" id=\"MathJax-Span-142\"><span class=\"mi\" id=\"MathJax-Span-143\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-144\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-145\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-146\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-6\">(C_{in}, C_{out})</script>, but the weights of the kernel (a tensor of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-7-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>K</mi><mo>,</mo><mi>K</mi><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-147\" style=\"width: 7.919em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.51em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-148\"><span class=\"mo\" id=\"MathJax-Span-149\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-150\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-151\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-152\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-153\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-154\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-155\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-156\"><span class=\"mrow\" id=\"MathJax-Span-157\"><span class=\"mi\" id=\"MathJax-Span-158\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-159\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-160\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-161\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-162\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-163\"><span class=\"mrow\" id=\"MathJax-Span-164\"><span class=\"mi\" id=\"MathJax-Span-165\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-166\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-167\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-168\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>K</mi><mo>,</mo><mi>K</mi><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-7\">(K, K, C_{in}, C_{out})</script> are independent of the location. Actually, this layer can accept images of any resolution, whereas, the fully connected can work only with a fixed resolution. Finally one has <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-8-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>K</mi><mo>,</mo><mi>K</mi><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-169\" style=\"width: 7.919em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.51em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-170\"><span class=\"mo\" id=\"MathJax-Span-171\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-172\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-173\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-174\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-175\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-176\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-177\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-178\"><span class=\"mrow\" id=\"MathJax-Span-179\"><span class=\"mi\" id=\"MathJax-Span-180\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-181\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-182\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-183\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-184\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-185\"><span class=\"mrow\" id=\"MathJax-Span-186\"><span class=\"mi\" id=\"MathJax-Span-187\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-188\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-189\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-190\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>K</mi><mo>,</mo><mi>K</mi><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-8\">(K, K, C_{in}, C_{out})</script> parameters, which for the kernel size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-191\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-192\"><span class=\"mi\" id=\"MathJax-Span-193\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-9\">K</script> much smaller, than the input resolution result into significant drop in the number of variables.</li>\n      <li>The sole fact that since AlexNet won the ImageNet competition, every neural network that has won it has used CNNs should be enough to convince you that CNNs are better for image data!</li>\n      <li>You most likely won’t be able to find any meaningful comparison, since CNNs are able to handle image data that is infeasible using only FC layers. Here’s why:\n        <ul>\n          <li>The number of weights in FC layer with 1000 neurons for <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>224</mn><mo>&amp;#x00D7;</mo><mn>224</mn><mo>&amp;#x00D7;</mo><mn>3</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-194\" style=\"width: 6.826em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-195\"><span class=\"mn\" id=\"MathJax-Span-196\" style=\"font-family: STIXGeneral-Regular;\">224</span><span class=\"mo\" id=\"MathJax-Span-197\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-198\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">224</span><span class=\"mo\" id=\"MathJax-Span-199\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-200\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>224</mn><mo>×</mo><mn>224</mn><mo>×</mo><mn>3</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-10\">224 \\times 224 \\times 3</script> image is something like 150M. <strong>That’s 150M for only one layer.</strong></li>\n          <li>If you’re not convinced this is a huge number, then note that modern CNN architectures that have 50-100 layers while having overall couple dozen million parameters (for example ResNet50 has 23M params, InceptionV3 has 21M parameters).</li>\n          <li>Mathematically, let’s compare the number of weights between CNNs and FCNs (with 100 hidden units) for an input image of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>500</mn><mo>&amp;#x00D7;</mo><mn>500</mn><mo>&amp;#x00D7;</mo><mn>3</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-201\" style=\"width: 6.826em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-202\"><span class=\"mn\" id=\"MathJax-Span-203\" style=\"font-family: STIXGeneral-Regular;\">500</span><span class=\"mo\" id=\"MathJax-Span-204\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-205\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">500</span><span class=\"mo\" id=\"MathJax-Span-206\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-207\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>500</mn><mo>×</mo><mn>500</mn><mo>×</mo><mn>3</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-11\">500 \\times 500 \\times 3</script>:\n            <ul>\n              <li>FC layer = Wx = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>100</mn><mo>&amp;#x00D7;</mo><mo stretchy=&quot;false&quot;>(</mo><mn>500</mn><mo>&amp;#x00D7;</mo><mn>500</mn><mo>&amp;#x00D7;</mo><mn>3</mn><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mn>100</mn><mo>&amp;#x00D7;</mo><mn>750000</mn><mo>=</mo><mn>75</mn><mi>M</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-208\" style=\"width: 22.659em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 18.857em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1018.86em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-209\"><span class=\"mn\" id=\"MathJax-Span-210\" style=\"font-family: STIXGeneral-Regular;\">100</span><span class=\"mo\" id=\"MathJax-Span-211\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mo\" id=\"MathJax-Span-212\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">(</span><span class=\"mn\" id=\"MathJax-Span-213\" style=\"font-family: STIXGeneral-Regular;\">500</span><span class=\"mo\" id=\"MathJax-Span-214\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">500</span><span class=\"mo\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span><span class=\"mo\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-219\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-220\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">100</span><span class=\"mo\" id=\"MathJax-Span-221\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-222\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">750000</span><span class=\"mo\" id=\"MathJax-Span-223\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-224\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">75</span><span class=\"mi\" id=\"MathJax-Span-225\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>100</mn><mo>×</mo><mo stretchy=\"false\">(</mo><mn>500</mn><mo>×</mo><mn>500</mn><mo>×</mo><mn>3</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>100</mn><mo>×</mo><mn>750000</mn><mo>=</mo><mn>75</mn><mi>M</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">100 \\times (500 \\times 500 \\times 3) = 100 \\times 750000 = 75M</script>.</li>\n              <li>CNN layer = <code class=\"language-plaintext highlighter-rouge\">((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)</code> (note that the <code class=\"language-plaintext highlighter-rouge\">+1</code> is for bias) = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>F</mi><mi>w</mi></msub><mo>&amp;#x00D7;</mo><mi>F</mi><mi>h</mi><mo>&amp;#x00D7;</mo><mi>D</mi><mo>+</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x00D7;</mo><mi>F</mi><mo>=</mo><mo stretchy=&quot;false&quot;>(</mo><mn>5</mn><mo>&amp;#x00D7;</mo><mn>5</mn><mo>&amp;#x00D7;</mo><mn>3</mn><mo>+</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2217;</mo><mn>2</mn><mo>=</mo><mn>152</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-226\" style=\"width: 24.638em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 20.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1020.52em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-227\"><span class=\"mo\" id=\"MathJax-Span-228\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-229\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-230\" style=\"font-family: STIXGeneral-Italic;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-231\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">w</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-233\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-234\" style=\"font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-235\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-236\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">D</span><span class=\"mo\" id=\"MathJax-Span-237\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-238\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-239\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-240\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-241\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-242\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mo\" id=\"MathJax-Span-243\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">(</span><span class=\"mn\" id=\"MathJax-Span-244\" style=\"font-family: STIXGeneral-Regular;\">5</span><span class=\"mo\" id=\"MathJax-Span-245\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">5</span><span class=\"mo\" id=\"MathJax-Span-247\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-248\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span><span class=\"mo\" id=\"MathJax-Span-249\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-251\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-252\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">∗</span><span class=\"mn\" id=\"MathJax-Span-253\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">2</span><span class=\"mo\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-255\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">152</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>F</mi><mi>w</mi></msub><mo>×</mo><mi>F</mi><mi>h</mi><mo>×</mo><mi>D</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>×</mo><mi>F</mi><mo>=</mo><mo stretchy=\"false\">(</mo><mn>5</mn><mo>×</mo><mn>5</mn><mo>×</mo><mn>3</mn><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>∗</mo><mn>2</mn><mo>=</mo><mn>152</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">(F_w \\times Fh \\times D + 1 ) \\times F  =  (5 \\times 5 \\times 3 + 1 )*2  = 152</script>.</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li><strong>Translation invariance:</strong> Invariance refers to the ability to remember an object as an object even though its object place changes. This is usually a positive thing because it maintains the object’s identity (category). Note that <a href=\"https://en.wikipedia.org/wiki/Translation_(geometry)\">translation</a> here has a specific meaning in vision, borrowed from geometry. The following figure shows The the same object in different locations (note that a CNN would recognize both as cats owing to translation invariance).</li>\n</ul>\n<ul>\n      <li>For a fully connected layer, you have an input of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-1-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>H</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1\" style=\"width: 8.388em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.982em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.93em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2\"><span class=\"mo\" id=\"MathJax-Span-3\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-4\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.78em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-5\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-6\"><span class=\"mrow\" id=\"MathJax-Span-7\"><span class=\"mi\" id=\"MathJax-Span-8\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-9\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-10\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-11\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.461em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-12\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-13\"><span class=\"mrow\" id=\"MathJax-Span-14\"><span class=\"mi\" id=\"MathJax-Span-15\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-16\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-17\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-18\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-19\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-20\"><span class=\"mrow\" id=\"MathJax-Span-21\"><span class=\"mi\" id=\"MathJax-Span-22\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-23\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-24\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>H</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-1\">(H_{in} \\times W_{in} \\times C_{in})</script> and the output of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-2-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>H</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-25\" style=\"width: 9.69em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 8.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1008.02em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-26\"><span class=\"mo\" id=\"MathJax-Span-27\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-28\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.78em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-29\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-30\"><span class=\"mrow\" id=\"MathJax-Span-31\"><span class=\"mi\" id=\"MathJax-Span-32\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-33\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-34\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-35\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-36\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-37\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-38\"><span class=\"mrow\" id=\"MathJax-Span-39\"><span class=\"mi\" id=\"MathJax-Span-40\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-41\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-42\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-43\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-44\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-45\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-46\"><span class=\"mrow\" id=\"MathJax-Span-47\"><span class=\"mi\" id=\"MathJax-Span-48\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-49\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-50\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-51\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>H</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-2\">(H_{out} \\times W_{out} \\times C_{out})</script>. This means, that each color of the pixel of the output feature map is connected to every color of the pixel from the input feature map. There is a separate learnable parameter for each pixel in the input image and the output. Hence, one gets this huge number of parameters : <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-3-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>H</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>H</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>&amp;#x00D7;</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-52\" style=\"width: 18.596em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 15.471em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1015.42em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-53\"><span class=\"mo\" id=\"MathJax-Span-54\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-55\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.78em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-56\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-57\"><span class=\"mrow\" id=\"MathJax-Span-58\"><span class=\"mi\" id=\"MathJax-Span-59\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-60\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-61\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-62\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.78em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-63\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-64\"><span class=\"mrow\" id=\"MathJax-Span-65\"><span class=\"mi\" id=\"MathJax-Span-66\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-67\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-68\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-69\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-70\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.461em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-71\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-72\"><span class=\"mrow\" id=\"MathJax-Span-73\"><span class=\"mi\" id=\"MathJax-Span-74\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-75\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-76\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-77\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.826em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-78\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-79\"><span class=\"mrow\" id=\"MathJax-Span-80\"><span class=\"mi\" id=\"MathJax-Span-81\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-82\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-83\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-84\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-85\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-86\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-87\"><span class=\"mrow\" id=\"MathJax-Span-88\"><span class=\"mi\" id=\"MathJax-Span-89\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-90\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-91\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"msubsup\" id=\"MathJax-Span-92\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-93\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-94\"><span class=\"mrow\" id=\"MathJax-Span-95\"><span class=\"mi\" id=\"MathJax-Span-96\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-97\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-98\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-99\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>H</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>H</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-3\">(H_{in} \\times H_{out} \\times  W_{in} \\times W_{out} \\times C_{in} \\times C_{out})</script></li>\n      <li>In the convolutional layer, the input is the image of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-4-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>H</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-100\" style=\"width: 6.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.732em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.68em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-101\"><span class=\"mo\" id=\"MathJax-Span-102\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-103\"><span style=\"display: inline-block; position: relative; width: 1.357em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.78em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-104\" style=\"font-family: STIXGeneral-Italic;\">H<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-105\"><span class=\"mrow\" id=\"MathJax-Span-106\"><span class=\"mi\" id=\"MathJax-Span-107\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-108\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-109\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-110\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.461em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-111\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-112\"><span class=\"mrow\" id=\"MathJax-Span-113\"><span class=\"mi\" id=\"MathJax-Span-114\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-115\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-116\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-117\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-118\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-119\"><span class=\"mrow\" id=\"MathJax-Span-120\"><span class=\"mi\" id=\"MathJax-Span-121\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-122\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-123\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>H</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-4\">(H_{in}, W_{in}, C_{in})</script> and the weights account for the neighborhood of the given pixel, say of size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-5-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi><mo>&amp;#x00D7;</mo><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-124\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.66em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-125\"><span class=\"mi\" id=\"MathJax-Span-126\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-127\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-128\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi><mo>×</mo><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-5\">K \\times K</script>. The output is obtained as a weighted sum of the given pixel and its neighborhood. There is a separate kernel for each pair of the input and output channel <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-6-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-129\" style=\"width: 4.951em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.117em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.07em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-130\"><span class=\"mo\" id=\"MathJax-Span-131\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-132\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-133\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-134\"><span class=\"mrow\" id=\"MathJax-Span-135\"><span class=\"mi\" id=\"MathJax-Span-136\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-137\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-138\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-139\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-140\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-141\"><span class=\"mrow\" id=\"MathJax-Span-142\"><span class=\"mi\" id=\"MathJax-Span-143\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-144\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-145\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-146\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-6\">(C_{in}, C_{out})</script>, but the weights of the kernel (a tensor of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-7-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>K</mi><mo>,</mo><mi>K</mi><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-147\" style=\"width: 7.919em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.51em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-148\"><span class=\"mo\" id=\"MathJax-Span-149\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-150\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-151\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-152\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-153\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-154\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-155\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-156\"><span class=\"mrow\" id=\"MathJax-Span-157\"><span class=\"mi\" id=\"MathJax-Span-158\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-159\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-160\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-161\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-162\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-163\"><span class=\"mrow\" id=\"MathJax-Span-164\"><span class=\"mi\" id=\"MathJax-Span-165\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-166\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-167\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-168\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>K</mi><mo>,</mo><mi>K</mi><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-7\">(K, K, C_{in}, C_{out})</script> are independent of the location. Actually, this layer can accept images of any resolution, whereas, the fully connected can work only with a fixed resolution. Finally one has <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-8-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><mi>K</mi><mo>,</mo><mi>K</mi><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-169\" style=\"width: 7.919em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 6.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1006.51em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-170\"><span class=\"mo\" id=\"MathJax-Span-171\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-172\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-173\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mi\" id=\"MathJax-Span-174\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.211em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-175\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-176\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-177\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-178\"><span class=\"mrow\" id=\"MathJax-Span-179\"><span class=\"mi\" id=\"MathJax-Span-180\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mi\" id=\"MathJax-Span-181\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-182\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-183\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.669em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.68em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-184\" style=\"font-family: STIXGeneral-Italic;\">C<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.68em;\"><span class=\"texatom\" id=\"MathJax-Span-185\"><span class=\"mrow\" id=\"MathJax-Span-186\"><span class=\"mi\" id=\"MathJax-Span-187\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-188\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">u</span><span class=\"mi\" id=\"MathJax-Span-189\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-190\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><mi>K</mi><mo>,</mo><mi>K</mi><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mi>n</mi></mrow></msub><mo>,</mo><msub><mi>C</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-8\">(K, K, C_{in}, C_{out})</script> parameters, which for the kernel size <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-191\" style=\"width: 0.94em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.78em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-192\"><span class=\"mi\" id=\"MathJax-Span-193\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-9\">K</script> much smaller, than the input resolution result into significant drop in the number of variables.</li>\n      <li>The sole fact that since AlexNet won the ImageNet competition, every neural network that has won it has used CNNs should be enough to convince you that CNNs are better for image data!</li>\n      <li>You most likely won’t be able to find any meaningful comparison, since CNNs are able to handle image data that is infeasible using only FC layers. Here’s why:\n        <ul>\n          <li>The number of weights in FC layer with 1000 neurons for <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>224</mn><mo>&amp;#x00D7;</mo><mn>224</mn><mo>&amp;#x00D7;</mo><mn>3</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-194\" style=\"width: 6.826em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-195\"><span class=\"mn\" id=\"MathJax-Span-196\" style=\"font-family: STIXGeneral-Regular;\">224</span><span class=\"mo\" id=\"MathJax-Span-197\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-198\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">224</span><span class=\"mo\" id=\"MathJax-Span-199\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-200\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>224</mn><mo>×</mo><mn>224</mn><mo>×</mo><mn>3</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-10\">224 \\times 224 \\times 3</script> image is something like 150M. <strong>That’s 150M for only one layer.</strong></li>\n          <li>If you’re not convinced this is a huge number, then note that modern CNN architectures that have 50-100 layers while having overall couple dozen million parameters (for example ResNet50 has 23M params, InceptionV3 has 21M parameters).</li>\n          <li>Mathematically, let’s compare the number of weights between CNNs and FCNs (with 100 hidden units) for an input image of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>500</mn><mo>&amp;#x00D7;</mo><mn>500</mn><mo>&amp;#x00D7;</mo><mn>3</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-201\" style=\"width: 6.826em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-202\"><span class=\"mn\" id=\"MathJax-Span-203\" style=\"font-family: STIXGeneral-Regular;\">500</span><span class=\"mo\" id=\"MathJax-Span-204\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-205\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">500</span><span class=\"mo\" id=\"MathJax-Span-206\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-207\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>500</mn><mo>×</mo><mn>500</mn><mo>×</mo><mn>3</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-11\">500 \\times 500 \\times 3</script>:\n            <ul>\n              <li>FC layer = Wx = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>100</mn><mo>&amp;#x00D7;</mo><mo stretchy=&quot;false&quot;>(</mo><mn>500</mn><mo>&amp;#x00D7;</mo><mn>500</mn><mo>&amp;#x00D7;</mo><mn>3</mn><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mn>100</mn><mo>&amp;#x00D7;</mo><mn>750000</mn><mo>=</mo><mn>75</mn><mi>M</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-208\" style=\"width: 22.659em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 18.857em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1018.86em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-209\"><span class=\"mn\" id=\"MathJax-Span-210\" style=\"font-family: STIXGeneral-Regular;\">100</span><span class=\"mo\" id=\"MathJax-Span-211\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mo\" id=\"MathJax-Span-212\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">(</span><span class=\"mn\" id=\"MathJax-Span-213\" style=\"font-family: STIXGeneral-Regular;\">500</span><span class=\"mo\" id=\"MathJax-Span-214\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">500</span><span class=\"mo\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span><span class=\"mo\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-219\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-220\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">100</span><span class=\"mo\" id=\"MathJax-Span-221\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-222\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">750000</span><span class=\"mo\" id=\"MathJax-Span-223\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-224\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">75</span><span class=\"mi\" id=\"MathJax-Span-225\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>100</mn><mo>×</mo><mo stretchy=\"false\">(</mo><mn>500</mn><mo>×</mo><mn>500</mn><mo>×</mo><mn>3</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>100</mn><mo>×</mo><mn>750000</mn><mo>=</mo><mn>75</mn><mi>M</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">100 \\times (500 \\times 500 \\times 3) = 100 \\times 750000 = 75M</script>.</li>\n              <li>CNN layer = <code class=\"language-plaintext highlighter-rouge\">((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)</code> (note that the <code class=\"language-plaintext highlighter-rouge\">+1</code> is for bias) = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>F</mi><mi>w</mi></msub><mo>&amp;#x00D7;</mo><mi>F</mi><mi>h</mi><mo>&amp;#x00D7;</mo><mi>D</mi><mo>+</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x00D7;</mo><mi>F</mi><mo>=</mo><mo stretchy=&quot;false&quot;>(</mo><mn>5</mn><mo>&amp;#x00D7;</mo><mn>5</mn><mo>&amp;#x00D7;</mo><mn>3</mn><mo>+</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2217;</mo><mn>2</mn><mo>=</mo><mn>152</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-226\" style=\"width: 24.638em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 20.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1020.52em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-227\"><span class=\"mo\" id=\"MathJax-Span-228\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-229\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-230\" style=\"font-family: STIXGeneral-Italic;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-231\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">w</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-233\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-234\" style=\"font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-235\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-236\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">D</span><span class=\"mo\" id=\"MathJax-Span-237\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-238\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-239\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-240\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-241\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-242\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mo\" id=\"MathJax-Span-243\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">(</span><span class=\"mn\" id=\"MathJax-Span-244\" style=\"font-family: STIXGeneral-Regular;\">5</span><span class=\"mo\" id=\"MathJax-Span-245\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">5</span><span class=\"mo\" id=\"MathJax-Span-247\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-248\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span><span class=\"mo\" id=\"MathJax-Span-249\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-251\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-252\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">∗</span><span class=\"mn\" id=\"MathJax-Span-253\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">2</span><span class=\"mo\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-255\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">152</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>F</mi><mi>w</mi></msub><mo>×</mo><mi>F</mi><mi>h</mi><mo>×</mo><mi>D</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>×</mo><mi>F</mi><mo>=</mo><mo stretchy=\"false\">(</mo><mn>5</mn><mo>×</mo><mn>5</mn><mo>×</mo><mn>3</mn><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>∗</mo><mn>2</mn><mo>=</mo><mn>152</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">(F_w \\times Fh \\times D + 1 ) \\times F  =  (5 \\times 5 \\times 3 + 1 )*2  = 152</script>.</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n    </ul>\n<ul>\n          <li>The number of weights in FC layer with 1000 neurons for <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>224</mn><mo>&amp;#x00D7;</mo><mn>224</mn><mo>&amp;#x00D7;</mo><mn>3</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-194\" style=\"width: 6.826em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-195\"><span class=\"mn\" id=\"MathJax-Span-196\" style=\"font-family: STIXGeneral-Regular;\">224</span><span class=\"mo\" id=\"MathJax-Span-197\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-198\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">224</span><span class=\"mo\" id=\"MathJax-Span-199\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-200\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>224</mn><mo>×</mo><mn>224</mn><mo>×</mo><mn>3</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-10\">224 \\times 224 \\times 3</script> image is something like 150M. <strong>That’s 150M for only one layer.</strong></li>\n          <li>If you’re not convinced this is a huge number, then note that modern CNN architectures that have 50-100 layers while having overall couple dozen million parameters (for example ResNet50 has 23M params, InceptionV3 has 21M parameters).</li>\n          <li>Mathematically, let’s compare the number of weights between CNNs and FCNs (with 100 hidden units) for an input image of shape <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>500</mn><mo>&amp;#x00D7;</mo><mn>500</mn><mo>&amp;#x00D7;</mo><mn>3</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-201\" style=\"width: 6.826em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1005.63em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-202\"><span class=\"mn\" id=\"MathJax-Span-203\" style=\"font-family: STIXGeneral-Regular;\">500</span><span class=\"mo\" id=\"MathJax-Span-204\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-205\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">500</span><span class=\"mo\" id=\"MathJax-Span-206\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-207\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>500</mn><mo>×</mo><mn>500</mn><mo>×</mo><mn>3</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-11\">500 \\times 500 \\times 3</script>:\n            <ul>\n              <li>FC layer = Wx = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>100</mn><mo>&amp;#x00D7;</mo><mo stretchy=&quot;false&quot;>(</mo><mn>500</mn><mo>&amp;#x00D7;</mo><mn>500</mn><mo>&amp;#x00D7;</mo><mn>3</mn><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mn>100</mn><mo>&amp;#x00D7;</mo><mn>750000</mn><mo>=</mo><mn>75</mn><mi>M</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-208\" style=\"width: 22.659em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 18.857em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1018.86em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-209\"><span class=\"mn\" id=\"MathJax-Span-210\" style=\"font-family: STIXGeneral-Regular;\">100</span><span class=\"mo\" id=\"MathJax-Span-211\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mo\" id=\"MathJax-Span-212\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">(</span><span class=\"mn\" id=\"MathJax-Span-213\" style=\"font-family: STIXGeneral-Regular;\">500</span><span class=\"mo\" id=\"MathJax-Span-214\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">500</span><span class=\"mo\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span><span class=\"mo\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-219\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-220\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">100</span><span class=\"mo\" id=\"MathJax-Span-221\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-222\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">750000</span><span class=\"mo\" id=\"MathJax-Span-223\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-224\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">75</span><span class=\"mi\" id=\"MathJax-Span-225\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>100</mn><mo>×</mo><mo stretchy=\"false\">(</mo><mn>500</mn><mo>×</mo><mn>500</mn><mo>×</mo><mn>3</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>100</mn><mo>×</mo><mn>750000</mn><mo>=</mo><mn>75</mn><mi>M</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">100 \\times (500 \\times 500 \\times 3) = 100 \\times 750000 = 75M</script>.</li>\n              <li>CNN layer = <code class=\"language-plaintext highlighter-rouge\">((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)</code> (note that the <code class=\"language-plaintext highlighter-rouge\">+1</code> is for bias) = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>F</mi><mi>w</mi></msub><mo>&amp;#x00D7;</mo><mi>F</mi><mi>h</mi><mo>&amp;#x00D7;</mo><mi>D</mi><mo>+</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x00D7;</mo><mi>F</mi><mo>=</mo><mo stretchy=&quot;false&quot;>(</mo><mn>5</mn><mo>&amp;#x00D7;</mo><mn>5</mn><mo>&amp;#x00D7;</mo><mn>3</mn><mo>+</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2217;</mo><mn>2</mn><mo>=</mo><mn>152</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-226\" style=\"width: 24.638em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 20.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1020.52em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-227\"><span class=\"mo\" id=\"MathJax-Span-228\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-229\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-230\" style=\"font-family: STIXGeneral-Italic;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-231\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">w</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-233\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-234\" style=\"font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-235\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-236\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">D</span><span class=\"mo\" id=\"MathJax-Span-237\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-238\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-239\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-240\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-241\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-242\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mo\" id=\"MathJax-Span-243\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">(</span><span class=\"mn\" id=\"MathJax-Span-244\" style=\"font-family: STIXGeneral-Regular;\">5</span><span class=\"mo\" id=\"MathJax-Span-245\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">5</span><span class=\"mo\" id=\"MathJax-Span-247\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-248\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span><span class=\"mo\" id=\"MathJax-Span-249\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-251\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-252\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">∗</span><span class=\"mn\" id=\"MathJax-Span-253\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">2</span><span class=\"mo\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-255\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">152</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>F</mi><mi>w</mi></msub><mo>×</mo><mi>F</mi><mi>h</mi><mo>×</mo><mi>D</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>×</mo><mi>F</mi><mo>=</mo><mo stretchy=\"false\">(</mo><mn>5</mn><mo>×</mo><mn>5</mn><mo>×</mo><mn>3</mn><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>∗</mo><mn>2</mn><mo>=</mo><mn>152</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">(F_w \\times Fh \\times D + 1 ) \\times F  =  (5 \\times 5 \\times 3 + 1 )*2  = 152</script>.</li>\n            </ul>\n          </li>\n        </ul>\n<ul>\n              <li>FC layer = Wx = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>100</mn><mo>&amp;#x00D7;</mo><mo stretchy=&quot;false&quot;>(</mo><mn>500</mn><mo>&amp;#x00D7;</mo><mn>500</mn><mo>&amp;#x00D7;</mo><mn>3</mn><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mn>100</mn><mo>&amp;#x00D7;</mo><mn>750000</mn><mo>=</mo><mn>75</mn><mi>M</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-208\" style=\"width: 22.659em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 18.857em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1018.86em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-209\"><span class=\"mn\" id=\"MathJax-Span-210\" style=\"font-family: STIXGeneral-Regular;\">100</span><span class=\"mo\" id=\"MathJax-Span-211\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mo\" id=\"MathJax-Span-212\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">(</span><span class=\"mn\" id=\"MathJax-Span-213\" style=\"font-family: STIXGeneral-Regular;\">500</span><span class=\"mo\" id=\"MathJax-Span-214\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">500</span><span class=\"mo\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span><span class=\"mo\" id=\"MathJax-Span-218\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-219\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-220\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">100</span><span class=\"mo\" id=\"MathJax-Span-221\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-222\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">750000</span><span class=\"mo\" id=\"MathJax-Span-223\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-224\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">75</span><span class=\"mi\" id=\"MathJax-Span-225\" style=\"font-family: STIXGeneral-Italic;\">M<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>100</mn><mo>×</mo><mo stretchy=\"false\">(</mo><mn>500</mn><mo>×</mo><mn>500</mn><mo>×</mo><mn>3</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>100</mn><mo>×</mo><mn>750000</mn><mo>=</mo><mn>75</mn><mi>M</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">100 \\times (500 \\times 500 \\times 3) = 100 \\times 750000 = 75M</script>.</li>\n              <li>CNN layer = <code class=\"language-plaintext highlighter-rouge\">((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)</code> (note that the <code class=\"language-plaintext highlighter-rouge\">+1</code> is for bias) = <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>(</mo><msub><mi>F</mi><mi>w</mi></msub><mo>&amp;#x00D7;</mo><mi>F</mi><mi>h</mi><mo>&amp;#x00D7;</mo><mi>D</mi><mo>+</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x00D7;</mo><mi>F</mi><mo>=</mo><mo stretchy=&quot;false&quot;>(</mo><mn>5</mn><mo>&amp;#x00D7;</mo><mn>5</mn><mo>&amp;#x00D7;</mo><mn>3</mn><mo>+</mo><mn>1</mn><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2217;</mo><mn>2</mn><mo>=</mo><mn>152</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-226\" style=\"width: 24.638em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 20.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1020.52em, 2.555em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-227\"><span class=\"mo\" id=\"MathJax-Span-228\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-229\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-230\" style=\"font-family: STIXGeneral-Italic;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-231\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">w</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-233\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-234\" style=\"font-family: STIXGeneral-Italic;\">h</span><span class=\"mo\" id=\"MathJax-Span-235\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-236\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">D</span><span class=\"mo\" id=\"MathJax-Span-237\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-238\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-239\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-240\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mi\" id=\"MathJax-Span-241\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">F<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-242\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mo\" id=\"MathJax-Span-243\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">(</span><span class=\"mn\" id=\"MathJax-Span-244\" style=\"font-family: STIXGeneral-Regular;\">5</span><span class=\"mo\" id=\"MathJax-Span-245\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">5</span><span class=\"mo\" id=\"MathJax-Span-247\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">×</span><span class=\"mn\" id=\"MathJax-Span-248\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">3</span><span class=\"mo\" id=\"MathJax-Span-249\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span><span class=\"mo\" id=\"MathJax-Span-251\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-252\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">∗</span><span class=\"mn\" id=\"MathJax-Span-253\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">2</span><span class=\"mo\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-255\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">152</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo stretchy=\"false\">(</mo><msub><mi>F</mi><mi>w</mi></msub><mo>×</mo><mi>F</mi><mi>h</mi><mo>×</mo><mi>D</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>×</mo><mi>F</mi><mo>=</mo><mo stretchy=\"false\">(</mo><mn>5</mn><mo>×</mo><mn>5</mn><mo>×</mo><mn>3</mn><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>∗</mo><mn>2</mn><mo>=</mo><mn>152</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">(F_w \\times Fh \\times D + 1 ) \\times F  =  (5 \\times 5 \\times 3 + 1 )*2  = 152</script>.</li>\n            </ul>\n<p><img src=\"/primers/ai/assets/dl-comp/ti.png\" alt=\"\"></p>",
    "contentMarkdown": "*   **Parameter sharing/Computational tractability:** Since CNNs utilize parameter sharing, the number of weights for a CNN vs. FCN architecture typically have a difference of several orders of magnitude.\n    *   For a fully connected layer, you have an input of shape (Hin×Win×Cin)(Hin×Win×Cin)(H\\_{in} \\\\times W\\_{in} \\\\times C\\_{in}) and the output of shape (Hout×Wout×Cout)(Hout×Wout×Cout)(H\\_{out} \\\\times W\\_{out} \\\\times C\\_{out}). This means, that each color of the pixel of the output feature map is connected to every color of the pixel from the input feature map. There is a separate learnable parameter for each pixel in the input image and the output. Hence, one gets this huge number of parameters : (Hin×Hout×Win×Wout×Cin×Cout)(Hin×Hout×Win×Wout×Cin×Cout)(H\\_{in} \\\\times H\\_{out} \\\\times W\\_{in} \\\\times W\\_{out} \\\\times C\\_{in} \\\\times C\\_{out})\n    *   In the convolutional layer, the input is the image of shape (Hin,Win,Cin)(Hin,Win,Cin)(H\\_{in}, W\\_{in}, C\\_{in}) and the weights account for the neighborhood of the given pixel, say of size K×KK×KK \\\\times K. The output is obtained as a weighted sum of the given pixel and its neighborhood. There is a separate kernel for each pair of the input and output channel (Cin,Cout)(Cin,Cout)(C\\_{in}, C\\_{out}), but the weights of the kernel (a tensor of shape (K,K,Cin,Cout)(K,K,Cin,Cout)(K, K, C\\_{in}, C\\_{out}) are independent of the location. Actually, this layer can accept images of any resolution, whereas, the fully connected can work only with a fixed resolution. Finally one has (K,K,Cin,Cout)(K,K,Cin,Cout)(K, K, C\\_{in}, C\\_{out}) parameters, which for the kernel size KKK much smaller, than the input resolution result into significant drop in the number of variables.\n    *   The sole fact that since AlexNet won the ImageNet competition, every neural network that has won it has used CNNs should be enough to convince you that CNNs are better for image data!\n    *   You most likely won’t be able to find any meaningful comparison, since CNNs are able to handle image data that is infeasible using only FC layers. Here’s why:\n        *   The number of weights in FC layer with 1000 neurons for 224×224×3224×224×3224 \\\\times 224 \\\\times 3 image is something like 150M. **That’s 150M for only one layer.**\n        *   If you’re not convinced this is a huge number, then note that modern CNN architectures that have 50-100 layers while having overall couple dozen million parameters (for example ResNet50 has 23M params, InceptionV3 has 21M parameters).\n        *   Mathematically, let’s compare the number of weights between CNNs and FCNs (with 100 hidden units) for an input image of shape 500×500×3500×500×3500 \\\\times 500 \\\\times 3:\n            *   FC layer = Wx = 100×(500×500×3)\\=100×750000\\=75M100×(500×500×3)\\=100×750000\\=75M100 \\\\times (500 \\\\times 500 \\\\times 3) = 100 \\\\times 750000 = 75M.\n            *   CNN layer = `((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)` (note that the `+1` is for bias) = (Fw×Fh×D+1)×F\\=(5×5×3+1)∗2\\=152(Fw×Fh×D+1)×F\\=(5×5×3+1)∗2\\=152(F\\_w \\\\times Fh \\\\times D + 1 ) \\\\times F = (5 \\\\times 5 \\\\times 3 + 1 )\\*2 = 152.\n*   **Translation invariance:** Invariance refers to the ability to remember an object as an object even though its object place changes. This is usually a positive thing because it maintains the object’s identity (category). Note that [translation](https://en.wikipedia.org/wiki/Translation_\\(geometry\\)) here has a specific meaning in vision, borrowed from geometry. The following figure shows The the same object in different locations (note that a CNN would recognize both as cats owing to translation invariance).\n\n*   For a fully connected layer, you have an input of shape (Hin×Win×Cin)(Hin×Win×Cin)(H\\_{in} \\\\times W\\_{in} \\\\times C\\_{in}) and the output of shape (Hout×Wout×Cout)(Hout×Wout×Cout)(H\\_{out} \\\\times W\\_{out} \\\\times C\\_{out}). This means, that each color of the pixel of the output feature map is connected to every color of the pixel from the input feature map. There is a separate learnable parameter for each pixel in the input image and the output. Hence, one gets this huge number of parameters : (Hin×Hout×Win×Wout×Cin×Cout)(Hin×Hout×Win×Wout×Cin×Cout)(H\\_{in} \\\\times H\\_{out} \\\\times W\\_{in} \\\\times W\\_{out} \\\\times C\\_{in} \\\\times C\\_{out})\n*   In the convolutional layer, the input is the image of shape (Hin,Win,Cin)(Hin,Win,Cin)(H\\_{in}, W\\_{in}, C\\_{in}) and the weights account for the neighborhood of the given pixel, say of size K×KK×KK \\\\times K. The output is obtained as a weighted sum of the given pixel and its neighborhood. There is a separate kernel for each pair of the input and output channel (Cin,Cout)(Cin,Cout)(C\\_{in}, C\\_{out}), but the weights of the kernel (a tensor of shape (K,K,Cin,Cout)(K,K,Cin,Cout)(K, K, C\\_{in}, C\\_{out}) are independent of the location. Actually, this layer can accept images of any resolution, whereas, the fully connected can work only with a fixed resolution. Finally one has (K,K,Cin,Cout)(K,K,Cin,Cout)(K, K, C\\_{in}, C\\_{out}) parameters, which for the kernel size KKK much smaller, than the input resolution result into significant drop in the number of variables.\n*   The sole fact that since AlexNet won the ImageNet competition, every neural network that has won it has used CNNs should be enough to convince you that CNNs are better for image data!\n*   You most likely won’t be able to find any meaningful comparison, since CNNs are able to handle image data that is infeasible using only FC layers. Here’s why:\n    *   The number of weights in FC layer with 1000 neurons for 224×224×3224×224×3224 \\\\times 224 \\\\times 3 image is something like 150M. **That’s 150M for only one layer.**\n    *   If you’re not convinced this is a huge number, then note that modern CNN architectures that have 50-100 layers while having overall couple dozen million parameters (for example ResNet50 has 23M params, InceptionV3 has 21M parameters).\n    *   Mathematically, let’s compare the number of weights between CNNs and FCNs (with 100 hidden units) for an input image of shape 500×500×3500×500×3500 \\\\times 500 \\\\times 3:\n        *   FC layer = Wx = 100×(500×500×3)\\=100×750000\\=75M100×(500×500×3)\\=100×750000\\=75M100 \\\\times (500 \\\\times 500 \\\\times 3) = 100 \\\\times 750000 = 75M.\n        *   CNN layer = `((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)` (note that the `+1` is for bias) = (Fw×Fh×D+1)×F\\=(5×5×3+1)∗2\\=152(Fw×Fh×D+1)×F\\=(5×5×3+1)∗2\\=152(F\\_w \\\\times Fh \\\\times D + 1 ) \\\\times F = (5 \\\\times 5 \\\\times 3 + 1 )\\*2 = 152.\n\n*   The number of weights in FC layer with 1000 neurons for 224×224×3224×224×3224 \\\\times 224 \\\\times 3 image is something like 150M. **That’s 150M for only one layer.**\n*   If you’re not convinced this is a huge number, then note that modern CNN architectures that have 50-100 layers while having overall couple dozen million parameters (for example ResNet50 has 23M params, InceptionV3 has 21M parameters).\n*   Mathematically, let’s compare the number of weights between CNNs and FCNs (with 100 hidden units) for an input image of shape 500×500×3500×500×3500 \\\\times 500 \\\\times 3:\n    *   FC layer = Wx = 100×(500×500×3)\\=100×750000\\=75M100×(500×500×3)\\=100×750000\\=75M100 \\\\times (500 \\\\times 500 \\\\times 3) = 100 \\\\times 750000 = 75M.\n    *   CNN layer = `((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)` (note that the `+1` is for bias) = (Fw×Fh×D+1)×F\\=(5×5×3+1)∗2\\=152(Fw×Fh×D+1)×F\\=(5×5×3+1)∗2\\=152(F\\_w \\\\times Fh \\\\times D + 1 ) \\\\times F = (5 \\\\times 5 \\\\times 3 + 1 )\\*2 = 152.\n\n*   FC layer = Wx = 100×(500×500×3)\\=100×750000\\=75M100×(500×500×3)\\=100×750000\\=75M100 \\\\times (500 \\\\times 500 \\\\times 3) = 100 \\\\times 750000 = 75M.\n*   CNN layer = `((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)` (note that the `+1` is for bias) = (Fw×Fh×D+1)×F\\=(5×5×3+1)∗2\\=152(Fw×Fh×D+1)×F\\=(5×5×3+1)∗2\\=152(F\\_w \\\\times Fh \\\\times D + 1 ) \\\\times F = (5 \\\\times 5 \\\\times 3 + 1 )\\*2 = 152.\n\n![](/primers/ai/assets/dl-comp/ti.png)",
    "order": 2,
    "orderInChapter": 2,
    "difficulty": 3,
    "estimatedMinutes": 7,
    "tags": [
      "algorithmsarchitecture",
      "neural network",
      "convolution",
      "cnn"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": true,
      "hasImages": true,
      "wordCount": 1242,
      "contentLength": 137980
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/dl-comp/#pros-of-cnns-compared-to-fcns",
    "scrapedAt": "2025-12-28T11:45:51.813Z"
  },
  {
    "id": "ai-dl-comp-use-cases-of-rnns-3",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "DL Architectures Comparative Analysis",
    "articleSlug": "dl-comp",
    "chapter": "Recurrent Neural Networks",
    "title": "Use-cases of RNNs",
    "subtitle": "Recurrent Neural Networks",
    "contentHtml": "<ul>\n  <li>RNNs are better suited to analyzing temporal, sequential data such as text or videos.</li>\n  <li>Use cases for RNNs include text translation, natural language processing, sentiment analysis and speech analysis.</li>\n</ul>",
    "contentMarkdown": "*   RNNs are better suited to analyzing temporal, sequential data such as text or videos.\n*   Use cases for RNNs include text translation, natural language processing, sentiment analysis and speech analysis.",
    "order": 3,
    "orderInChapter": 1,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "algorithmsarchitecture",
      "rnn"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 31,
      "contentLength": 232
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/dl-comp/#use-cases-of-rnns",
    "scrapedAt": "2025-12-28T11:45:51.813Z"
  },
  {
    "id": "ai-dl-comp-pros-of-rnns-vs-cnns-4",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "DL Architectures Comparative Analysis",
    "articleSlug": "dl-comp",
    "chapter": "Recurrent Neural Networks",
    "title": "Pros of RNNs vs. CNNs",
    "subtitle": "Recurrent Neural Networks",
    "contentHtml": "<ul>\n  <li>In CNNs, the size of the input and the resulting output are fixed. That is, a CNN receives images of fixed size and outputs them to the appropriate level, along with the confidence level of its prediction. In contrast, with RNNs, the model size does not increase with the size of input, thus enabling the possibility of processing inputs of any length. In other words, the size of the input and the resulting output may vary (this feature lends itself to applications where variable size input and output is needed, say in generating text).</li>\n</ul>",
    "contentMarkdown": "*   In CNNs, the size of the input and the resulting output are fixed. That is, a CNN receives images of fixed size and outputs them to the appropriate level, along with the confidence level of its prediction. In contrast, with RNNs, the model size does not increase with the size of input, thus enabling the possibility of processing inputs of any length. In other words, the size of the input and the resulting output may vary (this feature lends itself to applications where variable size input and output is needed, say in generating text).",
    "order": 4,
    "orderInChapter": 2,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "algorithmsarchitecture",
      "cnn",
      "rnn"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 95,
      "contentLength": 562
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/dl-comp/#pros-of-rnns-vs.-cnns",
    "scrapedAt": "2025-12-28T11:45:51.813Z"
  },
  {
    "id": "ai-dl-comp-vanishing-gradient-problem-solutions-5",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "DL Architectures Comparative Analysis",
    "articleSlug": "dl-comp",
    "chapter": "Recurrent Neural Networks",
    "title": "Vanishing Gradient Problem Solutions",
    "subtitle": "Recurrent Neural Networks",
    "contentHtml": "<ul>\n  <li>Both Gated Recurrent Units (GRU) and Long Short-Term Memory units (LSTM) provide a solution to the vanishing gradient problem that RNNs experience.</li>\n  <li>Let’s delve into each.</li>\n</ul>\n<h4 id=\"gated-recurrent-units-gru\">Gated Recurrent Units (GRU)</h4>\n<ul>\n  <li>GRUs have two gates, update and reset (which are essentially two vectors), to decide what information should be passed to the output.</li>\n  <li>Note that they’re missing the output gate present in <a href=\"#long-short-term-memory-lstm-cells\">LSTMs</a>.</li>\n</ul>\n<p><img src=\"/primers/ai/assets/dl-comp/11.jpg\" alt=\"\"></p>\n<ul>\n  <li><strong>Reset gate:</strong> helps the model to decide how much of the past information (previous time steps) can be forgotten.</li>\n  <li><strong>Update gate:</strong> helps the model in determining how much of the past information needs to be passed along to the future and how much of the new information needs to be saved in memory.</li>\n</ul>\n<h5 id=\"pros-of-grus-compared-to-lstms-and-rnns\">Pros of GRUs Compared to LSTMs and RNNs</h5>\n<ul>\n  <li>Just like RNNs, they are able to keep information for a long time and capture longer range dependencies than RNNs.</li>\n  <li>However, unlike LSTMs, GRUs are simpler and can be trained more quickly.</li>\n</ul>\n<h5 id=\"cons-of-grus-compared-to-lstms-and-rnns\">Cons of GRUs Compared to LSTMs and RNNs</h5>\n<ul>\n  <li>More parameters compared to RNNs owing to two gates (vs. none in RNNs).</li>\n  <li>Typically cannot capture longer range dependencies than LSTMs.</li>\n</ul>\n<h4 id=\"long-short-term-memory-lstm-cells\">Long-Short Term Memory (LSTM) Cells</h4>\n<ul>\n  <li>Long-Short Term Memory (LSTM) cells are a special kind of RNN that make it easier for RNNs to preserve information over many timestamps by learning long term dependencies.</li>\n  <li>\n    <p>Below we can see a visual representation of the LSTM architecture provided from <a href=\"https://nlp.stanford.edu/manning/\">CS224N’s lectures</a>.</p>\n\n    <p><img src=\"/primers/ai/assets/dl-comp/6.jpg\" alt=\"\">\n<img src=\"/primers/ai/assets/dl-comp/7.jpg\" alt=\"\"></p>\n  </li>\n  <li>What makes LSTM such a powerhouse is that it departed from the typical neuron-based architecture and instead employed the concept of a memory cell.\n    <ul>\n      <li>This memory cell retains its value for a short or long time as a function of its input. This allows the cell to remember what’s important and not just the last computed value.</li>\n    </ul>\n  </li>\n  <li>The LSTM memory cell contains three gates that control the information flow in or out of its cell.\n    <ul>\n      <li><strong>Input gate:</strong>\n        <ul>\n          <li>The input gate controls when information can flow into the memory.\n<img src=\"/primers/ai/assets/dl-comp/9.jpg\" alt=\"\"></li>\n        </ul>\n      </li>\n      <li><strong>Forget gate:</strong>\n        <ul>\n          <li>The forget gate is responsible for keeping track of which information can be “forgotten”, making room for the cell to remember new data.</li>\n        </ul>\n\n        <p><img src=\"/primers/ai/assets/dl-comp/8.jpg\" alt=\"\"></p>\n      </li>\n      <li><strong>Output gate:</strong>\n        <ul>\n          <li>The output gate decides when the information that the cell has stored inside, can be used as the output of the cell.</li>\n        </ul>\n\n        <p><img src=\"/primers/ai/assets/dl-comp/10.jpg\" alt=\"\"></p>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>Below we can see a visual representation of the LSTM architecture provided from <a href=\"https://nlp.stanford.edu/manning/\">CS224N’s lectures</a>.</p>\n<p><img src=\"/primers/ai/assets/dl-comp/6.jpg\" alt=\"\">\n<img src=\"/primers/ai/assets/dl-comp/7.jpg\" alt=\"\"></p>\n<ul>\n      <li>This memory cell retains its value for a short or long time as a function of its input. This allows the cell to remember what’s important and not just the last computed value.</li>\n    </ul>\n<ul>\n      <li><strong>Input gate:</strong>\n        <ul>\n          <li>The input gate controls when information can flow into the memory.\n<img src=\"/primers/ai/assets/dl-comp/9.jpg\" alt=\"\"></li>\n        </ul>\n      </li>\n      <li><strong>Forget gate:</strong>\n        <ul>\n          <li>The forget gate is responsible for keeping track of which information can be “forgotten”, making room for the cell to remember new data.</li>\n        </ul>\n\n        <p><img src=\"/primers/ai/assets/dl-comp/8.jpg\" alt=\"\"></p>\n      </li>\n      <li><strong>Output gate:</strong>\n        <ul>\n          <li>The output gate decides when the information that the cell has stored inside, can be used as the output of the cell.</li>\n        </ul>\n\n        <p><img src=\"/primers/ai/assets/dl-comp/10.jpg\" alt=\"\"></p>\n      </li>\n    </ul>\n<ul>\n          <li>The input gate controls when information can flow into the memory.\n<img src=\"/primers/ai/assets/dl-comp/9.jpg\" alt=\"\"></li>\n        </ul>\n<ul>\n          <li>The forget gate is responsible for keeping track of which information can be “forgotten”, making room for the cell to remember new data.</li>\n        </ul>\n<p><img src=\"/primers/ai/assets/dl-comp/8.jpg\" alt=\"\"></p>\n<ul>\n          <li>The output gate decides when the information that the cell has stored inside, can be used as the output of the cell.</li>\n        </ul>\n<p><img src=\"/primers/ai/assets/dl-comp/10.jpg\" alt=\"\"></p>\n<h5 id=\"pros-of-lstms-compared-to-grus-and-rnns\">Pros of LSTMs Compared to GRUs and RNNs</h5>\n<ul>\n  <li>Can learn longer term dependencies compared to GRUs and especially RNNs.</li>\n</ul>\n<h5 id=\"cons-of-lstms-compared-to-grus-and-rnns\">Cons of LSTMs Compared to GRUs and RNNs</h5>\n<ul>\n  <li>More parameters compared to RNNs and GRUs owing to three gates (vs. two in GRUs and none in RNNs).</li>\n</ul>",
    "contentMarkdown": "*   Both Gated Recurrent Units (GRU) and Long Short-Term Memory units (LSTM) provide a solution to the vanishing gradient problem that RNNs experience.\n*   Let’s delve into each.\n\n#### Gated Recurrent Units (GRU)\n\n*   GRUs have two gates, update and reset (which are essentially two vectors), to decide what information should be passed to the output.\n*   Note that they’re missing the output gate present in [LSTMs](#long-short-term-memory-lstm-cells).\n\n![](/primers/ai/assets/dl-comp/11.jpg)\n\n*   **Reset gate:** helps the model to decide how much of the past information (previous time steps) can be forgotten.\n*   **Update gate:** helps the model in determining how much of the past information needs to be passed along to the future and how much of the new information needs to be saved in memory.\n\n##### Pros of GRUs Compared to LSTMs and RNNs\n\n*   Just like RNNs, they are able to keep information for a long time and capture longer range dependencies than RNNs.\n*   However, unlike LSTMs, GRUs are simpler and can be trained more quickly.\n\n##### Cons of GRUs Compared to LSTMs and RNNs\n\n*   More parameters compared to RNNs owing to two gates (vs. none in RNNs).\n*   Typically cannot capture longer range dependencies than LSTMs.\n\n#### Long-Short Term Memory (LSTM) Cells\n\n*   Long-Short Term Memory (LSTM) cells are a special kind of RNN that make it easier for RNNs to preserve information over many timestamps by learning long term dependencies.\n*   Below we can see a visual representation of the LSTM architecture provided from [CS224N’s lectures](https://nlp.stanford.edu/manning/).\n    \n    ![](/primers/ai/assets/dl-comp/6.jpg) ![](/primers/ai/assets/dl-comp/7.jpg)\n    \n*   What makes LSTM such a powerhouse is that it departed from the typical neuron-based architecture and instead employed the concept of a memory cell.\n    *   This memory cell retains its value for a short or long time as a function of its input. This allows the cell to remember what’s important and not just the last computed value.\n*   The LSTM memory cell contains three gates that control the information flow in or out of its cell.\n    *   **Input gate:**\n        *   The input gate controls when information can flow into the memory. ![](/primers/ai/assets/dl-comp/9.jpg)\n    *   **Forget gate:**\n        \n        *   The forget gate is responsible for keeping track of which information can be “forgotten”, making room for the cell to remember new data.\n        \n        ![](/primers/ai/assets/dl-comp/8.jpg)\n        \n    *   **Output gate:**\n        \n        *   The output gate decides when the information that the cell has stored inside, can be used as the output of the cell.\n        \n        ![](/primers/ai/assets/dl-comp/10.jpg)\n        \n\nBelow we can see a visual representation of the LSTM architecture provided from [CS224N’s lectures](https://nlp.stanford.edu/manning/).\n\n![](/primers/ai/assets/dl-comp/6.jpg) ![](/primers/ai/assets/dl-comp/7.jpg)\n\n*   This memory cell retains its value for a short or long time as a function of its input. This allows the cell to remember what’s important and not just the last computed value.\n\n*   **Input gate:**\n    *   The input gate controls when information can flow into the memory. ![](/primers/ai/assets/dl-comp/9.jpg)\n*   **Forget gate:**\n    \n    *   The forget gate is responsible for keeping track of which information can be “forgotten”, making room for the cell to remember new data.\n    \n    ![](/primers/ai/assets/dl-comp/8.jpg)\n    \n*   **Output gate:**\n    \n    *   The output gate decides when the information that the cell has stored inside, can be used as the output of the cell.\n    \n    ![](/primers/ai/assets/dl-comp/10.jpg)\n    \n\n*   The input gate controls when information can flow into the memory. ![](/primers/ai/assets/dl-comp/9.jpg)\n\n*   The forget gate is responsible for keeping track of which information can be “forgotten”, making room for the cell to remember new data.\n\n![](/primers/ai/assets/dl-comp/8.jpg)\n\n*   The output gate decides when the information that the cell has stored inside, can be used as the output of the cell.\n\n![](/primers/ai/assets/dl-comp/10.jpg)\n\n##### Pros of LSTMs Compared to GRUs and RNNs\n\n*   Can learn longer term dependencies compared to GRUs and especially RNNs.\n\n##### Cons of LSTMs Compared to GRUs and RNNs\n\n*   More parameters compared to RNNs and GRUs owing to three gates (vs. two in GRUs and none in RNNs).",
    "order": 5,
    "orderInChapter": 3,
    "difficulty": 2,
    "estimatedMinutes": 4,
    "tags": [
      "algorithmsarchitecture",
      "rnn",
      "lstm",
      "gru",
      "nlp"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 634,
      "contentLength": 5716
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/dl-comp/#vanishing-gradient-problem-solutions",
    "scrapedAt": "2025-12-28T11:45:51.813Z"
  },
  {
    "id": "ai-dl-comp-use-cases-of-transformers-6",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "DL Architectures Comparative Analysis",
    "articleSlug": "dl-comp",
    "chapter": "Transformers",
    "title": "Use-cases of Transformers",
    "subtitle": "Transformers",
    "contentHtml": "<h4 id=\"language\">Language</h4>\n<ul>\n  <li>In a vanilla language model, for example, nearby words would first get grouped together. The transformer, by contrast, runs processes so that every element in the input data connects, or pays attention, to every other element. This is referred to as “self-attention.” This means that as soon as it starts training, the transformer can see traces of the entire data set.</li>\n  <li>Before transformers came along, progress on AI language tasks largely lagged behind developments in other areas. Infact, in this deep learning revolution that happened in the past 10 years or so, natural language processing was a latecomer and NLP was, in a sense, behind computer vision, per the computer scientist <a href=\"https://www.quantamagazine.org/will-transformers-take-over-artificial-intelligence-20220310/\">Anna Rumshisky</a> of the University of Massachusetts, Lowell.</li>\n  <li>However, with the arrival of Transformers, the field of NLP has received a much-needed push and has churned model after model that have beat the state-of-the-art in various NLP tasks.</li>\n  <li>As an example, to understand the difference between vanilla language models (based on say, a recurrent architecture such as RNNs, LSTMs or GRUs) vs. transformers, consider these sentences: “The owl spied a squirrel. It tried to grab it with its talons but only got the end of its tail.” The structure of the second sentence is confusing: What do those “it”s refer to? A vanilla language model that focuses only on the words immediately around the “it”s would struggle, but a transformer connecting every word to every other word could discern that the owl did the grabbing, and the squirrel lost part of its tail.</li>\n</ul>\n<h4 id=\"vision\">Vision</h4>\n<blockquote>\n  <p>In CNNs, you start off being very local and slowly get a global perspective. A CNN recognizes an image pixel by pixel, identifying features like corners or lines by building its way up from the local to the global. But in transformers, with self-attention, even the very first layer of information processing makes connections between distant image locations (just as with language). If a CNN’s approach is like starting at a single pixel and zooming out, a transformer slowly brings the whole fuzzy image into focus.</p>\n</blockquote>\n<p>In CNNs, you start off being very local and slowly get a global perspective. A CNN recognizes an image pixel by pixel, identifying features like corners or lines by building its way up from the local to the global. But in transformers, with self-attention, even the very first layer of information processing makes connections between distant image locations (just as with language). If a CNN’s approach is like starting at a single pixel and zooming out, a transformer slowly brings the whole fuzzy image into focus.</p>\n<ul>\n  <li>CNNs work by repeatedly applying filters on local patches of the input data, generating local feature representations (or “feature maps”) and incrementally increase their receptive field and build up to global feature representations. It is because of convolutions that photo apps can organize your library by faces or tell an avocado apart from a cloud. Prior to the transformer architecture, CNNs were thus considered indispensable to vision tasks.</li>\n  <li>With the Vision Transformer (ViT), the architecture of the model is nearly identical to that of the first transformer proposed in 2017, with only minor changes allowing it to analyze images instead of words. Since language tends to be discrete, a lot of adaptations were to discretize the input image to make transformers work with visual input. Exactly mimicing the language approach and performing self-attention on every pixel would be prohibitively expensive in computing time. Instead, ViT divides the larger image into square units, or patches (akin to tokens in NLP). The size is arbitrary, as the tokens could be made larger or smaller depending on the resolution of the original image (the default is 16x16 pixels). But by processing pixels in groups, and applying self-attention to each, the ViT could quickly churn through enormous training data sets, spitting out increasingly accurate classifications.</li>\n  <li>In <a href=\"https://arxiv.org/abs/2108.08810\">Do Vision Transformers See Like Convolutional Neural Networks?</a>, Raghu et al. sought to understand how self-attention powers transformers in vision-based tasks.</li>\n</ul>\n<h4 id=\"multimodal-tasks\">Multimodal Tasks</h4>\n<ul>\n  <li>Compared to the Transformer, other architectures are “one trick ponies” while multimodal learning requires handling of modalities with different patterns within a streamlined architecture with a reasonably high <a href=\"https://arxiv.org/abs/1806.01261\">relational inductive bias</a> to even remotely reach human-like intelligence. In other words, we needs a single versatile architecture that seamlessly transitions between senses like reading/seeing, speaking, and listening.</li>\n  <li>The potential to offer a universal architecture that can be adopted for multimodal tasks (that requires simultaneously handling multiple types of data, such as raw images, video and language) is something that makes the transformer architecture unique and popular.</li>\n  <li>Because of the siloed approach with earlier architectures where each type of data had its own specialized model, this was a difficult task to accomplish. However, transformers offer an easy way to combine multiple input sources. For example, multimodal networks might power a system that reads a person’s lips in addition to listening to their voice using rich representations of both language and image information.</li>\n  <li>With <a href=\"https://towardsdatascience.com/cross-attention-is-what-you-need-fusatnet-fusion-network-b8e6f673491\">cross-attention</a> where the query, key and value vectors are derived from different sources, transformers are able to lend themselves as a powerful tool for multimodal learning.</li>\n  <li>The transformer thus offers be a big step toward achieving a kind of “convergence” for neural net architectures, resulting in a universal approach to processing data from multiple modalities.</li>\n</ul>",
    "contentMarkdown": "#### Language\n\n*   In a vanilla language model, for example, nearby words would first get grouped together. The transformer, by contrast, runs processes so that every element in the input data connects, or pays attention, to every other element. This is referred to as “self-attention.” This means that as soon as it starts training, the transformer can see traces of the entire data set.\n*   Before transformers came along, progress on AI language tasks largely lagged behind developments in other areas. Infact, in this deep learning revolution that happened in the past 10 years or so, natural language processing was a latecomer and NLP was, in a sense, behind computer vision, per the computer scientist [Anna Rumshisky](https://www.quantamagazine.org/will-transformers-take-over-artificial-intelligence-20220310/) of the University of Massachusetts, Lowell.\n*   However, with the arrival of Transformers, the field of NLP has received a much-needed push and has churned model after model that have beat the state-of-the-art in various NLP tasks.\n*   As an example, to understand the difference between vanilla language models (based on say, a recurrent architecture such as RNNs, LSTMs or GRUs) vs. transformers, consider these sentences: “The owl spied a squirrel. It tried to grab it with its talons but only got the end of its tail.” The structure of the second sentence is confusing: What do those “it”s refer to? A vanilla language model that focuses only on the words immediately around the “it”s would struggle, but a transformer connecting every word to every other word could discern that the owl did the grabbing, and the squirrel lost part of its tail.\n\n#### Vision\n\n> In CNNs, you start off being very local and slowly get a global perspective. A CNN recognizes an image pixel by pixel, identifying features like corners or lines by building its way up from the local to the global. But in transformers, with self-attention, even the very first layer of information processing makes connections between distant image locations (just as with language). If a CNN’s approach is like starting at a single pixel and zooming out, a transformer slowly brings the whole fuzzy image into focus.\n\nIn CNNs, you start off being very local and slowly get a global perspective. A CNN recognizes an image pixel by pixel, identifying features like corners or lines by building its way up from the local to the global. But in transformers, with self-attention, even the very first layer of information processing makes connections between distant image locations (just as with language). If a CNN’s approach is like starting at a single pixel and zooming out, a transformer slowly brings the whole fuzzy image into focus.\n\n*   CNNs work by repeatedly applying filters on local patches of the input data, generating local feature representations (or “feature maps”) and incrementally increase their receptive field and build up to global feature representations. It is because of convolutions that photo apps can organize your library by faces or tell an avocado apart from a cloud. Prior to the transformer architecture, CNNs were thus considered indispensable to vision tasks.\n*   With the Vision Transformer (ViT), the architecture of the model is nearly identical to that of the first transformer proposed in 2017, with only minor changes allowing it to analyze images instead of words. Since language tends to be discrete, a lot of adaptations were to discretize the input image to make transformers work with visual input. Exactly mimicing the language approach and performing self-attention on every pixel would be prohibitively expensive in computing time. Instead, ViT divides the larger image into square units, or patches (akin to tokens in NLP). The size is arbitrary, as the tokens could be made larger or smaller depending on the resolution of the original image (the default is 16x16 pixels). But by processing pixels in groups, and applying self-attention to each, the ViT could quickly churn through enormous training data sets, spitting out increasingly accurate classifications.\n*   In [Do Vision Transformers See Like Convolutional Neural Networks?](https://arxiv.org/abs/2108.08810), Raghu et al. sought to understand how self-attention powers transformers in vision-based tasks.\n\n#### Multimodal Tasks\n\n*   Compared to the Transformer, other architectures are “one trick ponies” while multimodal learning requires handling of modalities with different patterns within a streamlined architecture with a reasonably high [relational inductive bias](https://arxiv.org/abs/1806.01261) to even remotely reach human-like intelligence. In other words, we needs a single versatile architecture that seamlessly transitions between senses like reading/seeing, speaking, and listening.\n*   The potential to offer a universal architecture that can be adopted for multimodal tasks (that requires simultaneously handling multiple types of data, such as raw images, video and language) is something that makes the transformer architecture unique and popular.\n*   Because of the siloed approach with earlier architectures where each type of data had its own specialized model, this was a difficult task to accomplish. However, transformers offer an easy way to combine multiple input sources. For example, multimodal networks might power a system that reads a person’s lips in addition to listening to their voice using rich representations of both language and image information.\n*   With [cross-attention](https://towardsdatascience.com/cross-attention-is-what-you-need-fusatnet-fusion-network-b8e6f673491) where the query, key and value vectors are derived from different sources, transformers are able to lend themselves as a powerful tool for multimodal learning.\n*   The transformer thus offers be a big step toward achieving a kind of “convergence” for neural net architectures, resulting in a universal approach to processing data from multiple modalities.",
    "order": 6,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 5,
    "tags": [
      "algorithmsarchitecture",
      "neural network",
      "deep learning",
      "transformer",
      "attention",
      "convolution",
      "cnn",
      "rnn"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 895,
      "contentLength": 6224
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/dl-comp/#use-cases-of-transformers",
    "scrapedAt": "2025-12-28T11:45:51.813Z"
  },
  {
    "id": "ai-dl-comp-benefits-of-transformers-compared-to-rnnsgruslstms-7",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "DL Architectures Comparative Analysis",
    "articleSlug": "dl-comp",
    "chapter": "Transformers",
    "title": "Benefits of Transformers Compared to RNNs/GRUs/LSTMs",
    "subtitle": "Transformers",
    "contentHtml": "<ul>\n  <li>The Transformer can learn longer-range dependencies than RNNs and its variants such as GRUs and LSTMs.</li>\n  <li>The biggest benefit, however, comes from how the Transformer lends itself to parallelization. Unlike an RNN which processes a word at each time step, a key property of the Transformer is that the word at each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer (since the self-attention layer computes how important each other word in the input sequence is to this word). However, once the self-attention output is generated, the feed-forward layer does not have those dependencies, and thus the various paths can be executed in parallel while flowing through the feed-forward layer. This is an especially useful trait in case of the Transformer encoder which can process each input word in parallel with other words after the self-attention layer. This feature, is however, not of great importance for the decoder since it generates one word at a time and thus does not utilize parallel word paths.</li>\n</ul>",
    "contentMarkdown": "*   The Transformer can learn longer-range dependencies than RNNs and its variants such as GRUs and LSTMs.\n*   The biggest benefit, however, comes from how the Transformer lends itself to parallelization. Unlike an RNN which processes a word at each time step, a key property of the Transformer is that the word at each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer (since the self-attention layer computes how important each other word in the input sequence is to this word). However, once the self-attention output is generated, the feed-forward layer does not have those dependencies, and thus the various paths can be executed in parallel while flowing through the feed-forward layer. This is an especially useful trait in case of the Transformer encoder which can process each input word in parallel with other words after the self-attention layer. This feature, is however, not of great importance for the decoder since it generates one word at a time and thus does not utilize parallel word paths.",
    "order": 7,
    "orderInChapter": 2,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "algorithmsarchitecture",
      "transformer",
      "attention",
      "rnn",
      "lstm",
      "gru"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 176,
      "contentLength": 1106
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/dl-comp/#benefits-of-transformers-compared-to-rnns/grus/lstms",
    "scrapedAt": "2025-12-28T11:45:51.813Z"
  },
  {
    "id": "ai-dl-comp-drawbacks-of-transformers-compared-to-rnnsgruslstm-8",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "DL Architectures Comparative Analysis",
    "articleSlug": "dl-comp",
    "chapter": "Transformers",
    "title": "Drawbacks of Transformers Compared to RNNs/GRUs/LSTMs",
    "subtitle": "Transformers",
    "contentHtml": "<ul>\n  <li>The runtime of Transformer architecture is quadratic in the length of the input sequence, which means it can be slow when processing long documents or taking characters as inputs. In other words, computing all pairs of interactions during self-attention means our computation grows quadratically with the sequence length, i.e., <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><msup><mi>T</mi><mn>2</mn></msup><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-265\" style=\"width: 3.701em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.076em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.201em, 1003.02em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-266\"><span class=\"mi\" id=\"MathJax-Span-267\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-268\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-269\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-270\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"mn\" id=\"MathJax-Span-271\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-272\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-273\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>T</mi><mn>2</mn></msup><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-17\">O(T^2 d)</script>, where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-274\" style=\"width: 0.836em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.68em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.68em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-275\"><span class=\"mi\" id=\"MathJax-Span-276\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-18\">T</script> is the sequence length, and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-277\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.58em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-278\"><span class=\"mi\" id=\"MathJax-Span-279\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-19\">d</script> is the dimensionality. Note that for recurrent models, it only grew linearly!\n    <ul>\n      <li>Say, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-20-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi><mo>=</mo><mn>1000</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-280\" style=\"width: 4.534em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.753em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.75em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-281\"><span class=\"mi\" id=\"MathJax-Span-282\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-283\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-284\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1000</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi><mo>=</mo><mn>1000</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-20\">d = 1000</script>. So, for a single (shortish) sentence, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi><mo>&amp;#x2264;</mo><mn>30</mn><mo stretchy=&quot;false&quot;>&amp;#x21D2;</mo><msup><mi>T</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>2</mn></mrow></msup><mo>&amp;#x2264;</mo><mn>900</mn><mo stretchy=&quot;false&quot;>&amp;#x21D2;</mo><msup><mi>T</mi><mn>2</mn></msup><mi>d</mi><mo>&amp;#x2248;</mo><mn>900</mn><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-285\" style=\"width: 17.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 14.846em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1014.85em, 2.763em, -999.997em); top: -2.497em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-286\"><span class=\"mi\" id=\"MathJax-Span-287\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-288\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≤</span><span class=\"mn\" id=\"MathJax-Span-289\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">30</span><span class=\"mo\" id=\"MathJax-Span-290\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">⇒</span><span class=\"msubsup\" id=\"MathJax-Span-291\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-292\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-293\"><span class=\"mrow\" id=\"MathJax-Span-294\"><span class=\"mn\" id=\"MathJax-Span-295\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-296\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≤</span><span class=\"mn\" id=\"MathJax-Span-297\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">900</span><span class=\"mo\" id=\"MathJax-Span-298\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">⇒</span><span class=\"msubsup\" id=\"MathJax-Span-299\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-300\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"mn\" id=\"MathJax-Span-301\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-302\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-303\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≈</span><span class=\"mn\" id=\"MathJax-Span-304\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">900</span><span class=\"mi\" id=\"MathJax-Span-305\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.503em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi><mo>≤</mo><mn>30</mn><mo stretchy=\"false\">⇒</mo><msup><mi>T</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>2</mn></mrow></msup><mo>≤</mo><mn>900</mn><mo stretchy=\"false\">⇒</mo><msup><mi>T</mi><mn>2</mn></msup><mi>d</mi><mo>≈</mo><mn>900</mn><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">T \\leq 30 \\Rightarrow T^{2} \\leq 900 \\Rightarrow T^2 d \\approx 900K</script>. Note that in practice, we set a bound such as <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi><mo>=</mo><mn>512</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-306\" style=\"width: 4.065em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.388em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.39em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-307\"><span class=\"mi\" id=\"MathJax-Span-308\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-309\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-310\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">512</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi><mo>=</mo><mn>512</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-22\">T=512</script>. Imagine working on long documents with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi><mo>&amp;#x2265;</mo><mn>10</mn><mo>,</mo><mn>000</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-311\" style=\"width: 5.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.794em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.79em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-312\"><span class=\"mi\" id=\"MathJax-Span-313\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-314\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≥</span><span class=\"mn\" id=\"MathJax-Span-315\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">10</span><span class=\"mo\" id=\"MathJax-Span-316\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mn\" id=\"MathJax-Span-317\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">000</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi><mo>≥</mo><mn>10</mn><mo>,</mo><mn>000</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-23\">T \\geq 10,000</script>!?</li>\n    </ul>\n  </li>\n  <li>Wouldn’t it be nice for Transformers if we didn’t have to compute pair-wise interactions between each word pair in the sentence? Recent studies such as:\n    <ul>\n      <li><a href=\"https://arxiv.org/abs/2005.00743\">Synthesizer: Rethinking Self-Attention in Transformer Models</a></li>\n      <li><a href=\"https://arxiv.org/abs/2006.04768\">Linformer: Self-Attention with Linear Complexity</a></li>\n      <li><a href=\"https://arxiv.org/abs/2009.14794\">Rethinking Attention with Performers</a></li>\n      <li><a href=\"https://arxiv.org/abs/2007.14062\">Big Bird: Transformers for Longer Sequences</a></li>\n      <li>… show that decent performance levels can be achieved without computing interactions between all word-pairs (such as by approximating pair-wise attention).</li>\n    </ul>\n  </li>\n  <li>Compared to CNNs, the data appetite of transformers is obscenely high. CNNs are still sample efficient, which makes them great candidates for low-resource tasks. This is especially true for image/video generation tasks where an exceptionally large amount of data is needed, even for CNN architectures (and thus implies that Transformer architectures would have a ridiculously high data requirement). For example, the recent <a href=\"https://arxiv.org/abs/2103.00020\">CLIP</a> architecture by Radford et al. was trained with CNN-based ResNets as vision backbones (and not a ViT-like transformer architecture). While transformers do offer accuracy bumps once their data requirement is satisfied, CNNs offer a way to deliver decent accuracy performance in tasks where the amount of data available is not exceptionally high. Both architectures thus have their usecases.</li>\n  <li>The runtime of the Transformer architecture is quadratic in the length of the input sequence. Computing attention over all word-pairs requires the number of edges in the graph to scale quadratically with the number of nodes, i.e., in an <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-318\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-319\"><span class=\"mi\" id=\"MathJax-Span-320\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">n</script> word sentence, a Transformer would be doing computations over <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>n</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>2</mn></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-321\" style=\"width: 1.148em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1000.94em, 2.294em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-322\"><span class=\"msubsup\" id=\"MathJax-Span-323\"><span style=\"display: inline-block; position: relative; width: 0.94em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-324\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-325\"><span class=\"mrow\" id=\"MathJax-Span-326\"><span class=\"mn\" id=\"MathJax-Span-327\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>n</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>2</mn></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">n^{2}</script> pairs of words. This implies a large parameter count (implying high memory footprint) and thereby high computational complexity.</li>\n  <li>High compute requirements has a negative impact on power and battery life requirements, especially for portable device targets.</li>\n  <li>Overall, a transformer requires higher computational power, more data, power/battery life, and memory footprint, for it to offer better performance (in terms of say, accuracy) compared to its conventional competitors.</li>\n</ul>\n<ul>\n      <li>Say, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-20-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi><mo>=</mo><mn>1000</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-280\" style=\"width: 4.534em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.753em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.75em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-281\"><span class=\"mi\" id=\"MathJax-Span-282\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-283\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-284\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">1000</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>d</mi><mo>=</mo><mn>1000</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-20\">d = 1000</script>. So, for a single (shortish) sentence, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi><mo>&amp;#x2264;</mo><mn>30</mn><mo stretchy=&quot;false&quot;>&amp;#x21D2;</mo><msup><mi>T</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>2</mn></mrow></msup><mo>&amp;#x2264;</mo><mn>900</mn><mo stretchy=&quot;false&quot;>&amp;#x21D2;</mo><msup><mi>T</mi><mn>2</mn></msup><mi>d</mi><mo>&amp;#x2248;</mo><mn>900</mn><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-285\" style=\"width: 17.815em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 14.846em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1014.85em, 2.763em, -999.997em); top: -2.497em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-286\"><span class=\"mi\" id=\"MathJax-Span-287\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-288\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≤</span><span class=\"mn\" id=\"MathJax-Span-289\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">30</span><span class=\"mo\" id=\"MathJax-Span-290\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">⇒</span><span class=\"msubsup\" id=\"MathJax-Span-291\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-292\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"texatom\" id=\"MathJax-Span-293\"><span class=\"mrow\" id=\"MathJax-Span-294\"><span class=\"mn\" id=\"MathJax-Span-295\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-296\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≤</span><span class=\"mn\" id=\"MathJax-Span-297\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">900</span><span class=\"mo\" id=\"MathJax-Span-298\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">⇒</span><span class=\"msubsup\" id=\"MathJax-Span-299\" style=\"padding-left: 0.315em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-300\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.732em;\"><span class=\"mn\" id=\"MathJax-Span-301\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-302\" style=\"font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-303\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≈</span><span class=\"mn\" id=\"MathJax-Span-304\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">900</span><span class=\"mi\" id=\"MathJax-Span-305\" style=\"font-family: STIXGeneral-Italic;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.503em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.184em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi><mo>≤</mo><mn>30</mn><mo stretchy=\"false\">⇒</mo><msup><mi>T</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>2</mn></mrow></msup><mo>≤</mo><mn>900</mn><mo stretchy=\"false\">⇒</mo><msup><mi>T</mi><mn>2</mn></msup><mi>d</mi><mo>≈</mo><mn>900</mn><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">T \\leq 30 \\Rightarrow T^{2} \\leq 900 \\Rightarrow T^2 d \\approx 900K</script>. Note that in practice, we set a bound such as <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi><mo>=</mo><mn>512</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-306\" style=\"width: 4.065em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.388em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.39em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-307\"><span class=\"mi\" id=\"MathJax-Span-308\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-309\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mn\" id=\"MathJax-Span-310\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">512</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi><mo>=</mo><mn>512</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-22\">T=512</script>. Imagine working on long documents with <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi><mo>&amp;#x2265;</mo><mn>10</mn><mo>,</mo><mn>000</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-311\" style=\"width: 5.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.794em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.79em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-312\"><span class=\"mi\" id=\"MathJax-Span-313\" style=\"font-family: STIXGeneral-Italic;\">T<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-314\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">≥</span><span class=\"mn\" id=\"MathJax-Span-315\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">10</span><span class=\"mo\" id=\"MathJax-Span-316\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mn\" id=\"MathJax-Span-317\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">000</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>T</mi><mo>≥</mo><mn>10</mn><mo>,</mo><mn>000</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-23\">T \\geq 10,000</script>!?</li>\n    </ul>\n<ul>\n      <li><a href=\"https://arxiv.org/abs/2005.00743\">Synthesizer: Rethinking Self-Attention in Transformer Models</a></li>\n      <li><a href=\"https://arxiv.org/abs/2006.04768\">Linformer: Self-Attention with Linear Complexity</a></li>\n      <li><a href=\"https://arxiv.org/abs/2009.14794\">Rethinking Attention with Performers</a></li>\n      <li><a href=\"https://arxiv.org/abs/2007.14062\">Big Bird: Transformers for Longer Sequences</a></li>\n      <li>… show that decent performance levels can be achieved without computing interactions between all word-pairs (such as by approximating pair-wise attention).</li>\n    </ul>",
    "contentMarkdown": "*   The runtime of Transformer architecture is quadratic in the length of the input sequence, which means it can be slow when processing long documents or taking characters as inputs. In other words, computing all pairs of interactions during self-attention means our computation grows quadratically with the sequence length, i.e., O(T2d)O(T2d)O(T^2 d), where TTT is the sequence length, and ddd is the dimensionality. Note that for recurrent models, it only grew linearly!\n    *   Say, d\\=1000d\\=1000d = 1000. So, for a single (shortish) sentence, T≤30⇒T2≤900⇒T2d≈900KT≤30⇒T2≤900⇒T2d≈900KT \\\\leq 30 \\\\Rightarrow T^{2} \\\\leq 900 \\\\Rightarrow T^2 d \\\\approx 900K. Note that in practice, we set a bound such as T\\=512T\\=512T=512. Imagine working on long documents with T≥10,000T≥10,000T \\\\geq 10,000!?\n*   Wouldn’t it be nice for Transformers if we didn’t have to compute pair-wise interactions between each word pair in the sentence? Recent studies such as:\n    *   [Synthesizer: Rethinking Self-Attention in Transformer Models](https://arxiv.org/abs/2005.00743)\n    *   [Linformer: Self-Attention with Linear Complexity](https://arxiv.org/abs/2006.04768)\n    *   [Rethinking Attention with Performers](https://arxiv.org/abs/2009.14794)\n    *   [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062)\n    *   … show that decent performance levels can be achieved without computing interactions between all word-pairs (such as by approximating pair-wise attention).\n*   Compared to CNNs, the data appetite of transformers is obscenely high. CNNs are still sample efficient, which makes them great candidates for low-resource tasks. This is especially true for image/video generation tasks where an exceptionally large amount of data is needed, even for CNN architectures (and thus implies that Transformer architectures would have a ridiculously high data requirement). For example, the recent [CLIP](https://arxiv.org/abs/2103.00020) architecture by Radford et al. was trained with CNN-based ResNets as vision backbones (and not a ViT-like transformer architecture). While transformers do offer accuracy bumps once their data requirement is satisfied, CNNs offer a way to deliver decent accuracy performance in tasks where the amount of data available is not exceptionally high. Both architectures thus have their usecases.\n*   The runtime of the Transformer architecture is quadratic in the length of the input sequence. Computing attention over all word-pairs requires the number of edges in the graph to scale quadratically with the number of nodes, i.e., in an nnn word sentence, a Transformer would be doing computations over n2n2n^{2} pairs of words. This implies a large parameter count (implying high memory footprint) and thereby high computational complexity.\n*   High compute requirements has a negative impact on power and battery life requirements, especially for portable device targets.\n*   Overall, a transformer requires higher computational power, more data, power/battery life, and memory footprint, for it to offer better performance (in terms of say, accuracy) compared to its conventional competitors.\n\n*   Say, d\\=1000d\\=1000d = 1000. So, for a single (shortish) sentence, T≤30⇒T2≤900⇒T2d≈900KT≤30⇒T2≤900⇒T2d≈900KT \\\\leq 30 \\\\Rightarrow T^{2} \\\\leq 900 \\\\Rightarrow T^2 d \\\\approx 900K. Note that in practice, we set a bound such as T\\=512T\\=512T=512. Imagine working on long documents with T≥10,000T≥10,000T \\\\geq 10,000!?\n\n*   [Synthesizer: Rethinking Self-Attention in Transformer Models](https://arxiv.org/abs/2005.00743)\n*   [Linformer: Self-Attention with Linear Complexity](https://arxiv.org/abs/2006.04768)\n*   [Rethinking Attention with Performers](https://arxiv.org/abs/2009.14794)\n*   [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062)\n*   … show that decent performance levels can be achieved without computing interactions between all word-pairs (such as by approximating pair-wise attention).",
    "order": 8,
    "orderInChapter": 3,
    "difficulty": 3,
    "estimatedMinutes": 3,
    "tags": [
      "algorithmsarchitecture",
      "transformer",
      "attention",
      "cnn"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 519,
      "contentLength": 31674
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/dl-comp/#drawbacks-of-transformers-compared-to-rnns/grus/lstms",
    "scrapedAt": "2025-12-28T11:45:51.813Z"
  },
  {
    "id": "ai-dl-comp-inductive-biases-of-standard-neural-architectures-9",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "DL Architectures Comparative Analysis",
    "articleSlug": "dl-comp",
    "chapter": "Inductive Bias",
    "title": "Inductive Biases of Standard Neural Architectures",
    "subtitle": "Inductive Bias",
    "contentHtml": "<ul>\n  <li>Every model architecture has an inherent inductive bias which helps understand patterns in data and thus enables learning. For instance, CNNs exhibit spatial parameter sharing, translational/spatial invariance, while RNNs exhibit temporal parameter sharing.</li>\n  <li><a href=\"https://arxiv.org/abs/1806.01261\">Relational inductive biases, deep learning, and graph networks</a> by Battaglia et al. (2018) from DeepMind/Google, MIT and the University of Edinburgh offers a great overview of the relational inductive biases of various neural net architectures, summarized in the table below from the paper.</li>\n</ul>\n<p><img src=\"/primers/ai/assets/inductive-bias/ib.jpg\" alt=\"\"></p>\n<ul>\n  <li><a href=\"https://www.youtube.com/watch?v=56e104J4ehA\">YouTube Video from UofT CSC2547: Relational inductive biases, deep learning, and graph networks</a>; <a href=\"https://aifrenz.github.io/present_file/Inductive%20biases,%20graph%20neural%20networks,%20attention%20and%20relational%20inference.pdf\">Slides by KAIST on inductive biases, graph neural networks,\nattention and relational inference</a></li>\n</ul>",
    "contentMarkdown": "*   Every model architecture has an inherent inductive bias which helps understand patterns in data and thus enables learning. For instance, CNNs exhibit spatial parameter sharing, translational/spatial invariance, while RNNs exhibit temporal parameter sharing.\n*   [Relational inductive biases, deep learning, and graph networks](https://arxiv.org/abs/1806.01261) by Battaglia et al. (2018) from DeepMind/Google, MIT and the University of Edinburgh offers a great overview of the relational inductive biases of various neural net architectures, summarized in the table below from the paper.\n\n![](/primers/ai/assets/inductive-bias/ib.jpg)\n\n*   [YouTube Video from UofT CSC2547: Relational inductive biases, deep learning, and graph networks](https://www.youtube.com/watch?v=56e104J4ehA); [Slides by KAIST on inductive biases, graph neural networks, attention and relational inference](https://aifrenz.github.io/present_file/Inductive%20biases,%20graph%20neural%20networks,%20attention%20and%20relational%20inference.pdf)",
    "order": 9,
    "orderInChapter": 1,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "algorithmsarchitecture",
      "neural network",
      "deep learning",
      "attention",
      "cnn",
      "rnn"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": true,
      "wordCount": 106,
      "contentLength": 1115
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/dl-comp/#inductive-biases-of-standard-neural-architectures",
    "scrapedAt": "2025-12-28T11:45:51.813Z"
  }
]