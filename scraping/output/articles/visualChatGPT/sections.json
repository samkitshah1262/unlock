[
  {
    "id": "ai-visualChatGPT-managing-vfms-1",
    "articleSlug": "visualChatGPT",
    "articleTitle": "Visual ChatGPT",
    "category": "Models",
    "chapter": "Prompt Manager",
    "title": "Managing VFMs",
    "order": 1,
    "orderInChapter": 1,
    "contentHtml": "<ul>\n  <li>Now let’s delve into how Prompt Manager manages the Foundation models.</li>\n  <li>Visual ChatGPT interacts with multiple VFMs so the prompt manager needed an efficient strategy on how to best coordinate with VFM to use for which task.</li>\n  <li>This is because different VFMs share similarities, like replacement of objects in image can be regarded as a generation of a new image. Or VQA task (image question answering) can be understood as offering a response according to the provided image.</li>\n  <li>Thus, the need to distinguish the VFM’s became imminent.</li>\n  <li>Below are the aspects Prompt Manager defines to help Visual ChatGPT accurately handle its VL task:\n    <ul>\n      <li>Name: The name prompt helps Visual ChatGPT to understand the purpose of VFM in a concise manner and severs as the entry to VFM.</li>\n      <li>Usage: The usage prompt describes the scenario where the VFM should be used.</li>\n      <li>Input/Output: The input/output prompt defines the format of input and output required by the VFM.</li>\n      <li>Example (optional): The example prompt is optional and as the name sounds, it gives an example to Visual ChatGPT which can be really helpful to better understand how a particular VFM works.</li>\n    </ul>\n  </li>\n</ul>\n<ul>\n      <li>Name: The name prompt helps Visual ChatGPT to understand the purpose of VFM in a concise manner and severs as the entry to VFM.</li>\n      <li>Usage: The usage prompt describes the scenario where the VFM should be used.</li>\n      <li>Input/Output: The input/output prompt defines the format of input and output required by the VFM.</li>\n      <li>Example (optional): The example prompt is optional and as the name sounds, it gives an example to Visual ChatGPT which can be really helpful to better understand how a particular VFM works.</li>\n    </ul>",
    "contentMarkdown": "*   Now let’s delve into how Prompt Manager manages the Foundation models.\n*   Visual ChatGPT interacts with multiple VFMs so the prompt manager needed an efficient strategy on how to best coordinate with VFM to use for which task.\n*   This is because different VFMs share similarities, like replacement of objects in image can be regarded as a generation of a new image. Or VQA task (image question answering) can be understood as offering a response according to the provided image.\n*   Thus, the need to distinguish the VFM’s became imminent.\n*   Below are the aspects Prompt Manager defines to help Visual ChatGPT accurately handle its VL task:\n    *   Name: The name prompt helps Visual ChatGPT to understand the purpose of VFM in a concise manner and severs as the entry to VFM.\n    *   Usage: The usage prompt describes the scenario where the VFM should be used.\n    *   Input/Output: The input/output prompt defines the format of input and output required by the VFM.\n    *   Example (optional): The example prompt is optional and as the name sounds, it gives an example to Visual ChatGPT which can be really helpful to better understand how a particular VFM works.\n\n*   Name: The name prompt helps Visual ChatGPT to understand the purpose of VFM in a concise manner and severs as the entry to VFM.\n*   Usage: The usage prompt describes the scenario where the VFM should be used.\n*   Input/Output: The input/output prompt defines the format of input and output required by the VFM.\n*   Example (optional): The example prompt is optional and as the name sounds, it gives an example to Visual ChatGPT which can be really helpful to better understand how a particular VFM works.",
    "contentLength": 1837,
    "wordCount": 284,
    "hasCode": false,
    "hasMath": false,
    "hasImages": false,
    "url": "https://aman.ai/primers/ai/visualChatGPT/#managing-vfms"
  },
  {
    "id": "ai-visualChatGPT-handling-queries-2",
    "articleSlug": "visualChatGPT",
    "articleTitle": "Visual ChatGPT",
    "category": "Models",
    "chapter": "Prompt Manager",
    "title": "Handling Queries",
    "order": 2,
    "orderInChapter": 2,
    "contentHtml": "<ul>\n  <li>Visual ChatGPT supports many user queries and languages. It supports images as well, singular or multiple.</li>\n  <li>In order to handle this, Prompt Manager uses the two aspects below:\n    <ol>\n      <li>Generate Unique Filename:\n        <ul>\n          <li>Visual ChatGPT handles two types of image queries: one where the image was uploaded and one where its a reference to an existing image.</li>\n          <li>“For newly uploaded images, Visual ChatGPT generates a unique filename with a universally unique identifier (UUID) and adds a prefix string ”image” representing the relative directory, e.g., <code class=\"language-plaintext highlighter-rouge\">image/{uuid}.png</code> <a href=\"https://arxiv.org/pdf/2303.04671.pdf\">(source)</a>.</li>\n          <li>For queries about existing images, Visual ChatGPT ignores the filename check.</li>\n        </ul>\n      </li>\n      <li>Force VFM Thinking:\n        <ul>\n          <li>The following suffix prompt is appended to the user query:</li>\n          <li>“Since Visual ChatGPT is a text language model, Visual ChatGPT must use tools to observe images rather than imagination. The thoughts and observations are only visible for Visual ChatGPT, Visual ChatGPT should remember to repeat important information in the final response for Human. Thought: Do I need to use a tool?”</li>\n          <li>The reasoning is two-fold provided below:\n            <ul>\n              <li>It prompts Visual ChatGPT to use foundation models instead of relying solely on its imagination.</li>\n              <li>It encourages Visual ChatGPT to provide specific out- puts generated by the foundation models, rather than generic responses such as “here you are” <a href=\"https://arxiv.org/pdf/2303.04671.pdf\">(source)</a>.</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n    </ol>\n  </li>\n  <li>The following diagram <a href=\"https://arxiv.org/pdf/2303.04671.pdf\">(source)</a> shows an example of multiple rounds of dialogue between human and Visual ChatGPT:</li>\n</ul>\n<ol>\n      <li>Generate Unique Filename:\n        <ul>\n          <li>Visual ChatGPT handles two types of image queries: one where the image was uploaded and one where its a reference to an existing image.</li>\n          <li>“For newly uploaded images, Visual ChatGPT generates a unique filename with a universally unique identifier (UUID) and adds a prefix string ”image” representing the relative directory, e.g., <code class=\"language-plaintext highlighter-rouge\">image/{uuid}.png</code> <a href=\"https://arxiv.org/pdf/2303.04671.pdf\">(source)</a>.</li>\n          <li>For queries about existing images, Visual ChatGPT ignores the filename check.</li>\n        </ul>\n      </li>\n      <li>Force VFM Thinking:\n        <ul>\n          <li>The following suffix prompt is appended to the user query:</li>\n          <li>“Since Visual ChatGPT is a text language model, Visual ChatGPT must use tools to observe images rather than imagination. The thoughts and observations are only visible for Visual ChatGPT, Visual ChatGPT should remember to repeat important information in the final response for Human. Thought: Do I need to use a tool?”</li>\n          <li>The reasoning is two-fold provided below:\n            <ul>\n              <li>It prompts Visual ChatGPT to use foundation models instead of relying solely on its imagination.</li>\n              <li>It encourages Visual ChatGPT to provide specific out- puts generated by the foundation models, rather than generic responses such as “here you are” <a href=\"https://arxiv.org/pdf/2303.04671.pdf\">(source)</a>.</li>\n            </ul>\n          </li>\n        </ul>\n      </li>\n    </ol>\n<ul>\n          <li>Visual ChatGPT handles two types of image queries: one where the image was uploaded and one where its a reference to an existing image.</li>\n          <li>“For newly uploaded images, Visual ChatGPT generates a unique filename with a universally unique identifier (UUID) and adds a prefix string ”image” representing the relative directory, e.g., <code class=\"language-plaintext highlighter-rouge\">image/{uuid}.png</code> <a href=\"https://arxiv.org/pdf/2303.04671.pdf\">(source)</a>.</li>\n          <li>For queries about existing images, Visual ChatGPT ignores the filename check.</li>\n        </ul>\n<ul>\n          <li>The following suffix prompt is appended to the user query:</li>\n          <li>“Since Visual ChatGPT is a text language model, Visual ChatGPT must use tools to observe images rather than imagination. The thoughts and observations are only visible for Visual ChatGPT, Visual ChatGPT should remember to repeat important information in the final response for Human. Thought: Do I need to use a tool?”</li>\n          <li>The reasoning is two-fold provided below:\n            <ul>\n              <li>It prompts Visual ChatGPT to use foundation models instead of relying solely on its imagination.</li>\n              <li>It encourages Visual ChatGPT to provide specific out- puts generated by the foundation models, rather than generic responses such as “here you are” <a href=\"https://arxiv.org/pdf/2303.04671.pdf\">(source)</a>.</li>\n            </ul>\n          </li>\n        </ul>\n<ul>\n              <li>It prompts Visual ChatGPT to use foundation models instead of relying solely on its imagination.</li>\n              <li>It encourages Visual ChatGPT to provide specific out- puts generated by the foundation models, rather than generic responses such as “here you are” <a href=\"https://arxiv.org/pdf/2303.04671.pdf\">(source)</a>.</li>\n            </ul>\n<p><img src=\"/primers/ai/assets/visualchatgpt/5.png\" alt=\"\"></p>",
    "contentMarkdown": "*   Visual ChatGPT supports many user queries and languages. It supports images as well, singular or multiple.\n*   In order to handle this, Prompt Manager uses the two aspects below:\n    1.  Generate Unique Filename:\n        *   Visual ChatGPT handles two types of image queries: one where the image was uploaded and one where its a reference to an existing image.\n        *   “For newly uploaded images, Visual ChatGPT generates a unique filename with a universally unique identifier (UUID) and adds a prefix string ”image” representing the relative directory, e.g., `image/{uuid}.png` [(source)](https://arxiv.org/pdf/2303.04671.pdf).\n        *   For queries about existing images, Visual ChatGPT ignores the filename check.\n    2.  Force VFM Thinking:\n        *   The following suffix prompt is appended to the user query:\n        *   “Since Visual ChatGPT is a text language model, Visual ChatGPT must use tools to observe images rather than imagination. The thoughts and observations are only visible for Visual ChatGPT, Visual ChatGPT should remember to repeat important information in the final response for Human. Thought: Do I need to use a tool?”\n        *   The reasoning is two-fold provided below:\n            *   It prompts Visual ChatGPT to use foundation models instead of relying solely on its imagination.\n            *   It encourages Visual ChatGPT to provide specific out- puts generated by the foundation models, rather than generic responses such as “here you are” [(source)](https://arxiv.org/pdf/2303.04671.pdf).\n*   The following diagram [(source)](https://arxiv.org/pdf/2303.04671.pdf) shows an example of multiple rounds of dialogue between human and Visual ChatGPT:\n\n1.  Generate Unique Filename:\n    *   Visual ChatGPT handles two types of image queries: one where the image was uploaded and one where its a reference to an existing image.\n    *   “For newly uploaded images, Visual ChatGPT generates a unique filename with a universally unique identifier (UUID) and adds a prefix string ”image” representing the relative directory, e.g., `image/{uuid}.png` [(source)](https://arxiv.org/pdf/2303.04671.pdf).\n    *   For queries about existing images, Visual ChatGPT ignores the filename check.\n2.  Force VFM Thinking:\n    *   The following suffix prompt is appended to the user query:\n    *   “Since Visual ChatGPT is a text language model, Visual ChatGPT must use tools to observe images rather than imagination. The thoughts and observations are only visible for Visual ChatGPT, Visual ChatGPT should remember to repeat important information in the final response for Human. Thought: Do I need to use a tool?”\n    *   The reasoning is two-fold provided below:\n        *   It prompts Visual ChatGPT to use foundation models instead of relying solely on its imagination.\n        *   It encourages Visual ChatGPT to provide specific out- puts generated by the foundation models, rather than generic responses such as “here you are” [(source)](https://arxiv.org/pdf/2303.04671.pdf).\n\n*   Visual ChatGPT handles two types of image queries: one where the image was uploaded and one where its a reference to an existing image.\n*   “For newly uploaded images, Visual ChatGPT generates a unique filename with a universally unique identifier (UUID) and adds a prefix string ”image” representing the relative directory, e.g., `image/{uuid}.png` [(source)](https://arxiv.org/pdf/2303.04671.pdf).\n*   For queries about existing images, Visual ChatGPT ignores the filename check.\n\n*   The following suffix prompt is appended to the user query:\n*   “Since Visual ChatGPT is a text language model, Visual ChatGPT must use tools to observe images rather than imagination. The thoughts and observations are only visible for Visual ChatGPT, Visual ChatGPT should remember to repeat important information in the final response for Human. Thought: Do I need to use a tool?”\n*   The reasoning is two-fold provided below:\n    *   It prompts Visual ChatGPT to use foundation models instead of relying solely on its imagination.\n    *   It encourages Visual ChatGPT to provide specific out- puts generated by the foundation models, rather than generic responses such as “here you are” [(source)](https://arxiv.org/pdf/2303.04671.pdf).\n\n*   It prompts Visual ChatGPT to use foundation models instead of relying solely on its imagination.\n*   It encourages Visual ChatGPT to provide specific out- puts generated by the foundation models, rather than generic responses such as “here you are” [(source)](https://arxiv.org/pdf/2303.04671.pdf).\n\n![](/primers/ai/assets/visualchatgpt/5.png)",
    "contentLength": 5604,
    "wordCount": 640,
    "hasCode": true,
    "hasMath": false,
    "hasImages": true,
    "url": "https://aman.ai/primers/ai/visualChatGPT/#handling-queries"
  }
]