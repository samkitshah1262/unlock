[
  {
    "id": "ai-speculative-decoding-speculative-decoding-via-draft-models-1",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Core Techniques",
    "title": "Speculative Decoding Via Draft Models",
    "subtitle": "Core Techniques",
    "contentHtml": "<ul>\n  <li>\n    <p>Introduced in <a href=\"https://arxiv.org/abs/2211.17192\">Fast Inference from Transformers via Speculative Decoding</a> by Leviathan et al. (2023).</p>\n  </li>\n  <li>\n    <p><strong>Pipeline Overview</strong>:</p>\n\n    <ol>\n      <li><strong>Drafting</strong>: Use a smaller (faster) model to generate <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-6-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-16\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-17\"><span class=\"mi\" id=\"MathJax-Span-18\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-6\">\\gamma</script> speculative tokens.</li>\n      <li><strong>Verification</strong>: Run the large model to score all tokens up to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-7-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-19\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-20\"><span class=\"mi\" id=\"MathJax-Span-21\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-7\">\\gamma</script>.</li>\n      <li><strong>Acceptance</strong>: Accept prefix tokens that match the large model’s top predictions.</li>\n      <li><strong>Fallback</strong>: If a token diverges, fall back to large model sampling for correction.</li>\n    </ol>\n  </li>\n  <li>\n    <p>The following figure from the paper shows a technique illustrated in the case of unconditional language modeling. Each line represents one iteration of the algorithm. The green tokens are the suggestions made by the approximation model (here, a GPT-like Transformer decoder with 6M parameters trained on 1m1b with 8k tokens) that the target model (here, a GPT-like Transformer decoder with 97M parameters in the same setting) accepted, while the red and blue tokens are the rejected suggestions and their corrections, respectively. For example, in the first line the target model was run only once, and 5 tokens were generated.</p>\n  </li>\n</ul>\n<p>Introduced in <a href=\"https://arxiv.org/abs/2211.17192\">Fast Inference from Transformers via Speculative Decoding</a> by Leviathan et al. (2023).</p>\n<p><strong>Pipeline Overview</strong>:</p>\n<ol>\n      <li><strong>Drafting</strong>: Use a smaller (faster) model to generate <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-6-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-16\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-17\"><span class=\"mi\" id=\"MathJax-Span-18\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-6\">\\gamma</script> speculative tokens.</li>\n      <li><strong>Verification</strong>: Run the large model to score all tokens up to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-7-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-19\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-20\"><span class=\"mi\" id=\"MathJax-Span-21\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-7\">\\gamma</script>.</li>\n      <li><strong>Acceptance</strong>: Accept prefix tokens that match the large model’s top predictions.</li>\n      <li><strong>Fallback</strong>: If a token diverges, fall back to large model sampling for correction.</li>\n    </ol>\n<p>The following figure from the paper shows a technique illustrated in the case of unconditional language modeling. Each line represents one iteration of the algorithm. The green tokens are the suggestions made by the approximation model (here, a GPT-like Transformer decoder with 6M parameters trained on 1m1b with 8k tokens) that the target model (here, a GPT-like Transformer decoder with 97M parameters in the same setting) accepted, while the red and blue tokens are the rejected suggestions and their corrections, respectively. For example, in the first line the target model was run only once, and 5 tokens were generated.</p>\n<p><img src=\"../../../images/papers/SD.jpg\" alt=\"\"></p>\n<ul>\n  <li>\n    <p><strong>Algorithm Summary (simplified from Leviathan et al.)</strong>:</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code0\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code0\">  <span class=\"k\">def</span> <span class=\"nf\">speculative_decode</span><span class=\"p\">(</span><span class=\"n\">draft_model</span><span class=\"p\">,</span> <span class=\"n\">target_model</span><span class=\"p\">,</span> <span class=\"n\">prompt</span><span class=\"p\">,</span> <span class=\"n\">gamma</span><span class=\"p\">):</span>\n      <span class=\"n\">draft_tokens</span> <span class=\"o\">=</span> <span class=\"n\">draft_model</span><span class=\"p\">.</span><span class=\"n\">generate</span><span class=\"p\">(</span><span class=\"n\">prompt</span><span class=\"p\">,</span> <span class=\"n\">max_new_tokens</span><span class=\"o\">=</span><span class=\"n\">gamma</span><span class=\"p\">)</span>\n      <span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">target_model</span><span class=\"p\">.</span><span class=\"n\">score</span><span class=\"p\">(</span><span class=\"n\">prompt</span> <span class=\"o\">+</span> <span class=\"n\">draft_tokens</span><span class=\"p\">)</span>\n        \n      <span class=\"c1\"># accept up to the first mismatch\n</span>      <span class=\"n\">n_accept</span> <span class=\"o\">=</span> <span class=\"n\">count_agreement</span><span class=\"p\">(</span><span class=\"n\">draft_tokens</span><span class=\"p\">,</span> <span class=\"n\">scores</span><span class=\"p\">)</span>\n      <span class=\"n\">accepted</span> <span class=\"o\">=</span> <span class=\"n\">draft_tokens</span><span class=\"p\">[:</span><span class=\"n\">n_accept</span><span class=\"p\">]</span>\n        \n      <span class=\"c1\"># complete the next token from the target model\n</span>      <span class=\"n\">next_token</span> <span class=\"o\">=</span> <span class=\"n\">target_model</span><span class=\"p\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">prompt</span> <span class=\"o\">+</span> <span class=\"n\">accepted</span><span class=\"p\">)</span>\n      <span class=\"k\">return</span> <span class=\"n\">accepted</span> <span class=\"o\">+</span> <span class=\"p\">[</span><span class=\"n\">next_token</span><span class=\"p\">]</span>\n</code></pre></div>    </div>\n  </li>\n  <li>\n    <p><strong>Advantages</strong>:</p>\n\n    <ul>\n      <li>Can be plugged into existing models without retraining.</li>\n      <li>Requires no architectural changes to the large model.</li>\n      <li>Fully preserves output distribution.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Challenges</strong>:</p>\n\n    <ul>\n      <li>Maintaining a separate draft model increases system complexity.</li>\n      <li>Distribution mismatch between draft and target models can reduce acceptance rate.</li>\n      <li>Memory and compute pressure if both models are large.</li>\n    </ul>\n  </li>\n</ul>\n<p><strong>Algorithm Summary (simplified from Leviathan et al.)</strong>:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code0\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code0\">  <span class=\"k\">def</span> <span class=\"nf\">speculative_decode</span><span class=\"p\">(</span><span class=\"n\">draft_model</span><span class=\"p\">,</span> <span class=\"n\">target_model</span><span class=\"p\">,</span> <span class=\"n\">prompt</span><span class=\"p\">,</span> <span class=\"n\">gamma</span><span class=\"p\">):</span>\n      <span class=\"n\">draft_tokens</span> <span class=\"o\">=</span> <span class=\"n\">draft_model</span><span class=\"p\">.</span><span class=\"n\">generate</span><span class=\"p\">(</span><span class=\"n\">prompt</span><span class=\"p\">,</span> <span class=\"n\">max_new_tokens</span><span class=\"o\">=</span><span class=\"n\">gamma</span><span class=\"p\">)</span>\n      <span class=\"n\">scores</span> <span class=\"o\">=</span> <span class=\"n\">target_model</span><span class=\"p\">.</span><span class=\"n\">score</span><span class=\"p\">(</span><span class=\"n\">prompt</span> <span class=\"o\">+</span> <span class=\"n\">draft_tokens</span><span class=\"p\">)</span>\n        \n      <span class=\"c1\"># accept up to the first mismatch\n</span>      <span class=\"n\">n_accept</span> <span class=\"o\">=</span> <span class=\"n\">count_agreement</span><span class=\"p\">(</span><span class=\"n\">draft_tokens</span><span class=\"p\">,</span> <span class=\"n\">scores</span><span class=\"p\">)</span>\n      <span class=\"n\">accepted</span> <span class=\"o\">=</span> <span class=\"n\">draft_tokens</span><span class=\"p\">[:</span><span class=\"n\">n_accept</span><span class=\"p\">]</span>\n        \n      <span class=\"c1\"># complete the next token from the target model\n</span>      <span class=\"n\">next_token</span> <span class=\"o\">=</span> <span class=\"n\">target_model</span><span class=\"p\">.</span><span class=\"n\">sample</span><span class=\"p\">(</span><span class=\"n\">prompt</span> <span class=\"o\">+</span> <span class=\"n\">accepted</span><span class=\"p\">)</span>\n      <span class=\"k\">return</span> <span class=\"n\">accepted</span> <span class=\"o\">+</span> <span class=\"p\">[</span><span class=\"n\">next_token</span><span class=\"p\">]</span>\n</code></pre>\n<p><strong>Advantages</strong>:</p>\n<ul>\n      <li>Can be plugged into existing models without retraining.</li>\n      <li>Requires no architectural changes to the large model.</li>\n      <li>Fully preserves output distribution.</li>\n    </ul>\n<p><strong>Challenges</strong>:</p>\n<ul>\n      <li>Maintaining a separate draft model increases system complexity.</li>\n      <li>Distribution mismatch between draft and target models can reduce acceptance rate.</li>\n      <li>Memory and compute pressure if both models are large.</li>\n    </ul>",
    "contentMarkdown": "*   Introduced in [Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/abs/2211.17192) by Leviathan et al. (2023).\n    \n*   **Pipeline Overview**:\n    \n    1.  **Drafting**: Use a smaller (faster) model to generate γγ\\\\gamma speculative tokens.\n    2.  **Verification**: Run the large model to score all tokens up to γγ\\\\gamma.\n    3.  **Acceptance**: Accept prefix tokens that match the large model’s top predictions.\n    4.  **Fallback**: If a token diverges, fall back to large model sampling for correction.\n*   The following figure from the paper shows a technique illustrated in the case of unconditional language modeling. Each line represents one iteration of the algorithm. The green tokens are the suggestions made by the approximation model (here, a GPT-like Transformer decoder with 6M parameters trained on 1m1b with 8k tokens) that the target model (here, a GPT-like Transformer decoder with 97M parameters in the same setting) accepted, while the red and blue tokens are the rejected suggestions and their corrections, respectively. For example, in the first line the target model was run only once, and 5 tokens were generated.\n    \n\nIntroduced in [Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/abs/2211.17192) by Leviathan et al. (2023).\n\n**Pipeline Overview**:\n\n1.  **Drafting**: Use a smaller (faster) model to generate γγ\\\\gamma speculative tokens.\n2.  **Verification**: Run the large model to score all tokens up to γγ\\\\gamma.\n3.  **Acceptance**: Accept prefix tokens that match the large model’s top predictions.\n4.  **Fallback**: If a token diverges, fall back to large model sampling for correction.\n\nThe following figure from the paper shows a technique illustrated in the case of unconditional language modeling. Each line represents one iteration of the algorithm. The green tokens are the suggestions made by the approximation model (here, a GPT-like Transformer decoder with 6M parameters trained on 1m1b with 8k tokens) that the target model (here, a GPT-like Transformer decoder with 97M parameters in the same setting) accepted, while the red and blue tokens are the rejected suggestions and their corrections, respectively. For example, in the first line the target model was run only once, and 5 tokens were generated.\n\n![](../../../images/papers/SD.jpg)\n\n*   **Algorithm Summary (simplified from Leviathan et al.)**:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n      `def speculative_decode(draft_model, target_model, prompt, gamma):       draft_tokens = draft_model.generate(prompt, max_new_tokens=gamma)       scores = target_model.score(prompt + draft_tokens)                # accept up to the first mismatch       n_accept = count_agreement(draft_tokens, scores)       accepted = draft_tokens[:n_accept]                # complete the next token from the target model       next_token = target_model.sample(prompt + accepted)       return accepted + [next_token]`\n    \n*   **Advantages**:\n    \n    *   Can be plugged into existing models without retraining.\n    *   Requires no architectural changes to the large model.\n    *   Fully preserves output distribution.\n*   **Challenges**:\n    \n    *   Maintaining a separate draft model increases system complexity.\n    *   Distribution mismatch between draft and target models can reduce acceptance rate.\n    *   Memory and compute pressure if both models are large.\n\n**Algorithm Summary (simplified from Leviathan et al.)**:\n\n![](https://aman.ai/images/copy.png)\n\n  `def speculative_decode(draft_model, target_model, prompt, gamma):       draft_tokens = draft_model.generate(prompt, max_new_tokens=gamma)       scores = target_model.score(prompt + draft_tokens)                # accept up to the first mismatch       n_accept = count_agreement(draft_tokens, scores)       accepted = draft_tokens[:n_accept]                # complete the next token from the target model       next_token = target_model.sample(prompt + accepted)       return accepted + [next_token]`\n\n**Advantages**:\n\n*   Can be plugged into existing models without retraining.\n*   Requires no architectural changes to the large model.\n*   Fully preserves output distribution.\n\n**Challenges**:\n\n*   Maintaining a separate draft model increases system complexity.\n*   Distribution mismatch between draft and target models can reduce acceptance rate.\n*   Memory and compute pressure if both models are large.",
    "order": 1,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 3,
    "tags": [
      "algorithmsarchitecture",
      "transformer",
      "gpt"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": true,
      "hasImages": true,
      "wordCount": 559,
      "contentLength": 13763
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#speculative-decoding-via-draft-models",
    "scrapedAt": "2025-12-28T11:47:57.256Z"
  },
  {
    "id": "ai-speculative-decoding-tree-based-multi-head-verification-medusa-2",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Core Techniques",
    "title": "Tree-based Multi-Head Verification (Medusa)",
    "subtitle": "Core Techniques",
    "contentHtml": "<ul>\n  <li>\n    <p>Medusa, introduced in <a href=\"https://arxiv.org/abs/2401.10774\">Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads</a> by Cai et al. (2024), improves over basic multi-head speculative decoding by using <strong>tree attention</strong>.</p>\n  </li>\n  <li>\n    <p>The following image from the blog (<a href=\"https://sites.google.com/view/medusa-llm\">source</a>) shows the performance of Medusa on Vicuna-7b.</p>\n  </li>\n</ul>\n<p>Medusa, introduced in <a href=\"https://arxiv.org/abs/2401.10774\">Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads</a> by Cai et al. (2024), improves over basic multi-head speculative decoding by using <strong>tree attention</strong>.</p>\n<p>The following image from the blog (<a href=\"https://sites.google.com/view/medusa-llm\">source</a>) shows the performance of Medusa on Vicuna-7b.</p>\n<p><img src=\"../../../images/papers/Medusa.gif\" alt=\"\"></p>\n<ul>\n  <li>\n    <p><strong>Core Features</strong>:</p>\n\n    <ul>\n      <li><strong>Medusa Heads</strong>: Each predicts <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-8-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi><mo>+</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-22\" style=\"width: 2.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.98em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-23\"><span class=\"mi\" id=\"MathJax-Span-24\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-25\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-26\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi><mo>+</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-8\">k+1</script> tokens into the future from the last hidden state.</li>\n      <li><strong>Candidate Assembly</strong>: The top-k outputs from each head are combined to form speculative trees.</li>\n      <li><strong>Tree Attention</strong>: A custom attention mask ensures tokens attend only to predecessors in their path.</li>\n      <li>\n        <p><strong>Acceptance Schemes</strong>: Two options:</p>\n\n        <ul>\n          <li><strong>Rejection Sampling</strong> (match base model)</li>\n          <li><strong>Typical Acceptance</strong> (heuristic, faster)</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Benefits</strong>:</p>\n\n    <ul>\n      <li>Higher speedups (~2.3–2.8<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-27\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-28\"><span class=\"mo\" id=\"MathJax-Span-29\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-9\">\\times</script> in production) with minimal quality drop.</li>\n      <li>Easy integration into existing models without retraining (Medusa-1) or with joint training (Medusa-2).</li>\n      <li>Suitable for batch size = 1, which aligns with real-world use (e.g., chat).</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Implementation Details</strong>:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>p</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mi>k</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi></mrow></msub></mrow></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub><mo>&amp;#x2217;</mo><mo stretchy=&quot;false&quot;>(</mo><mtext>SiLU</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>1</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub><mo>&amp;#x2217;</mo><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-30\" style=\"width: 21.096em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.555em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.409em, 1017.5em, 2.659em, -999.997em); top: -2.237em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-31\"><span class=\"msubsup\" id=\"MathJax-Span-32\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-33\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-34\"><span class=\"mrow\" id=\"MathJax-Span-35\"><span class=\"msubsup\" id=\"MathJax-Span-36\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-37\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.315em;\"><span class=\"texatom\" id=\"MathJax-Span-38\"><span class=\"mrow\" id=\"MathJax-Span-39\"><span class=\"mi\" id=\"MathJax-Span-40\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-41\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-42\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">softmax</span><span class=\"mo\" id=\"MathJax-Span-43\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-44\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-45\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-46\"><span class=\"mrow\" id=\"MathJax-Span-47\"><span class=\"msubsup\" id=\"MathJax-Span-48\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-49\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-50\"><span class=\"mrow\" id=\"MathJax-Span-51\"><span class=\"mi\" id=\"MathJax-Span-52\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-53\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">∗</span><span class=\"mo\" id=\"MathJax-Span-54\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">(</span><span class=\"mtext\" id=\"MathJax-Span-55\" style=\"font-family: STIXGeneral-Regular;\">SiLU</span><span class=\"mo\" id=\"MathJax-Span-56\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-57\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-58\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-59\"><span class=\"mrow\" id=\"MathJax-Span-60\"><span class=\"msubsup\" id=\"MathJax-Span-61\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-62\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-63\"><span class=\"mrow\" id=\"MathJax-Span-64\"><span class=\"mi\" id=\"MathJax-Span-65\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-66\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">∗</span><span class=\"msubsup\" id=\"MathJax-Span-67\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-68\" style=\"font-family: STIXGeneral-Italic;\">h</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-69\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-70\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-71\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"msubsup\" id=\"MathJax-Span-72\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-73\" style=\"font-family: STIXGeneral-Italic;\">h</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-74\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-75\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-76\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.242em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>p</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mi>k</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>t</mi></mrow></msub></mrow></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>2</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub><mo>∗</mo><mo stretchy=\"false\">(</mo><mtext>SiLU</mtext><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>1</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub><mo>∗</mo><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mo>+</mo><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-10\">p_{k_{t}} = \\text{softmax}(W_{2_{k}} * (\\text{SiLU}(W_{1_{k}} * h_t) + h_t))</script>\n\n    <ul>\n      <li>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>1</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-77\" style=\"width: 1.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.57em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-78\"><span class=\"msubsup\" id=\"MathJax-Span-79\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-80\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-81\"><span class=\"mrow\" id=\"MathJax-Span-82\"><span class=\"msubsup\" id=\"MathJax-Span-83\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-84\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-85\"><span class=\"mrow\" id=\"MathJax-Span-86\"><span class=\"mi\" id=\"MathJax-Span-87\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>1</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-11\">W_{1_{k}}</script> is initialized to 0 and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-88\" style=\"width: 1.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.57em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-89\"><span class=\"msubsup\" id=\"MathJax-Span-90\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-91\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-92\"><span class=\"mrow\" id=\"MathJax-Span-93\"><span class=\"msubsup\" id=\"MathJax-Span-94\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-95\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-96\"><span class=\"mrow\" id=\"MathJax-Span-97\"><span class=\"mi\" id=\"MathJax-Span-98\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>2</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">W_{2_{k}}</script> is a clone of the base model’s LM head.</li>\n    </ul>\n  </li>\n</ul>\n<p><strong>Core Features</strong>:</p>\n<ul>\n      <li><strong>Medusa Heads</strong>: Each predicts <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-8-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi><mo>+</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-22\" style=\"width: 2.503em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.98em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-23\"><span class=\"mi\" id=\"MathJax-Span-24\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-25\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-26\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi><mo>+</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-8\">k+1</script> tokens into the future from the last hidden state.</li>\n      <li><strong>Candidate Assembly</strong>: The top-k outputs from each head are combined to form speculative trees.</li>\n      <li><strong>Tree Attention</strong>: A custom attention mask ensures tokens attend only to predecessors in their path.</li>\n      <li>\n        <p><strong>Acceptance Schemes</strong>: Two options:</p>\n\n        <ul>\n          <li><strong>Rejection Sampling</strong> (match base model)</li>\n          <li><strong>Typical Acceptance</strong> (heuristic, faster)</li>\n        </ul>\n      </li>\n    </ul>\n<p><strong>Acceptance Schemes</strong>: Two options:</p>\n<ul>\n          <li><strong>Rejection Sampling</strong> (match base model)</li>\n          <li><strong>Typical Acceptance</strong> (heuristic, faster)</li>\n        </ul>\n<p><strong>Benefits</strong>:</p>\n<ul>\n      <li>Higher speedups (~2.3–2.8<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-27\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-28\"><span class=\"mo\" id=\"MathJax-Span-29\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-9\">\\times</script> in production) with minimal quality drop.</li>\n      <li>Easy integration into existing models without retraining (Medusa-1) or with joint training (Medusa-2).</li>\n      <li>Suitable for batch size = 1, which aligns with real-world use (e.g., chat).</li>\n    </ul>\n<p><strong>Implementation Details</strong>:</p>\n<ul>\n      <li>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>1</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-77\" style=\"width: 1.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.57em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-78\"><span class=\"msubsup\" id=\"MathJax-Span-79\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-80\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-81\"><span class=\"mrow\" id=\"MathJax-Span-82\"><span class=\"msubsup\" id=\"MathJax-Span-83\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-84\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-85\"><span class=\"mrow\" id=\"MathJax-Span-86\"><span class=\"mi\" id=\"MathJax-Span-87\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>1</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-11\">W_{1_{k}}</script> is initialized to 0 and <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-88\" style=\"width: 1.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.57em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-89\"><span class=\"msubsup\" id=\"MathJax-Span-90\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-91\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-92\"><span class=\"mrow\" id=\"MathJax-Span-93\"><span class=\"msubsup\" id=\"MathJax-Span-94\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-95\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-96\"><span class=\"mrow\" id=\"MathJax-Span-97\"><span class=\"mi\" id=\"MathJax-Span-98\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>2</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-12\">W_{2_{k}}</script> is a clone of the base model’s LM head.</li>\n    </ul>",
    "contentMarkdown": "*   Medusa, introduced in [Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads](https://arxiv.org/abs/2401.10774) by Cai et al. (2024), improves over basic multi-head speculative decoding by using **tree attention**.\n    \n*   The following image from the blog ([source](https://sites.google.com/view/medusa-llm)) shows the performance of Medusa on Vicuna-7b.\n    \n\nMedusa, introduced in [Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads](https://arxiv.org/abs/2401.10774) by Cai et al. (2024), improves over basic multi-head speculative decoding by using **tree attention**.\n\nThe following image from the blog ([source](https://sites.google.com/view/medusa-llm)) shows the performance of Medusa on Vicuna-7b.\n\n![](../../../images/papers/Medusa.gif)\n\n*   **Core Features**:\n    \n    *   **Medusa Heads**: Each predicts k+1k+1k+1 tokens into the future from the last hidden state.\n    *   **Candidate Assembly**: The top-k outputs from each head are combined to form speculative trees.\n    *   **Tree Attention**: A custom attention mask ensures tokens attend only to predecessors in their path.\n    *   **Acceptance Schemes**: Two options:\n        \n        *   **Rejection Sampling** (match base model)\n        *   **Typical Acceptance** (heuristic, faster)\n*   **Benefits**:\n    \n    *   Higher speedups (~2.3–2.8××\\\\times in production) with minimal quality drop.\n    *   Easy integration into existing models without retraining (Medusa-1) or with joint training (Medusa-2).\n    *   Suitable for batch size = 1, which aligns with real-world use (e.g., chat).\n*   **Implementation Details**:\n    \n    pkt\\=softmax(W2k∗(SiLU(W1k∗ht)+ht))pkt\\=softmax(W2k∗(SiLU(W1k∗ht)+ht))\n    \n    p\\_{k\\_{t}} = \\\\text{softmax}(W\\_{2\\_{k}} \\* (\\\\text{SiLU}(W\\_{1\\_{k}} \\* h\\_t) + h\\_t))\n    *   where W1kW1kW\\_{1\\_{k}} is initialized to 0 and W2kW2kW\\_{2\\_{k}} is a clone of the base model’s LM head.\n\n**Core Features**:\n\n*   **Medusa Heads**: Each predicts k+1k+1k+1 tokens into the future from the last hidden state.\n*   **Candidate Assembly**: The top-k outputs from each head are combined to form speculative trees.\n*   **Tree Attention**: A custom attention mask ensures tokens attend only to predecessors in their path.\n*   **Acceptance Schemes**: Two options:\n    \n    *   **Rejection Sampling** (match base model)\n    *   **Typical Acceptance** (heuristic, faster)\n\n**Acceptance Schemes**: Two options:\n\n*   **Rejection Sampling** (match base model)\n*   **Typical Acceptance** (heuristic, faster)\n\n**Benefits**:\n\n*   Higher speedups (~2.3–2.8××\\\\times in production) with minimal quality drop.\n*   Easy integration into existing models without retraining (Medusa-1) or with joint training (Medusa-2).\n*   Suitable for batch size = 1, which aligns with real-world use (e.g., chat).\n\n**Implementation Details**:\n\n*   where W1kW1kW\\_{1\\_{k}} is initialized to 0 and W2kW2kW\\_{2\\_{k}} is a clone of the base model’s LM head.",
    "order": 2,
    "orderInChapter": 2,
    "difficulty": 3,
    "estimatedMinutes": 2,
    "tags": [
      "algorithmsarchitecture",
      "attention",
      "llm"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": true,
      "wordCount": 361,
      "contentLength": 31555
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#tree-based-multi-head-verification-(medusa)",
    "scrapedAt": "2025-12-28T11:47:57.256Z"
  },
  {
    "id": "ai-speculative-decoding-multi-token-prediction-heads-self-speculative-deco-3",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Core Techniques",
    "title": "Multi-token Prediction Heads (Self-Speculative Decoding)",
    "subtitle": "Core Techniques",
    "contentHtml": "<ul>\n  <li>Introduced in <a href=\"https://arxiv.org/abs/2404.19737\">Better &amp; Faster Large Language Models via Multi-token Prediction</a> by Gloeckle et al. (2024).</li>\n  <li>Instead of using a separate draft model, a recent trend is to build speculative capabilities directly into the main model. This is where <strong>multi-token prediction heads</strong> come in.</li>\n  <li>The figure below from the paper illustrates an overview of multi-token prediction. (Top) During training, the model predicts 4 future tokens at once, by means of a shared trunk and 4 dedicated output heads. During inference, we employ only the next-token output head. Optionally, the other three heads may be used to speed-up inference time. (Bottom) Multi-token prediction improves pass@1 on the MBPP code task, significantly so as model size increases. Error bars are confidence intervals of 90% computed with bootstrapping over dataset samples.</li>\n</ul>\n<p><img src=\"../../../images/papers/MTP.jpg\" alt=\"\"></p>\n<ul>\n  <li>\n    <p><strong>Architecture</strong>:</p>\n\n    <ul>\n      <li>A shared transformer trunk encodes context.</li>\n      <li>Multiple decoder heads (1 per future token) make independent predictions.</li>\n      <li>The first head is the standard next-token predictor; others predict <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mi>d</mi></mrow></msup><mo>,</mo><msup><mn>3</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>r</mi><mi>d</mi></mrow></msup><mo>,</mo><mo>&amp;#x2026;</mo><msup><mi>n</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>h</mi></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-99\" style=\"width: 7.034em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.836em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1005.84em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-100\"><span class=\"msubsup\" id=\"MathJax-Span-101\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-102\" style=\"font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-103\"><span class=\"mrow\" id=\"MathJax-Span-104\"><span class=\"mi\" id=\"MathJax-Span-105\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-106\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-107\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-108\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-109\" style=\"font-family: STIXGeneral-Regular;\">3</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-110\"><span class=\"mrow\" id=\"MathJax-Span-111\"><span class=\"mi\" id=\"MathJax-Span-112\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-113\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-114\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-115\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"msubsup\" id=\"MathJax-Span-116\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-117\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-118\"><span class=\"mrow\" id=\"MathJax-Span-119\"><span class=\"mi\" id=\"MathJax-Span-120\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-121\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mn>2</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mi>d</mi></mrow></msup><mo>,</mo><msup><mn>3</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>r</mi><mi>d</mi></mrow></msup><mo>,</mo><mo>…</mo><msup><mi>n</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>t</mi><mi>h</mi></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">2^{nd}, 3^{rd}, \\dots n^{th}</script> tokens.</li>\n    </ul>\n  </li>\n  <li>\n    <p>Each head is trained with a cross-entropy loss on its respective position:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-14-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>L</mi><mi>n</mi></msub><mo>=</mo><mo>&amp;#x2212;</mo><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x3A3;</mo></mrow><mi>t</mi></msub><msubsup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x3A3;</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi></mrow></msubsup><mi>l</mi><mi>o</mi><mi>g</mi><mi>P</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow><msub><mi>z</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-122\" style=\"width: 12.971em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 10.784em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.669em, 1010.73em, 2.919em, -999.997em); top: -2.497em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-123\"><span class=\"msubsup\" id=\"MathJax-Span-124\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.58em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-125\" style=\"font-family: STIXGeneral-Italic;\">L<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.576em;\"><span class=\"mi\" id=\"MathJax-Span-126\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-127\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mo\" id=\"MathJax-Span-128\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">−</span><span class=\"msubsup\" id=\"MathJax-Span-129\"><span style=\"display: inline-block; position: relative; width: 0.888em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-130\"><span class=\"mrow\" id=\"MathJax-Span-131\"><span class=\"mo\" id=\"MathJax-Span-132\" style=\"font-family: STIXGeneral-Regular;\">Σ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.628em;\"><span class=\"mi\" id=\"MathJax-Span-133\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"msubsup\" id=\"MathJax-Span-134\"><span style=\"display: inline-block; position: relative; width: 1.721em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.63em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"texatom\" id=\"MathJax-Span-135\"><span class=\"mrow\" id=\"MathJax-Span-136\"><span class=\"mo\" id=\"MathJax-Span-137\" style=\"font-family: STIXGeneral-Regular;\">Σ</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.544em, 1000.42em, 4.169em, -999.997em); top: -4.372em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-138\"><span class=\"mrow\" id=\"MathJax-Span-139\"><span class=\"mi\" id=\"MathJax-Span-140\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; clip: rect(3.388em, 1001.1em, 4.169em, -999.997em); top: -3.747em; left: 0.628em;\"><span class=\"texatom\" id=\"MathJax-Span-141\"><span class=\"mrow\" id=\"MathJax-Span-142\"><span class=\"mi\" id=\"MathJax-Span-143\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span><span class=\"mo\" id=\"MathJax-Span-144\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">=</span><span class=\"mn\" id=\"MathJax-Span-145\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mi\" id=\"MathJax-Span-146\" style=\"font-family: STIXGeneral-Italic;\">l<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-147\" style=\"font-family: STIXGeneral-Italic;\">o</span><span class=\"mi\" id=\"MathJax-Span-148\" style=\"font-family: STIXGeneral-Italic;\">g</span><span class=\"mi\" id=\"MathJax-Span-149\" style=\"font-family: STIXGeneral-Italic;\">P</span><span class=\"mo\" id=\"MathJax-Span-150\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-151\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-152\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-153\"><span class=\"mrow\" id=\"MathJax-Span-154\"><span class=\"mi\" id=\"MathJax-Span-155\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-156\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mi\" id=\"MathJax-Span-157\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"texatom\" id=\"MathJax-Span-158\"><span class=\"mrow\" id=\"MathJax-Span-159\"><span class=\"mo\" id=\"MathJax-Span-160\" style=\"font-family: STIXVariants;\">|</span></span></span><span class=\"msubsup\" id=\"MathJax-Span-161\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-162\" style=\"font-family: STIXGeneral-Italic;\">z</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-163\"><span class=\"mrow\" id=\"MathJax-Span-164\"><span class=\"mn\" id=\"MathJax-Span-165\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-166\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-167\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-168\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.503em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.316em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>L</mi><mi>n</mi></msub><mo>=</mo><mo>−</mo><msub><mrow class=\"MJX-TeXAtom-ORD\"><mo>Σ</mo></mrow><mi>t</mi></msub><msubsup><mrow class=\"MJX-TeXAtom-ORD\"><mo>Σ</mo></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi></mrow></msubsup><mi>l</mi><mi>o</mi><mi>g</mi><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mrow class=\"MJX-TeXAtom-ORD\"><mo stretchy=\"false\">|</mo></mrow><msub><mi>z</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-14\">L_n = - Σ_t Σ_{i=1}^{n} log P( x_{t+i} | z_{1:t} )</script>\n\n    <ul>\n      <li>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-15-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>z</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-169\" style=\"width: 1.461em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1001.2em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-170\"><span class=\"msubsup\" id=\"MathJax-Span-171\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-172\" style=\"font-family: STIXGeneral-Italic;\">z</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-173\"><span class=\"mrow\" id=\"MathJax-Span-174\"><span class=\"mn\" id=\"MathJax-Span-175\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-176\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-177\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>z</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-15\">z_{1:t}</script> is the shared latent context and each <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-16-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-178\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.61em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-179\"><span class=\"mi\" id=\"MathJax-Span-180\" style=\"font-family: STIXGeneral-Italic;\">P</span><span class=\"mo\" id=\"MathJax-Span-181\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-182\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-183\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-184\"><span class=\"mrow\" id=\"MathJax-Span-185\"><span class=\"mi\" id=\"MathJax-Span-186\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-187\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mi\" id=\"MathJax-Span-188\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-189\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-16\">P(x_{t+i})</script> is computed via its dedicated head.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Memory Optimization</strong>:</p>\n\n    <ul>\n      <li>\n        <p>Instead of materializing all logits for all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-190\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-191\"><span class=\"mi\" id=\"MathJax-Span-192\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-17\">n</script> heads, training sequentially processes each head to reduce GPU memory:</p>\n\n        <ul>\n          <li>Compute forward and backward for head 1</li>\n          <li>Free logits, move to head 2</li>\n          <li>Accumulate gradients on shared trunk</li>\n        </ul>\n      </li>\n      <li>\n        <p>This reduces peak memory from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-193\" style=\"width: 5.211em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.326em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.27em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-194\"><span class=\"mi\" id=\"MathJax-Span-195\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-196\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-197\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-198\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-199\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-200\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-201\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-18\">O(nV + d)</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-202\" style=\"width: 4.586em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.805em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.75em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-203\"><span class=\"mi\" id=\"MathJax-Span-204\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-205\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-206\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-207\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-208\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-209\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-19\">O(V + d)</script>, with no speed tradeoff.</p>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Advantages</strong>:</p>\n\n    <ul>\n      <li>No need for separate draft model.</li>\n      <li>Unified architecture (easier to deploy, quantize, and train).</li>\n      <li>Compatible with speculative decoding methods like blockwise parallelism or Medusa.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Drawbacks</strong>:</p>\n\n    <ul>\n      <li>Requires modifying the model during pretraining.</li>\n      <li>Gains only materialize at scale (7B+ models).</li>\n      <li>Finetuning these models may require care to preserve alignment.</li>\n    </ul>\n  </li>\n</ul>\n<p><strong>Architecture</strong>:</p>\n<ul>\n      <li>A shared transformer trunk encodes context.</li>\n      <li>Multiple decoder heads (1 per future token) make independent predictions.</li>\n      <li>The first head is the standard next-token predictor; others predict <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>n</mi><mi>d</mi></mrow></msup><mo>,</mo><msup><mn>3</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>r</mi><mi>d</mi></mrow></msup><mo>,</mo><mo>&amp;#x2026;</mo><msup><mi>n</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>h</mi></mrow></msup></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-99\" style=\"width: 7.034em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.836em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.148em, 1005.84em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-100\"><span class=\"msubsup\" id=\"MathJax-Span-101\"><span style=\"display: inline-block; position: relative; width: 1.305em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-102\" style=\"font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-103\"><span class=\"mrow\" id=\"MathJax-Span-104\"><span class=\"mi\" id=\"MathJax-Span-105\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-106\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-107\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"msubsup\" id=\"MathJax-Span-108\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.253em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.42em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-109\" style=\"font-family: STIXGeneral-Regular;\">3</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.424em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-110\"><span class=\"mrow\" id=\"MathJax-Span-111\"><span class=\"mi\" id=\"MathJax-Span-112\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">r<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-113\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-114\" style=\"font-family: STIXGeneral-Regular;\">,</span><span class=\"mo\" id=\"MathJax-Span-115\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.211em;\">…</span><span class=\"msubsup\" id=\"MathJax-Span-116\" style=\"padding-left: 0.211em;\"><span style=\"display: inline-block; position: relative; width: 1.148em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-117\" style=\"font-family: STIXGeneral-Italic;\">n</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -4.372em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-118\"><span class=\"mrow\" id=\"MathJax-Span-119\"><span class=\"mi\" id=\"MathJax-Span-120\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mi\" id=\"MathJax-Span-121\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">h</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.378em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mn>2</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>n</mi><mi>d</mi></mrow></msup><mo>,</mo><msup><mn>3</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>r</mi><mi>d</mi></mrow></msup><mo>,</mo><mo>…</mo><msup><mi>n</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>t</mi><mi>h</mi></mrow></msup></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-13\">2^{nd}, 3^{rd}, \\dots n^{th}</script> tokens.</li>\n    </ul>\n<p>Each head is trained with a cross-entropy loss on its respective position:</p>\n<ul>\n      <li>where <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-15-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>z</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-169\" style=\"width: 1.461em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.565em, 1001.2em, 2.451em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-170\"><span class=\"msubsup\" id=\"MathJax-Span-171\"><span style=\"display: inline-block; position: relative; width: 1.201em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.37em, 4.273em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-172\" style=\"font-family: STIXGeneral-Italic;\">z</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-173\"><span class=\"mrow\" id=\"MathJax-Span-174\"><span class=\"mn\" id=\"MathJax-Span-175\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span class=\"mo\" id=\"MathJax-Span-176\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">:</span><span class=\"mi\" id=\"MathJax-Span-177\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>z</mi><mrow class=\"MJX-TeXAtom-ORD\"><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-15\">z_{1:t}</script> is the shared latent context and each <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-16-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-178\" style=\"width: 3.232em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.659em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.61em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-179\"><span class=\"mi\" id=\"MathJax-Span-180\" style=\"font-family: STIXGeneral-Italic;\">P</span><span class=\"mo\" id=\"MathJax-Span-181\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-182\"><span style=\"display: inline-block; position: relative; width: 1.409em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-183\" style=\"font-family: STIXGeneral-Italic;\">x<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.471em;\"><span class=\"texatom\" id=\"MathJax-Span-184\"><span class=\"mrow\" id=\"MathJax-Span-185\"><span class=\"mi\" id=\"MathJax-Span-186\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-187\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">+</span><span class=\"mi\" id=\"MathJax-Span-188\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">i</span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-189\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.128em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>P</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-16\">P(x_{t+i})</script> is computed via its dedicated head.</li>\n    </ul>\n<p><strong>Memory Optimization</strong>:</p>\n<ul>\n      <li>\n        <p>Instead of materializing all logits for all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-190\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-191\"><span class=\"mi\" id=\"MathJax-Span-192\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-17\">n</script> heads, training sequentially processes each head to reduce GPU memory:</p>\n\n        <ul>\n          <li>Compute forward and backward for head 1</li>\n          <li>Free logits, move to head 2</li>\n          <li>Accumulate gradients on shared trunk</li>\n        </ul>\n      </li>\n      <li>\n        <p>This reduces peak memory from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-193\" style=\"width: 5.211em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.326em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.27em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-194\"><span class=\"mi\" id=\"MathJax-Span-195\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-196\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-197\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-198\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-199\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-200\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-201\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-18\">O(nV + d)</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-202\" style=\"width: 4.586em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.805em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.75em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-203\"><span class=\"mi\" id=\"MathJax-Span-204\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-205\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-206\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-207\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-208\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-209\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-19\">O(V + d)</script>, with no speed tradeoff.</p>\n      </li>\n    </ul>\n<p>Instead of materializing all logits for all <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-190\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-191\"><span class=\"mi\" id=\"MathJax-Span-192\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-17\">n</script> heads, training sequentially processes each head to reduce GPU memory:</p>\n<ul>\n          <li>Compute forward and backward for head 1</li>\n          <li>Free logits, move to head 2</li>\n          <li>Accumulate gradients on shared trunk</li>\n        </ul>\n<p>This reduces peak memory from <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-193\" style=\"width: 5.211em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.326em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1004.27em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-194\"><span class=\"mi\" id=\"MathJax-Span-195\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-196\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-197\" style=\"font-family: STIXGeneral-Italic;\">n</span><span class=\"mi\" id=\"MathJax-Span-198\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-199\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-200\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-201\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-18\">O(nV + d)</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-202\" style=\"width: 4.586em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.805em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1003.75em, 2.503em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-203\"><span class=\"mi\" id=\"MathJax-Span-204\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-205\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-206\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-207\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-208\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-209\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.247em; border-left: 0px solid; width: 0px; height: 1.191em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-19\">O(V + d)</script>, with no speed tradeoff.</p>\n<p><strong>Advantages</strong>:</p>\n<ul>\n      <li>No need for separate draft model.</li>\n      <li>Unified architecture (easier to deploy, quantize, and train).</li>\n      <li>Compatible with speculative decoding methods like blockwise parallelism or Medusa.</li>\n    </ul>\n<p><strong>Drawbacks</strong>:</p>\n<ul>\n      <li>Requires modifying the model during pretraining.</li>\n      <li>Gains only materialize at scale (7B+ models).</li>\n      <li>Finetuning these models may require care to preserve alignment.</li>\n    </ul>",
    "contentMarkdown": "*   Introduced in [Better & Faster Large Language Models via Multi-token Prediction](https://arxiv.org/abs/2404.19737) by Gloeckle et al. (2024).\n*   Instead of using a separate draft model, a recent trend is to build speculative capabilities directly into the main model. This is where **multi-token prediction heads** come in.\n*   The figure below from the paper illustrates an overview of multi-token prediction. (Top) During training, the model predicts 4 future tokens at once, by means of a shared trunk and 4 dedicated output heads. During inference, we employ only the next-token output head. Optionally, the other three heads may be used to speed-up inference time. (Bottom) Multi-token prediction improves pass@1 on the MBPP code task, significantly so as model size increases. Error bars are confidence intervals of 90% computed with bootstrapping over dataset samples.\n\n![](../../../images/papers/MTP.jpg)\n\n*   **Architecture**:\n    \n    *   A shared transformer trunk encodes context.\n    *   Multiple decoder heads (1 per future token) make independent predictions.\n    *   The first head is the standard next-token predictor; others predict 2nd,3rd,…nth2nd,3rd,…nth2^{nd}, 3^{rd}, \\\\dots n^{th} tokens.\n*   Each head is trained with a cross-entropy loss on its respective position:\n    \n    Ln\\=−ΣtΣni\\=1logP(xt+i|z1:t)Ln\\=−ΣtΣi\\=1nlogP(xt+i|z1:t)\n    \n    L\\_n = - Σ\\_t Σ\\_{i=1}^{n} log P( x\\_{t+i} | z\\_{1:t} )\n    *   where z1:tz1:tz\\_{1:t} is the shared latent context and each P(xt+i)P(xt+i)P(x\\_{t+i}) is computed via its dedicated head.\n*   **Memory Optimization**:\n    \n    *   Instead of materializing all logits for all nnn heads, training sequentially processes each head to reduce GPU memory:\n        \n        *   Compute forward and backward for head 1\n        *   Free logits, move to head 2\n        *   Accumulate gradients on shared trunk\n    *   This reduces peak memory from O(nV+d)O(nV+d)O(nV + d) to O(V+d)O(V+d)O(V + d), with no speed tradeoff.\n        \n*   **Advantages**:\n    \n    *   No need for separate draft model.\n    *   Unified architecture (easier to deploy, quantize, and train).\n    *   Compatible with speculative decoding methods like blockwise parallelism or Medusa.\n*   **Drawbacks**:\n    \n    *   Requires modifying the model during pretraining.\n    *   Gains only materialize at scale (7B+ models).\n    *   Finetuning these models may require care to preserve alignment.\n\n**Architecture**:\n\n*   A shared transformer trunk encodes context.\n*   Multiple decoder heads (1 per future token) make independent predictions.\n*   The first head is the standard next-token predictor; others predict 2nd,3rd,…nth2nd,3rd,…nth2^{nd}, 3^{rd}, \\\\dots n^{th} tokens.\n\nEach head is trained with a cross-entropy loss on its respective position:\n\n*   where z1:tz1:tz\\_{1:t} is the shared latent context and each P(xt+i)P(xt+i)P(x\\_{t+i}) is computed via its dedicated head.\n\n**Memory Optimization**:\n\n*   Instead of materializing all logits for all nnn heads, training sequentially processes each head to reduce GPU memory:\n    \n    *   Compute forward and backward for head 1\n    *   Free logits, move to head 2\n    *   Accumulate gradients on shared trunk\n*   This reduces peak memory from O(nV+d)O(nV+d)O(nV + d) to O(V+d)O(V+d)O(V + d), with no speed tradeoff.\n    \n\nInstead of materializing all logits for all nnn heads, training sequentially processes each head to reduce GPU memory:\n\n*   Compute forward and backward for head 1\n*   Free logits, move to head 2\n*   Accumulate gradients on shared trunk\n\nThis reduces peak memory from O(nV+d)O(nV+d)O(nV + d) to O(V+d)O(V+d)O(V + d), with no speed tradeoff.\n\n**Advantages**:\n\n*   No need for separate draft model.\n*   Unified architecture (easier to deploy, quantize, and train).\n*   Compatible with speculative decoding methods like blockwise parallelism or Medusa.\n\n**Drawbacks**:\n\n*   Requires modifying the model during pretraining.\n*   Gains only materialize at scale (7B+ models).\n*   Finetuning these models may require care to preserve alignment.",
    "order": 3,
    "orderInChapter": 3,
    "difficulty": 4,
    "estimatedMinutes": 3,
    "tags": [
      "algorithmsarchitecture",
      "transformer",
      "optimization"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": true,
      "wordCount": 558,
      "contentLength": 50276
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#multi-token-prediction-heads-(self-speculative-decoding)",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-comparison-table-4",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Comparative Analysis",
    "title": "Comparison Table",
    "subtitle": "Comparative Analysis",
    "contentHtml": "<div align=\"center\">\n<table class=\"tg\">\n<thead>\n<tr>\n<th class=\"tg-hcenter-valign-first\"><strong>Criteria</strong></th>\n<th class=\"tg-hcenter-valign-first\"><strong>Draft Model<br>(Leviathan et al., Nov 2022)</strong></th>\n<th class=\"tg-hcenter-valign-first\"><strong>Medusa Tree‑Attention<br>(Cai et al., Jan 2024)</strong></th>\n<th class=\"tg-hcenter-valign-second\"><strong>Multi‑Token Prediction Heads<br>(Gloeckle et al., Apr 2024)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tg-tleft-valign-first\">Model changes required</td>\n<td class=\"tg-tleft-valign-first\">None</td>\n<td class=\"tg-tleft-valign-first\">Optional (Medusa‑1) / joint (Medusa‑2)</td>\n<td class=\"tg-tleft-valign-second\">Yes (requires modifying output heads during pre-training)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Training cost</td>\n<td class=\"tg-tleft-valign-first\">Low (can use off-the-shelf models as draft and target models)</td>\n<td class=\"tg-tleft-valign-first\">Moderate (fine‑tune extra heads)</td>\n<td class=\"tg-tleft-valign-second\">High (requires pre-training)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Inference speedup (observed)</td>\n<td class=\"tg-tleft-valign-first\"><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-20-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x223C;</mo><mn>2</mn><mo>&amp;#x00D7;</mo><mtext>&amp;#x2013;</mtext><mn>3</mn><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-210\" style=\"width: 4.824em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.991em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1003.93em, 2.443em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-211\"><span class=\"mo\" id=\"MathJax-Span-212\" style=\"font-family: STIXGeneral-Regular;\">∼</span><span class=\"mn\" id=\"MathJax-Span-213\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.301em;\">2</span><span class=\"mo\" id=\"MathJax-Span-214\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">–</span><span class=\"mn\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular;\">3</span><span class=\"mo\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>∼</mo><mn>2</mn><mo>×</mo><mtext>–</mtext><mn>3</mn><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-20\">\\sim 2\\times\\text{–}3\\times</script></td>\n<td class=\"tg-tleft-valign-first\"><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x223C;</mo><mn>2.2</mn><mo>&amp;#x00D7;</mo><mtext>&amp;#x2013;</mtext><mn>3.6</mn><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-218\" style=\"width: 6.61em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.479em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1005.42em, 2.443em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-219\"><span class=\"mo\" id=\"MathJax-Span-220\" style=\"font-family: STIXGeneral-Regular;\">∼</span><span class=\"mn\" id=\"MathJax-Span-221\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.301em;\">2.2</span><span class=\"mo\" id=\"MathJax-Span-222\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-223\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">–</span><span class=\"mn\" id=\"MathJax-Span-224\" style=\"font-family: STIXGeneral-Regular;\">3.6</span><span class=\"mo\" id=\"MathJax-Span-225\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>∼</mo><mn>2.2</mn><mo>×</mo><mtext>–</mtext><mn>3.6</mn><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">\\sim 2.2\\times\\text{–}3.6\\times</script> (typically <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>2.3</mn><mo>&amp;#x00D7;</mo><mtext>&amp;#x2013;</mtext><mn>2.8</mn><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-226\" style=\"width: 5.539em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.586em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1004.53em, 2.443em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-227\"><span class=\"mn\" id=\"MathJax-Span-228\" style=\"font-family: STIXGeneral-Regular;\">2.3</span><span class=\"mo\" id=\"MathJax-Span-229\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-230\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">–</span><span class=\"mn\" id=\"MathJax-Span-231\" style=\"font-family: STIXGeneral-Regular;\">2.8</span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>2.3</mn><mo>×</mo><mtext>–</mtext><mn>2.8</mn><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-22\">2.3\\times\\text{–}2.8\\times</script>)</td>\n<td class=\"tg-tleft-valign-second\"><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x223C;</mo><mn>3</mn><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-233\" style=\"width: 2.324em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.908em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1001.85em, 2.443em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-234\"><span class=\"mo\" id=\"MathJax-Span-235\" style=\"font-family: STIXGeneral-Regular;\">∼</span><span class=\"mn\" id=\"MathJax-Span-236\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.301em;\">3</span><span class=\"mo\" id=\"MathJax-Span-237\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>∼</mo><mn>3</mn><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-23\">\\sim 3\\times</script> (4‑token), up to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x223C;</mo><mn>6</mn><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-238\" style=\"width: 2.324em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.908em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1001.85em, 2.443em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-239\"><span class=\"mo\" id=\"MathJax-Span-240\" style=\"font-family: STIXGeneral-Regular;\">∼</span><span class=\"mn\" id=\"MathJax-Span-241\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.301em;\">6</span><span class=\"mo\" id=\"MathJax-Span-242\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>∼</mo><mn>6</mn><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">\\sim 6\\times</script> (8‑token draft window)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Output quality</td>\n<td class=\"tg-tleft-valign-first\">Identical to base model</td>\n<td class=\"tg-tleft-valign-first\">High (rejection + typical acceptance schemes)</td>\n<td class=\"tg-tleft-valign-second\">Matches next‑token head</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Deployment ease</td>\n<td class=\"tg-tleft-valign-first\">Moderate (dual‑model system)</td>\n<td class=\"tg-tleft-valign-first\">High (single model with extra heads)</td>\n<td class=\"tg-tleft-valign-second\">High (single model if integrated from pretraining)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Memory overhead (training)</td>\n<td class=\"tg-tleft-valign-first\">High (two model states / KV‑cache)</td>\n<td class=\"tg-tleft-valign-first\">Low (single trunk + small head layers)</td>\n<td class=\"tg-tleft-valign-second\">Efficient (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-243\" style=\"width: 4.527em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.753em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1003.69em, 2.622em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-244\"><span class=\"mi\" id=\"MathJax-Span-245\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-247\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.063em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-248\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">+</span><span class=\"mi\" id=\"MathJax-Span-249\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.241em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.282em; border-left: 0px solid; width: 0px; height: 1.146em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">O(V + d)</script> peak memory)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Batch‑size friendliness</td>\n<td class=\"tg-tleft-valign-first\">High</td>\n<td class=\"tg-tleft-valign-first\">Optimized for batch size = 1</td>\n<td class=\"tg-tleft-valign-second\">High</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Implementation maturity</td>\n<td class=\"tg-tleft-valign-first\">Widely used since 2022 (T5, GPT)</td>\n<td class=\"tg-tleft-valign-first\">Early adoption in LLMs like Vicuna, Zephyr</td>\n<td class=\"tg-tleft-valign-second\"><a href=\"https://arxiv.org/html/2412.19437v1\">DeepSeek V3</a></td>\n</tr>\n</tbody>\n</table>\n</div>\n<table class=\"tg\">\n<thead>\n<tr>\n<th class=\"tg-hcenter-valign-first\"><strong>Criteria</strong></th>\n<th class=\"tg-hcenter-valign-first\"><strong>Draft Model<br>(Leviathan et al., Nov 2022)</strong></th>\n<th class=\"tg-hcenter-valign-first\"><strong>Medusa Tree‑Attention<br>(Cai et al., Jan 2024)</strong></th>\n<th class=\"tg-hcenter-valign-second\"><strong>Multi‑Token Prediction Heads<br>(Gloeckle et al., Apr 2024)</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td class=\"tg-tleft-valign-first\">Model changes required</td>\n<td class=\"tg-tleft-valign-first\">None</td>\n<td class=\"tg-tleft-valign-first\">Optional (Medusa‑1) / joint (Medusa‑2)</td>\n<td class=\"tg-tleft-valign-second\">Yes (requires modifying output heads during pre-training)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Training cost</td>\n<td class=\"tg-tleft-valign-first\">Low (can use off-the-shelf models as draft and target models)</td>\n<td class=\"tg-tleft-valign-first\">Moderate (fine‑tune extra heads)</td>\n<td class=\"tg-tleft-valign-second\">High (requires pre-training)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Inference speedup (observed)</td>\n<td class=\"tg-tleft-valign-first\"><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-20-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x223C;</mo><mn>2</mn><mo>&amp;#x00D7;</mo><mtext>&amp;#x2013;</mtext><mn>3</mn><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-210\" style=\"width: 4.824em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.991em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1003.93em, 2.443em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-211\"><span class=\"mo\" id=\"MathJax-Span-212\" style=\"font-family: STIXGeneral-Regular;\">∼</span><span class=\"mn\" id=\"MathJax-Span-213\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.301em;\">2</span><span class=\"mo\" id=\"MathJax-Span-214\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-215\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">–</span><span class=\"mn\" id=\"MathJax-Span-216\" style=\"font-family: STIXGeneral-Regular;\">3</span><span class=\"mo\" id=\"MathJax-Span-217\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>∼</mo><mn>2</mn><mo>×</mo><mtext>–</mtext><mn>3</mn><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-20\">\\sim 2\\times\\text{–}3\\times</script></td>\n<td class=\"tg-tleft-valign-first\"><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x223C;</mo><mn>2.2</mn><mo>&amp;#x00D7;</mo><mtext>&amp;#x2013;</mtext><mn>3.6</mn><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-218\" style=\"width: 6.61em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 5.479em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1005.42em, 2.443em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-219\"><span class=\"mo\" id=\"MathJax-Span-220\" style=\"font-family: STIXGeneral-Regular;\">∼</span><span class=\"mn\" id=\"MathJax-Span-221\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.301em;\">2.2</span><span class=\"mo\" id=\"MathJax-Span-222\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-223\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">–</span><span class=\"mn\" id=\"MathJax-Span-224\" style=\"font-family: STIXGeneral-Regular;\">3.6</span><span class=\"mo\" id=\"MathJax-Span-225\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>∼</mo><mn>2.2</mn><mo>×</mo><mtext>–</mtext><mn>3.6</mn><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-21\">\\sim 2.2\\times\\text{–}3.6\\times</script> (typically <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>2.3</mn><mo>&amp;#x00D7;</mo><mtext>&amp;#x2013;</mtext><mn>2.8</mn><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-226\" style=\"width: 5.539em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.586em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1004.53em, 2.443em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-227\"><span class=\"mn\" id=\"MathJax-Span-228\" style=\"font-family: STIXGeneral-Regular;\">2.3</span><span class=\"mo\" id=\"MathJax-Span-229\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">×</span><span class=\"mtext\" id=\"MathJax-Span-230\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">–</span><span class=\"mn\" id=\"MathJax-Span-231\" style=\"font-family: STIXGeneral-Regular;\">2.8</span><span class=\"mo\" id=\"MathJax-Span-232\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>2.3</mn><mo>×</mo><mtext>–</mtext><mn>2.8</mn><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-22\">2.3\\times\\text{–}2.8\\times</script>)</td>\n<td class=\"tg-tleft-valign-second\"><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x223C;</mo><mn>3</mn><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-233\" style=\"width: 2.324em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.908em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1001.85em, 2.443em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-234\"><span class=\"mo\" id=\"MathJax-Span-235\" style=\"font-family: STIXGeneral-Regular;\">∼</span><span class=\"mn\" id=\"MathJax-Span-236\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.301em;\">3</span><span class=\"mo\" id=\"MathJax-Span-237\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>∼</mo><mn>3</mn><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-23\">\\sim 3\\times</script> (4‑token), up to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x223C;</mo><mn>6</mn><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-238\" style=\"width: 2.324em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.908em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1001.85em, 2.443em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-239\"><span class=\"mo\" id=\"MathJax-Span-240\" style=\"font-family: STIXGeneral-Regular;\">∼</span><span class=\"mn\" id=\"MathJax-Span-241\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.301em;\">6</span><span class=\"mo\" id=\"MathJax-Span-242\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>∼</mo><mn>6</mn><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-24\">\\sim 6\\times</script> (8‑token draft window)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Output quality</td>\n<td class=\"tg-tleft-valign-first\">Identical to base model</td>\n<td class=\"tg-tleft-valign-first\">High (rejection + typical acceptance schemes)</td>\n<td class=\"tg-tleft-valign-second\">Matches next‑token head</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Deployment ease</td>\n<td class=\"tg-tleft-valign-first\">Moderate (dual‑model system)</td>\n<td class=\"tg-tleft-valign-first\">High (single model with extra heads)</td>\n<td class=\"tg-tleft-valign-second\">High (single model if integrated from pretraining)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Memory overhead (training)</td>\n<td class=\"tg-tleft-valign-first\">High (two model states / KV‑cache)</td>\n<td class=\"tg-tleft-valign-first\">Low (single trunk + small head layers)</td>\n<td class=\"tg-tleft-valign-second\">Efficient (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>O</mi><mo stretchy=&quot;false&quot;>(</mo><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-243\" style=\"width: 4.527em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 3.753em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1003.69em, 2.622em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-244\"><span class=\"mi\" id=\"MathJax-Span-245\" style=\"font-family: STIXGeneral-Italic;\">O</span><span class=\"mo\" id=\"MathJax-Span-246\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mi\" id=\"MathJax-Span-247\" style=\"font-family: STIXGeneral-Italic;\">V<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.063em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-248\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.241em;\">+</span><span class=\"mi\" id=\"MathJax-Span-249\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.241em;\">d<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-250\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.282em; border-left: 0px solid; width: 0px; height: 1.146em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>O</mi><mo stretchy=\"false\">(</mo><mi>V</mi><mo>+</mo><mi>d</mi><mo stretchy=\"false\">)</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-25\">O(V + d)</script> peak memory)</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Batch‑size friendliness</td>\n<td class=\"tg-tleft-valign-first\">High</td>\n<td class=\"tg-tleft-valign-first\">Optimized for batch size = 1</td>\n<td class=\"tg-tleft-valign-second\">High</td>\n</tr>\n<tr>\n<td class=\"tg-tleft-valign-first\">Implementation maturity</td>\n<td class=\"tg-tleft-valign-first\">Widely used since 2022 (T5, GPT)</td>\n<td class=\"tg-tleft-valign-first\">Early adoption in LLMs like Vicuna, Zephyr</td>\n<td class=\"tg-tleft-valign-second\"><a href=\"https://arxiv.org/html/2412.19437v1\">DeepSeek V3</a></td>\n</tr>\n</tbody>\n</table>",
    "contentMarkdown": "**Criteria**\n\n**Draft Model  \n(Leviathan et al., Nov 2022)**\n\n**Medusa Tree‑Attention  \n(Cai et al., Jan 2024)**\n\n**Multi‑Token Prediction Heads  \n(Gloeckle et al., Apr 2024)**\n\nModel changes required\n\nNone\n\nOptional (Medusa‑1) / joint (Medusa‑2)\n\nYes (requires modifying output heads during pre-training)\n\nTraining cost\n\nLow (can use off-the-shelf models as draft and target models)\n\nModerate (fine‑tune extra heads)\n\nHigh (requires pre-training)\n\nInference speedup (observed)\n\n∼2×–3×∼2×–3×\\\\sim 2\\\\times\\\\text{–}3\\\\times\n\n∼2.2×–3.6×∼2.2×–3.6×\\\\sim 2.2\\\\times\\\\text{–}3.6\\\\times (typically 2.3×–2.8×2.3×–2.8×2.3\\\\times\\\\text{–}2.8\\\\times)\n\n∼3×∼3×\\\\sim 3\\\\times (4‑token), up to ∼6×∼6×\\\\sim 6\\\\times (8‑token draft window)\n\nOutput quality\n\nIdentical to base model\n\nHigh (rejection + typical acceptance schemes)\n\nMatches next‑token head\n\nDeployment ease\n\nModerate (dual‑model system)\n\nHigh (single model with extra heads)\n\nHigh (single model if integrated from pretraining)\n\nMemory overhead (training)\n\nHigh (two model states / KV‑cache)\n\nLow (single trunk + small head layers)\n\nEfficient (O(V+d)O(V+d)O(V + d) peak memory)\n\nBatch‑size friendliness\n\nHigh\n\nOptimized for batch size = 1\n\nHigh\n\nImplementation maturity\n\nWidely used since 2022 (T5, GPT)\n\nEarly adoption in LLMs like Vicuna, Zephyr\n\n[DeepSeek V3](https://arxiv.org/html/2412.19437v1)\n\n**Criteria**\n\n**Draft Model  \n(Leviathan et al., Nov 2022)**\n\n**Medusa Tree‑Attention  \n(Cai et al., Jan 2024)**\n\n**Multi‑Token Prediction Heads  \n(Gloeckle et al., Apr 2024)**\n\nModel changes required\n\nNone\n\nOptional (Medusa‑1) / joint (Medusa‑2)\n\nYes (requires modifying output heads during pre-training)\n\nTraining cost\n\nLow (can use off-the-shelf models as draft and target models)\n\nModerate (fine‑tune extra heads)\n\nHigh (requires pre-training)\n\nInference speedup (observed)\n\n∼2×–3×∼2×–3×\\\\sim 2\\\\times\\\\text{–}3\\\\times\n\n∼2.2×–3.6×∼2.2×–3.6×\\\\sim 2.2\\\\times\\\\text{–}3.6\\\\times (typically 2.3×–2.8×2.3×–2.8×2.3\\\\times\\\\text{–}2.8\\\\times)\n\n∼3×∼3×\\\\sim 3\\\\times (4‑token), up to ∼6×∼6×\\\\sim 6\\\\times (8‑token draft window)\n\nOutput quality\n\nIdentical to base model\n\nHigh (rejection + typical acceptance schemes)\n\nMatches next‑token head\n\nDeployment ease\n\nModerate (dual‑model system)\n\nHigh (single model with extra heads)\n\nHigh (single model if integrated from pretraining)\n\nMemory overhead (training)\n\nHigh (two model states / KV‑cache)\n\nLow (single trunk + small head layers)\n\nEfficient (O(V+d)O(V+d)O(V + d) peak memory)\n\nBatch‑size friendliness\n\nHigh\n\nOptimized for batch size = 1\n\nHigh\n\nImplementation maturity\n\nWidely used since 2022 (T5, GPT)\n\nEarly adoption in LLMs like Vicuna, Zephyr\n\n[DeepSeek V3](https://arxiv.org/html/2412.19437v1)",
    "order": 4,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 2,
    "tags": [
      "algorithmsarchitecture",
      "attention",
      "gpt",
      "llm"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 318,
      "contentLength": 26491
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#comparison-table",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-when-to-use-each-technique-5",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Comparative Analysis",
    "title": "When to Use Each Technique",
    "subtitle": "Comparative Analysis",
    "contentHtml": "<ul>\n  <li>\n    <p><strong>Draft Model (Leviathan-style speculative decoding)</strong>:</p>\n\n    <ul>\n      <li>Ideal when you can’t modify or retrain the base model.</li>\n      <li>Suitable for legacy systems or commercial APIs.</li>\n      <li>Offers “plug-and-play” inference acceleration with minimal integration overhead.</li>\n      <li>Best when a strong, compact draft model is already available.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Medusa (Cai et al., 2024)</strong>:</p>\n\n    <ul>\n      <li>Ideal for single-user interactive settings (e.g., chatbots).</li>\n      <li>Offers fine-grained control via Medusa-1 (frozen backbone) or Medusa-2 (joint fine-tuning).</li>\n      <li>Introduces <strong>tree attention</strong> to optimize speculative token verification.</li>\n      <li>Can outperform others when output diversity or control is key.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Multi-token Prediction Heads (Gloeckle et al., 2024)</strong>:</p>\n\n    <ul>\n      <li>Recommended during full model pretraining.</li>\n      <li>Best for institutions training models from scratch or at scale.</li>\n      <li>Enables <strong>self-speculative decoding</strong> with minimal architectural footprint.</li>\n      <li>Very efficient for longer inputs or batch decoding workloads.</li>\n    </ul>\n  </li>\n</ul>\n<p><strong>Draft Model (Leviathan-style speculative decoding)</strong>:</p>\n<ul>\n      <li>Ideal when you can’t modify or retrain the base model.</li>\n      <li>Suitable for legacy systems or commercial APIs.</li>\n      <li>Offers “plug-and-play” inference acceleration with minimal integration overhead.</li>\n      <li>Best when a strong, compact draft model is already available.</li>\n    </ul>\n<p><strong>Medusa (Cai et al., 2024)</strong>:</p>\n<ul>\n      <li>Ideal for single-user interactive settings (e.g., chatbots).</li>\n      <li>Offers fine-grained control via Medusa-1 (frozen backbone) or Medusa-2 (joint fine-tuning).</li>\n      <li>Introduces <strong>tree attention</strong> to optimize speculative token verification.</li>\n      <li>Can outperform others when output diversity or control is key.</li>\n    </ul>\n<p><strong>Multi-token Prediction Heads (Gloeckle et al., 2024)</strong>:</p>\n<ul>\n      <li>Recommended during full model pretraining.</li>\n      <li>Best for institutions training models from scratch or at scale.</li>\n      <li>Enables <strong>self-speculative decoding</strong> with minimal architectural footprint.</li>\n      <li>Very efficient for longer inputs or batch decoding workloads.</li>\n    </ul>",
    "contentMarkdown": "*   **Draft Model (Leviathan-style speculative decoding)**:\n    \n    *   Ideal when you can’t modify or retrain the base model.\n    *   Suitable for legacy systems or commercial APIs.\n    *   Offers “plug-and-play” inference acceleration with minimal integration overhead.\n    *   Best when a strong, compact draft model is already available.\n*   **Medusa (Cai et al., 2024)**:\n    \n    *   Ideal for single-user interactive settings (e.g., chatbots).\n    *   Offers fine-grained control via Medusa-1 (frozen backbone) or Medusa-2 (joint fine-tuning).\n    *   Introduces **tree attention** to optimize speculative token verification.\n    *   Can outperform others when output diversity or control is key.\n*   **Multi-token Prediction Heads (Gloeckle et al., 2024)**:\n    \n    *   Recommended during full model pretraining.\n    *   Best for institutions training models from scratch or at scale.\n    *   Enables **self-speculative decoding** with minimal architectural footprint.\n    *   Very efficient for longer inputs or batch decoding workloads.\n\n**Draft Model (Leviathan-style speculative decoding)**:\n\n*   Ideal when you can’t modify or retrain the base model.\n*   Suitable for legacy systems or commercial APIs.\n*   Offers “plug-and-play” inference acceleration with minimal integration overhead.\n*   Best when a strong, compact draft model is already available.\n\n**Medusa (Cai et al., 2024)**:\n\n*   Ideal for single-user interactive settings (e.g., chatbots).\n*   Offers fine-grained control via Medusa-1 (frozen backbone) or Medusa-2 (joint fine-tuning).\n*   Introduces **tree attention** to optimize speculative token verification.\n*   Can outperform others when output diversity or control is key.\n\n**Multi-token Prediction Heads (Gloeckle et al., 2024)**:\n\n*   Recommended during full model pretraining.\n*   Best for institutions training models from scratch or at scale.\n*   Enables **self-speculative decoding** with minimal architectural footprint.\n*   Very efficient for longer inputs or batch decoding workloads.",
    "order": 5,
    "orderInChapter": 2,
    "difficulty": 2,
    "estimatedMinutes": 2,
    "tags": [
      "algorithmsarchitecture",
      "attention",
      "fine-tuning"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 265,
      "contentLength": 2556
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#when-to-use-each-technique",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-implementation-details-6",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Comparative Analysis",
    "title": "Implementation Details",
    "subtitle": "Comparative Analysis",
    "contentHtml": "<ul>\n  <li>\n    <p><strong>Draft-based Implementation</strong>:</p>\n\n    <ul>\n      <li>Ensure the draft model is <strong>close enough</strong> in distribution to the main model; divergence kills speedup.</li>\n      <li>Batch speculative runs and base model verifications.</li>\n      <li>Use caching (KV cache reuse) to reduce redundant computations.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Multi-token Heads Implementation</strong>:</p>\n\n    <ul>\n      <li>Train with n-token loss: each head predicts future token i.</li>\n      <li>Use gradient checkpointing or staggered backprop to control memory.</li>\n      <li>At inference, use blockwise or greedy speculative decoding.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Medusa Implementation</strong>:</p>\n\n    <ul>\n      <li>\n        <p>Add feedforward speculative heads:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-26-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>p</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mi>k</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi></mrow></msub></mrow></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>@</mo></mrow><mo stretchy=&quot;false&quot;>(</mo><mtext>SiLU</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>1</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>@</mo></mrow><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-251\" style=\"width: 20.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1017.24em, 2.607em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-252\"><span class=\"msubsup\" id=\"MathJax-Span-253\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-255\"><span class=\"mrow\" id=\"MathJax-Span-256\"><span class=\"msubsup\" id=\"MathJax-Span-257\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-258\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.315em;\"><span class=\"texatom\" id=\"MathJax-Span-259\"><span class=\"mrow\" id=\"MathJax-Span-260\"><span class=\"mi\" id=\"MathJax-Span-261\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-262\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-263\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">softmax</span><span class=\"mo\" id=\"MathJax-Span-264\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-265\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-266\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-267\"><span class=\"mrow\" id=\"MathJax-Span-268\"><span class=\"msubsup\" id=\"MathJax-Span-269\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-270\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-271\"><span class=\"mrow\" id=\"MathJax-Span-272\"><span class=\"mi\" id=\"MathJax-Span-273\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"texatom\" id=\"MathJax-Span-274\"><span class=\"mrow\" id=\"MathJax-Span-275\"><span class=\"mo\" id=\"MathJax-Span-276\" style=\"font-family: STIXGeneral-Regular;\">@</span></span></span><span class=\"mo\" id=\"MathJax-Span-277\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-278\" style=\"font-family: STIXGeneral-Regular;\">SiLU</span><span class=\"mo\" id=\"MathJax-Span-279\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-280\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-281\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-282\"><span class=\"mrow\" id=\"MathJax-Span-283\"><span class=\"msubsup\" id=\"MathJax-Span-284\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-285\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-286\"><span class=\"mrow\" id=\"MathJax-Span-287\"><span class=\"mi\" id=\"MathJax-Span-288\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"texatom\" id=\"MathJax-Span-289\"><span class=\"mrow\" id=\"MathJax-Span-290\"><span class=\"mo\" id=\"MathJax-Span-291\" style=\"font-family: STIXGeneral-Regular;\">@</span></span></span><span class=\"msubsup\" id=\"MathJax-Span-292\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-293\" style=\"font-family: STIXGeneral-Italic;\">h</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-294\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-295\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-296\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"msubsup\" id=\"MathJax-Span-297\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-298\" style=\"font-family: STIXGeneral-Italic;\">h</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-299\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-300\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-301\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>p</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mi>k</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>t</mi></mrow></msub></mrow></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>2</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub><mrow class=\"MJX-TeXAtom-ORD\"><mo>@</mo></mrow><mo stretchy=\"false\">(</mo><mtext>SiLU</mtext><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>1</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub><mrow class=\"MJX-TeXAtom-ORD\"><mo>@</mo></mrow><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mo>+</mo><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-26\">p_{k_{t}} = \\text{softmax}(W_{2_{k}} @ (\\text{SiLU}(W_{1_{k}} @ h_t) + h_t))</script>\n      </li>\n      <li>For <strong>tree attention</strong>, modify attention masks to ensure tokens only see ancestors.</li>\n      <li>Use <strong>typical acceptance</strong> scheme to boost accepted token length without complex sampling.</li>\n    </ul>\n  </li>\n</ul>\n<p><strong>Draft-based Implementation</strong>:</p>\n<ul>\n      <li>Ensure the draft model is <strong>close enough</strong> in distribution to the main model; divergence kills speedup.</li>\n      <li>Batch speculative runs and base model verifications.</li>\n      <li>Use caching (KV cache reuse) to reduce redundant computations.</li>\n    </ul>\n<p><strong>Multi-token Heads Implementation</strong>:</p>\n<ul>\n      <li>Train with n-token loss: each head predicts future token i.</li>\n      <li>Use gradient checkpointing or staggered backprop to control memory.</li>\n      <li>At inference, use blockwise or greedy speculative decoding.</li>\n    </ul>\n<p><strong>Medusa Implementation</strong>:</p>\n<ul>\n      <li>\n        <p>Add feedforward speculative heads:</p>\n\n<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><div class=\"MathJax_Display\" style=\"text-align: center;\"><span class=\"MathJax\" id=\"MathJax-Element-26-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>p</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mi>k</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi></mrow></msub></mrow></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>@</mo></mrow><mo stretchy=&quot;false&quot;>(</mo><mtext>SiLU</mtext><mo stretchy=&quot;false&quot;>(</mo><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>1</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>@</mo></mrow><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>)</mo></math>\" role=\"presentation\" style=\"text-align: center; position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-251\" style=\"width: 20.784em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 17.294em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1017.24em, 2.607em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-252\"><span class=\"msubsup\" id=\"MathJax-Span-253\"><span style=\"display: inline-block; position: relative; width: 1.096em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.44em, 1000.47em, 4.378em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-254\" style=\"font-family: STIXGeneral-Italic;\">p</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"texatom\" id=\"MathJax-Span-255\"><span class=\"mrow\" id=\"MathJax-Span-256\"><span class=\"msubsup\" id=\"MathJax-Span-257\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-258\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.315em;\"><span class=\"texatom\" id=\"MathJax-Span-259\"><span class=\"mrow\" id=\"MathJax-Span-260\"><span class=\"mi\" id=\"MathJax-Span-261\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-262\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">=</span><span class=\"mtext\" id=\"MathJax-Span-263\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.315em;\">softmax</span><span class=\"mo\" id=\"MathJax-Span-264\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-265\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-266\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-267\"><span class=\"mrow\" id=\"MathJax-Span-268\"><span class=\"msubsup\" id=\"MathJax-Span-269\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-270\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-271\"><span class=\"mrow\" id=\"MathJax-Span-272\"><span class=\"mi\" id=\"MathJax-Span-273\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"texatom\" id=\"MathJax-Span-274\"><span class=\"mrow\" id=\"MathJax-Span-275\"><span class=\"mo\" id=\"MathJax-Span-276\" style=\"font-family: STIXGeneral-Regular;\">@</span></span></span><span class=\"mo\" id=\"MathJax-Span-277\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"mtext\" id=\"MathJax-Span-278\" style=\"font-family: STIXGeneral-Regular;\">SiLU</span><span class=\"mo\" id=\"MathJax-Span-279\" style=\"font-family: STIXGeneral-Regular;\">(</span><span class=\"msubsup\" id=\"MathJax-Span-280\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-281\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-282\"><span class=\"mrow\" id=\"MathJax-Span-283\"><span class=\"msubsup\" id=\"MathJax-Span-284\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-285\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-286\"><span class=\"mrow\" id=\"MathJax-Span-287\"><span class=\"mi\" id=\"MathJax-Span-288\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"texatom\" id=\"MathJax-Span-289\"><span class=\"mrow\" id=\"MathJax-Span-290\"><span class=\"mo\" id=\"MathJax-Span-291\" style=\"font-family: STIXGeneral-Regular;\">@</span></span></span><span class=\"msubsup\" id=\"MathJax-Span-292\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-293\" style=\"font-family: STIXGeneral-Italic;\">h</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-294\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-295\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-296\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"msubsup\" id=\"MathJax-Span-297\" style=\"padding-left: 0.263em;\"><span style=\"display: inline-block; position: relative; width: 0.784em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.47em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-298\" style=\"font-family: STIXGeneral-Italic;\">h</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.523em;\"><span class=\"mi\" id=\"MathJax-Span-299\" style=\"font-size: 70.7%; font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span><span class=\"mo\" id=\"MathJax-Span-300\" style=\"font-family: STIXGeneral-Regular;\">)</span><span class=\"mo\" id=\"MathJax-Span-301\" style=\"font-family: STIXGeneral-Regular;\">)</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML MJX_Assistive_MathML_Block\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><msub><mi>p</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mi>k</mi><mrow class=\"MJX-TeXAtom-ORD\"><mi>t</mi></mrow></msub></mrow></msub><mo>=</mo><mtext>softmax</mtext><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>2</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub><mrow class=\"MJX-TeXAtom-ORD\"><mo>@</mo></mrow><mo stretchy=\"false\">(</mo><mtext>SiLU</mtext><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>1</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub><mrow class=\"MJX-TeXAtom-ORD\"><mo>@</mo></mrow><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mo>+</mo><msub><mi>h</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></math></span></span></div><script type=\"math/tex; mode=display\" id=\"MathJax-Element-26\">p_{k_{t}} = \\text{softmax}(W_{2_{k}} @ (\\text{SiLU}(W_{1_{k}} @ h_t) + h_t))</script>\n      </li>\n      <li>For <strong>tree attention</strong>, modify attention masks to ensure tokens only see ancestors.</li>\n      <li>Use <strong>typical acceptance</strong> scheme to boost accepted token length without complex sampling.</li>\n    </ul>\n<p>Add feedforward speculative heads:</p>",
    "contentMarkdown": "*   **Draft-based Implementation**:\n    \n    *   Ensure the draft model is **close enough** in distribution to the main model; divergence kills speedup.\n    *   Batch speculative runs and base model verifications.\n    *   Use caching (KV cache reuse) to reduce redundant computations.\n*   **Multi-token Heads Implementation**:\n    \n    *   Train with n-token loss: each head predicts future token i.\n    *   Use gradient checkpointing or staggered backprop to control memory.\n    *   At inference, use blockwise or greedy speculative decoding.\n*   **Medusa Implementation**:\n    \n    *   Add feedforward speculative heads:\n        \n        pkt\\=softmax(W2k@(SiLU(W1k@ht)+ht))pkt\\=softmax(W2k@(SiLU(W1k@ht)+ht))\n        \n        p\\_{k\\_{t}} = \\\\text{softmax}(W\\_{2\\_{k}} @ (\\\\text{SiLU}(W\\_{1\\_{k}} @ h\\_t) + h\\_t))\n    *   For **tree attention**, modify attention masks to ensure tokens only see ancestors.\n    *   Use **typical acceptance** scheme to boost accepted token length without complex sampling.\n\n**Draft-based Implementation**:\n\n*   Ensure the draft model is **close enough** in distribution to the main model; divergence kills speedup.\n*   Batch speculative runs and base model verifications.\n*   Use caching (KV cache reuse) to reduce redundant computations.\n\n**Multi-token Heads Implementation**:\n\n*   Train with n-token loss: each head predicts future token i.\n*   Use gradient checkpointing or staggered backprop to control memory.\n*   At inference, use blockwise or greedy speculative decoding.\n\n**Medusa Implementation**:\n\n*   Add feedforward speculative heads:\n    \n    pkt\\=softmax(W2k@(SiLU(W1k@ht)+ht))pkt\\=softmax(W2k@(SiLU(W1k@ht)+ht))\n    \n    p\\_{k\\_{t}} = \\\\text{softmax}(W\\_{2\\_{k}} @ (\\\\text{SiLU}(W\\_{1\\_{k}} @ h\\_t) + h\\_t))\n*   For **tree attention**, modify attention masks to ensure tokens only see ancestors.\n*   Use **typical acceptance** scheme to boost accepted token length without complex sampling.\n\nAdd feedforward speculative heads:",
    "order": 6,
    "orderInChapter": 3,
    "difficulty": 3,
    "estimatedMinutes": 2,
    "tags": [
      "algorithmsarchitecture",
      "attention"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 233,
      "contentLength": 23822
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#implementation-details",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-empirical-results-snapshot-7",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Comparative Analysis",
    "title": "Empirical Results Snapshot",
    "subtitle": "Comparative Analysis",
    "contentHtml": "<ul>\n  <li>\n    <p>From <a href=\"https://arxiv.org/abs/2404.19737\">Better &amp; Faster Large Language Models via Multi-token Prediction</a> by Gloeckle et al. (2024), using 4-token prediction on a 7B model:</p>\n\n    <ul>\n      <li>3<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-27-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-302\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-303\"><span class=\"mo\" id=\"MathJax-Span-304\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-27\">\\times</script> faster inference.</li>\n      <li>+4% higher pass@1 on HumanEval (code generation).</li>\n      <li>Optimal token prediction window (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-28-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-305\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-306\"><span class=\"mi\" id=\"MathJax-Span-307\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-28\">n</script>) varies: 4 is best for natural language, 8 for byte-level models.</li>\n    </ul>\n  </li>\n  <li>\n    <p>From <a href=\"https://arxiv.org/abs/2401.10774\">Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads</a> by Cai et al. (2024), Medusa on Vicuna-7B:</p>\n\n    <ul>\n      <li>2.3–2.8<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-29-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-308\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-309\"><span class=\"mo\" id=\"MathJax-Span-310\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-29\">\\times</script> speedup.</li>\n      <li>Quality preserved via training schemes (especially Medusa-2).</li>\n      <li>Compatible with quantized backbones (QLoRA).</li>\n    </ul>\n  </li>\n</ul>\n<p>From <a href=\"https://arxiv.org/abs/2404.19737\">Better &amp; Faster Large Language Models via Multi-token Prediction</a> by Gloeckle et al. (2024), using 4-token prediction on a 7B model:</p>\n<ul>\n      <li>3<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-27-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-302\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-303\"><span class=\"mo\" id=\"MathJax-Span-304\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-27\">\\times</script> faster inference.</li>\n      <li>+4% higher pass@1 on HumanEval (code generation).</li>\n      <li>Optimal token prediction window (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-28-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-305\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-306\"><span class=\"mi\" id=\"MathJax-Span-307\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-28\">n</script>) varies: 4 is best for natural language, 8 for byte-level models.</li>\n    </ul>\n<p>From <a href=\"https://arxiv.org/abs/2401.10774\">Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads</a> by Cai et al. (2024), Medusa on Vicuna-7B:</p>\n<ul>\n      <li>2.3–2.8<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-29-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-308\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-309\"><span class=\"mo\" id=\"MathJax-Span-310\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-29\">\\times</script> speedup.</li>\n      <li>Quality preserved via training schemes (especially Medusa-2).</li>\n      <li>Compatible with quantized backbones (QLoRA).</li>\n    </ul>",
    "contentMarkdown": "*   From [Better & Faster Large Language Models via Multi-token Prediction](https://arxiv.org/abs/2404.19737) by Gloeckle et al. (2024), using 4-token prediction on a 7B model:\n    \n    *   3××\\\\times faster inference.\n    *   +4% higher pass@1 on HumanEval (code generation).\n    *   Optimal token prediction window (nnn) varies: 4 is best for natural language, 8 for byte-level models.\n*   From [Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads](https://arxiv.org/abs/2401.10774) by Cai et al. (2024), Medusa on Vicuna-7B:\n    \n    *   2.3–2.8××\\\\times speedup.\n    *   Quality preserved via training schemes (especially Medusa-2).\n    *   Compatible with quantized backbones (QLoRA).\n\nFrom [Better & Faster Large Language Models via Multi-token Prediction](https://arxiv.org/abs/2404.19737) by Gloeckle et al. (2024), using 4-token prediction on a 7B model:\n\n*   3××\\\\times faster inference.\n*   +4% higher pass@1 on HumanEval (code generation).\n*   Optimal token prediction window (nnn) varies: 4 is best for natural language, 8 for byte-level models.\n\nFrom [Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads](https://arxiv.org/abs/2401.10774) by Cai et al. (2024), Medusa on Vicuna-7B:\n\n*   2.3–2.8××\\\\times speedup.\n*   Quality preserved via training schemes (especially Medusa-2).\n*   Compatible with quantized backbones (QLoRA).",
    "order": 7,
    "orderInChapter": 4,
    "difficulty": 3,
    "estimatedMinutes": 1,
    "tags": [
      "algorithmsarchitecture",
      "llm"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 176,
      "contentLength": 8784
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#empirical-results-snapshot",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-key-takeaways-8",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Comparative Analysis",
    "title": "Key Takeaways",
    "subtitle": "Comparative Analysis",
    "contentHtml": "<ul>\n  <li><strong>Speed vs Simplicity</strong>: Draft-based methods are simpler but less efficient long-term. Integrated heads unlock better scaling.</li>\n  <li><strong>Training Budget Matters</strong>: If you’re training from scratch, invest in multi-token or Medusa heads.</li>\n  <li><strong>Serving Constraints</strong>: For distributed serving or edge deployment, Medusa-1 or next-token heads provide clean integration.</li>\n</ul>",
    "contentMarkdown": "*   **Speed vs Simplicity**: Draft-based methods are simpler but less efficient long-term. Integrated heads unlock better scaling.\n*   **Training Budget Matters**: If you’re training from scratch, invest in multi-token or Medusa heads.\n*   **Serving Constraints**: For distributed serving or edge deployment, Medusa-1 or next-token heads provide clean integration.",
    "order": 8,
    "orderInChapter": 5,
    "difficulty": 2,
    "estimatedMinutes": 1,
    "tags": [
      "algorithmsarchitecture"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 48,
      "contentLength": 435
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#key-takeaways",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-draft-model-based-speculative-decoding-9",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Implementation Deep Dive: How to Build Speculative Decoders",
    "title": "Draft Model-Based Speculative Decoding",
    "subtitle": "Implementation Deep Dive: How to Build Speculative Decoders",
    "contentHtml": "<ul>\n  <li>\n    <p>This method involves using two models:</p>\n\n    <ul>\n      <li><strong>Target model</strong>: The large, accurate LLM whose output must be preserved.</li>\n      <li><strong>Draft model</strong>: A smaller model trained to approximate the target model’s predictions.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Architecture Overview</strong>:</p>\n\n    <ul>\n      <li>The following figure from the paper shows the workflow of draft model-based speculative decoding: proposal, parallel verification, selective acceptance. In the case of unconditional language modeling, each line represents one iteration of the algorithm. The green tokens are the suggestions made by the approximation model (here, a GPT-like Transformer decoder with 6M parameters trained on lm1b with 8k tokens) that the target model (here, a GPT-like Transformer decoder with 97M parameters in the same setting) accepted, while the red and blue tokens are the rejected suggestions and their corrections, respectively. For example, in the first line the target model was run only once, and 5 tokens were generated.</li>\n    </ul>\n\n    <p><img src=\"../../../images/papers/SD.jpg\" alt=\"\"></p>\n  </li>\n  <li>\n    <p>Each decoding step proceeds as follows:</p>\n\n    <ol>\n      <li>Generate a speculative prefix of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-311\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-312\"><span class=\"mi\" id=\"MathJax-Span-313\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-30\">\\gamma</script> tokens using the draft model (e.g., <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-314\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-315\"><span class=\"mi\" id=\"MathJax-Span-316\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-31\">\\gamma</script> = 4).</li>\n      <li>Run the target model in parallel to verify each token.</li>\n      <li>Accept matching tokens; reject mismatches and resume standard decoding from there.</li>\n    </ol>\n  </li>\n  <li>\n    <p><strong>Key Implementation Elements</strong>:</p>\n\n    <ul>\n      <li>\n        <p><strong>Speculative Sampling</strong>:\nUses rejection sampling to ensure distributional equivalence:</p>\n\n        <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code1\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code1\"><span class=\"k\">def</span> <span class=\"nf\">accept_token</span><span class=\"p\">(</span><span class=\"n\">p_large</span><span class=\"p\">,</span> <span class=\"n\">p_draft</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"n\">p_draft</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]</span> <span class=\"o\">&lt;=</span> <span class=\"n\">p_large</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">True</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">accept_prob</span> <span class=\"o\">=</span> <span class=\"n\">p_large</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]</span> <span class=\"o\">/</span> <span class=\"n\">p_draft</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">()</span> <span class=\"o\">&lt;</span> <span class=\"n\">accept_prob</span>\n</code></pre></div>        </div>\n      </li>\n      <li>\n        <p><strong>Parallel Verification</strong>:\nRun <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-317\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-318\"><span class=\"mi\" id=\"MathJax-Span-319\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">\\gamma</script> + 1 parallel forward passes of the target model:</p>\n\n        <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code2\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code2\"><span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n    <span class=\"n\">logits</span> <span class=\"o\">=</span> <span class=\"n\">target_model</span><span class=\"p\">(</span><span class=\"n\">prefix</span> <span class=\"o\">+</span> <span class=\"n\">draft_tokens</span><span class=\"p\">)</span>\n    <span class=\"n\">verified_probs</span> <span class=\"o\">=</span> <span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">)</span>\n</code></pre></div>        </div>\n      </li>\n      <li>\n        <p><strong>Fallback Correction</strong>:\nIf a token is rejected, sample again from an adjusted distribution:</p>\n\n        <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code3\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code3\"><span class=\"n\">residual</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">clamp</span><span class=\"p\">(</span><span class=\"n\">p_large</span> <span class=\"o\">-</span> <span class=\"n\">p_draft</span><span class=\"p\">,</span> <span class=\"nb\">min</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">residual</span> <span class=\"o\">/=</span> <span class=\"n\">residual</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">()</span>\n<span class=\"n\">next_token</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">multinomial</span><span class=\"p\">(</span><span class=\"n\">residual</span><span class=\"p\">,</span> <span class=\"n\">num_samples</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</code></pre></div>        </div>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Optimization Tip</strong>: Cache activations across reused prefixes to avoid redundant computation.</p>\n  </li>\n</ul>\n<p>This method involves using two models:</p>\n<ul>\n      <li><strong>Target model</strong>: The large, accurate LLM whose output must be preserved.</li>\n      <li><strong>Draft model</strong>: A smaller model trained to approximate the target model’s predictions.</li>\n    </ul>\n<p><strong>Architecture Overview</strong>:</p>\n<ul>\n      <li>The following figure from the paper shows the workflow of draft model-based speculative decoding: proposal, parallel verification, selective acceptance. In the case of unconditional language modeling, each line represents one iteration of the algorithm. The green tokens are the suggestions made by the approximation model (here, a GPT-like Transformer decoder with 6M parameters trained on lm1b with 8k tokens) that the target model (here, a GPT-like Transformer decoder with 97M parameters in the same setting) accepted, while the red and blue tokens are the rejected suggestions and their corrections, respectively. For example, in the first line the target model was run only once, and 5 tokens were generated.</li>\n    </ul>\n<p><img src=\"../../../images/papers/SD.jpg\" alt=\"\"></p>\n<p>Each decoding step proceeds as follows:</p>\n<ol>\n      <li>Generate a speculative prefix of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-311\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-312\"><span class=\"mi\" id=\"MathJax-Span-313\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-30\">\\gamma</script> tokens using the draft model (e.g., <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-314\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-315\"><span class=\"mi\" id=\"MathJax-Span-316\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-31\">\\gamma</script> = 4).</li>\n      <li>Run the target model in parallel to verify each token.</li>\n      <li>Accept matching tokens; reject mismatches and resume standard decoding from there.</li>\n    </ol>\n<p><strong>Key Implementation Elements</strong>:</p>\n<ul>\n      <li>\n        <p><strong>Speculative Sampling</strong>:\nUses rejection sampling to ensure distributional equivalence:</p>\n\n        <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code1\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code1\"><span class=\"k\">def</span> <span class=\"nf\">accept_token</span><span class=\"p\">(</span><span class=\"n\">p_large</span><span class=\"p\">,</span> <span class=\"n\">p_draft</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"n\">p_draft</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]</span> <span class=\"o\">&lt;=</span> <span class=\"n\">p_large</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">True</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">accept_prob</span> <span class=\"o\">=</span> <span class=\"n\">p_large</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]</span> <span class=\"o\">/</span> <span class=\"n\">p_draft</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">()</span> <span class=\"o\">&lt;</span> <span class=\"n\">accept_prob</span>\n</code></pre></div>        </div>\n      </li>\n      <li>\n        <p><strong>Parallel Verification</strong>:\nRun <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-317\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-318\"><span class=\"mi\" id=\"MathJax-Span-319\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">\\gamma</script> + 1 parallel forward passes of the target model:</p>\n\n        <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code2\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code2\"><span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n    <span class=\"n\">logits</span> <span class=\"o\">=</span> <span class=\"n\">target_model</span><span class=\"p\">(</span><span class=\"n\">prefix</span> <span class=\"o\">+</span> <span class=\"n\">draft_tokens</span><span class=\"p\">)</span>\n    <span class=\"n\">verified_probs</span> <span class=\"o\">=</span> <span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">)</span>\n</code></pre></div>        </div>\n      </li>\n      <li>\n        <p><strong>Fallback Correction</strong>:\nIf a token is rejected, sample again from an adjusted distribution:</p>\n\n        <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code3\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code3\"><span class=\"n\">residual</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">clamp</span><span class=\"p\">(</span><span class=\"n\">p_large</span> <span class=\"o\">-</span> <span class=\"n\">p_draft</span><span class=\"p\">,</span> <span class=\"nb\">min</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">residual</span> <span class=\"o\">/=</span> <span class=\"n\">residual</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">()</span>\n<span class=\"n\">next_token</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">multinomial</span><span class=\"p\">(</span><span class=\"n\">residual</span><span class=\"p\">,</span> <span class=\"n\">num_samples</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</code></pre></div>        </div>\n      </li>\n    </ul>\n<p><strong>Speculative Sampling</strong>:\nUses rejection sampling to ensure distributional equivalence:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code1\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code1\"><span class=\"k\">def</span> <span class=\"nf\">accept_token</span><span class=\"p\">(</span><span class=\"n\">p_large</span><span class=\"p\">,</span> <span class=\"n\">p_draft</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n    <span class=\"k\">if</span> <span class=\"n\">p_draft</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]</span> <span class=\"o\">&lt;=</span> <span class=\"n\">p_large</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]:</span>\n        <span class=\"k\">return</span> <span class=\"bp\">True</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">accept_prob</span> <span class=\"o\">=</span> <span class=\"n\">p_large</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]</span> <span class=\"o\">/</span> <span class=\"n\">p_draft</span><span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">]</span>\n        <span class=\"k\">return</span> <span class=\"n\">random</span><span class=\"p\">.</span><span class=\"n\">random</span><span class=\"p\">()</span> <span class=\"o\">&lt;</span> <span class=\"n\">accept_prob</span>\n</code></pre>\n<p><strong>Parallel Verification</strong>:\nRun <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-317\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-318\"><span class=\"mi\" id=\"MathJax-Span-319\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-32\">\\gamma</script> + 1 parallel forward passes of the target model:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code2\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code2\"><span class=\"k\">with</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">no_grad</span><span class=\"p\">():</span>\n    <span class=\"n\">logits</span> <span class=\"o\">=</span> <span class=\"n\">target_model</span><span class=\"p\">(</span><span class=\"n\">prefix</span> <span class=\"o\">+</span> <span class=\"n\">draft_tokens</span><span class=\"p\">)</span>\n    <span class=\"n\">verified_probs</span> <span class=\"o\">=</span> <span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">)</span>\n</code></pre>\n<p><strong>Fallback Correction</strong>:\nIf a token is rejected, sample again from an adjusted distribution:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code3\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code3\"><span class=\"n\">residual</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">clamp</span><span class=\"p\">(</span><span class=\"n\">p_large</span> <span class=\"o\">-</span> <span class=\"n\">p_draft</span><span class=\"p\">,</span> <span class=\"nb\">min</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n<span class=\"n\">residual</span> <span class=\"o\">/=</span> <span class=\"n\">residual</span><span class=\"p\">.</span><span class=\"nb\">sum</span><span class=\"p\">()</span>\n<span class=\"n\">next_token</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">multinomial</span><span class=\"p\">(</span><span class=\"n\">residual</span><span class=\"p\">,</span> <span class=\"n\">num_samples</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</code></pre>\n<p><strong>Optimization Tip</strong>: Cache activations across reused prefixes to avoid redundant computation.</p>",
    "contentMarkdown": "*   This method involves using two models:\n    \n    *   **Target model**: The large, accurate LLM whose output must be preserved.\n    *   **Draft model**: A smaller model trained to approximate the target model’s predictions.\n*   **Architecture Overview**:\n    \n    *   The following figure from the paper shows the workflow of draft model-based speculative decoding: proposal, parallel verification, selective acceptance. In the case of unconditional language modeling, each line represents one iteration of the algorithm. The green tokens are the suggestions made by the approximation model (here, a GPT-like Transformer decoder with 6M parameters trained on lm1b with 8k tokens) that the target model (here, a GPT-like Transformer decoder with 97M parameters in the same setting) accepted, while the red and blue tokens are the rejected suggestions and their corrections, respectively. For example, in the first line the target model was run only once, and 5 tokens were generated.\n    \n    ![](../../../images/papers/SD.jpg)\n    \n*   Each decoding step proceeds as follows:\n    \n    1.  Generate a speculative prefix of γγ\\\\gamma tokens using the draft model (e.g., γγ\\\\gamma = 4).\n    2.  Run the target model in parallel to verify each token.\n    3.  Accept matching tokens; reject mismatches and resume standard decoding from there.\n*   **Key Implementation Elements**:\n    \n    *   **Speculative Sampling**: Uses rejection sampling to ensure distributional equivalence:\n        \n        ![](https://aman.ai/images/copy.png)\n        \n        `def accept_token(p_large, p_draft, x):     if p_draft[x] <= p_large[x]:         return True     else:         accept_prob = p_large[x] / p_draft[x]         return random.random() < accept_prob`\n        \n    *   **Parallel Verification**: Run γγ\\\\gamma + 1 parallel forward passes of the target model:\n        \n        ![](https://aman.ai/images/copy.png)\n        \n        `with torch.no_grad():     logits = target_model(prefix + draft_tokens)     verified_probs = softmax(logits)`\n        \n    *   **Fallback Correction**: If a token is rejected, sample again from an adjusted distribution:\n        \n        ![](https://aman.ai/images/copy.png)\n        \n        `residual = torch.clamp(p_large - p_draft, min=0) residual /= residual.sum() next_token = torch.multinomial(residual, num_samples=1)`\n        \n*   **Optimization Tip**: Cache activations across reused prefixes to avoid redundant computation.\n    \n\nThis method involves using two models:\n\n*   **Target model**: The large, accurate LLM whose output must be preserved.\n*   **Draft model**: A smaller model trained to approximate the target model’s predictions.\n\n**Architecture Overview**:\n\n*   The following figure from the paper shows the workflow of draft model-based speculative decoding: proposal, parallel verification, selective acceptance. In the case of unconditional language modeling, each line represents one iteration of the algorithm. The green tokens are the suggestions made by the approximation model (here, a GPT-like Transformer decoder with 6M parameters trained on lm1b with 8k tokens) that the target model (here, a GPT-like Transformer decoder with 97M parameters in the same setting) accepted, while the red and blue tokens are the rejected suggestions and their corrections, respectively. For example, in the first line the target model was run only once, and 5 tokens were generated.\n\n![](../../../images/papers/SD.jpg)\n\nEach decoding step proceeds as follows:\n\n1.  Generate a speculative prefix of γγ\\\\gamma tokens using the draft model (e.g., γγ\\\\gamma = 4).\n2.  Run the target model in parallel to verify each token.\n3.  Accept matching tokens; reject mismatches and resume standard decoding from there.\n\n**Key Implementation Elements**:\n\n*   **Speculative Sampling**: Uses rejection sampling to ensure distributional equivalence:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n    `def accept_token(p_large, p_draft, x):     if p_draft[x] <= p_large[x]:         return True     else:         accept_prob = p_large[x] / p_draft[x]         return random.random() < accept_prob`\n    \n*   **Parallel Verification**: Run γγ\\\\gamma + 1 parallel forward passes of the target model:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n    `with torch.no_grad():     logits = target_model(prefix + draft_tokens)     verified_probs = softmax(logits)`\n    \n*   **Fallback Correction**: If a token is rejected, sample again from an adjusted distribution:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n    `residual = torch.clamp(p_large - p_draft, min=0) residual /= residual.sum() next_token = torch.multinomial(residual, num_samples=1)`\n    \n\n**Speculative Sampling**: Uses rejection sampling to ensure distributional equivalence:\n\n![](https://aman.ai/images/copy.png)\n\n`def accept_token(p_large, p_draft, x):     if p_draft[x] <= p_large[x]:         return True     else:         accept_prob = p_large[x] / p_draft[x]         return random.random() < accept_prob`\n\n**Parallel Verification**: Run γγ\\\\gamma + 1 parallel forward passes of the target model:\n\n![](https://aman.ai/images/copy.png)\n\n`with torch.no_grad():     logits = target_model(prefix + draft_tokens)     verified_probs = softmax(logits)`\n\n**Fallback Correction**: If a token is rejected, sample again from an adjusted distribution:\n\n![](https://aman.ai/images/copy.png)\n\n`residual = torch.clamp(p_large - p_draft, min=0) residual /= residual.sum() next_token = torch.multinomial(residual, num_samples=1)`\n\n**Optimization Tip**: Cache activations across reused prefixes to avoid redundant computation.",
    "order": 9,
    "orderInChapter": 1,
    "difficulty": 4,
    "estimatedMinutes": 4,
    "tags": [
      "algorithmsarchitecture",
      "transformer",
      "gpt",
      "llm",
      "optimization",
      "activation"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": true,
      "hasImages": true,
      "wordCount": 658,
      "contentLength": 24408
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#draft-model-based-speculative-decoding",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-medusa-tree-attention-parallel-heads-10",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Implementation Deep Dive: How to Build Speculative Decoders",
    "title": "Medusa: Tree Attention + Parallel Heads",
    "subtitle": "Implementation Deep Dive: How to Build Speculative Decoders",
    "contentHtml": "<ul>\n  <li>\n    <p>Medusa extends multi-token decoding with a novel attention mechanism that verifies multiple speculative paths simultaneously.</p>\n  </li>\n  <li>\n    <p><strong>Architecture Overview</strong>:</p>\n\n    <ul>\n      <li>The following figure from the paper shows the proposed tree attention in Medusa: parallel candidates from multiple heads form branches that are verified simultaneously.</li>\n    </ul>\n\n    <p><img src=\"/primers/ai/assets/speculative-decoding/Medusa_treeattn.jpg\" alt=\"\"></p>\n\n    <ul>\n      <li>Multiple lightweight Medusa heads project from the last hidden state.</li>\n      <li>Each head proposes tokens at future positions (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>+</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-320\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.77em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-321\"><span class=\"mi\" id=\"MathJax-Span-322\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-323\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-324\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>+</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">t+1</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>+</mo><mn>2</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-325\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.88em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-326\"><span class=\"mi\" id=\"MathJax-Span-327\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-328\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-329\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">2</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>+</mo><mn>2</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">t+2</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-35-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x2026;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-330\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.93em, 1000.89em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-331\"><span class=\"mo\" id=\"MathJax-Span-332\" style=\"font-family: STIXGeneral-Regular;\">…</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>…</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-35\">\\dots</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>+</mo><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-333\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.14em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-334\"><span class=\"mi\" id=\"MathJax-Span-335\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-336\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-337\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>+</mo><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-36\">t+K</script>).</li>\n      <li>Tree-structured attention masks control information flow to ensure correctness.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Medusa Head Definition</strong>:</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code4\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code4\">  <span class=\"k\">def</span> <span class=\"nf\">medusa_head</span><span class=\"p\">(</span><span class=\"n\">h_t</span><span class=\"p\">,</span> <span class=\"n\">W1_k</span><span class=\"p\">,</span> <span class=\"n\">W2_k</span><span class=\"p\">):</span>\n      <span class=\"n\">ff_out</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">silu</span><span class=\"p\">(</span><span class=\"n\">W1_k</span> <span class=\"o\">@</span> <span class=\"n\">h_t</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">h_t</span>\n      <span class=\"k\">return</span> <span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">W2_k</span> <span class=\"o\">@</span> <span class=\"n\">ff_out</span><span class=\"p\">)</span>\n</code></pre></div>    </div>\n  </li>\n  <li>\n    <ul>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-37-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>1</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-338\" style=\"width: 1.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.57em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-339\"><span class=\"msubsup\" id=\"MathJax-Span-340\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-341\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-342\"><span class=\"mrow\" id=\"MathJax-Span-343\"><span class=\"msubsup\" id=\"MathJax-Span-344\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-345\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-346\"><span class=\"mrow\" id=\"MathJax-Span-347\"><span class=\"mi\" id=\"MathJax-Span-348\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>1</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-37\">W_{1_{k}}</script> is initialized as zero, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-349\" style=\"width: 1.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.57em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-350\"><span class=\"msubsup\" id=\"MathJax-Span-351\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-352\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-353\"><span class=\"mrow\" id=\"MathJax-Span-354\"><span class=\"msubsup\" id=\"MathJax-Span-355\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-356\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-357\"><span class=\"mrow\" id=\"MathJax-Span-358\"><span class=\"mi\" id=\"MathJax-Span-359\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>2</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-38\">W_{2_{k}}</script> cloned from LM head.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Tree Attention Implementation</strong>:</p>\n\n    <ul>\n      <li>Construct Cartesian product of top-k predictions from each head.</li>\n      <li>Use attention mask that only allows intra-branch communication.</li>\n      <li>Modify positional encodings for tree-based candidate verification.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Candidate Verification</strong>:</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code5\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code5\">  <span class=\"c1\"># Assume 2 heads with top-2 and top-3 predictions\n</span>  <span class=\"c1\"># Generate 6 branches, verify each in parallel\n</span>  <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">build_tree_attention_mask</span><span class=\"p\">(</span><span class=\"n\">branch_structure</span><span class=\"p\">)</span>\n  <span class=\"n\">attention_output</span> <span class=\"o\">=</span> <span class=\"n\">transformer_with_mask</span><span class=\"p\">(</span><span class=\"n\">input_ids</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"p\">)</span>\n</code></pre></div>    </div>\n  </li>\n  <li>\n    <p><strong>Acceptance Strategy</strong>:</p>\n\n    <ul>\n      <li><strong>Rejection sampling</strong> ensures fidelity.</li>\n      <li><strong>Typical acceptance</strong> (heuristic cutoff on deviation from target) boosts speed.</li>\n    </ul>\n  </li>\n</ul>\n<p>Medusa extends multi-token decoding with a novel attention mechanism that verifies multiple speculative paths simultaneously.</p>\n<p><strong>Architecture Overview</strong>:</p>\n<ul>\n      <li>The following figure from the paper shows the proposed tree attention in Medusa: parallel candidates from multiple heads form branches that are verified simultaneously.</li>\n    </ul>\n<p><img src=\"/primers/ai/assets/speculative-decoding/Medusa_treeattn.jpg\" alt=\"\"></p>\n<ul>\n      <li>Multiple lightweight Medusa heads project from the last hidden state.</li>\n      <li>Each head proposes tokens at future positions (<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>+</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-320\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.77em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-321\"><span class=\"mi\" id=\"MathJax-Span-322\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-323\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-324\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>+</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-33\">t+1</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>+</mo><mn>2</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-325\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.88em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-326\"><span class=\"mi\" id=\"MathJax-Span-327\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-328\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-329\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">2</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>+</mo><mn>2</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-34\">t+2</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-35-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x2026;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-330\" style=\"width: 1.201em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.992em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.93em, 1000.89em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-331\"><span class=\"mo\" id=\"MathJax-Span-332\" style=\"font-family: STIXGeneral-Regular;\">…</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>…</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-35\">\\dots</script>, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>+</mo><mi>K</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-333\" style=\"width: 2.607em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 2.138em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1002.14em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-334\"><span class=\"mi\" id=\"MathJax-Span-335\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-336\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-337\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">K<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>+</mo><mi>K</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-36\">t+K</script>).</li>\n      <li>Tree-structured attention masks control information flow to ensure correctness.</li>\n    </ul>\n<p><strong>Medusa Head Definition</strong>:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code4\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code4\">  <span class=\"k\">def</span> <span class=\"nf\">medusa_head</span><span class=\"p\">(</span><span class=\"n\">h_t</span><span class=\"p\">,</span> <span class=\"n\">W1_k</span><span class=\"p\">,</span> <span class=\"n\">W2_k</span><span class=\"p\">):</span>\n      <span class=\"n\">ff_out</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">silu</span><span class=\"p\">(</span><span class=\"n\">W1_k</span> <span class=\"o\">@</span> <span class=\"n\">h_t</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"n\">h_t</span>\n      <span class=\"k\">return</span> <span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">W2_k</span> <span class=\"o\">@</span> <span class=\"n\">ff_out</span><span class=\"p\">)</span>\n</code></pre>\n<ul>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-37-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>1</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-338\" style=\"width: 1.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.57em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-339\"><span class=\"msubsup\" id=\"MathJax-Span-340\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-341\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-342\"><span class=\"mrow\" id=\"MathJax-Span-343\"><span class=\"msubsup\" id=\"MathJax-Span-344\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.26em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-345\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">1</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-346\"><span class=\"mrow\" id=\"MathJax-Span-347\"><span class=\"mi\" id=\"MathJax-Span-348\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>1</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-37\">W_{1_{k}}</script> is initialized as zero, <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>W</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><msub><mn>2</mn><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>k</mi></mrow></msub></mrow></msub></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-349\" style=\"width: 1.878em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.305em, 1001.57em, 2.555em, -999.997em); top: -2.133em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-350\"><span class=\"msubsup\" id=\"MathJax-Span-351\"><span style=\"display: inline-block; position: relative; width: 1.565em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.18em, 1000.89em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mi\" id=\"MathJax-Span-352\" style=\"font-family: STIXGeneral-Italic;\">W<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.852em; left: 0.836em;\"><span class=\"texatom\" id=\"MathJax-Span-353\"><span class=\"mrow\" id=\"MathJax-Span-354\"><span class=\"msubsup\" id=\"MathJax-Span-355\"><span style=\"display: inline-block; position: relative; width: 0.628em; height: 0px;\"><span style=\"position: absolute; clip: rect(3.388em, 1000.32em, 4.169em, -999.997em); top: -4.008em; left: 0em;\"><span class=\"mn\" id=\"MathJax-Span-356\" style=\"font-size: 70.7%; font-family: STIXGeneral-Regular;\">2</span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span><span style=\"position: absolute; top: -3.904em; left: 0.367em;\"><span class=\"texatom\" id=\"MathJax-Span-357\"><span class=\"mrow\" id=\"MathJax-Span-358\"><span class=\"mi\" id=\"MathJax-Span-359\" style=\"font-size: 50%; font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 4.013em;\"></span></span></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.138em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.372em; border-left: 0px solid; width: 0px; height: 1.253em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msub><mi>W</mi><mrow class=\"MJX-TeXAtom-ORD\"><msub><mn>2</mn><mrow class=\"MJX-TeXAtom-ORD\"><mi>k</mi></mrow></msub></mrow></msub></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-38\">W_{2_{k}}</script> cloned from LM head.</li>\n    </ul>\n<p><strong>Tree Attention Implementation</strong>:</p>\n<ul>\n      <li>Construct Cartesian product of top-k predictions from each head.</li>\n      <li>Use attention mask that only allows intra-branch communication.</li>\n      <li>Modify positional encodings for tree-based candidate verification.</li>\n    </ul>\n<p><strong>Candidate Verification</strong>:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code5\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code5\">  <span class=\"c1\"># Assume 2 heads with top-2 and top-3 predictions\n</span>  <span class=\"c1\"># Generate 6 branches, verify each in parallel\n</span>  <span class=\"n\">mask</span> <span class=\"o\">=</span> <span class=\"n\">build_tree_attention_mask</span><span class=\"p\">(</span><span class=\"n\">branch_structure</span><span class=\"p\">)</span>\n  <span class=\"n\">attention_output</span> <span class=\"o\">=</span> <span class=\"n\">transformer_with_mask</span><span class=\"p\">(</span><span class=\"n\">input_ids</span><span class=\"p\">,</span> <span class=\"n\">mask</span><span class=\"p\">)</span>\n</code></pre>\n<p><strong>Acceptance Strategy</strong>:</p>\n<ul>\n      <li><strong>Rejection sampling</strong> ensures fidelity.</li>\n      <li><strong>Typical acceptance</strong> (heuristic cutoff on deviation from target) boosts speed.</li>\n    </ul>",
    "contentMarkdown": "*   Medusa extends multi-token decoding with a novel attention mechanism that verifies multiple speculative paths simultaneously.\n    \n*   **Architecture Overview**:\n    \n    *   The following figure from the paper shows the proposed tree attention in Medusa: parallel candidates from multiple heads form branches that are verified simultaneously.\n    \n    ![](/primers/ai/assets/speculative-decoding/Medusa_treeattn.jpg)\n    \n    *   Multiple lightweight Medusa heads project from the last hidden state.\n    *   Each head proposes tokens at future positions (t+1t+1t+1, t+2t+2t+2, ……\\\\dots, t+Kt+Kt+K).\n    *   Tree-structured attention masks control information flow to ensure correctness.\n*   **Medusa Head Definition**:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n      `def medusa_head(h_t, W1_k, W2_k):       ff_out = F.silu(W1_k @ h_t) + h_t       return softmax(W2_k @ ff_out)`\n    \n*   *   W1kW1kW\\_{1\\_{k}} is initialized as zero, W2kW2kW\\_{2\\_{k}} cloned from LM head.\n*   **Tree Attention Implementation**:\n    \n    *   Construct Cartesian product of top-k predictions from each head.\n    *   Use attention mask that only allows intra-branch communication.\n    *   Modify positional encodings for tree-based candidate verification.\n*   **Candidate Verification**:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n      `# Assume 2 heads with top-2 and top-3 predictions   # Generate 6 branches, verify each in parallel   mask = build_tree_attention_mask(branch_structure)   attention_output = transformer_with_mask(input_ids, mask)`\n    \n*   **Acceptance Strategy**:\n    \n    *   **Rejection sampling** ensures fidelity.\n    *   **Typical acceptance** (heuristic cutoff on deviation from target) boosts speed.\n\nMedusa extends multi-token decoding with a novel attention mechanism that verifies multiple speculative paths simultaneously.\n\n**Architecture Overview**:\n\n*   The following figure from the paper shows the proposed tree attention in Medusa: parallel candidates from multiple heads form branches that are verified simultaneously.\n\n![](/primers/ai/assets/speculative-decoding/Medusa_treeattn.jpg)\n\n*   Multiple lightweight Medusa heads project from the last hidden state.\n*   Each head proposes tokens at future positions (t+1t+1t+1, t+2t+2t+2, ……\\\\dots, t+Kt+Kt+K).\n*   Tree-structured attention masks control information flow to ensure correctness.\n\n**Medusa Head Definition**:\n\n![](https://aman.ai/images/copy.png)\n\n  `def medusa_head(h_t, W1_k, W2_k):       ff_out = F.silu(W1_k @ h_t) + h_t       return softmax(W2_k @ ff_out)`\n\n*   W1kW1kW\\_{1\\_{k}} is initialized as zero, W2kW2kW\\_{2\\_{k}} cloned from LM head.\n\n**Tree Attention Implementation**:\n\n*   Construct Cartesian product of top-k predictions from each head.\n*   Use attention mask that only allows intra-branch communication.\n*   Modify positional encodings for tree-based candidate verification.\n\n**Candidate Verification**:\n\n![](https://aman.ai/images/copy.png)\n\n  `# Assume 2 heads with top-2 and top-3 predictions   # Generate 6 branches, verify each in parallel   mask = build_tree_attention_mask(branch_structure)   attention_output = transformer_with_mask(input_ids, mask)`\n\n**Acceptance Strategy**:\n\n*   **Rejection sampling** ensures fidelity.\n*   **Typical acceptance** (heuristic cutoff on deviation from target) boosts speed.",
    "order": 10,
    "orderInChapter": 2,
    "difficulty": 4,
    "estimatedMinutes": 2,
    "tags": [
      "algorithmsarchitecture",
      "transformer",
      "attention"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": true,
      "hasImages": true,
      "wordCount": 369,
      "contentLength": 30870
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#medusa:-tree-attention-+-parallel-heads",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-multi-token-prediction-heads-11",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Implementation Deep Dive: How to Build Speculative Decoders",
    "title": "Multi-Token Prediction Heads",
    "subtitle": "Implementation Deep Dive: How to Build Speculative Decoders",
    "contentHtml": "<ul>\n  <li>\n    <p>This approach modifies the LLM architecture to predict <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-360\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-361\"><span class=\"mi\" id=\"MathJax-Span-362\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">n</script> future tokens at once during training.</p>\n  </li>\n  <li>\n    <p><strong>Architecture Overview</strong>:</p>\n\n    <ul>\n      <li>The following figure from the paper shows the implementation structure of multi-token prediction: one trunk, multiple future-predicting heads, and staged loss computation.</li>\n    </ul>\n\n    <p><img src=\"../../../images/papers/MTP.jpg\" alt=\"\"></p>\n\n    <ul>\n      <li>A shared transformer trunk generates a hidden state.</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-40-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-363\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-364\"><span class=\"mi\" id=\"MathJax-Span-365\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-40\">n</script> lightweight output heads decode tokens <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-41-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>+</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-366\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.77em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-367\"><span class=\"mi\" id=\"MathJax-Span-368\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-369\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-370\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>+</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-41\">t+1</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-42-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>+</mo><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-371\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.461em, 1001.88em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-372\"><span class=\"mi\" id=\"MathJax-Span-373\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-374\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-375\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>+</mo><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-42\">t+n</script>.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Model Structure</strong>:</p>\n\n    <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code6\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code6\">  <span class=\"c1\"># Trunk\n</span>  <span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">transformer_trunk</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n  <span class=\"c1\"># Heads\n</span>  <span class=\"n\">logits</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">head_i</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"p\">)]</span>\n  <span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">logit</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">logit</span> <span class=\"ow\">in</span> <span class=\"n\">logits</span><span class=\"p\">]</span>\n</code></pre></div>    </div>\n\n    <ul>\n      <li>\n        <p>Each head minimizes its own cross-entropy loss:</p>\n\n        <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code7\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code7\">  <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"nb\">sum</span><span class=\"p\">([</span><span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">target</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"p\">)])</span>\n</code></pre></div>        </div>\n      </li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Memory-Efficient Training</strong>:</p>\n\n    <ul>\n      <li>\n        <p><strong>Sequential gradient computation</strong> for each head reduces memory:</p>\n\n        <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code8\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code8\"><span class=\"k\">for</span> <span class=\"n\">head</span> <span class=\"ow\">in</span> <span class=\"n\">heads</span><span class=\"p\">:</span>\n    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">head</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span><span class=\"p\">.</span><span class=\"n\">backward</span><span class=\"p\">(</span><span class=\"n\">retain_graph</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n</code></pre></div>        </div>\n      </li>\n    </ul>\n\n    <p><strong>Inference Options</strong>:</p>\n\n    <ul>\n      <li>Use the next-token head for traditional generation.</li>\n      <li>Use the other heads to propose speculative sequences for greedy decoding (e.g., blockwise).</li>\n    </ul>\n  </li>\n</ul>\n<p>This approach modifies the LLM architecture to predict <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-360\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-361\"><span class=\"mi\" id=\"MathJax-Span-362\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-39\">n</script> future tokens at once during training.</p>\n<p><strong>Architecture Overview</strong>:</p>\n<ul>\n      <li>The following figure from the paper shows the implementation structure of multi-token prediction: one trunk, multiple future-predicting heads, and staged loss computation.</li>\n    </ul>\n<p><img src=\"../../../images/papers/MTP.jpg\" alt=\"\"></p>\n<ul>\n      <li>A shared transformer trunk generates a hidden state.</li>\n      <li><span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-40-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-363\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-364\"><span class=\"mi\" id=\"MathJax-Span-365\" style=\"font-family: STIXGeneral-Italic;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.691em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-40\">n</script> lightweight output heads decode tokens <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-41-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>+</mo><mn>1</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-366\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1001.77em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-367\"><span class=\"mi\" id=\"MathJax-Span-368\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-369\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mn\" id=\"MathJax-Span-370\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">1</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 1.003em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>+</mo><mn>1</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-41\">t+1</script> to <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-42-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi><mo>+</mo><mi>n</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-371\" style=\"width: 2.294em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 1.878em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.461em, 1001.88em, 2.398em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-372\"><span class=\"mi\" id=\"MathJax-Span-373\" style=\"font-family: STIXGeneral-Italic;\">t<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span><span class=\"mo\" id=\"MathJax-Span-374\" style=\"font-family: STIXGeneral-Regular; padding-left: 0.263em;\">+</span><span class=\"mi\" id=\"MathJax-Span-375\" style=\"font-family: STIXGeneral-Italic; padding-left: 0.263em;\">n</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.122em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>t</mi><mo>+</mo><mi>n</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-42\">t+n</script>.</li>\n    </ul>\n<p><strong>Model Structure</strong>:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code6\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code6\">  <span class=\"c1\"># Trunk\n</span>  <span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"n\">transformer_trunk</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n\n  <span class=\"c1\"># Heads\n</span>  <span class=\"n\">logits</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">head_i</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"p\">)]</span>\n  <span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">softmax</span><span class=\"p\">(</span><span class=\"n\">logit</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">logit</span> <span class=\"ow\">in</span> <span class=\"n\">logits</span><span class=\"p\">]</span>\n</code></pre>\n<ul>\n      <li>\n        <p>Each head minimizes its own cross-entropy loss:</p>\n\n        <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code7\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code7\">  <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"nb\">sum</span><span class=\"p\">([</span><span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">target</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"p\">)])</span>\n</code></pre></div>        </div>\n      </li>\n    </ul>\n<p>Each head minimizes its own cross-entropy loss:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code7\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code7\">  <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"nb\">sum</span><span class=\"p\">([</span><span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">logits</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span> <span class=\"n\">target</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span> <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">n</span><span class=\"p\">)])</span>\n</code></pre>\n<p><strong>Memory-Efficient Training</strong>:</p>\n<ul>\n      <li>\n        <p><strong>Sequential gradient computation</strong> for each head reduces memory:</p>\n\n        <div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code8\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code8\"><span class=\"k\">for</span> <span class=\"n\">head</span> <span class=\"ow\">in</span> <span class=\"n\">heads</span><span class=\"p\">:</span>\n    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">head</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span><span class=\"p\">.</span><span class=\"n\">backward</span><span class=\"p\">(</span><span class=\"n\">retain_graph</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n</code></pre></div>        </div>\n      </li>\n    </ul>\n<p><strong>Sequential gradient computation</strong> for each head reduces memory:</p>\n<pre class=\"highlight\"><div><button class=\"btn-copy\" data-clipboard-action=\"copy\" data-clipboard-target=\"#code8\"><img src=\"https://aman.ai/images/copy.png\" style=\"margin:0; border:none; padding:2px 0px; width:100%; height:18px; width:18px;\"></button></div><code id=\"code8\"><span class=\"k\">for</span> <span class=\"n\">head</span> <span class=\"ow\">in</span> <span class=\"n\">heads</span><span class=\"p\">:</span>\n    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">head</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">output</span><span class=\"p\">,</span> <span class=\"n\">target</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span><span class=\"p\">.</span><span class=\"n\">backward</span><span class=\"p\">(</span><span class=\"n\">retain_graph</span><span class=\"o\">=</span><span class=\"bp\">True</span><span class=\"p\">)</span>\n</code></pre>\n<p><strong>Inference Options</strong>:</p>\n<ul>\n      <li>Use the next-token head for traditional generation.</li>\n      <li>Use the other heads to propose speculative sequences for greedy decoding (e.g., blockwise).</li>\n    </ul>",
    "contentMarkdown": "*   This approach modifies the LLM architecture to predict nnn future tokens at once during training.\n    \n*   **Architecture Overview**:\n    \n    *   The following figure from the paper shows the implementation structure of multi-token prediction: one trunk, multiple future-predicting heads, and staged loss computation.\n    \n    ![](../../../images/papers/MTP.jpg)\n    \n    *   A shared transformer trunk generates a hidden state.\n    *   nnn lightweight output heads decode tokens t+1t+1t+1 to t+nt+nt+n.\n*   **Model Structure**:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n      `# Trunk   z = transformer_trunk(x)    # Heads   logits = [head_i(z) for i in range(n)]   outputs = [softmax(logit) for logit in logits]`\n    \n    *   Each head minimizes its own cross-entropy loss:\n        \n        ![](https://aman.ai/images/copy.png)\n        \n          `loss = sum([F.cross_entropy(logits[i], target[i]) for i in range(n)])`\n        \n*   **Memory-Efficient Training**:\n    \n    *   **Sequential gradient computation** for each head reduces memory:\n        \n        ![](https://aman.ai/images/copy.png)\n        \n        `for head in heads:     output = head(z)     loss = F.cross_entropy(output, target)     loss.backward(retain_graph=True)`\n        \n    \n    **Inference Options**:\n    \n    *   Use the next-token head for traditional generation.\n    *   Use the other heads to propose speculative sequences for greedy decoding (e.g., blockwise).\n\nThis approach modifies the LLM architecture to predict nnn future tokens at once during training.\n\n**Architecture Overview**:\n\n*   The following figure from the paper shows the implementation structure of multi-token prediction: one trunk, multiple future-predicting heads, and staged loss computation.\n\n![](../../../images/papers/MTP.jpg)\n\n*   A shared transformer trunk generates a hidden state.\n*   nnn lightweight output heads decode tokens t+1t+1t+1 to t+nt+nt+n.\n\n**Model Structure**:\n\n![](https://aman.ai/images/copy.png)\n\n  `# Trunk   z = transformer_trunk(x)    # Heads   logits = [head_i(z) for i in range(n)]   outputs = [softmax(logit) for logit in logits]`\n\n*   Each head minimizes its own cross-entropy loss:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n      `loss = sum([F.cross_entropy(logits[i], target[i]) for i in range(n)])`\n    \n\nEach head minimizes its own cross-entropy loss:\n\n![](https://aman.ai/images/copy.png)\n\n  `loss = sum([F.cross_entropy(logits[i], target[i]) for i in range(n)])`\n\n**Memory-Efficient Training**:\n\n*   **Sequential gradient computation** for each head reduces memory:\n    \n    ![](https://aman.ai/images/copy.png)\n    \n    `for head in heads:     output = head(z)     loss = F.cross_entropy(output, target)     loss.backward(retain_graph=True)`\n    \n\n**Sequential gradient computation** for each head reduces memory:\n\n![](https://aman.ai/images/copy.png)\n\n`for head in heads:     output = head(z)     loss = F.cross_entropy(output, target)     loss.backward(retain_graph=True)`\n\n**Inference Options**:\n\n*   Use the next-token head for traditional generation.\n*   Use the other heads to propose speculative sequences for greedy decoding (e.g., blockwise).",
    "order": 11,
    "orderInChapter": 3,
    "difficulty": 4,
    "estimatedMinutes": 2,
    "tags": [
      "algorithmsarchitecture",
      "transformer",
      "llm"
    ],
    "metadata": {
      "hasCode": true,
      "hasMath": true,
      "hasImages": true,
      "wordCount": 339,
      "contentLength": 22150
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#multi-token-prediction-heads",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-hybrid-approaches-combining-draft-head-12",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Future Directions",
    "title": "Hybrid Approaches: Combining Draft + Head",
    "subtitle": "Future Directions",
    "contentHtml": "<ul>\n  <li>\n    <p>Some systems now combine <strong>draft models</strong> with <strong>multi-token or Medusa heads</strong> to maximize acceptance rates and throughput.</p>\n  </li>\n  <li>\n    <p><strong>Motivation</strong>:</p>\n\n    <ul>\n      <li>Use a draft model for a long speculative prefix.</li>\n      <li>Use Medusa or multi-token heads to verify batches of predictions instead of verifying token-by-token.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Example Pipeline</strong>:</p>\n\n    <ol>\n      <li>Draft model proposes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-43-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-376\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-377\"><span class=\"mi\" id=\"MathJax-Span-378\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-43\">\\gamma</script> tokens.</li>\n      <li>Medusa-style heads are used within the large model to validate candidate branches.</li>\n      <li>Longest valid candidate is accepted.</li>\n    </ol>\n  </li>\n  <li>\n    <p><strong>Advantages</strong>:</p>\n\n    <ul>\n      <li>Combines high-quality approximation from draft with structural verification efficiency.</li>\n      <li>Supports deeper pipelines (e.g., hierarchical draft-check loops).</li>\n      <li>Naturally extensible to distributed and batched decoding.</li>\n    </ul>\n  </li>\n</ul>\n<p>Some systems now combine <strong>draft models</strong> with <strong>multi-token or Medusa heads</strong> to maximize acceptance rates and throughput.</p>\n<p><strong>Motivation</strong>:</p>\n<ul>\n      <li>Use a draft model for a long speculative prefix.</li>\n      <li>Use Medusa or multi-token heads to verify batches of predictions instead of verifying token-by-token.</li>\n    </ul>\n<p><strong>Example Pipeline</strong>:</p>\n<ol>\n      <li>Draft model proposes <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-43-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B3;</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-376\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.58em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-377\"><span class=\"mi\" id=\"MathJax-Span-378\" style=\"font-family: STIXGeneral-Italic;\">γ<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.055em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>γ</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-43\">\\gamma</script> tokens.</li>\n      <li>Medusa-style heads are used within the large model to validate candidate branches.</li>\n      <li>Longest valid candidate is accepted.</li>\n    </ol>\n<p><strong>Advantages</strong>:</p>\n<ul>\n      <li>Combines high-quality approximation from draft with structural verification efficiency.</li>\n      <li>Supports deeper pipelines (e.g., hierarchical draft-check loops).</li>\n      <li>Naturally extensible to distributed and batched decoding.</li>\n    </ul>",
    "contentMarkdown": "*   Some systems now combine **draft models** with **multi-token or Medusa heads** to maximize acceptance rates and throughput.\n    \n*   **Motivation**:\n    \n    *   Use a draft model for a long speculative prefix.\n    *   Use Medusa or multi-token heads to verify batches of predictions instead of verifying token-by-token.\n*   **Example Pipeline**:\n    \n    1.  Draft model proposes γγ\\\\gamma tokens.\n    2.  Medusa-style heads are used within the large model to validate candidate branches.\n    3.  Longest valid candidate is accepted.\n*   **Advantages**:\n    \n    *   Combines high-quality approximation from draft with structural verification efficiency.\n    *   Supports deeper pipelines (e.g., hierarchical draft-check loops).\n    *   Naturally extensible to distributed and batched decoding.\n\nSome systems now combine **draft models** with **multi-token or Medusa heads** to maximize acceptance rates and throughput.\n\n**Motivation**:\n\n*   Use a draft model for a long speculative prefix.\n*   Use Medusa or multi-token heads to verify batches of predictions instead of verifying token-by-token.\n\n**Example Pipeline**:\n\n1.  Draft model proposes γγ\\\\gamma tokens.\n2.  Medusa-style heads are used within the large model to validate candidate branches.\n3.  Longest valid candidate is accepted.\n\n**Advantages**:\n\n*   Combines high-quality approximation from draft with structural verification efficiency.\n*   Supports deeper pipelines (e.g., hierarchical draft-check loops).\n*   Naturally extensible to distributed and batched decoding.",
    "order": 12,
    "orderInChapter": 1,
    "difficulty": 3,
    "estimatedMinutes": 1,
    "tags": [
      "algorithmsarchitecture"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 198,
      "contentLength": 4571
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#hybrid-approaches:-combining-draft-+-head",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-integration-with-quantization-pruning-13",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Future Directions",
    "title": "Integration with Quantization & Pruning",
    "subtitle": "Future Directions",
    "contentHtml": "<ul>\n  <li>\n    <p>Speculative decoding can synergize with model compression techniques:</p>\n\n    <ul>\n      <li><strong>Quantized Models</strong> (e.g., QLoRA, GPTQ):\n        <ul>\n          <li>Medusa heads can be trained/fine-tuned atop a frozen quantized model. Even the trunk used in multi-token prediction can be quantized (as in Medusa-1).</li>\n        </ul>\n      </li>\n      <li><strong>Pruned Heads</strong>:\n        <ul>\n          <li>Lightweight speculative heads use &lt;0.1% of model parameters. This makes them ideal candidates for post-training head-specific pruning or low-rank approximations.</li>\n        </ul>\n      </li>\n      <li><strong>Shared KV Caches</strong>:\n        <ul>\n          <li>As seen in IBM’s PyTorch implementation, speculative tokens and trunk outputs can reuse the same attention cache with minimal overhead by adapting the paged attention kernel.</li>\n        </ul>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>Speculative decoding can synergize with model compression techniques:</p>\n<ul>\n      <li><strong>Quantized Models</strong> (e.g., QLoRA, GPTQ):\n        <ul>\n          <li>Medusa heads can be trained/fine-tuned atop a frozen quantized model. Even the trunk used in multi-token prediction can be quantized (as in Medusa-1).</li>\n        </ul>\n      </li>\n      <li><strong>Pruned Heads</strong>:\n        <ul>\n          <li>Lightweight speculative heads use &lt;0.1% of model parameters. This makes them ideal candidates for post-training head-specific pruning or low-rank approximations.</li>\n        </ul>\n      </li>\n      <li><strong>Shared KV Caches</strong>:\n        <ul>\n          <li>As seen in IBM’s PyTorch implementation, speculative tokens and trunk outputs can reuse the same attention cache with minimal overhead by adapting the paged attention kernel.</li>\n        </ul>\n      </li>\n    </ul>\n<ul>\n          <li>Medusa heads can be trained/fine-tuned atop a frozen quantized model. Even the trunk used in multi-token prediction can be quantized (as in Medusa-1).</li>\n        </ul>\n<ul>\n          <li>Lightweight speculative heads use &lt;0.1% of model parameters. This makes them ideal candidates for post-training head-specific pruning or low-rank approximations.</li>\n        </ul>\n<ul>\n          <li>As seen in IBM’s PyTorch implementation, speculative tokens and trunk outputs can reuse the same attention cache with minimal overhead by adapting the paged attention kernel.</li>\n        </ul>",
    "contentMarkdown": "*   Speculative decoding can synergize with model compression techniques:\n    \n    *   **Quantized Models** (e.g., QLoRA, GPTQ):\n        *   Medusa heads can be trained/fine-tuned atop a frozen quantized model. Even the trunk used in multi-token prediction can be quantized (as in Medusa-1).\n    *   **Pruned Heads**:\n        *   Lightweight speculative heads use <0.1% of model parameters. This makes them ideal candidates for post-training head-specific pruning or low-rank approximations.\n    *   **Shared KV Caches**:\n        *   As seen in IBM’s PyTorch implementation, speculative tokens and trunk outputs can reuse the same attention cache with minimal overhead by adapting the paged attention kernel.\n\nSpeculative decoding can synergize with model compression techniques:\n\n*   **Quantized Models** (e.g., QLoRA, GPTQ):\n    *   Medusa heads can be trained/fine-tuned atop a frozen quantized model. Even the trunk used in multi-token prediction can be quantized (as in Medusa-1).\n*   **Pruned Heads**:\n    *   Lightweight speculative heads use <0.1% of model parameters. This makes them ideal candidates for post-training head-specific pruning or low-rank approximations.\n*   **Shared KV Caches**:\n    *   As seen in IBM’s PyTorch implementation, speculative tokens and trunk outputs can reuse the same attention cache with minimal overhead by adapting the paged attention kernel.\n\n*   Medusa heads can be trained/fine-tuned atop a frozen quantized model. Even the trunk used in multi-token prediction can be quantized (as in Medusa-1).\n\n*   Lightweight speculative heads use <0.1% of model parameters. This makes them ideal candidates for post-training head-specific pruning or low-rank approximations.\n\n*   As seen in IBM’s PyTorch implementation, speculative tokens and trunk outputs can reuse the same attention cache with minimal overhead by adapting the paged attention kernel.",
    "order": 13,
    "orderInChapter": 2,
    "difficulty": 2,
    "estimatedMinutes": 2,
    "tags": [
      "algorithmsarchitecture",
      "attention",
      "gpt"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 259,
      "contentLength": 2455
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#integration-with-quantization-&-pruning",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-speculative-decoding-for-byte-level-model-14",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Future Directions",
    "title": "Speculative Decoding for Byte-Level Model",
    "subtitle": "Future Directions",
    "contentHtml": "<ul>\n  <li>\n    <p>Recent experiments show that speculative decoding is <strong>especially effective for byte-level tokenization</strong> models.</p>\n  </li>\n  <li>\n    <p><strong>Why?</strong></p>\n\n    <ul>\n      <li>Byte-level tokenizers (e.g., Tiktoken with vocab size 256) produce longer sequences for the same semantic content.</li>\n      <li>This increases the number of decoding steps per input and exacerbates autoregressive latency.</li>\n    </ul>\n  </li>\n  <li>\n    <p><strong>Findings from <a href=\"https://arxiv.org/abs/2404.19737\">Better &amp; Faster Large Language Models via Multi-token Prediction</a> by Gloeckle et al. (2024)</strong>:</p>\n\n    <ul>\n      <li>8-byte prediction outperforms single-token next prediction by 67% on MBPP pass@1.</li>\n      <li>Inference speedup of 6.4<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-44-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-379\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-380\"><span class=\"mo\" id=\"MathJax-Span-381\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-44\">\\times</script>, fully amortizing byte-level overhead.</li>\n    </ul>\n  </li>\n</ul>\n<p>Recent experiments show that speculative decoding is <strong>especially effective for byte-level tokenization</strong> models.</p>\n<p><strong>Why?</strong></p>\n<ul>\n      <li>Byte-level tokenizers (e.g., Tiktoken with vocab size 256) produce longer sequences for the same semantic content.</li>\n      <li>This increases the number of decoding steps per input and exacerbates autoregressive latency.</li>\n    </ul>\n<p><strong>Findings from <a href=\"https://arxiv.org/abs/2404.19737\">Better &amp; Faster Large Language Models via Multi-token Prediction</a> by Gloeckle et al. (2024)</strong>:</p>\n<ul>\n      <li>8-byte prediction outperforms single-token next prediction by 67% on MBPP pass@1.</li>\n      <li>Inference speedup of 6.4<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-44-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo>&amp;#x00D7;</mo></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-379\" style=\"width: 0.732em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.576em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.513em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-380\"><span class=\"mo\" id=\"MathJax-Span-381\" style=\"font-family: STIXGeneral-Regular;\">×</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>×</mo></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-44\">\\times</script>, fully amortizing byte-level overhead.</li>\n    </ul>",
    "contentMarkdown": "*   Recent experiments show that speculative decoding is **especially effective for byte-level tokenization** models.\n    \n*   **Why?**\n    \n    *   Byte-level tokenizers (e.g., Tiktoken with vocab size 256) produce longer sequences for the same semantic content.\n    *   This increases the number of decoding steps per input and exacerbates autoregressive latency.\n*   **Findings from [Better & Faster Large Language Models via Multi-token Prediction](https://arxiv.org/abs/2404.19737) by Gloeckle et al. (2024)**:\n    \n    *   8-byte prediction outperforms single-token next prediction by 67% on MBPP pass@1.\n    *   Inference speedup of 6.4××\\\\times, fully amortizing byte-level overhead.\n\nRecent experiments show that speculative decoding is **especially effective for byte-level tokenization** models.\n\n**Why?**\n\n*   Byte-level tokenizers (e.g., Tiktoken with vocab size 256) produce longer sequences for the same semantic content.\n*   This increases the number of decoding steps per input and exacerbates autoregressive latency.\n\n**Findings from [Better & Faster Large Language Models via Multi-token Prediction](https://arxiv.org/abs/2404.19737) by Gloeckle et al. (2024)**:\n\n*   8-byte prediction outperforms single-token next prediction by 67% on MBPP pass@1.\n*   Inference speedup of 6.4××\\\\times, fully amortizing byte-level overhead.",
    "order": 14,
    "orderInChapter": 3,
    "difficulty": 3,
    "estimatedMinutes": 1,
    "tags": [
      "algorithmsarchitecture"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 167,
      "contentLength": 4047
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#speculative-decoding-for-byte-level-model",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-beyond-decoding-speculative-sampling-for-diverse-o-15",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Future Directions",
    "title": "Beyond Decoding: Speculative Sampling for Diverse Output",
    "subtitle": "Future Directions",
    "contentHtml": "<ul>\n  <li>\n    <p>While initial work focused on greedy or top-<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-45-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-382\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-383\"><span class=\"mi\" id=\"MathJax-Span-384\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-45\">k</script> decoding, speculative techniques are being extended to support:</p>\n\n    <ul>\n      <li><strong>Diverse sampling</strong> (via top-<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-46-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>p</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-385\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-386\"><span class=\"mi\" id=\"MathJax-Span-387\" style=\"font-family: STIXGeneral-Italic;\">p</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>p</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-46\">p</script> or temperature-controlled typical decoding)</li>\n      <li><strong>Beam search variants</strong> (speculative beam candidates + top-scoring path verification)</li>\n      <li><strong>Stochastic acceptance</strong> (accept “close enough” tokens under Wasserstein distance or KL threshold)</li>\n    </ul>\n  </li>\n  <li>\n    <p>This makes speculative decoding viable for tasks requiring diversity, such as story generation, summarization, and open-ended Q\\&amp;A.</p>\n  </li>\n</ul>\n<p>While initial work focused on greedy or top-<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-45-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>k</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-382\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.357em, 1000.52em, 2.346em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-383\"><span class=\"mi\" id=\"MathJax-Span-384\" style=\"font-family: STIXGeneral-Italic;\">k<span style=\"display: inline-block; overflow: hidden; height: 1px; width: 0.003em;\"></span></span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.941em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>k</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-45\">k</script> decoding, speculative techniques are being extended to support:</p>\n<ul>\n      <li><strong>Diverse sampling</strong> (via top-<span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-46-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>p</mi></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-385\" style=\"width: 0.628em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 0.523em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.617em, 1000.47em, 2.555em, -999.997em); top: -2.185em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-386\"><span class=\"mi\" id=\"MathJax-Span-387\" style=\"font-family: STIXGeneral-Italic;\">p</span></span><span style=\"display: inline-block; width: 0px; height: 2.19em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 0.878em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>p</mi></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-46\">p</script> or temperature-controlled typical decoding)</li>\n      <li><strong>Beam search variants</strong> (speculative beam candidates + top-scoring path verification)</li>\n      <li><strong>Stochastic acceptance</strong> (accept “close enough” tokens under Wasserstein distance or KL threshold)</li>\n    </ul>\n<p>This makes speculative decoding viable for tasks requiring diversity, such as story generation, summarization, and open-ended Q\\&amp;A.</p>",
    "contentMarkdown": "*   While initial work focused on greedy or top-kkk decoding, speculative techniques are being extended to support:\n    \n    *   **Diverse sampling** (via top-ppp or temperature-controlled typical decoding)\n    *   **Beam search variants** (speculative beam candidates + top-scoring path verification)\n    *   **Stochastic acceptance** (accept “close enough” tokens under Wasserstein distance or KL threshold)\n*   This makes speculative decoding viable for tasks requiring diversity, such as story generation, summarization, and open-ended Q\\\\&A.\n    \n\nWhile initial work focused on greedy or top-kkk decoding, speculative techniques are being extended to support:\n\n*   **Diverse sampling** (via top-ppp or temperature-controlled typical decoding)\n*   **Beam search variants** (speculative beam candidates + top-scoring path verification)\n*   **Stochastic acceptance** (accept “close enough” tokens under Wasserstein distance or KL threshold)\n\nThis makes speculative decoding viable for tasks requiring diversity, such as story generation, summarization, and open-ended Q\\\\&A.",
    "order": 15,
    "orderInChapter": 4,
    "difficulty": 3,
    "estimatedMinutes": 1,
    "tags": [
      "algorithmsarchitecture"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": true,
      "hasImages": false,
      "wordCount": 134,
      "contentLength": 6191
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#beyond-decoding:-speculative-sampling-for-diverse-output",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  },
  {
    "id": "ai-speculative-decoding-future-research-directions-16",
    "domain": "ai_primers",
    "category": "Algorithms/Architecture",
    "article": "Speculative Decoding",
    "articleSlug": "speculative-decoding",
    "chapter": "Future Directions",
    "title": "Future Research Directions",
    "subtitle": "Future Directions",
    "contentHtml": "<ul>\n  <li>\n    <p>Several open questions and promising directions remain:</p>\n\n    <ul>\n      <li>\n        <p><strong>Speculative Training</strong>:\nCan models be explicitly trained to improve speculative token acceptance rates (e.g., contrastive token alignment)? This would unify training and decoding under a shared goal.</p>\n      </li>\n      <li>\n        <p><strong>Reinforcement-Tuned Speculators</strong>:\nHow can RLHF-style alignment guide draft model predictions or head outputs for better human preference alignment?</p>\n      </li>\n      <li>\n        <p><strong>Adaptive Drafting</strong>:\nCan models dynamically adjust the speculative prefix length based on uncertainty, entropy, or input complexity?</p>\n      </li>\n      <li>\n        <p><strong>Token-Free Decoding</strong>:\nRecent proposals like “latent decoding” (generating hidden states directly) could be paired with speculative strategies to push inference latency even lower.</p>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>Several open questions and promising directions remain:</p>\n<ul>\n      <li>\n        <p><strong>Speculative Training</strong>:\nCan models be explicitly trained to improve speculative token acceptance rates (e.g., contrastive token alignment)? This would unify training and decoding under a shared goal.</p>\n      </li>\n      <li>\n        <p><strong>Reinforcement-Tuned Speculators</strong>:\nHow can RLHF-style alignment guide draft model predictions or head outputs for better human preference alignment?</p>\n      </li>\n      <li>\n        <p><strong>Adaptive Drafting</strong>:\nCan models dynamically adjust the speculative prefix length based on uncertainty, entropy, or input complexity?</p>\n      </li>\n      <li>\n        <p><strong>Token-Free Decoding</strong>:\nRecent proposals like “latent decoding” (generating hidden states directly) could be paired with speculative strategies to push inference latency even lower.</p>\n      </li>\n    </ul>\n<p><strong>Speculative Training</strong>:\nCan models be explicitly trained to improve speculative token acceptance rates (e.g., contrastive token alignment)? This would unify training and decoding under a shared goal.</p>\n<p><strong>Reinforcement-Tuned Speculators</strong>:\nHow can RLHF-style alignment guide draft model predictions or head outputs for better human preference alignment?</p>\n<p><strong>Adaptive Drafting</strong>:\nCan models dynamically adjust the speculative prefix length based on uncertainty, entropy, or input complexity?</p>\n<p><strong>Token-Free Decoding</strong>:\nRecent proposals like “latent decoding” (generating hidden states directly) could be paired with speculative strategies to push inference latency even lower.</p>",
    "contentMarkdown": "*   Several open questions and promising directions remain:\n    \n    *   **Speculative Training**: Can models be explicitly trained to improve speculative token acceptance rates (e.g., contrastive token alignment)? This would unify training and decoding under a shared goal.\n        \n    *   **Reinforcement-Tuned Speculators**: How can RLHF-style alignment guide draft model predictions or head outputs for better human preference alignment?\n        \n    *   **Adaptive Drafting**: Can models dynamically adjust the speculative prefix length based on uncertainty, entropy, or input complexity?\n        \n    *   **Token-Free Decoding**: Recent proposals like “latent decoding” (generating hidden states directly) could be paired with speculative strategies to push inference latency even lower.\n        \n\nSeveral open questions and promising directions remain:\n\n*   **Speculative Training**: Can models be explicitly trained to improve speculative token acceptance rates (e.g., contrastive token alignment)? This would unify training and decoding under a shared goal.\n    \n*   **Reinforcement-Tuned Speculators**: How can RLHF-style alignment guide draft model predictions or head outputs for better human preference alignment?\n    \n*   **Adaptive Drafting**: Can models dynamically adjust the speculative prefix length based on uncertainty, entropy, or input complexity?\n    \n*   **Token-Free Decoding**: Recent proposals like “latent decoding” (generating hidden states directly) could be paired with speculative strategies to push inference latency even lower.\n    \n\n**Speculative Training**: Can models be explicitly trained to improve speculative token acceptance rates (e.g., contrastive token alignment)? This would unify training and decoding under a shared goal.\n\n**Reinforcement-Tuned Speculators**: How can RLHF-style alignment guide draft model predictions or head outputs for better human preference alignment?\n\n**Adaptive Drafting**: Can models dynamically adjust the speculative prefix length based on uncertainty, entropy, or input complexity?\n\n**Token-Free Decoding**: Recent proposals like “latent decoding” (generating hidden states directly) could be paired with speculative strategies to push inference latency even lower.",
    "order": 16,
    "orderInChapter": 5,
    "difficulty": 3,
    "estimatedMinutes": 2,
    "tags": [
      "algorithmsarchitecture"
    ],
    "metadata": {
      "hasCode": false,
      "hasMath": false,
      "hasImages": false,
      "wordCount": 278,
      "contentLength": 2691
    },
    "nextCards": [],
    "relatedCards": [],
    "prerequisites": [],
    "sourceUrl": "https://aman.ai/primers/ai/speculative-decoding/#future-research-directions",
    "scrapedAt": "2025-12-28T11:47:57.257Z"
  }
]